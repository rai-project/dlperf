{
  "context": {
    "date": "2019-09-15 21:42:50",
    "executable": "./scope",
    "num_cpus": 16,
    "mhz_per_cpu": 3601,
    "cpu_scaling_enabled": true,
    "caches": [
      {
        "type": "Data",
        "level": 1,
        "size": 32000000,
        "num_sharing": 2
      },
      {
        "type": "Instruction",
        "level": 1,
        "size": 32000000,
        "num_sharing": 2
      },
      {
        "type": "Unified",
        "level": 2,
        "size": 1024000000,
        "num_sharing": 2
      },
      {
        "type": "Unified",
        "level": 3,
        "size": 11264000000,
        "num_sharing": 16
      }
    ],
    "library_build_type": "release"
  },
  "benchmarks": [
    {
      "name": "LAYER_CUBLAS_GEMM_FWD_FLOAT32__BatchSize_128__17676855649145509353/input[0]:128/input[1]:1000/input[2]:512/input[3]:0/input[4]:1/input[5]:1/input[6]:1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 29185,
      "real_time": 2.3873017716818806e+04,
      "cpu_time": 2.9763866575295633e+04,
      "time_unit": "ns",
      "items_per_second": 2.7451912773402402e+12,
      "K": 5.1200000000000000e+02,
      "M": 1.2800000000000000e+02,
      "N": 1.0000000000000000e+03,
      "alpha": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cublas_gemm_fwd.cpp": 7.2770906096155412e+18,
      "benchmark_func:void iLAYER_CUBLAS_GEMM_FWD_Impl(benchmark::State&) [with T = float]": 7.4787548781531884e+18,
      "beta": 1.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUBLAS_GEMM_FWD_Impl": 1.7610984762236383e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 1.0000000000000000e+03,
      "input[2]": 5.1200000000000000e+02,
      "input[3]": 0.0000000000000000e+00,
      "input[4]": 1.0000000000000000e+00,
      "input[5]": 1.0000000000000000e+00,
      "input[6]": 1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "lda": 1.2800000000000000e+02,
      "ldb": 1.0000000000000000e+03,
      "num_iterations": 2.9185000000000000e+04,
      "predicted_flops": 5.4903825546804805e+12,
      "predicted_flops_count": 1.3107200000000000e+08,
      "transA": 0.0000000000000000e+00,
      "transB": 1.0000000000000000e+00
    },
    {
      "name": "LAYER_CUBLAS_GEMM_FWD_FLOAT32__BatchSize_128__16937435199922785188/input[0]:128/input[1]:1000/input[2]:2048/input[3]:0/input[4]:1/input[5]:1/input[6]:1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 9350,
      "real_time": 7.5117057493768312e+04,
      "cpu_time": 8.1546948770054179e+04,
      "time_unit": "ns",
      "items_per_second": 3.4898065598715361e+12,
      "K": 2.0480000000000000e+03,
      "M": 1.2800000000000000e+02,
      "N": 1.0000000000000000e+03,
      "alpha": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cublas_gemm_fwd.cpp": 7.2770906096155412e+18,
      "benchmark_func:void iLAYER_CUBLAS_GEMM_FWD_Impl(benchmark::State&) [with T = float]": 7.4787548781531884e+18,
      "beta": 1.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUBLAS_GEMM_FWD_Impl": 1.7610984762236383e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 1.0000000000000000e+03,
      "input[2]": 2.0480000000000000e+03,
      "input[3]": 0.0000000000000000e+00,
      "input[4]": 1.0000000000000000e+00,
      "input[5]": 1.0000000000000000e+00,
      "input[6]": 1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "lda": 1.2800000000000000e+02,
      "ldb": 1.0000000000000000e+03,
      "num_iterations": 9.3500000000000000e+03,
      "predicted_flops": 6.9796131197430723e+12,
      "predicted_flops_count": 5.2428800000000000e+08,
      "transA": 0.0000000000000000e+00,
      "transB": 1.0000000000000000e+00
    },
    {
      "name": "LAYER_CUBLAS_GEMM_FWD_FLOAT32__BatchSize_128__4694614461405789430/input[0]:128/input[1]:512/input[2]:512/input[3]:0/input[4]:1/input[5]:1/input[6]:1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 31221,
      "real_time": 2.2424943249259046e+04,
      "cpu_time": 2.8354745043400384e+04,
      "time_unit": "ns",
      "items_per_second": 1.4962995280315232e+12,
      "K": 5.1200000000000000e+02,
      "M": 1.2800000000000000e+02,
      "N": 5.1200000000000000e+02,
      "alpha": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cublas_gemm_fwd.cpp": 7.2770906096155412e+18,
      "benchmark_func:void iLAYER_CUBLAS_GEMM_FWD_Impl(benchmark::State&) [with T = float]": 7.4787548781531884e+18,
      "beta": 1.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUBLAS_GEMM_FWD_Impl": 1.7610984762236383e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 5.1200000000000000e+02,
      "input[3]": 0.0000000000000000e+00,
      "input[4]": 1.0000000000000000e+00,
      "input[5]": 1.0000000000000000e+00,
      "input[6]": 1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "lda": 1.2800000000000000e+02,
      "ldb": 5.1200000000000000e+02,
      "num_iterations": 3.1221000000000000e+04,
      "predicted_flops": 2.9925990560630464e+12,
      "predicted_flops_count": 6.7108864000000000e+07,
      "transA": 0.0000000000000000e+00,
      "transB": 1.0000000000000000e+00
    },
    {
      "name": "LAYER_CUBLAS_GEMM_FWD_FLOAT32__BatchSize_128__10764868209387565776/input[0]:128/input[1]:4096/input[2]:4096/input[3]:0/input[4]:1/input[5]:1/input[6]:1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 1749,
      "real_time": 4.0015725121996325e+05,
      "cpu_time": 4.0862092395654647e+05,
      "time_unit": "ns",
      "items_per_second": 5.3665993592592559e+12,
      "K": 4.0960000000000000e+03,
      "M": 1.2800000000000000e+02,
      "N": 4.0960000000000000e+03,
      "alpha": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cublas_gemm_fwd.cpp": 7.2770906096155412e+18,
      "benchmark_func:void iLAYER_CUBLAS_GEMM_FWD_Impl(benchmark::State&) [with T = float]": 7.4787548781531884e+18,
      "beta": 1.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUBLAS_GEMM_FWD_Impl": 1.7610984762236383e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 4.0960000000000000e+03,
      "input[2]": 4.0960000000000000e+03,
      "input[3]": 0.0000000000000000e+00,
      "input[4]": 1.0000000000000000e+00,
      "input[5]": 1.0000000000000000e+00,
      "input[6]": 1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "lda": 1.2800000000000000e+02,
      "ldb": 4.0960000000000000e+03,
      "num_iterations": 1.7490000000000000e+03,
      "predicted_flops": 1.0733198718518512e+13,
      "predicted_flops_count": 4.2949672960000000e+09,
      "transA": 0.0000000000000000e+00,
      "transB": 1.0000000000000000e+00
    },
    {
      "name": "LAYER_CUBLAS_GEMM_FWD_FLOAT32__BatchSize_128__12192339566104258143/input[0]:128/input[1]:1000/input[2]:4096/input[3]:0/input[4]:1/input[5]:1/input[6]:1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 3994,
      "real_time": 1.7627337794608923e+05,
      "cpu_time": 1.8286799048572383e+05,
      "time_unit": "ns",
      "items_per_second": 2.9742891757616753e+12,
      "K": 4.0960000000000000e+03,
      "M": 1.2800000000000000e+02,
      "N": 1.0000000000000000e+03,
      "alpha": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cublas_gemm_fwd.cpp": 7.2770906096155412e+18,
      "benchmark_func:void iLAYER_CUBLAS_GEMM_FWD_Impl(benchmark::State&) [with T = float]": 7.4787548781531884e+18,
      "beta": 1.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUBLAS_GEMM_FWD_Impl": 1.7610984762236383e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 1.0000000000000000e+03,
      "input[2]": 4.0960000000000000e+03,
      "input[3]": 0.0000000000000000e+00,
      "input[4]": 1.0000000000000000e+00,
      "input[5]": 1.0000000000000000e+00,
      "input[6]": 1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "lda": 1.2800000000000000e+02,
      "ldb": 1.0000000000000000e+03,
      "num_iterations": 3.9940000000000000e+03,
      "predicted_flops": 5.9485783515233506e+12,
      "predicted_flops_count": 1.0485760000000000e+09,
      "transA": 0.0000000000000000e+00,
      "transB": 1.0000000000000000e+00
    },
    {
      "name": "LAYER_CUBLAS_GEMM_FWD_FLOAT32__BatchSize_128__10967186961755427398/input[0]:128/input[1]:4096/input[2]:512/input[3]:0/input[4]:1/input[5]:1/input[6]:1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 9615,
      "real_time": 7.2938337002154891e+04,
      "cpu_time": 7.9203035049399899e+04,
      "time_unit": "ns",
      "items_per_second": 3.6803067773819595e+12,
      "K": 5.1200000000000000e+02,
      "M": 1.2800000000000000e+02,
      "N": 4.0960000000000000e+03,
      "alpha": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cublas_gemm_fwd.cpp": 7.2770906096155412e+18,
      "benchmark_func:void iLAYER_CUBLAS_GEMM_FWD_Impl(benchmark::State&) [with T = float]": 7.4787548781531884e+18,
      "beta": 1.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUBLAS_GEMM_FWD_Impl": 1.7610984762236383e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 4.0960000000000000e+03,
      "input[2]": 5.1200000000000000e+02,
      "input[3]": 0.0000000000000000e+00,
      "input[4]": 1.0000000000000000e+00,
      "input[5]": 1.0000000000000000e+00,
      "input[6]": 1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "lda": 1.2800000000000000e+02,
      "ldb": 4.0960000000000000e+03,
      "num_iterations": 9.6150000000000000e+03,
      "predicted_flops": 7.3606135547639189e+12,
      "predicted_flops_count": 5.3687091200000000e+08,
      "transA": 0.0000000000000000e+00,
      "transB": 1.0000000000000000e+00
    },
    {
      "name": "LAYER_CUBLAS_GEMV_FWD_FLOAT32__BatchSize_128__1885253562452235648/input[0]:4096/input[1]:18432/input[2]:1/input[3]:1/input[4]:1/input[5]:-1/input[6]:0/input[7]:0/batch_size:128/manual_time",
      "iterations": 1443,
      "real_time": 4.8480326017269341e+05,
      "cpu_time": 4.9432557865556295e+05,
      "time_unit": "ns",
      "items_per_second": 1.5572806167414551e+11,
      "K": 1.8432000000000000e+04,
      "M": 4.0960000000000000e+03,
      "alpha": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cublas_gemv_fwd.cpp": 1.1852848766119408e+19,
      "benchmark_func:void iLAYER_CUBLAS_GEMV_FWD_Impl(benchmark::State&) [with T = float]": 4.8895028309123133e+18,
      "beta": 1.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUBLAS_GEMV_FWD_Impl": 8.8227505551773747e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 4.0960000000000000e+03,
      "input[1]": 1.8432000000000000e+04,
      "input[2]": 1.0000000000000000e+00,
      "input[3]": 1.0000000000000000e+00,
      "input[4]": 1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": 0.0000000000000000e+00,
      "input[7]": 0.0000000000000000e+00,
      "lda": 4.0960000000000000e+03,
      "num_iterations": 1.4430000000000000e+03,
      "predicted_flops": 1.5572806167414551e+11,
      "predicted_flops_count": 7.5497472000000000e+07,
      "transA": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUBLAS_GEMV_FWD_FLOAT32__BatchSize_128__5615474277073359473/input[0]:1024/input[1]:4096/input[2]:1/input[3]:1/input[4]:1/input[5]:-1/input[6]:0/input[7]:0/batch_size:128/manual_time",
      "iterations": 13318,
      "real_time": 5.2580921356816943e+04,
      "cpu_time": 5.8827839540470457e+04,
      "time_unit": "ns",
      "items_per_second": 7.9768552771018005e+10,
      "K": 4.0960000000000000e+03,
      "M": 1.0240000000000000e+03,
      "alpha": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cublas_gemv_fwd.cpp": 1.1852848766119408e+19,
      "benchmark_func:void iLAYER_CUBLAS_GEMV_FWD_Impl(benchmark::State&) [with T = float]": 4.8895028309123133e+18,
      "beta": 1.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUBLAS_GEMV_FWD_Impl": 8.8227505551773747e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 4.0960000000000000e+03,
      "input[2]": 1.0000000000000000e+00,
      "input[3]": 1.0000000000000000e+00,
      "input[4]": 1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": 0.0000000000000000e+00,
      "input[7]": 0.0000000000000000e+00,
      "lda": 1.0240000000000000e+03,
      "num_iterations": 1.3318000000000000e+04,
      "predicted_flops": 7.9768552771018005e+10,
      "predicted_flops_count": 4.1943040000000000e+06,
      "transA": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUBLAS_GEMV_FWD_FLOAT32__BatchSize_128__17151817648129995468/input[0]:1000/input[1]:1024/input[2]:1/input[3]:1/input[4]:1/input[5]:-1/input[6]:0/input[7]:0/batch_size:128/manual_time",
      "iterations": 64383,
      "real_time": 1.0866329273505951e+04,
      "cpu_time": 1.6730596741375539e+04,
      "time_unit": "ns",
      "items_per_second": 9.4236054717824036e+10,
      "K": 1.0240000000000000e+03,
      "M": 1.0000000000000000e+03,
      "alpha": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cublas_gemv_fwd.cpp": 1.1852848766119408e+19,
      "benchmark_func:void iLAYER_CUBLAS_GEMV_FWD_Impl(benchmark::State&) [with T = float]": 4.8895028309123133e+18,
      "beta": 1.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUBLAS_GEMV_FWD_Impl": 8.8227505551773747e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+03,
      "input[1]": 1.0240000000000000e+03,
      "input[2]": 1.0000000000000000e+00,
      "input[3]": 1.0000000000000000e+00,
      "input[4]": 1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": 0.0000000000000000e+00,
      "input[7]": 0.0000000000000000e+00,
      "lda": 1.0000000000000000e+03,
      "num_iterations": 6.4383000000000000e+04,
      "predicted_flops": 9.4236054717824036e+10,
      "predicted_flops_count": 1.0240000000000000e+06,
      "transA": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUBLAS_GEMV_FWD_FLOAT32__BatchSize_128__1660754998456486955/input[0]:10/input[1]:256/input[2]:0/input[3]:1/input[4]:0/input[5]:-1/input[6]:0/input[7]:0/batch_size:128/manual_time",
      "iterations": 123365,
      "real_time": 5.6585991949228446e+03,
      "cpu_time": 1.1606439881658085e+04,
      "time_unit": "ns",
      "items_per_second": 4.5240878737213790e+08,
      "K": 2.5600000000000000e+02,
      "M": 1.0000000000000000e+01,
      "alpha": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cublas_gemv_fwd.cpp": 1.1852848766119408e+19,
      "benchmark_func:void iLAYER_CUBLAS_GEMV_FWD_Impl(benchmark::State&) [with T = float]": 4.8895028309123133e+18,
      "beta": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUBLAS_GEMV_FWD_Impl": 8.8227505551773747e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+01,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 0.0000000000000000e+00,
      "input[3]": 1.0000000000000000e+00,
      "input[4]": 0.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": 0.0000000000000000e+00,
      "input[7]": 0.0000000000000000e+00,
      "lda": 1.0000000000000000e+01,
      "num_iterations": 1.2336500000000000e+05,
      "predicted_flops": 4.5240878737213790e+08,
      "predicted_flops_count": 2.5600000000000000e+03,
      "transA": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUBLAS_GEMV_FWD_FLOAT32__BatchSize_128__7316101744961235287/input[0]:4096/input[1]:9216/input[2]:1/input[3]:1/input[4]:1/input[5]:-1/input[6]:0/input[7]:0/batch_size:128/manual_time",
      "iterations": 2826,
      "real_time": 2.4767668221342942e+05,
      "cpu_time": 2.5471149575369019e+05,
      "time_unit": "ns",
      "items_per_second": 1.5241134394505066e+11,
      "K": 9.2160000000000000e+03,
      "M": 4.0960000000000000e+03,
      "alpha": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cublas_gemv_fwd.cpp": 1.1852848766119408e+19,
      "benchmark_func:void iLAYER_CUBLAS_GEMV_FWD_Impl(benchmark::State&) [with T = float]": 4.8895028309123133e+18,
      "beta": 1.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUBLAS_GEMV_FWD_Impl": 8.8227505551773747e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 4.0960000000000000e+03,
      "input[1]": 9.2160000000000000e+03,
      "input[2]": 1.0000000000000000e+00,
      "input[3]": 1.0000000000000000e+00,
      "input[4]": 1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": 0.0000000000000000e+00,
      "input[7]": 0.0000000000000000e+00,
      "lda": 4.0960000000000000e+03,
      "num_iterations": 2.8260000000000000e+03,
      "predicted_flops": 1.5241134394505066e+11,
      "predicted_flops_count": 3.7748736000000000e+07,
      "transA": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUBLAS_GEMV_FWD_FLOAT32__BatchSize_128__3960740257363593187/input[0]:4096/input[1]:4096/input[2]:1/input[3]:1/input[4]:1/input[5]:-1/input[6]:0/input[7]:0/batch_size:128/manual_time",
      "iterations": 6327,
      "real_time": 1.1059851521811289e+05,
      "cpu_time": 1.1697307586534839e+05,
      "time_unit": "ns",
      "items_per_second": 1.5169476703112527e+11,
      "K": 4.0960000000000000e+03,
      "M": 4.0960000000000000e+03,
      "alpha": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cublas_gemv_fwd.cpp": 1.1852848766119408e+19,
      "benchmark_func:void iLAYER_CUBLAS_GEMV_FWD_Impl(benchmark::State&) [with T = float]": 4.8895028309123133e+18,
      "beta": 1.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUBLAS_GEMV_FWD_Impl": 8.8227505551773747e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 4.0960000000000000e+03,
      "input[1]": 4.0960000000000000e+03,
      "input[2]": 1.0000000000000000e+00,
      "input[3]": 1.0000000000000000e+00,
      "input[4]": 1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": 0.0000000000000000e+00,
      "input[7]": 0.0000000000000000e+00,
      "lda": 4.0960000000000000e+03,
      "num_iterations": 6.3270000000000000e+03,
      "predicted_flops": 1.5169476703112527e+11,
      "predicted_flops_count": 1.6777216000000000e+07,
      "transA": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUBLAS_GEMV_FWD_FLOAT32__BatchSize_128__1973303644173646720/input[0]:1000/input[1]:4096/input[2]:1/input[3]:1/input[4]:1/input[5]:-1/input[6]:0/input[7]:0/batch_size:128/manual_time",
      "iterations": 17689,
      "real_time": 3.9572107061827701e+04,
      "cpu_time": 4.5799045225866677e+04,
      "time_unit": "ns",
      "items_per_second": 1.0350725053888045e+11,
      "K": 4.0960000000000000e+03,
      "M": 1.0000000000000000e+03,
      "alpha": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cublas_gemv_fwd.cpp": 1.1852848766119408e+19,
      "benchmark_func:void iLAYER_CUBLAS_GEMV_FWD_Impl(benchmark::State&) [with T = float]": 4.8895028309123133e+18,
      "beta": 1.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUBLAS_GEMV_FWD_Impl": 8.8227505551773747e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+03,
      "input[1]": 4.0960000000000000e+03,
      "input[2]": 1.0000000000000000e+00,
      "input[3]": 1.0000000000000000e+00,
      "input[4]": 1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": 0.0000000000000000e+00,
      "input[7]": 0.0000000000000000e+00,
      "lda": 1.0000000000000000e+03,
      "num_iterations": 1.7689000000000000e+04,
      "predicted_flops": 1.0350725053888045e+11,
      "predicted_flops_count": 4.0960000000000000e+06,
      "transA": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUBLAS_GEMV_FWD_FLOAT32__BatchSize_128__8611919153945511522/input[0]:1024/input[1]:1024/input[2]:0/input[3]:1/input[4]:0/input[5]:-1/input[6]:0/input[7]:0/batch_size:128/manual_time",
      "iterations": 53799,
      "real_time": 1.3004136568127462e+04,
      "cpu_time": 1.8863126061820243e+04,
      "time_unit": "ns",
      "items_per_second": 8.0634034755526291e+10,
      "K": 1.0240000000000000e+03,
      "M": 1.0240000000000000e+03,
      "alpha": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cublas_gemv_fwd.cpp": 1.1852848766119408e+19,
      "benchmark_func:void iLAYER_CUBLAS_GEMV_FWD_Impl(benchmark::State&) [with T = float]": 4.8895028309123133e+18,
      "beta": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUBLAS_GEMV_FWD_Impl": 8.8227505551773747e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 1.0240000000000000e+03,
      "input[2]": 0.0000000000000000e+00,
      "input[3]": 1.0000000000000000e+00,
      "input[4]": 0.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": 0.0000000000000000e+00,
      "input[7]": 0.0000000000000000e+00,
      "lda": 1.0240000000000000e+03,
      "num_iterations": 5.3799000000000000e+04,
      "predicted_flops": 8.0634034755526291e+10,
      "predicted_flops_count": 1.0485760000000000e+06,
      "transA": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUBLAS_GEMV_FWD_FLOAT32__BatchSize_128__17035014280979531381/input[0]:8/input[1]:1024/input[2]:0/input[3]:1/input[4]:0/input[5]:-1/input[6]:0/input[7]:0/batch_size:128/manual_time",
      "iterations": 97652,
      "real_time": 7.1699534935202091e+03,
      "cpu_time": 1.3029751914961977e+04,
      "time_unit": "ns",
      "items_per_second": 1.1425457651020272e+09,
      "K": 1.0240000000000000e+03,
      "M": 8.0000000000000000e+00,
      "alpha": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cublas_gemv_fwd.cpp": 1.1852848766119408e+19,
      "benchmark_func:void iLAYER_CUBLAS_GEMV_FWD_Impl(benchmark::State&) [with T = float]": 4.8895028309123133e+18,
      "beta": 0.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUBLAS_GEMV_FWD_Impl": 8.8227505551773747e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 1.0240000000000000e+03,
      "input[2]": 0.0000000000000000e+00,
      "input[3]": 1.0000000000000000e+00,
      "input[4]": 0.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": 0.0000000000000000e+00,
      "input[7]": 0.0000000000000000e+00,
      "lda": 8.0000000000000000e+00,
      "num_iterations": 9.7652000000000000e+04,
      "predicted_flops": 1.1425457651020272e+09,
      "predicted_flops_count": 8.1920000000000000e+03,
      "transA": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUBLAS_GEMV_FWD_FLOAT32__BatchSize_128__8314068294429619807/input[0]:200/input[1]:4096/input[2]:1/input[3]:1/input[4]:1/input[5]:-1/input[6]:0/input[7]:0/batch_size:128/manual_time",
      "iterations": 40161,
      "real_time": 1.7563163275849223e+04,
      "cpu_time": 2.3556605512807491e+04,
      "time_unit": "ns",
      "items_per_second": 4.6643078307338097e+10,
      "K": 4.0960000000000000e+03,
      "M": 2.0000000000000000e+02,
      "alpha": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cublas_gemv_fwd.cpp": 1.1852848766119408e+19,
      "benchmark_func:void iLAYER_CUBLAS_GEMV_FWD_Impl(benchmark::State&) [with T = float]": 4.8895028309123133e+18,
      "beta": 1.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUBLAS_GEMV_FWD_Impl": 8.8227505551773747e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 2.0000000000000000e+02,
      "input[1]": 4.0960000000000000e+03,
      "input[2]": 1.0000000000000000e+00,
      "input[3]": 1.0000000000000000e+00,
      "input[4]": 1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": 0.0000000000000000e+00,
      "input[7]": 0.0000000000000000e+00,
      "lda": 2.0000000000000000e+02,
      "num_iterations": 4.0161000000000000e+04,
      "predicted_flops": 4.6643078307338097e+10,
      "predicted_flops_count": 8.1920000000000000e+05,
      "transA": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUBLAS_GEMV_FWD_FLOAT32__BatchSize_128__1633669750846757249/input[0]:1000/input[1]:544/input[2]:1/input[3]:1/input[4]:1/input[5]:-1/input[6]:0/input[7]:0/batch_size:128/manual_time",
      "iterations": 77347,
      "real_time": 9.0885233630662551e+03,
      "cpu_time": 1.5150326088929218e+04,
      "time_unit": "ns",
      "items_per_second": 5.9855707937187622e+10,
      "K": 5.4400000000000000e+02,
      "M": 1.0000000000000000e+03,
      "alpha": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cublas_gemv_fwd.cpp": 1.1852848766119408e+19,
      "benchmark_func:void iLAYER_CUBLAS_GEMV_FWD_Impl(benchmark::State&) [with T = float]": 4.8895028309123133e+18,
      "beta": 1.0000000000000000e+00,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUBLAS_GEMV_FWD_Impl": 8.8227505551773747e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+03,
      "input[1]": 5.4400000000000000e+02,
      "input[2]": 1.0000000000000000e+00,
      "input[3]": 1.0000000000000000e+00,
      "input[4]": 1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": 0.0000000000000000e+00,
      "input[7]": 0.0000000000000000e+00,
      "lda": 1.0000000000000000e+03,
      "num_iterations": 7.7347000000000000e+04,
      "predicted_flops": 5.9855707937187622e+10,
      "predicted_flops_count": 5.4400000000000000e+05,
      "transA": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__4766757501735142039<CUDNN_ACTIVATION_RELU>/input[0]:128/input[1]:16/input[2]:55/input[3]:55/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 7638,
      "real_time": 9.1603932192781518e+04,
      "cpu_time": 9.7886421445414846e+04,
      "time_unit": "ns",
      "items_per_second": 6.7630284548944160e+10,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 1.6000000000000000e+01,
      "input[2]": 5.5000000000000000e+01,
      "input[3]": 5.5000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 1.6000000000000000e+01,
      "input_height": 5.5000000000000000e+01,
      "input_size": 6.1952000000000000e+06,
      "input_width": 5.5000000000000000e+01,
      "num_iterations": 7.6380000000000000e+03,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 1.6000000000000000e+01,
      "output_height": 5.5000000000000000e+01,
      "output_size": 6.1952000000000000e+06,
      "output_width": 5.5000000000000000e+01,
      "predicted_flops": 6.7630284548944160e+10,
      "predicted_flops_count": 6.1952000000000000e+06
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__4766757501735142039<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:128/input[1]:16/input[2]:55/input[3]:55/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 7631,
      "real_time": 9.1615922658210795e+04,
      "cpu_time": 9.7908655222114976e+04,
      "time_unit": "ns",
      "items_per_second": 6.7621433264524071e+10,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 1.6000000000000000e+01,
      "input[2]": 5.5000000000000000e+01,
      "input[3]": 5.5000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 1.6000000000000000e+01,
      "input_height": 5.5000000000000000e+01,
      "input_size": 6.1952000000000000e+06,
      "input_width": 5.5000000000000000e+01,
      "num_iterations": 7.6310000000000000e+03,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 1.6000000000000000e+01,
      "output_height": 5.5000000000000000e+01,
      "output_size": 6.1952000000000000e+06,
      "output_width": 5.5000000000000000e+01,
      "predicted_flops": 6.7621433264524071e+10,
      "predicted_flops_count": 6.1952000000000000e+06
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__5194913184951549321<CUDNN_ACTIVATION_RELU>/input[0]:128/input[1]:112/input[2]:56/input[3]:56/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 1096,
      "real_time": 6.3845173727268912e+05,
      "cpu_time": 6.5057239324819483e+05,
      "time_unit": "ns",
      "items_per_second": 7.0416749419538528e+10,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 1.1200000000000000e+02,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 1.1200000000000000e+02,
      "input_height": 5.6000000000000000e+01,
      "input_size": 4.4957696000000000e+07,
      "input_width": 5.6000000000000000e+01,
      "num_iterations": 1.0960000000000000e+03,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 1.1200000000000000e+02,
      "output_height": 5.6000000000000000e+01,
      "output_size": 4.4957696000000000e+07,
      "output_width": 5.6000000000000000e+01,
      "predicted_flops": 7.0416749419538528e+10,
      "predicted_flops_count": 4.4957696000000000e+07
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__5194913184951549321<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:128/input[1]:112/input[2]:56/input[3]:56/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 1097,
      "real_time": 6.3865308455847797e+05,
      "cpu_time": 6.5079941750225821e+05,
      "time_unit": "ns",
      "items_per_second": 7.0394549227114029e+10,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 1.1200000000000000e+02,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 1.1200000000000000e+02,
      "input_height": 5.6000000000000000e+01,
      "input_size": 4.4957696000000000e+07,
      "input_width": 5.6000000000000000e+01,
      "num_iterations": 1.0970000000000000e+03,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 1.1200000000000000e+02,
      "output_height": 5.6000000000000000e+01,
      "output_size": 4.4957696000000000e+07,
      "output_width": 5.6000000000000000e+01,
      "predicted_flops": 7.0394549227114029e+10,
      "predicted_flops_count": 4.4957696000000000e+07
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__5798228081268702451<CUDNN_ACTIVATION_RELU>/input[0]:128/input[1]:192/input[2]:28/input[3]:28/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 2540,
      "real_time": 2.7575974594884162e+05,
      "cpu_time": 2.8301999330703338e+05,
      "time_unit": "ns",
      "items_per_second": 6.9870908582772202e+10,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 1.9200000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 1.9200000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 1.9267584000000000e+07,
      "input_width": 2.8000000000000000e+01,
      "num_iterations": 2.5400000000000000e+03,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 1.9200000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 1.9267584000000000e+07,
      "output_width": 2.8000000000000000e+01,
      "predicted_flops": 6.9870908582772202e+10,
      "predicted_flops_count": 1.9267584000000000e+07
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__5798228081268702451<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:128/input[1]:192/input[2]:28/input[3]:28/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 2537,
      "real_time": 2.7589038802108186e+05,
      "cpu_time": 2.8315886401258403e+05,
      "time_unit": "ns",
      "items_per_second": 6.9837822688218079e+10,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 1.9200000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 1.9200000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 1.9267584000000000e+07,
      "input_width": 2.8000000000000000e+01,
      "num_iterations": 2.5370000000000000e+03,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 1.9200000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 1.9267584000000000e+07,
      "output_width": 2.8000000000000000e+01,
      "predicted_flops": 6.9837822688218079e+10,
      "predicted_flops_count": 1.9267584000000000e+07
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__6391337342107196727<CUDNN_ACTIVATION_RELU>/input[0]:1/input[1]:136/input[2]:28/input[3]:28/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 104311,
      "real_time": 6.8412648527661304e+03,
      "cpu_time": 1.2765986827847875e+04,
      "time_unit": "ns",
      "items_per_second": 1.5585422037401268e+10,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 1.3600000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 1.3600000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 1.0662400000000000e+05,
      "input_width": 2.8000000000000000e+01,
      "num_iterations": 1.0431100000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 1.3600000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 1.0662400000000000e+05,
      "output_width": 2.8000000000000000e+01,
      "predicted_flops": 1.5585422037401268e+10,
      "predicted_flops_count": 1.0662400000000000e+05
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__6391337342107196727<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1/input[1]:136/input[2]:28/input[3]:28/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 102072,
      "real_time": 6.8773409477003415e+03,
      "cpu_time": 1.2730813141717597e+04,
      "time_unit": "ns",
      "items_per_second": 1.5503666433122400e+10,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 1.3600000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 1.3600000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 1.0662400000000000e+05,
      "input_width": 2.8000000000000000e+01,
      "num_iterations": 1.0207200000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 1.3600000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 1.0662400000000000e+05,
      "output_width": 2.8000000000000000e+01,
      "predicted_flops": 1.5503666433122400e+10,
      "predicted_flops_count": 1.0662400000000000e+05
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__7784745323467852026<CUDNN_ACTIVATION_RELU>/input[0]:1/input[1]:272/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 104785,
      "real_time": 6.6178969165464150e+03,
      "cpu_time": 1.2526485966490143e+04,
      "time_unit": "ns",
      "items_per_second": 8.0557314011202745e+09,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 2.7200000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 2.7200000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 5.3312000000000000e+04,
      "input_width": 1.4000000000000000e+01,
      "num_iterations": 1.0478500000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 2.7200000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 5.3312000000000000e+04,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 8.0557314011202745e+09,
      "predicted_flops_count": 5.3312000000000000e+04
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__7784745323467852026<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1/input[1]:272/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 110042,
      "real_time": 6.3701854168121845e+03,
      "cpu_time": 1.2222499463838652e+04,
      "time_unit": "ns",
      "items_per_second": 8.3689871662603474e+09,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 2.7200000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 2.7200000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 5.3312000000000000e+04,
      "input_width": 1.4000000000000000e+01,
      "num_iterations": 1.1004200000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 2.7200000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 5.3312000000000000e+04,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 8.3689871662603474e+09,
      "predicted_flops_count": 5.3312000000000000e+04
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__6616252567149605233<CUDNN_ACTIVATION_RELU>/input[0]:128/input[1]:24/input[2]:112/input[3]:112/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 1280,
      "real_time": 5.4697255159226188e+05,
      "cpu_time": 5.5751237265628809e+05,
      "time_unit": "ns",
      "items_per_second": 7.0451740014782059e+10,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 2.4000000000000000e+01,
      "input[2]": 1.1200000000000000e+02,
      "input[3]": 1.1200000000000000e+02,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 2.4000000000000000e+01,
      "input_height": 1.1200000000000000e+02,
      "input_size": 3.8535168000000000e+07,
      "input_width": 1.1200000000000000e+02,
      "num_iterations": 1.2800000000000000e+03,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 2.4000000000000000e+01,
      "output_height": 1.1200000000000000e+02,
      "output_size": 3.8535168000000000e+07,
      "output_width": 1.1200000000000000e+02,
      "predicted_flops": 7.0451740014782059e+10,
      "predicted_flops_count": 3.8535168000000000e+07
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__6616252567149605233<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:128/input[1]:24/input[2]:112/input[3]:112/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 1279,
      "real_time": 5.4726505204612878e+05,
      "cpu_time": 5.5780848475372756e+05,
      "time_unit": "ns",
      "items_per_second": 7.0414085196786667e+10,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 2.4000000000000000e+01,
      "input[2]": 1.1200000000000000e+02,
      "input[3]": 1.1200000000000000e+02,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 2.4000000000000000e+01,
      "input_height": 1.1200000000000000e+02,
      "input_size": 3.8535168000000000e+07,
      "input_width": 1.1200000000000000e+02,
      "num_iterations": 1.2790000000000000e+03,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 2.4000000000000000e+01,
      "output_height": 1.1200000000000000e+02,
      "output_size": 3.8535168000000000e+07,
      "output_width": 1.1200000000000000e+02,
      "predicted_flops": 7.0414085196786667e+10,
      "predicted_flops_count": 3.8535168000000000e+07
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__1492073206292568976<CUDNN_ACTIVATION_RELU>/input[0]:128/input[1]:64/input[2]:55/input[3]:55/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 1985,
      "real_time": 3.5264635159779503e+05,
      "cpu_time": 3.6060928614603332e+05,
      "time_unit": "ns",
      "items_per_second": 7.0270966614914352e+10,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 5.5000000000000000e+01,
      "input[3]": 5.5000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 5.5000000000000000e+01,
      "input_size": 2.4780800000000000e+07,
      "input_width": 5.5000000000000000e+01,
      "num_iterations": 1.9850000000000000e+03,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 5.5000000000000000e+01,
      "output_size": 2.4780800000000000e+07,
      "output_width": 5.5000000000000000e+01,
      "predicted_flops": 7.0270966614914352e+10,
      "predicted_flops_count": 2.4780800000000000e+07
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__1492073206292568976<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:128/input[1]:64/input[2]:55/input[3]:55/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 1984,
      "real_time": 3.5282659563005925e+05,
      "cpu_time": 3.6080121673392848e+05,
      "time_unit": "ns",
      "items_per_second": 7.0235068180582443e+10,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 5.5000000000000000e+01,
      "input[3]": 5.5000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 5.5000000000000000e+01,
      "input_size": 2.4780800000000000e+07,
      "input_width": 5.5000000000000000e+01,
      "num_iterations": 1.9840000000000000e+03,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 5.5000000000000000e+01,
      "output_size": 2.4780800000000000e+07,
      "output_width": 5.5000000000000000e+01,
      "predicted_flops": 7.0235068180582443e+10,
      "predicted_flops_count": 2.4780800000000000e+07
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__17160497613309952170<CUDNN_ACTIVATION_RELU>/input[0]:128/input[1]:48/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 30779,
      "real_time": 2.2709491081384120e+04,
      "cpu_time": 2.8912696741297903e+04,
      "time_unit": "ns",
      "items_per_second": 5.3027344192100838e+10,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 4.8000000000000000e+01,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 4.8000000000000000e+01,
      "input_height": 1.4000000000000000e+01,
      "input_size": 1.2042240000000000e+06,
      "input_width": 1.4000000000000000e+01,
      "num_iterations": 3.0779000000000000e+04,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 4.8000000000000000e+01,
      "output_height": 1.4000000000000000e+01,
      "output_size": 1.2042240000000000e+06,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 5.3027344192100838e+10,
      "predicted_flops_count": 1.2042240000000000e+06
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__17160497613309952170<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:128/input[1]:48/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 30807,
      "real_time": 2.2738783328364960e+04,
      "cpu_time": 2.8939025156615851e+04,
      "time_unit": "ns",
      "items_per_second": 5.2959034026144188e+10,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 4.8000000000000000e+01,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 4.8000000000000000e+01,
      "input_height": 1.4000000000000000e+01,
      "input_size": 1.2042240000000000e+06,
      "input_width": 1.4000000000000000e+01,
      "num_iterations": 3.0807000000000000e+04,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 4.8000000000000000e+01,
      "output_height": 1.4000000000000000e+01,
      "output_size": 1.2042240000000000e+06,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 5.2959034026144188e+10,
      "predicted_flops_count": 1.2042240000000000e+06
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__16709145530537253138<CUDNN_ACTIVATION_RELU>/input[0]:128/input[1]:16/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 90980,
      "real_time": 7.7064384696416109e+03,
      "cpu_time": 1.3618158639242247e+04,
      "time_unit": "ns",
      "items_per_second": 5.2087355473126556e+10,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 1.6000000000000000e+01,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 1.6000000000000000e+01,
      "input_height": 1.4000000000000000e+01,
      "input_size": 4.0140800000000000e+05,
      "input_width": 1.4000000000000000e+01,
      "num_iterations": 9.0980000000000000e+04,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 1.6000000000000000e+01,
      "output_height": 1.4000000000000000e+01,
      "output_size": 4.0140800000000000e+05,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 5.2087355473126556e+10,
      "predicted_flops_count": 4.0140800000000000e+05
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__16709145530537253138<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:128/input[1]:16/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 90028,
      "real_time": 7.7374992114590650e+03,
      "cpu_time": 1.3602417281293299e+04,
      "time_unit": "ns",
      "items_per_second": 5.1878260537399940e+10,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 1.6000000000000000e+01,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 1.6000000000000000e+01,
      "input_height": 1.4000000000000000e+01,
      "input_size": 4.0140800000000000e+05,
      "input_width": 1.4000000000000000e+01,
      "num_iterations": 9.0028000000000000e+04,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 1.6000000000000000e+01,
      "output_height": 1.4000000000000000e+01,
      "output_size": 4.0140800000000000e+05,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 5.1878260537399940e+10,
      "predicted_flops_count": 4.0140800000000000e+05
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__17328317262907191043<CUDNN_ACTIVATION_RELU>/input[0]:1/input[1]:32/input[2]:6/input[3]:6/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 111502,
      "real_time": 6.2657534289970554e+03,
      "cpu_time": 1.2109581325885556e+04,
      "time_unit": "ns",
      "items_per_second": 1.8385658054603624e+08,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 3.2000000000000000e+01,
      "input[2]": 6.0000000000000000e+00,
      "input[3]": 6.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 3.2000000000000000e+01,
      "input_height": 6.0000000000000000e+00,
      "input_size": 1.1520000000000000e+03,
      "input_width": 6.0000000000000000e+00,
      "num_iterations": 1.1150200000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 3.2000000000000000e+01,
      "output_height": 6.0000000000000000e+00,
      "output_size": 1.1520000000000000e+03,
      "output_width": 6.0000000000000000e+00,
      "predicted_flops": 1.8385658054603624e+08,
      "predicted_flops_count": 1.1520000000000000e+03
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__17328317262907191043<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1/input[1]:32/input[2]:6/input[3]:6/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 111761,
      "real_time": 6.2678414733158397e+03,
      "cpu_time": 1.2105394672559560e+04,
      "time_unit": "ns",
      "items_per_second": 1.8379533128022206e+08,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 3.2000000000000000e+01,
      "input[2]": 6.0000000000000000e+00,
      "input[3]": 6.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 3.2000000000000000e+01,
      "input_height": 6.0000000000000000e+00,
      "input_size": 1.1520000000000000e+03,
      "input_width": 6.0000000000000000e+00,
      "num_iterations": 1.1176100000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 3.2000000000000000e+01,
      "output_height": 6.0000000000000000e+00,
      "output_size": 1.1520000000000000e+03,
      "output_width": 6.0000000000000000e+00,
      "predicted_flops": 1.8379533128022206e+08,
      "predicted_flops_count": 1.1520000000000000e+03
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__14387487927722068168<CUDNN_ACTIVATION_RELU>/input[0]:1/input[1]:192/input[2]:6/input[3]:6/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 111552,
      "real_time": 6.2681377552009526e+03,
      "cpu_time": 1.2108358514428124e+04,
      "time_unit": "ns",
      "items_per_second": 1.1027198619342413e+09,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 1.9200000000000000e+02,
      "input[2]": 6.0000000000000000e+00,
      "input[3]": 6.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 1.9200000000000000e+02,
      "input_height": 6.0000000000000000e+00,
      "input_size": 6.9120000000000000e+03,
      "input_width": 6.0000000000000000e+00,
      "num_iterations": 1.1155200000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 1.9200000000000000e+02,
      "output_height": 6.0000000000000000e+00,
      "output_size": 6.9120000000000000e+03,
      "output_width": 6.0000000000000000e+00,
      "predicted_flops": 1.1027198619342413e+09,
      "predicted_flops_count": 6.9120000000000000e+03
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__14387487927722068168<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1/input[1]:192/input[2]:6/input[3]:6/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 111563,
      "real_time": 6.2741128766025622e+03,
      "cpu_time": 1.2123071224330113e+04,
      "time_unit": "ns",
      "items_per_second": 1.1016696919458125e+09,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 1.9200000000000000e+02,
      "input[2]": 6.0000000000000000e+00,
      "input[3]": 6.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 1.9200000000000000e+02,
      "input_height": 6.0000000000000000e+00,
      "input_size": 6.9120000000000000e+03,
      "input_width": 6.0000000000000000e+00,
      "num_iterations": 1.1156300000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 1.9200000000000000e+02,
      "output_height": 6.0000000000000000e+00,
      "output_size": 6.9120000000000000e+03,
      "output_width": 6.0000000000000000e+00,
      "predicted_flops": 1.1016696919458125e+09,
      "predicted_flops_count": 6.9120000000000000e+03
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__3690569681699314221<CUDNN_ACTIVATION_RELU>/input[0]:128/input[1]:128/input[2]:27/input[3]:27/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 4069,
      "real_time": 1.7202997391170971e+05,
      "cpu_time": 1.7862255615630531e+05,
      "time_unit": "ns",
      "items_per_second": 6.9429389125699341e+10,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 1.2800000000000000e+02,
      "input[2]": 2.7000000000000000e+01,
      "input[3]": 2.7000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 1.2800000000000000e+02,
      "input_height": 2.7000000000000000e+01,
      "input_size": 1.1943936000000000e+07,
      "input_width": 2.7000000000000000e+01,
      "num_iterations": 4.0690000000000000e+03,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 2.7000000000000000e+01,
      "output_size": 1.1943936000000000e+07,
      "output_width": 2.7000000000000000e+01,
      "predicted_flops": 6.9429389125699341e+10,
      "predicted_flops_count": 1.1943936000000000e+07
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__3690569681699314221<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:128/input[1]:128/input[2]:27/input[3]:27/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 4068,
      "real_time": 1.7211891692314338e+05,
      "cpu_time": 1.7870088274345410e+05,
      "time_unit": "ns",
      "items_per_second": 6.9393511262526428e+10,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 1.2800000000000000e+02,
      "input[2]": 2.7000000000000000e+01,
      "input[3]": 2.7000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 1.2800000000000000e+02,
      "input_height": 2.7000000000000000e+01,
      "input_size": 1.1943936000000000e+07,
      "input_width": 2.7000000000000000e+01,
      "num_iterations": 4.0680000000000000e+03,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 2.7000000000000000e+01,
      "output_size": 1.1943936000000000e+07,
      "output_width": 2.7000000000000000e+01,
      "predicted_flops": 6.9393511262526428e+10,
      "predicted_flops_count": 1.1943936000000000e+07
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__2085018503842899052<CUDNN_ACTIVATION_RELU>/input[0]:1/input[1]:160/input[2]:28/input[3]:28/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 102990,
      "real_time": 6.8101314175771840e+03,
      "cpu_time": 1.2674177444413630e+04,
      "time_unit": "ns",
      "items_per_second": 1.8419615174566975e+10,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 1.6000000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 1.6000000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 1.2544000000000000e+05,
      "input_width": 2.8000000000000000e+01,
      "num_iterations": 1.0299000000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 1.6000000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 1.2544000000000000e+05,
      "output_width": 2.8000000000000000e+01,
      "predicted_flops": 1.8419615174566975e+10,
      "predicted_flops_count": 1.2544000000000000e+05
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__2085018503842899052<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1/input[1]:160/input[2]:28/input[3]:28/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 103391,
      "real_time": 6.7874814108136006e+03,
      "cpu_time": 1.2632795765585312e+04,
      "time_unit": "ns",
      "items_per_second": 1.8481081922398045e+10,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 1.6000000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 1.6000000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 1.2544000000000000e+05,
      "input_width": 2.8000000000000000e+01,
      "num_iterations": 1.0339100000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 1.6000000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 1.2544000000000000e+05,
      "output_width": 2.8000000000000000e+01,
      "predicted_flops": 1.8481081922398045e+10,
      "predicted_flops_count": 1.2544000000000000e+05
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__2438092847813789227<CUDNN_ACTIVATION_RELU>/input[0]:128/input[1]:32/input[2]:27/input[3]:27/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 14725,
      "real_time": 4.7495293461174922e+04,
      "cpu_time": 5.3704688353139230e+04,
      "time_unit": "ns",
      "items_per_second": 6.2869050434247681e+10,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 3.2000000000000000e+01,
      "input[2]": 2.7000000000000000e+01,
      "input[3]": 2.7000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 3.2000000000000000e+01,
      "input_height": 2.7000000000000000e+01,
      "input_size": 2.9859840000000000e+06,
      "input_width": 2.7000000000000000e+01,
      "num_iterations": 1.4725000000000000e+04,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 3.2000000000000000e+01,
      "output_height": 2.7000000000000000e+01,
      "output_size": 2.9859840000000000e+06,
      "output_width": 2.7000000000000000e+01,
      "predicted_flops": 6.2869050434247681e+10,
      "predicted_flops_count": 2.9859840000000000e+06
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__2438092847813789227<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:128/input[1]:32/input[2]:27/input[3]:27/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 14718,
      "real_time": 4.7490870241275996e+04,
      "cpu_time": 5.3690887009076025e+04,
      "time_unit": "ns",
      "items_per_second": 6.2874905952023926e+10,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 3.2000000000000000e+01,
      "input[2]": 2.7000000000000000e+01,
      "input[3]": 2.7000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 3.2000000000000000e+01,
      "input_height": 2.7000000000000000e+01,
      "input_size": 2.9859840000000000e+06,
      "input_width": 2.7000000000000000e+01,
      "num_iterations": 1.4718000000000000e+04,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 3.2000000000000000e+01,
      "output_height": 2.7000000000000000e+01,
      "output_size": 2.9859840000000000e+06,
      "output_width": 2.7000000000000000e+01,
      "predicted_flops": 6.2874905952023926e+10,
      "predicted_flops_count": 2.9859840000000000e+06
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__11921838210132704273<CUDNN_ACTIVATION_RELU>/input[0]:1/input[1]:48/input[2]:6/input[3]:6/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 111845,
      "real_time": 6.2659167853825475e+03,
      "cpu_time": 1.2097452456525227e+04,
      "time_unit": "ns",
      "items_per_second": 2.7577768093428355e+08,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 4.8000000000000000e+01,
      "input[2]": 6.0000000000000000e+00,
      "input[3]": 6.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 4.8000000000000000e+01,
      "input_height": 6.0000000000000000e+00,
      "input_size": 1.7280000000000000e+03,
      "input_width": 6.0000000000000000e+00,
      "num_iterations": 1.1184500000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 4.8000000000000000e+01,
      "output_height": 6.0000000000000000e+00,
      "output_size": 1.7280000000000000e+03,
      "output_width": 6.0000000000000000e+00,
      "predicted_flops": 2.7577768093428355e+08,
      "predicted_flops_count": 1.7280000000000000e+03
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__11921838210132704273<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1/input[1]:48/input[2]:6/input[3]:6/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 110326,
      "real_time": 6.2745066694987645e+03,
      "cpu_time": 1.2103622582174692e+04,
      "time_unit": "ns",
      "items_per_second": 2.7540013757576269e+08,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 4.8000000000000000e+01,
      "input[2]": 6.0000000000000000e+00,
      "input[3]": 6.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 4.8000000000000000e+01,
      "input_height": 6.0000000000000000e+00,
      "input_size": 1.7280000000000000e+03,
      "input_width": 6.0000000000000000e+00,
      "num_iterations": 1.1032600000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 4.8000000000000000e+01,
      "output_height": 6.0000000000000000e+00,
      "output_size": 1.7280000000000000e+03,
      "output_width": 6.0000000000000000e+00,
      "predicted_flops": 2.7540013757576269e+08,
      "predicted_flops_count": 1.7280000000000000e+03
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__5520895430017230184<CUDNN_ACTIVATION_RELU>/input[0]:1/input[1]:224/input[2]:28/input[3]:28/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 99942,
      "real_time": 7.3436722379204894e+03,
      "cpu_time": 1.3227195693457867e+04,
      "time_unit": "ns",
      "items_per_second": 2.3913921306723412e+10,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 2.2400000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 2.2400000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 1.7561600000000000e+05,
      "input_width": 2.8000000000000000e+01,
      "num_iterations": 9.9942000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 2.2400000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 1.7561600000000000e+05,
      "output_width": 2.8000000000000000e+01,
      "predicted_flops": 2.3913921306723412e+10,
      "predicted_flops_count": 1.7561600000000000e+05
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__5520895430017230184<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1/input[1]:224/input[2]:28/input[3]:28/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 98249,
      "real_time": 7.2968997040366266e+03,
      "cpu_time": 1.3138078290865897e+04,
      "time_unit": "ns",
      "items_per_second": 2.4067207598159756e+10,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 2.2400000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 2.2400000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 1.7561600000000000e+05,
      "input_width": 2.8000000000000000e+01,
      "num_iterations": 9.8249000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 2.2400000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 1.7561600000000000e+05,
      "output_width": 2.8000000000000000e+01,
      "predicted_flops": 2.4067207598159756e+10,
      "predicted_flops_count": 1.7561600000000000e+05
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__3347073775340954534<CUDNN_ACTIVATION_RELU>/input[0]:1/input[1]:64/input[2]:13/input[3]:13/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 108646,
      "real_time": 6.5339773479902369e+03,
      "cpu_time": 1.2319022771189009e+04,
      "time_unit": "ns",
      "items_per_second": 1.6553470304464486e+09,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 1.3000000000000000e+01,
      "input[3]": 1.3000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 1.3000000000000000e+01,
      "input_size": 1.0816000000000000e+04,
      "input_width": 1.3000000000000000e+01,
      "num_iterations": 1.0864600000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 1.3000000000000000e+01,
      "output_size": 1.0816000000000000e+04,
      "output_width": 1.3000000000000000e+01,
      "predicted_flops": 1.6553470304464486e+09,
      "predicted_flops_count": 1.0816000000000000e+04
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__3347073775340954534<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1/input[1]:64/input[2]:13/input[3]:13/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 111386,
      "real_time": 6.2748606012189630e+03,
      "cpu_time": 1.2117736537794166e+04,
      "time_unit": "ns",
      "items_per_second": 1.7237036306270881e+09,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 1.3000000000000000e+01,
      "input[3]": 1.3000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 1.3000000000000000e+01,
      "input_size": 1.0816000000000000e+04,
      "input_width": 1.3000000000000000e+01,
      "num_iterations": 1.1138600000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 1.3000000000000000e+01,
      "output_size": 1.0816000000000000e+04,
      "output_width": 1.3000000000000000e+01,
      "predicted_flops": 1.7237036306270881e+09,
      "predicted_flops_count": 1.0816000000000000e+04
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__4706172207893919367<CUDNN_ACTIVATION_RELU>/input[0]:1/input[1]:64/input[2]:55/input[3]:55/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 99071,
      "real_time": 7.0628394892478536e+03,
      "cpu_time": 1.2892510118994966e+04,
      "time_unit": "ns",
      "items_per_second": 2.7411071750211494e+10,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 5.5000000000000000e+01,
      "input[3]": 5.5000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 5.5000000000000000e+01,
      "input_size": 1.9360000000000000e+05,
      "input_width": 5.5000000000000000e+01,
      "num_iterations": 9.9071000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 5.5000000000000000e+01,
      "output_size": 1.9360000000000000e+05,
      "output_width": 5.5000000000000000e+01,
      "predicted_flops": 2.7411071750211494e+10,
      "predicted_flops_count": 1.9360000000000000e+05
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__4706172207893919367<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1/input[1]:64/input[2]:55/input[3]:55/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 98553,
      "real_time": 7.1054836594878561e+03,
      "cpu_time": 1.2953052875081130e+04,
      "time_unit": "ns",
      "items_per_second": 2.7246561849662205e+10,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 5.5000000000000000e+01,
      "input[3]": 5.5000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 5.5000000000000000e+01,
      "input_size": 1.9360000000000000e+05,
      "input_width": 5.5000000000000000e+01,
      "num_iterations": 9.8553000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 5.5000000000000000e+01,
      "output_size": 1.9360000000000000e+05,
      "output_width": 5.5000000000000000e+01,
      "predicted_flops": 2.7246561849662205e+10,
      "predicted_flops_count": 1.9360000000000000e+05
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__10053889073009322567<CUDNN_ACTIVATION_RELU>/input[0]:128/input[1]:192/input[2]:13/input[3]:13/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 11000,
      "real_time": 6.3642736790908122e+04,
      "cpu_time": 6.9876320272753524e+04,
      "time_unit": "ns",
      "items_per_second": 6.5260298494789726e+10,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 1.9200000000000000e+02,
      "input[2]": 1.3000000000000000e+01,
      "input[3]": 1.3000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 1.9200000000000000e+02,
      "input_height": 1.3000000000000000e+01,
      "input_size": 4.1533440000000000e+06,
      "input_width": 1.3000000000000000e+01,
      "num_iterations": 1.1000000000000000e+04,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 1.9200000000000000e+02,
      "output_height": 1.3000000000000000e+01,
      "output_size": 4.1533440000000000e+06,
      "output_width": 1.3000000000000000e+01,
      "predicted_flops": 6.5260298494789726e+10,
      "predicted_flops_count": 4.1533440000000000e+06
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__10053889073009322567<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:128/input[1]:192/input[2]:13/input[3]:13/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 10996,
      "real_time": 6.3654695541584188e+04,
      "cpu_time": 6.9877085394771595e+04,
      "time_unit": "ns",
      "items_per_second": 6.5248038100923973e+10,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 1.9200000000000000e+02,
      "input[2]": 1.3000000000000000e+01,
      "input[3]": 1.3000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 1.9200000000000000e+02,
      "input_height": 1.3000000000000000e+01,
      "input_size": 4.1533440000000000e+06,
      "input_width": 1.3000000000000000e+01,
      "num_iterations": 1.0996000000000000e+04,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 1.9200000000000000e+02,
      "output_height": 1.3000000000000000e+01,
      "output_size": 4.1533440000000000e+06,
      "output_width": 1.3000000000000000e+01,
      "predicted_flops": 6.5248038100923973e+10,
      "predicted_flops_count": 4.1533440000000000e+06
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__11468939099632256613<CUDNN_ACTIVATION_RELU>/input[0]:128/input[1]:64/input[2]:13/input[3]:13/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 27800,
      "real_time": 2.5180962767676352e+04,
      "cpu_time": 3.1363183093552183e+04,
      "time_unit": "ns",
      "items_per_second": 5.4979947064500343e+10,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 1.3000000000000000e+01,
      "input[3]": 1.3000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 1.3000000000000000e+01,
      "input_size": 1.3844480000000000e+06,
      "input_width": 1.3000000000000000e+01,
      "num_iterations": 2.7800000000000000e+04,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 1.3000000000000000e+01,
      "output_size": 1.3844480000000000e+06,
      "output_width": 1.3000000000000000e+01,
      "predicted_flops": 5.4979947064500343e+10,
      "predicted_flops_count": 1.3844480000000000e+06
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__11468939099632256613<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:128/input[1]:64/input[2]:13/input[3]:13/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 27773,
      "real_time": 2.5210588567689229e+04,
      "cpu_time": 3.1381062686826452e+04,
      "time_unit": "ns",
      "items_per_second": 5.4915338302508217e+10,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 1.3000000000000000e+01,
      "input[3]": 1.3000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 1.3000000000000000e+01,
      "input_size": 1.3844480000000000e+06,
      "input_width": 1.3000000000000000e+01,
      "num_iterations": 2.7773000000000000e+04,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 1.3000000000000000e+01,
      "output_size": 1.3844480000000000e+06,
      "output_width": 1.3000000000000000e+01,
      "predicted_flops": 5.4915338302508217e+10,
      "predicted_flops_count": 1.3844480000000000e+06
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__1940379314062000542<CUDNN_ACTIVATION_RELU>/input[0]:128/input[1]:48/input[2]:13/input[3]:13/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 34163,
      "real_time": 2.0488479657937452e+04,
      "cpu_time": 2.6672539238404428e+04,
      "time_unit": "ns",
      "items_per_second": 5.0679016566157837e+10,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 4.8000000000000000e+01,
      "input[2]": 1.3000000000000000e+01,
      "input[3]": 1.3000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 4.8000000000000000e+01,
      "input_height": 1.3000000000000000e+01,
      "input_size": 1.0383360000000000e+06,
      "input_width": 1.3000000000000000e+01,
      "num_iterations": 3.4163000000000000e+04,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 4.8000000000000000e+01,
      "output_height": 1.3000000000000000e+01,
      "output_size": 1.0383360000000000e+06,
      "output_width": 1.3000000000000000e+01,
      "predicted_flops": 5.0679016566157837e+10,
      "predicted_flops_count": 1.0383360000000000e+06
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__1940379314062000542<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:128/input[1]:48/input[2]:13/input[3]:13/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 34056,
      "real_time": 2.0494674024755943e+04,
      "cpu_time": 2.6675135541446900e+04,
      "time_unit": "ns",
      "items_per_second": 5.0663699200376274e+10,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 4.8000000000000000e+01,
      "input[2]": 1.3000000000000000e+01,
      "input[3]": 1.3000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 4.8000000000000000e+01,
      "input_height": 1.3000000000000000e+01,
      "input_size": 1.0383360000000000e+06,
      "input_width": 1.3000000000000000e+01,
      "num_iterations": 3.4056000000000000e+04,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 4.8000000000000000e+01,
      "output_height": 1.3000000000000000e+01,
      "output_size": 1.0383360000000000e+06,
      "output_width": 1.3000000000000000e+01,
      "predicted_flops": 5.0663699200376274e+10,
      "predicted_flops_count": 1.0383360000000000e+06
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__9876695692234492599<CUDNN_ACTIVATION_RELU>/input[0]:128/input[1]:384/input[2]:13/input[3]:13/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 5781,
      "real_time": 1.2117315768892929e+05,
      "cpu_time": 1.2756104341796966e+05,
      "time_unit": "ns",
      "items_per_second": 6.8552212044556808e+10,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 3.8400000000000000e+02,
      "input[2]": 1.3000000000000000e+01,
      "input[3]": 1.3000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 3.8400000000000000e+02,
      "input_height": 1.3000000000000000e+01,
      "input_size": 8.3066880000000000e+06,
      "input_width": 1.3000000000000000e+01,
      "num_iterations": 5.7810000000000000e+03,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 3.8400000000000000e+02,
      "output_height": 1.3000000000000000e+01,
      "output_size": 8.3066880000000000e+06,
      "output_width": 1.3000000000000000e+01,
      "predicted_flops": 6.8552212044556808e+10,
      "predicted_flops_count": 8.3066880000000000e+06
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__9876695692234492599<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:128/input[1]:384/input[2]:13/input[3]:13/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 5777,
      "real_time": 1.2114120568307182e+05,
      "cpu_time": 1.2749871975070715e+05,
      "time_unit": "ns",
      "items_per_second": 6.8570293263646873e+10,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 3.8400000000000000e+02,
      "input[2]": 1.3000000000000000e+01,
      "input[3]": 1.3000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 3.8400000000000000e+02,
      "input_height": 1.3000000000000000e+01,
      "input_size": 8.3066880000000000e+06,
      "input_width": 1.3000000000000000e+01,
      "num_iterations": 5.7770000000000000e+03,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 3.8400000000000000e+02,
      "output_height": 1.3000000000000000e+01,
      "output_size": 8.3066880000000000e+06,
      "output_width": 1.3000000000000000e+01,
      "predicted_flops": 6.8570293263646873e+10,
      "predicted_flops_count": 8.3066880000000000e+06
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__11112938498448767206<CUDNN_ACTIVATION_RELU>/input[0]:1/input[1]:64/input[2]:112/input[3]:112/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 44468,
      "real_time": 1.5740897239073207e+04,
      "cpu_time": 2.1880467032456498e+04,
      "time_unit": "ns",
      "items_per_second": 5.1001921161596260e+10,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 1.1200000000000000e+02,
      "input[3]": 1.1200000000000000e+02,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 1.1200000000000000e+02,
      "input_size": 8.0281600000000000e+05,
      "input_width": 1.1200000000000000e+02,
      "num_iterations": 4.4468000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 1.1200000000000000e+02,
      "output_size": 8.0281600000000000e+05,
      "output_width": 1.1200000000000000e+02,
      "predicted_flops": 5.1001921161596260e+10,
      "predicted_flops_count": 8.0281600000000000e+05
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__11112938498448767206<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1/input[1]:64/input[2]:112/input[3]:112/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 44477,
      "real_time": 1.5759030738427013e+04,
      "cpu_time": 2.1879356049217171e+04,
      "time_unit": "ns",
      "items_per_second": 5.0943234601503990e+10,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 1.1200000000000000e+02,
      "input[3]": 1.1200000000000000e+02,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 1.1200000000000000e+02,
      "input_size": 8.0281600000000000e+05,
      "input_width": 1.1200000000000000e+02,
      "num_iterations": 4.4477000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 1.1200000000000000e+02,
      "output_size": 8.0281600000000000e+05,
      "output_width": 1.1200000000000000e+02,
      "predicted_flops": 5.0943234601503990e+10,
      "predicted_flops_count": 8.0281600000000000e+05
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__8389815448405428378<CUDNN_ACTIVATION_RELU>/input[0]:1/input[1]:64/input[2]:56/input[3]:56/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 99144,
      "real_time": 7.0607456932096102e+03,
      "cpu_time": 1.2902361252314255e+04,
      "time_unit": "ns",
      "items_per_second": 2.8425326264479267e+10,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 2.0070400000000000e+05,
      "input_width": 5.6000000000000000e+01,
      "num_iterations": 9.9144000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 5.6000000000000000e+01,
      "output_size": 2.0070400000000000e+05,
      "output_width": 5.6000000000000000e+01,
      "predicted_flops": 2.8425326264479267e+10,
      "predicted_flops_count": 2.0070400000000000e+05
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__8389815448405428378<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1/input[1]:64/input[2]:56/input[3]:56/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 98770,
      "real_time": 7.0926330974820621e+03,
      "cpu_time": 1.2933651513643032e+04,
      "time_unit": "ns",
      "items_per_second": 2.8297530302427662e+10,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 2.0070400000000000e+05,
      "input_width": 5.6000000000000000e+01,
      "num_iterations": 9.8770000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 5.6000000000000000e+01,
      "output_size": 2.0070400000000000e+05,
      "output_width": 5.6000000000000000e+01,
      "predicted_flops": 2.8297530302427662e+10,
      "predicted_flops_count": 2.0070400000000000e+05
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__13008855741978255737<CUDNN_ACTIVATION_RELU>/input[0]:1/input[1]:128/input[2]:6/input[3]:6/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 111734,
      "real_time": 6.2581537476417370e+03,
      "cpu_time": 1.2102412273807811e+04,
      "time_unit": "ns",
      "items_per_second": 7.3631939799121022e+08,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 1.2800000000000000e+02,
      "input[2]": 6.0000000000000000e+00,
      "input[3]": 6.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 1.2800000000000000e+02,
      "input_height": 6.0000000000000000e+00,
      "input_size": 4.6080000000000000e+03,
      "input_width": 6.0000000000000000e+00,
      "num_iterations": 1.1173400000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 6.0000000000000000e+00,
      "output_size": 4.6080000000000000e+03,
      "output_width": 6.0000000000000000e+00,
      "predicted_flops": 7.3631939799121022e+08,
      "predicted_flops_count": 4.6080000000000000e+03
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__13008855741978255737<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1/input[1]:128/input[2]:6/input[3]:6/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 111802,
      "real_time": 6.2490414728931710e+03,
      "cpu_time": 1.2092845476821907e+04,
      "time_unit": "ns",
      "items_per_second": 7.3739308980239427e+08,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 1.2800000000000000e+02,
      "input[2]": 6.0000000000000000e+00,
      "input[3]": 6.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 1.2800000000000000e+02,
      "input_height": 6.0000000000000000e+00,
      "input_size": 4.6080000000000000e+03,
      "input_width": 6.0000000000000000e+00,
      "num_iterations": 1.1180200000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 6.0000000000000000e+00,
      "output_size": 4.6080000000000000e+03,
      "output_width": 6.0000000000000000e+00,
      "predicted_flops": 7.3739308980239427e+08,
      "predicted_flops_count": 4.6080000000000000e+03
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__404216268009676040<CUDNN_ACTIVATION_RELU>/input[0]:1/input[1]:96/input[2]:56/input[3]:56/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 94930,
      "real_time": 7.3945157607508227e+03,
      "cpu_time": 1.3230960950183815e+04,
      "time_unit": "ns",
      "items_per_second": 4.0713416502263489e+10,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 9.6000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 9.6000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 3.0105600000000000e+05,
      "input_width": 5.6000000000000000e+01,
      "num_iterations": 9.4930000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 9.6000000000000000e+01,
      "output_height": 5.6000000000000000e+01,
      "output_size": 3.0105600000000000e+05,
      "output_width": 5.6000000000000000e+01,
      "predicted_flops": 4.0713416502263489e+10,
      "predicted_flops_count": 3.0105600000000000e+05
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__404216268009676040<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1/input[1]:96/input[2]:56/input[3]:56/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 93733,
      "real_time": 7.4191508696437786e+03,
      "cpu_time": 1.3248547341934183e+04,
      "time_unit": "ns",
      "items_per_second": 4.0578228599151649e+10,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 9.6000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 9.6000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 3.0105600000000000e+05,
      "input_width": 5.6000000000000000e+01,
      "num_iterations": 9.3733000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 9.6000000000000000e+01,
      "output_height": 5.6000000000000000e+01,
      "output_size": 3.0105600000000000e+05,
      "output_width": 5.6000000000000000e+01,
      "predicted_flops": 4.0578228599151649e+10,
      "predicted_flops_count": 3.0105600000000000e+05
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__11598021558777893144<CUDNN_ACTIVATION_RELU>/input[0]:1/input[1]:160/input[2]:56/input[3]:56/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 87159,
      "real_time": 8.0350291919540168e+03,
      "cpu_time": 1.3839381050762991e+04,
      "time_unit": "ns",
      "items_per_second": 6.2446568396097931e+10,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 1.6000000000000000e+02,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 1.6000000000000000e+02,
      "input_height": 5.6000000000000000e+01,
      "input_size": 5.0176000000000000e+05,
      "input_width": 5.6000000000000000e+01,
      "num_iterations": 8.7159000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 1.6000000000000000e+02,
      "output_height": 5.6000000000000000e+01,
      "output_size": 5.0176000000000000e+05,
      "output_width": 5.6000000000000000e+01,
      "predicted_flops": 6.2446568396097931e+10,
      "predicted_flops_count": 5.0176000000000000e+05
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__11598021558777893144<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1/input[1]:160/input[2]:56/input[3]:56/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 86760,
      "real_time": 8.0705654758246292e+03,
      "cpu_time": 1.3895615928977837e+04,
      "time_unit": "ns",
      "items_per_second": 6.2171603898515106e+10,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 1.6000000000000000e+02,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 1.6000000000000000e+02,
      "input_height": 5.6000000000000000e+01,
      "input_size": 5.0176000000000000e+05,
      "input_width": 5.6000000000000000e+01,
      "num_iterations": 8.6760000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 1.6000000000000000e+02,
      "output_height": 5.6000000000000000e+01,
      "output_size": 5.0176000000000000e+05,
      "output_width": 5.6000000000000000e+01,
      "predicted_flops": 6.2171603898515106e+10,
      "predicted_flops_count": 5.0176000000000000e+05
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__3426667249210137038<CUDNN_ACTIVATION_RELU>/input[0]:1/input[1]:16/input[2]:27/input[3]:27/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 111191,
      "real_time": 6.2893349909726521e+03,
      "cpu_time": 1.2130238436568083e+04,
      "time_unit": "ns",
      "items_per_second": 1.8545680929290347e+09,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 1.6000000000000000e+01,
      "input[2]": 2.7000000000000000e+01,
      "input[3]": 2.7000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 1.6000000000000000e+01,
      "input_height": 2.7000000000000000e+01,
      "input_size": 1.1664000000000000e+04,
      "input_width": 2.7000000000000000e+01,
      "num_iterations": 1.1119100000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 1.6000000000000000e+01,
      "output_height": 2.7000000000000000e+01,
      "output_size": 1.1664000000000000e+04,
      "output_width": 2.7000000000000000e+01,
      "predicted_flops": 1.8545680929290347e+09,
      "predicted_flops_count": 1.1664000000000000e+04
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__3426667249210137038<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1/input[1]:16/input[2]:27/input[3]:27/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 111215,
      "real_time": 6.2873824484330225e+03,
      "cpu_time": 1.2142286966683421e+04,
      "time_unit": "ns",
      "items_per_second": 1.8551440278469095e+09,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 1.6000000000000000e+01,
      "input[2]": 2.7000000000000000e+01,
      "input[3]": 2.7000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 1.6000000000000000e+01,
      "input_height": 2.7000000000000000e+01,
      "input_size": 1.1664000000000000e+04,
      "input_width": 2.7000000000000000e+01,
      "num_iterations": 1.1121500000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 1.6000000000000000e+01,
      "output_height": 2.7000000000000000e+01,
      "output_size": 1.1664000000000000e+04,
      "output_width": 2.7000000000000000e+01,
      "predicted_flops": 1.8551440278469095e+09,
      "predicted_flops_count": 1.1664000000000000e+04
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__17090033127250641120<CUDNN_ACTIVATION_RELU>/input[0]:1/input[1]:192/input[2]:56/input[3]:56/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 72482,
      "real_time": 9.6652992296279535e+03,
      "cpu_time": 1.5594937432761013e+04,
      "time_unit": "ns",
      "items_per_second": 6.2296260642845825e+10,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 1.9200000000000000e+02,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 1.9200000000000000e+02,
      "input_height": 5.6000000000000000e+01,
      "input_size": 6.0211200000000000e+05,
      "input_width": 5.6000000000000000e+01,
      "num_iterations": 7.2482000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 1.9200000000000000e+02,
      "output_height": 5.6000000000000000e+01,
      "output_size": 6.0211200000000000e+05,
      "output_width": 5.6000000000000000e+01,
      "predicted_flops": 6.2296260642845825e+10,
      "predicted_flops_count": 6.0211200000000000e+05
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__17090033127250641120<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1/input[1]:192/input[2]:56/input[3]:56/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 72014,
      "real_time": 9.7330748944931674e+03,
      "cpu_time": 1.5659630363570821e+04,
      "time_unit": "ns",
      "items_per_second": 6.1862464485983383e+10,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 1.9200000000000000e+02,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 1.9200000000000000e+02,
      "input_height": 5.6000000000000000e+01,
      "input_size": 6.0211200000000000e+05,
      "input_width": 5.6000000000000000e+01,
      "num_iterations": 7.2014000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 1.9200000000000000e+02,
      "output_height": 5.6000000000000000e+01,
      "output_size": 6.0211200000000000e+05,
      "output_width": 5.6000000000000000e+01,
      "predicted_flops": 6.1862464485983383e+10,
      "predicted_flops_count": 6.0211200000000000e+05
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__4689638324051192956<CUDNN_ACTIVATION_RELU>/input[0]:1/input[1]:224/input[2]:56/input[3]:56/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 51575,
      "real_time": 1.3578490224659472e+04,
      "cpu_time": 1.9569889966033534e+04,
      "time_unit": "ns",
      "items_per_second": 5.1733586604810966e+10,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 2.2400000000000000e+02,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 2.2400000000000000e+02,
      "input_height": 5.6000000000000000e+01,
      "input_size": 7.0246400000000000e+05,
      "input_width": 5.6000000000000000e+01,
      "num_iterations": 5.1575000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 2.2400000000000000e+02,
      "output_height": 5.6000000000000000e+01,
      "output_size": 7.0246400000000000e+05,
      "output_width": 5.6000000000000000e+01,
      "predicted_flops": 5.1733586604810966e+10,
      "predicted_flops_count": 7.0246400000000000e+05
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__4689638324051192956<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1/input[1]:224/input[2]:56/input[3]:56/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 51557,
      "real_time": 1.3586103949452010e+04,
      "cpu_time": 1.9578702911350814e+04,
      "time_unit": "ns",
      "items_per_second": 5.1704594828183510e+10,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 2.2400000000000000e+02,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 2.2400000000000000e+02,
      "input_height": 5.6000000000000000e+01,
      "input_size": 7.0246400000000000e+05,
      "input_width": 5.6000000000000000e+01,
      "num_iterations": 5.1557000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 2.2400000000000000e+02,
      "output_height": 5.6000000000000000e+01,
      "output_size": 7.0246400000000000e+05,
      "output_width": 5.6000000000000000e+01,
      "predicted_flops": 5.1704594828183510e+10,
      "predicted_flops_count": 7.0246400000000000e+05
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__10922300483511070290<CUDNN_ACTIVATION_RELU>/input[0]:128/input[1]:96/input[2]:109/input[3]:109/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 329,
      "real_time": 2.1271995929746372e+06,
      "cpu_time": 2.2002851306987419e+06,
      "time_unit": "ns",
      "items_per_second": 6.8631889777604294e+10,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 9.6000000000000000e+01,
      "input[2]": 1.0900000000000000e+02,
      "input[3]": 1.0900000000000000e+02,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 9.6000000000000000e+01,
      "input_height": 1.0900000000000000e+02,
      "input_size": 1.4599372800000000e+08,
      "input_width": 1.0900000000000000e+02,
      "num_iterations": 3.2900000000000000e+02,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 9.6000000000000000e+01,
      "output_height": 1.0900000000000000e+02,
      "output_size": 1.4599372800000000e+08,
      "output_width": 1.0900000000000000e+02,
      "predicted_flops": 6.8631889777604294e+10,
      "predicted_flops_count": 1.4599372800000000e+08
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__10922300483511070290<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:128/input[1]:96/input[2]:109/input[3]:109/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 329,
      "real_time": 2.1272029063882348e+06,
      "cpu_time": 2.2004293890581639e+06,
      "time_unit": "ns",
      "items_per_second": 6.8631782873915825e+10,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 9.6000000000000000e+01,
      "input[2]": 1.0900000000000000e+02,
      "input[3]": 1.0900000000000000e+02,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 9.6000000000000000e+01,
      "input_height": 1.0900000000000000e+02,
      "input_size": 1.4599372800000000e+08,
      "input_width": 1.0900000000000000e+02,
      "num_iterations": 3.2900000000000000e+02,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 9.6000000000000000e+01,
      "output_height": 1.0900000000000000e+02,
      "output_size": 1.4599372800000000e+08,
      "output_width": 1.0900000000000000e+02,
      "predicted_flops": 6.8631782873915825e+10,
      "predicted_flops_count": 1.4599372800000000e+08
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__4421964639979822548<CUDNN_ACTIVATION_RELU>/input[0]:1/input[1]:192/input[2]:28/input[3]:28/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 100424,
      "real_time": 7.0794740188198766e+03,
      "cpu_time": 1.2932884718772908e+04,
      "time_unit": "ns",
      "items_per_second": 2.1262596571417675e+10,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 1.9200000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 1.9200000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 1.5052800000000000e+05,
      "input_width": 2.8000000000000000e+01,
      "num_iterations": 1.0042400000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 1.9200000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 1.5052800000000000e+05,
      "output_width": 2.8000000000000000e+01,
      "predicted_flops": 2.1262596571417675e+10,
      "predicted_flops_count": 1.5052800000000000e+05
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__4421964639979822548<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1/input[1]:192/input[2]:28/input[3]:28/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 98282,
      "real_time": 7.0265397405534404e+03,
      "cpu_time": 1.2848511985946612e+04,
      "time_unit": "ns",
      "items_per_second": 2.1422777861944286e+10,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 1.9200000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 1.9200000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 1.5052800000000000e+05,
      "input_width": 2.8000000000000000e+01,
      "num_iterations": 9.8282000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 1.9200000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 1.5052800000000000e+05,
      "output_width": 2.8000000000000000e+01,
      "predicted_flops": 2.1422777861944286e+10,
      "predicted_flops_count": 1.5052800000000000e+05
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__11288725732342988941<CUDNN_ACTIVATION_RELU>/input[0]:1/input[1]:128/input[2]:56/input[3]:56/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 90883,
      "real_time": 7.7134967380581538e+03,
      "cpu_time": 1.3625095507408534e+04,
      "time_unit": "ns",
      "items_per_second": 5.2039692714131248e+10,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 1.2800000000000000e+02,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 1.2800000000000000e+02,
      "input_height": 5.6000000000000000e+01,
      "input_size": 4.0140800000000000e+05,
      "input_width": 5.6000000000000000e+01,
      "num_iterations": 9.0883000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 5.6000000000000000e+01,
      "output_size": 4.0140800000000000e+05,
      "output_width": 5.6000000000000000e+01,
      "predicted_flops": 5.2039692714131248e+10,
      "predicted_flops_count": 4.0140800000000000e+05
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__11288725732342988941<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1/input[1]:128/input[2]:56/input[3]:56/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 89700,
      "real_time": 7.7393829547434862e+03,
      "cpu_time": 1.3611232998904616e+04,
      "time_unit": "ns",
      "items_per_second": 5.1865633519785461e+10,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 1.2800000000000000e+02,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 1.2800000000000000e+02,
      "input_height": 5.6000000000000000e+01,
      "input_size": 4.0140800000000000e+05,
      "input_width": 5.6000000000000000e+01,
      "num_iterations": 8.9700000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 5.6000000000000000e+01,
      "output_size": 4.0140800000000000e+05,
      "output_width": 5.6000000000000000e+01,
      "predicted_flops": 5.1865633519785461e+10,
      "predicted_flops_count": 4.0140800000000000e+05
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__7522329841868264703<CUDNN_ACTIVATION_RELU>/input[0]:128/input[1]:512/input[2]:12/input[3]:12/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 5103,
      "real_time": 1.3712395117960798e+05,
      "cpu_time": 1.4357617617084971e+05,
      "time_unit": "ns",
      "items_per_second": 6.8822287564037369e+10,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 1.2000000000000000e+01,
      "input[3]": 1.2000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 1.2000000000000000e+01,
      "input_size": 9.4371840000000000e+06,
      "input_width": 1.2000000000000000e+01,
      "num_iterations": 5.1030000000000000e+03,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 1.2000000000000000e+01,
      "output_size": 9.4371840000000000e+06,
      "output_width": 1.2000000000000000e+01,
      "predicted_flops": 6.8822287564037369e+10,
      "predicted_flops_count": 9.4371840000000000e+06
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__7522329841868264703<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:128/input[1]:512/input[2]:12/input[3]:12/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 5095,
      "real_time": 1.3715292999607266e+05,
      "cpu_time": 1.4358004102065231e+05,
      "time_unit": "ns",
      "items_per_second": 6.8807746216360306e+10,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 1.2000000000000000e+01,
      "input[3]": 1.2000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 1.2000000000000000e+01,
      "input_size": 9.4371840000000000e+06,
      "input_width": 1.2000000000000000e+01,
      "num_iterations": 5.0950000000000000e+03,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 1.2000000000000000e+01,
      "output_size": 9.4371840000000000e+06,
      "output_width": 1.2000000000000000e+01,
      "predicted_flops": 6.8807746216360306e+10,
      "predicted_flops_count": 9.4371840000000000e+06
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__3492501323084921491<CUDNN_ACTIVATION_RELU>/input[0]:1/input[1]:192/input[2]:27/input[3]:27/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 101738,
      "real_time": 6.8767818010004285e+03,
      "cpu_time": 1.2719276366746370e+04,
      "time_unit": "ns",
      "items_per_second": 2.0353706726544323e+10,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 1.9200000000000000e+02,
      "input[2]": 2.7000000000000000e+01,
      "input[3]": 2.7000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 1.9200000000000000e+02,
      "input_height": 2.7000000000000000e+01,
      "input_size": 1.3996800000000000e+05,
      "input_width": 2.7000000000000000e+01,
      "num_iterations": 1.0173800000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 1.9200000000000000e+02,
      "output_height": 2.7000000000000000e+01,
      "output_size": 1.3996800000000000e+05,
      "output_width": 2.7000000000000000e+01,
      "predicted_flops": 2.0353706726544323e+10,
      "predicted_flops_count": 1.3996800000000000e+05
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__3492501323084921491<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1/input[1]:192/input[2]:27/input[3]:27/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 102096,
      "real_time": 6.8753005291355557e+03,
      "cpu_time": 1.2698608868103442e+04,
      "time_unit": "ns",
      "items_per_second": 2.0358091898216763e+10,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 1.9200000000000000e+02,
      "input[2]": 2.7000000000000000e+01,
      "input[3]": 2.7000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 1.9200000000000000e+02,
      "input_height": 2.7000000000000000e+01,
      "input_size": 1.3996800000000000e+05,
      "input_width": 2.7000000000000000e+01,
      "num_iterations": 1.0209600000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 1.9200000000000000e+02,
      "output_height": 2.7000000000000000e+01,
      "output_size": 1.3996800000000000e+05,
      "output_width": 2.7000000000000000e+01,
      "predicted_flops": 2.0358091898216763e+10,
      "predicted_flops_count": 1.3996800000000000e+05
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__1711419874698263545<CUDNN_ACTIVATION_RELU>/input[0]:128/input[1]:256/input[2]:25/input[3]:25/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 2398,
      "real_time": 2.9191375419565843e+05,
      "cpu_time": 2.9931036697266012e+05,
      "time_unit": "ns",
      "items_per_second": 7.0157708246501648e+10,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 2.5000000000000000e+01,
      "input[3]": 2.5000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 2.5000000000000000e+01,
      "input_size": 2.0480000000000000e+07,
      "input_width": 2.5000000000000000e+01,
      "num_iterations": 2.3980000000000000e+03,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 2.5000000000000000e+01,
      "output_size": 2.0480000000000000e+07,
      "output_width": 2.5000000000000000e+01,
      "predicted_flops": 7.0157708246501648e+10,
      "predicted_flops_count": 2.0480000000000000e+07
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__1711419874698263545<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:128/input[1]:256/input[2]:25/input[3]:25/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 2397,
      "real_time": 2.9203819379954127e+05,
      "cpu_time": 2.9941607884857722e+05,
      "time_unit": "ns",
      "items_per_second": 7.0127813535436844e+10,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 2.5000000000000000e+01,
      "input[3]": 2.5000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 2.5000000000000000e+01,
      "input_size": 2.0480000000000000e+07,
      "input_width": 2.5000000000000000e+01,
      "num_iterations": 2.3970000000000000e+03,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 2.5000000000000000e+01,
      "output_size": 2.0480000000000000e+07,
      "output_width": 2.5000000000000000e+01,
      "predicted_flops": 7.0127813535436844e+10,
      "predicted_flops_count": 2.0480000000000000e+07
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__16506615735362298912<CUDNN_ACTIVATION_RELU>/input[0]:1/input[1]:32/input[2]:27/input[3]:27/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 111032,
      "real_time": 6.3105769075648313e+03,
      "cpu_time": 1.2150308703845321e+04,
      "time_unit": "ns",
      "items_per_second": 3.6966509309213014e+09,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 3.2000000000000000e+01,
      "input[2]": 2.7000000000000000e+01,
      "input[3]": 2.7000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 3.2000000000000000e+01,
      "input_height": 2.7000000000000000e+01,
      "input_size": 2.3328000000000000e+04,
      "input_width": 2.7000000000000000e+01,
      "num_iterations": 1.1103200000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 3.2000000000000000e+01,
      "output_height": 2.7000000000000000e+01,
      "output_size": 2.3328000000000000e+04,
      "output_width": 2.7000000000000000e+01,
      "predicted_flops": 3.6966509309213014e+09,
      "predicted_flops_count": 2.3328000000000000e+04
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__16506615735362298912<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1/input[1]:32/input[2]:27/input[3]:27/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 110683,
      "real_time": 6.3143792564032674e+03,
      "cpu_time": 1.2157814497300413e+04,
      "time_unit": "ns",
      "items_per_second": 3.6944249074592104e+09,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 3.2000000000000000e+01,
      "input[2]": 2.7000000000000000e+01,
      "input[3]": 2.7000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 3.2000000000000000e+01,
      "input_height": 2.7000000000000000e+01,
      "input_size": 2.3328000000000000e+04,
      "input_width": 2.7000000000000000e+01,
      "num_iterations": 1.1068300000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 3.2000000000000000e+01,
      "output_height": 2.7000000000000000e+01,
      "output_size": 2.3328000000000000e+04,
      "output_width": 2.7000000000000000e+01,
      "predicted_flops": 3.6944249074592104e+09,
      "predicted_flops_count": 2.3328000000000000e+04
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__15643481193937761859<CUDNN_ACTIVATION_RELU>/input[0]:1/input[1]:96/input[2]:27/input[3]:27/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 108675,
      "real_time": 6.4308293174214141e+03,
      "cpu_time": 1.2275020317464716e+04,
      "time_unit": "ns",
      "items_per_second": 1.0882577743186264e+10,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 9.6000000000000000e+01,
      "input[2]": 2.7000000000000000e+01,
      "input[3]": 2.7000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 9.6000000000000000e+01,
      "input_height": 2.7000000000000000e+01,
      "input_size": 6.9984000000000000e+04,
      "input_width": 2.7000000000000000e+01,
      "num_iterations": 1.0867500000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 9.6000000000000000e+01,
      "output_height": 2.7000000000000000e+01,
      "output_size": 6.9984000000000000e+04,
      "output_width": 2.7000000000000000e+01,
      "predicted_flops": 1.0882577743186264e+10,
      "predicted_flops_count": 6.9984000000000000e+04
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__15643481193937761859<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1/input[1]:96/input[2]:27/input[3]:27/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 108936,
      "real_time": 6.4396549182677791e+03,
      "cpu_time": 1.2286340466022202e+04,
      "time_unit": "ns",
      "items_per_second": 1.0867663079503208e+10,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 9.6000000000000000e+01,
      "input[2]": 2.7000000000000000e+01,
      "input[3]": 2.7000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 9.6000000000000000e+01,
      "input_height": 2.7000000000000000e+01,
      "input_size": 6.9984000000000000e+04,
      "input_width": 2.7000000000000000e+01,
      "num_iterations": 1.0893600000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 9.6000000000000000e+01,
      "output_height": 2.7000000000000000e+01,
      "output_size": 6.9984000000000000e+04,
      "output_width": 2.7000000000000000e+01,
      "predicted_flops": 1.0867663079503208e+10,
      "predicted_flops_count": 6.9984000000000000e+04
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__4522224137620633537<CUDNN_ACTIVATION_RELU>/input[0]:1/input[1]:64/input[2]:27/input[3]:27/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 110179,
      "real_time": 6.3502991265846267e+03,
      "cpu_time": 1.2198199656869139e+04,
      "time_unit": "ns",
      "items_per_second": 7.3470554803759203e+09,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 2.7000000000000000e+01,
      "input[3]": 2.7000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 2.7000000000000000e+01,
      "input_size": 4.6656000000000000e+04,
      "input_width": 2.7000000000000000e+01,
      "num_iterations": 1.1017900000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 2.7000000000000000e+01,
      "output_size": 4.6656000000000000e+04,
      "output_width": 2.7000000000000000e+01,
      "predicted_flops": 7.3470554803759203e+09,
      "predicted_flops_count": 4.6656000000000000e+04
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__4522224137620633537<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1/input[1]:64/input[2]:27/input[3]:27/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 110177,
      "real_time": 6.3594837352948261e+03,
      "cpu_time": 1.2220320665766836e+04,
      "time_unit": "ns",
      "items_per_second": 7.3364445829244699e+09,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 2.7000000000000000e+01,
      "input[3]": 2.7000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 2.7000000000000000e+01,
      "input_size": 4.6656000000000000e+04,
      "input_width": 2.7000000000000000e+01,
      "num_iterations": 1.1017700000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 2.7000000000000000e+01,
      "output_size": 4.6656000000000000e+04,
      "output_width": 2.7000000000000000e+01,
      "predicted_flops": 7.3364445829244699e+09,
      "predicted_flops_count": 4.6656000000000000e+04
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__14052554398038873058<CUDNN_ACTIVATION_RELU>/input[0]:128/input[1]:208/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 8950,
      "real_time": 7.8149597447003922e+04,
      "cpu_time": 8.4426528491705962e+04,
      "time_unit": "ns",
      "items_per_second": 6.6773267815470467e+10,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 2.0800000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 2.0800000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 5.2183040000000000e+06,
      "input_width": 1.4000000000000000e+01,
      "num_iterations": 8.9500000000000000e+03,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 2.0800000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 5.2183040000000000e+06,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 6.6773267815470467e+10,
      "predicted_flops_count": 5.2183040000000000e+06
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__14052554398038873058<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:128/input[1]:208/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 8955,
      "real_time": 7.8190777849803548e+04,
      "cpu_time": 8.4465597319852663e+04,
      "time_unit": "ns",
      "items_per_second": 6.6738100623884651e+10,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 2.0800000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 2.0800000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 5.2183040000000000e+06,
      "input_width": 1.4000000000000000e+01,
      "num_iterations": 8.9550000000000000e+03,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 2.0800000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 5.2183040000000000e+06,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 6.6738100623884651e+10,
      "predicted_flops_count": 5.2183040000000000e+06
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__13834392779313692946<CUDNN_ACTIVATION_RELU>/input[0]:1/input[1]:512/input[2]:28/input[3]:28/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 90702,
      "real_time": 7.7125633806631622e+03,
      "cpu_time": 1.3631545853457859e+04,
      "time_unit": "ns",
      "items_per_second": 5.2045990442866882e+10,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 4.0140800000000000e+05,
      "input_width": 2.8000000000000000e+01,
      "num_iterations": 9.0702000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 4.0140800000000000e+05,
      "output_width": 2.8000000000000000e+01,
      "predicted_flops": 5.2045990442866882e+10,
      "predicted_flops_count": 4.0140800000000000e+05
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__13834392779313692946<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1/input[1]:512/input[2]:28/input[3]:28/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 90708,
      "real_time": 7.7286522395035436e+03,
      "cpu_time": 1.3601470895619188e+04,
      "time_unit": "ns",
      "items_per_second": 5.1937645473072128e+10,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 4.0140800000000000e+05,
      "input_width": 2.8000000000000000e+01,
      "num_iterations": 9.0708000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 4.0140800000000000e+05,
      "output_width": 2.8000000000000000e+01,
      "predicted_flops": 5.1937645473072128e+10,
      "predicted_flops_count": 4.0140800000000000e+05
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__3117977759906910434<CUDNN_ACTIVATION_RELU>/input[0]:1/input[1]:256/input[2]:56/input[3]:56/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 44563,
      "real_time": 1.5734841780124818e+04,
      "cpu_time": 2.1876351524688638e+04,
      "time_unit": "ns",
      "items_per_second": 5.1021548943317795e+10,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 5.6000000000000000e+01,
      "input_size": 8.0281600000000000e+05,
      "input_width": 5.6000000000000000e+01,
      "num_iterations": 4.4563000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 5.6000000000000000e+01,
      "output_size": 8.0281600000000000e+05,
      "output_width": 5.6000000000000000e+01,
      "predicted_flops": 5.1021548943317795e+10,
      "predicted_flops_count": 8.0281600000000000e+05
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__3117977759906910434<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1/input[1]:256/input[2]:56/input[3]:56/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 44425,
      "real_time": 1.5758827195888553e+04,
      "cpu_time": 2.1895507146866363e+04,
      "time_unit": "ns",
      "items_per_second": 5.0943892589256454e+10,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 5.6000000000000000e+01,
      "input_size": 8.0281600000000000e+05,
      "input_width": 5.6000000000000000e+01,
      "num_iterations": 4.4425000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 5.6000000000000000e+01,
      "output_size": 8.0281600000000000e+05,
      "output_width": 5.6000000000000000e+01,
      "predicted_flops": 5.0943892589256454e+10,
      "predicted_flops_count": 8.0281600000000000e+05
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__3521402535742402018<CUDNN_ACTIVATION_RELU>/input[0]:1/input[1]:1024/input[2]:-1/input[3]:-1/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 112212,
      "real_time": 6.2391992895658941e+03,
      "cpu_time": 1.2088794415932180e+04,
      "time_unit": "ns",
      "items_per_second": 1.6412362427859664e+08,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 1.0240000000000000e+03,
      "input[2]": -1.0000000000000000e+00,
      "input[3]": -1.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 1.0240000000000000e+03,
      "input_height": 1.0000000000000000e+00,
      "input_size": 1.0240000000000000e+03,
      "input_width": 1.0000000000000000e+00,
      "num_iterations": 1.1221200000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 1.0240000000000000e+03,
      "output_height": 1.0000000000000000e+00,
      "output_size": 1.0240000000000000e+03,
      "output_width": 1.0000000000000000e+00,
      "predicted_flops": 1.6412362427859664e+08,
      "predicted_flops_count": 1.0240000000000000e+03
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__3521402535742402018<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1/input[1]:1024/input[2]:-1/input[3]:-1/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 112202,
      "real_time": 6.2285270361158455e+03,
      "cpu_time": 1.2068257490942387e+04,
      "time_unit": "ns",
      "items_per_second": 1.6440484147574222e+08,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 1.0240000000000000e+03,
      "input[2]": -1.0000000000000000e+00,
      "input[3]": -1.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 1.0240000000000000e+03,
      "input_height": 1.0000000000000000e+00,
      "input_size": 1.0240000000000000e+03,
      "input_width": 1.0000000000000000e+00,
      "num_iterations": 1.1220200000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 1.0240000000000000e+03,
      "output_height": 1.0000000000000000e+00,
      "output_size": 1.0240000000000000e+03,
      "output_width": 1.0000000000000000e+00,
      "predicted_flops": 1.6440484147574222e+08,
      "predicted_flops_count": 1.0240000000000000e+03
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__6807071951388914076<CUDNN_ACTIVATION_RELU>/input[0]:1/input[1]:384/input[2]:6/input[3]:6/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 111308,
      "real_time": 6.2857743107863162e+03,
      "cpu_time": 1.2118458367771736e+04,
      "time_unit": "ns",
      "items_per_second": 2.1992517256431203e+09,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 3.8400000000000000e+02,
      "input[2]": 6.0000000000000000e+00,
      "input[3]": 6.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 3.8400000000000000e+02,
      "input_height": 6.0000000000000000e+00,
      "input_size": 1.3824000000000000e+04,
      "input_width": 6.0000000000000000e+00,
      "num_iterations": 1.1130800000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 3.8400000000000000e+02,
      "output_height": 6.0000000000000000e+00,
      "output_size": 1.3824000000000000e+04,
      "output_width": 6.0000000000000000e+00,
      "predicted_flops": 2.1992517256431203e+09,
      "predicted_flops_count": 1.3824000000000000e+04
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__6807071951388914076<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1/input[1]:384/input[2]:6/input[3]:6/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 111390,
      "real_time": 6.2917993269182762e+03,
      "cpu_time": 1.2134551333129875e+04,
      "time_unit": "ns",
      "items_per_second": 2.1971457260018806e+09,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 3.8400000000000000e+02,
      "input[2]": 6.0000000000000000e+00,
      "input[3]": 6.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 3.8400000000000000e+02,
      "input_height": 6.0000000000000000e+00,
      "input_size": 1.3824000000000000e+04,
      "input_width": 6.0000000000000000e+00,
      "num_iterations": 1.1139000000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 3.8400000000000000e+02,
      "output_height": 6.0000000000000000e+00,
      "output_size": 1.3824000000000000e+04,
      "output_width": 6.0000000000000000e+00,
      "predicted_flops": 2.1971457260018806e+09,
      "predicted_flops_count": 1.3824000000000000e+04
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__17820315011612243101<CUDNN_ACTIVATION_RELU>/input[0]:128/input[1]:112/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 15547,
      "real_time": 4.5037613517633508e+04,
      "cpu_time": 5.1229014086212475e+04,
      "time_unit": "ns",
      "items_per_second": 6.2389096147376045e+10,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 1.1200000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 1.1200000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 2.8098560000000000e+06,
      "input_width": 1.4000000000000000e+01,
      "num_iterations": 1.5547000000000000e+04,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 1.1200000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 2.8098560000000000e+06,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 6.2389096147376045e+10,
      "predicted_flops_count": 2.8098560000000000e+06
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__17820315011612243101<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:128/input[1]:112/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 15520,
      "real_time": 4.5058398025025075e+04,
      "cpu_time": 5.1259181121129841e+04,
      "time_unit": "ns",
      "items_per_second": 6.2360317347266281e+10,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 1.1200000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 1.1200000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 2.8098560000000000e+06,
      "input_width": 1.4000000000000000e+01,
      "num_iterations": 1.5520000000000000e+04,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 1.1200000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 2.8098560000000000e+06,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 6.2360317347266281e+10,
      "predicted_flops_count": 2.8098560000000000e+06
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__293481316760285886<CUDNN_ACTIVATION_RELU>/input[0]:128/input[1]:1000/input[2]:13/input[3]:13/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 2267,
      "real_time": 3.0883785766924487e+05,
      "cpu_time": 3.1638668416393473e+05,
      "time_unit": "ns",
      "items_per_second": 7.0043226446568466e+10,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 1.0000000000000000e+03,
      "input[2]": 1.3000000000000000e+01,
      "input[3]": 1.3000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 1.0000000000000000e+03,
      "input_height": 1.3000000000000000e+01,
      "input_size": 2.1632000000000000e+07,
      "input_width": 1.3000000000000000e+01,
      "num_iterations": 2.2670000000000000e+03,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 1.0000000000000000e+03,
      "output_height": 1.3000000000000000e+01,
      "output_size": 2.1632000000000000e+07,
      "output_width": 1.3000000000000000e+01,
      "predicted_flops": 7.0043226446568466e+10,
      "predicted_flops_count": 2.1632000000000000e+07
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__293481316760285886<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:128/input[1]:1000/input[2]:13/input[3]:13/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 2266,
      "real_time": 3.0906074453825061e+05,
      "cpu_time": 3.1664841526970913e+05,
      "time_unit": "ns",
      "items_per_second": 6.9992713025781052e+10,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 1.0000000000000000e+03,
      "input[2]": 1.3000000000000000e+01,
      "input[3]": 1.3000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 1.0000000000000000e+03,
      "input_height": 1.3000000000000000e+01,
      "input_size": 2.1632000000000000e+07,
      "input_width": 1.3000000000000000e+01,
      "num_iterations": 2.2660000000000000e+03,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 1.0000000000000000e+03,
      "output_height": 1.3000000000000000e+01,
      "output_size": 2.1632000000000000e+07,
      "output_width": 1.3000000000000000e+01,
      "predicted_flops": 6.9992713025781052e+10,
      "predicted_flops_count": 2.1632000000000000e+07
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__502896168059433249<CUDNN_ACTIVATION_RELU>/input[0]:1/input[1]:128/input[2]:13/input[3]:13/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 110926,
      "real_time": 6.3108007066480750e+03,
      "cpu_time": 1.2159255548725312e+04,
      "time_unit": "ns",
      "items_per_second": 3.4277742247844872e+09,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 1.2800000000000000e+02,
      "input[2]": 1.3000000000000000e+01,
      "input[3]": 1.3000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 1.2800000000000000e+02,
      "input_height": 1.3000000000000000e+01,
      "input_size": 2.1632000000000000e+04,
      "input_width": 1.3000000000000000e+01,
      "num_iterations": 1.1092600000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 1.3000000000000000e+01,
      "output_size": 2.1632000000000000e+04,
      "output_width": 1.3000000000000000e+01,
      "predicted_flops": 3.4277742247844872e+09,
      "predicted_flops_count": 2.1632000000000000e+04
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__502896168059433249<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1/input[1]:128/input[2]:13/input[3]:13/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 110849,
      "real_time": 6.3200348519437966e+03,
      "cpu_time": 1.2165333931756046e+04,
      "time_unit": "ns",
      "items_per_second": 3.4227659351193042e+09,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 1.2800000000000000e+02,
      "input[2]": 1.3000000000000000e+01,
      "input[3]": 1.3000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 1.2800000000000000e+02,
      "input_height": 1.3000000000000000e+01,
      "input_size": 2.1632000000000000e+04,
      "input_width": 1.3000000000000000e+01,
      "num_iterations": 1.1084900000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 1.3000000000000000e+01,
      "output_size": 2.1632000000000000e+04,
      "output_width": 1.3000000000000000e+01,
      "predicted_flops": 3.4227659351193042e+09,
      "predicted_flops_count": 2.1632000000000000e+04
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__7051596880887468266<CUDNN_ACTIVATION_RELU>/input[0]:128/input[1]:8/input[2]:28/input[3]:28/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 44478,
      "real_time": 1.5745699586940284e+04,
      "cpu_time": 2.1880360582682664e+04,
      "time_unit": "ns",
      "items_per_second": 5.0986365868803154e+10,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 8.0000000000000000e+00,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 8.0000000000000000e+00,
      "input_height": 2.8000000000000000e+01,
      "input_size": 8.0281600000000000e+05,
      "input_width": 2.8000000000000000e+01,
      "num_iterations": 4.4478000000000000e+04,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 8.0000000000000000e+00,
      "output_height": 2.8000000000000000e+01,
      "output_size": 8.0281600000000000e+05,
      "output_width": 2.8000000000000000e+01,
      "predicted_flops": 5.0986365868803154e+10,
      "predicted_flops_count": 8.0281600000000000e+05
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__7051596880887468266<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:128/input[1]:8/input[2]:28/input[3]:28/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 44317,
      "real_time": 1.5787959886946095e+04,
      "cpu_time": 2.1924800505393134e+04,
      "time_unit": "ns",
      "items_per_second": 5.0849888506734138e+10,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 8.0000000000000000e+00,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 8.0000000000000000e+00,
      "input_height": 2.8000000000000000e+01,
      "input_size": 8.0281600000000000e+05,
      "input_width": 2.8000000000000000e+01,
      "num_iterations": 4.4317000000000000e+04,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 8.0000000000000000e+00,
      "output_height": 2.8000000000000000e+01,
      "output_size": 8.0281600000000000e+05,
      "output_width": 2.8000000000000000e+01,
      "predicted_flops": 5.0849888506734138e+10,
      "predicted_flops_count": 8.0281600000000000e+05
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__11362622006370161458<CUDNN_ACTIVATION_RELU>/input[0]:1/input[1]:576/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 103289,
      "real_time": 6.7481057828251396e+03,
      "cpu_time": 1.2608691641872781e+04,
      "time_unit": "ns",
      "items_per_second": 1.6730028193591143e+10,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 5.7600000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 5.7600000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 1.1289600000000000e+05,
      "input_width": 1.4000000000000000e+01,
      "num_iterations": 1.0328900000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 5.7600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 1.1289600000000000e+05,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 1.6730028193591143e+10,
      "predicted_flops_count": 1.1289600000000000e+05
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__11362622006370161458<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1/input[1]:576/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 104313,
      "real_time": 6.7102699946252906e+03,
      "cpu_time": 1.2564860515949400e+04,
      "time_unit": "ns",
      "items_per_second": 1.6824360285119085e+10,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 5.7600000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 5.7600000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 1.1289600000000000e+05,
      "input_width": 1.4000000000000000e+01,
      "num_iterations": 1.0431300000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 5.7600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 1.1289600000000000e+05,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 1.6824360285119085e+10,
      "predicted_flops_count": 1.1289600000000000e+05
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__2913345447427522790<CUDNN_ACTIVATION_RELU>/input[0]:1/input[1]:256/input[2]:28/input[3]:28/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 99033,
      "real_time": 7.1039364570026019e+03,
      "cpu_time": 1.2996382741052757e+04,
      "time_unit": "ns",
      "items_per_second": 2.8252504961831261e+10,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 2.0070400000000000e+05,
      "input_width": 2.8000000000000000e+01,
      "num_iterations": 9.9033000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 2.0070400000000000e+05,
      "output_width": 2.8000000000000000e+01,
      "predicted_flops": 2.8252504961831261e+10,
      "predicted_flops_count": 2.0070400000000000e+05
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__2913345447427522790<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1/input[1]:256/input[2]:28/input[3]:28/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 98838,
      "real_time": 7.0957477393496756e+03,
      "cpu_time": 1.2977539347224079e+04,
      "time_unit": "ns",
      "items_per_second": 2.8285109247470863e+10,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 2.0070400000000000e+05,
      "input_width": 2.8000000000000000e+01,
      "num_iterations": 9.8838000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 2.0070400000000000e+05,
      "output_width": 2.8000000000000000e+01,
      "predicted_flops": 2.8285109247470863e+10,
      "predicted_flops_count": 2.0070400000000000e+05
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__18314163827723913184<CUDNN_ACTIVATION_RELU>/input[0]:1/input[1]:288/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 109490,
      "real_time": 6.6026475437553136e+03,
      "cpu_time": 1.2455355594120956e+04,
      "time_unit": "ns",
      "items_per_second": 8.5492977818250618e+09,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 2.8800000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 2.8800000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 5.6448000000000000e+04,
      "input_width": 1.4000000000000000e+01,
      "num_iterations": 1.0949000000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 2.8800000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 5.6448000000000000e+04,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 8.5492977818250618e+09,
      "predicted_flops_count": 5.6448000000000000e+04
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__18314163827723913184<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1/input[1]:288/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 98163,
      "real_time": 6.6073176156765403e+03,
      "cpu_time": 1.2556859753723091e+04,
      "time_unit": "ns",
      "items_per_second": 8.5432551124939585e+09,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 2.8800000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 2.8800000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 5.6448000000000000e+04,
      "input_width": 1.4000000000000000e+01,
      "num_iterations": 9.8163000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 2.8800000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 5.6448000000000000e+04,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 8.5432551124939585e+09,
      "predicted_flops_count": 5.6448000000000000e+04
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__6404210537747550654<CUDNN_ACTIVATION_RELU>/input[0]:1/input[1]:256/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 110162,
      "real_time": 6.3566654886164724e+03,
      "cpu_time": 1.2219948439543608e+04,
      "time_unit": "ns",
      "items_per_second": 7.8934466647419577e+09,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 5.0176000000000000e+04,
      "input_width": 1.4000000000000000e+01,
      "num_iterations": 1.1016200000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 5.0176000000000000e+04,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 7.8934466647419577e+09,
      "predicted_flops_count": 5.0176000000000000e+04
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__6404210537747550654<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1/input[1]:256/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 110236,
      "real_time": 6.3766233135201101e+03,
      "cpu_time": 1.2244821818647133e+04,
      "time_unit": "ns",
      "items_per_second": 7.8687414220648336e+09,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 5.0176000000000000e+04,
      "input_width": 1.4000000000000000e+01,
      "num_iterations": 1.1023600000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 5.0176000000000000e+04,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 7.8687414220648336e+09,
      "predicted_flops_count": 5.0176000000000000e+04
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__9727171201631670604<CUDNN_ACTIVATION_RELU>/input[0]:1/input[1]:288/input[2]:28/input[3]:28/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 97018,
      "real_time": 7.1343166292740088e+03,
      "cpu_time": 1.3067510915490344e+04,
      "time_unit": "ns",
      "items_per_second": 3.1648721487004799e+10,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 2.8800000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 2.8800000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 2.2579200000000000e+05,
      "input_width": 2.8000000000000000e+01,
      "num_iterations": 9.7018000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 2.8800000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 2.2579200000000000e+05,
      "output_width": 2.8000000000000000e+01,
      "predicted_flops": 3.1648721487004799e+10,
      "predicted_flops_count": 2.2579200000000000e+05
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__9727171201631670604<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1/input[1]:288/input[2]:28/input[3]:28/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 98070,
      "real_time": 7.1514688977587393e+03,
      "cpu_time": 1.3079261089025140e+04,
      "time_unit": "ns",
      "items_per_second": 3.1572814372549801e+10,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 2.8800000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 2.8800000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 2.2579200000000000e+05,
      "input_width": 2.8000000000000000e+01,
      "num_iterations": 9.8070000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 2.8800000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 2.2579200000000000e+05,
      "output_width": 2.8000000000000000e+01,
      "predicted_flops": 3.1572814372549801e+10,
      "predicted_flops_count": 2.2579200000000000e+05
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__1151422461893528909<CUDNN_ACTIVATION_RELU>/input[0]:1/input[1]:208/input[2]:13/input[3]:13/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 103253,
      "real_time": 6.3601299991133692e+03,
      "cpu_time": 1.2240253426049294e+04,
      "time_unit": "ns",
      "items_per_second": 5.5269310540665588e+09,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 2.0800000000000000e+02,
      "input[2]": 1.3000000000000000e+01,
      "input[3]": 1.3000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 2.0800000000000000e+02,
      "input_height": 1.3000000000000000e+01,
      "input_size": 3.5152000000000000e+04,
      "input_width": 1.3000000000000000e+01,
      "num_iterations": 1.0325300000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 2.0800000000000000e+02,
      "output_height": 1.3000000000000000e+01,
      "output_size": 3.5152000000000000e+04,
      "output_width": 1.3000000000000000e+01,
      "predicted_flops": 5.5269310540665588e+09,
      "predicted_flops_count": 3.5152000000000000e+04
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__1151422461893528909<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1/input[1]:208/input[2]:13/input[3]:13/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 110625,
      "real_time": 6.3351843379117945e+03,
      "cpu_time": 1.2201853731112813e+04,
      "time_unit": "ns",
      "items_per_second": 5.5486941066006632e+09,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 2.0800000000000000e+02,
      "input[2]": 1.3000000000000000e+01,
      "input[3]": 1.3000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 2.0800000000000000e+02,
      "input_height": 1.3000000000000000e+01,
      "input_size": 3.5152000000000000e+04,
      "input_width": 1.3000000000000000e+01,
      "num_iterations": 1.1062500000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 2.0800000000000000e+02,
      "output_height": 1.3000000000000000e+01,
      "output_size": 3.5152000000000000e+04,
      "output_width": 1.3000000000000000e+01,
      "predicted_flops": 5.5486941066006632e+09,
      "predicted_flops_count": 3.5152000000000000e+04
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__10421255572259519808<CUDNN_ACTIVATION_RELU>/input[0]:1/input[1]:192/input[2]:13/input[3]:13/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 110991,
      "real_time": 6.5753659323302027e+03,
      "cpu_time": 1.2580453928720503e+04,
      "time_unit": "ns",
      "items_per_second": 4.9347823883774261e+09,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 1.9200000000000000e+02,
      "input[2]": 1.3000000000000000e+01,
      "input[3]": 1.3000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 1.9200000000000000e+02,
      "input_height": 1.3000000000000000e+01,
      "input_size": 3.2448000000000000e+04,
      "input_width": 1.3000000000000000e+01,
      "num_iterations": 1.1099100000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 1.9200000000000000e+02,
      "output_height": 1.3000000000000000e+01,
      "output_size": 3.2448000000000000e+04,
      "output_width": 1.3000000000000000e+01,
      "predicted_flops": 4.9347823883774261e+09,
      "predicted_flops_count": 3.2448000000000000e+04
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__10421255572259519808<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1/input[1]:192/input[2]:13/input[3]:13/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 110441,
      "real_time": 6.4489642016893813e+03,
      "cpu_time": 1.2362253230190647e+04,
      "time_unit": "ns",
      "items_per_second": 5.0315056783072023e+09,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 1.9200000000000000e+02,
      "input[2]": 1.3000000000000000e+01,
      "input[3]": 1.3000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 1.9200000000000000e+02,
      "input_height": 1.3000000000000000e+01,
      "input_size": 3.2448000000000000e+04,
      "input_width": 1.3000000000000000e+01,
      "num_iterations": 1.1044100000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 1.9200000000000000e+02,
      "output_height": 1.3000000000000000e+01,
      "output_size": 3.2448000000000000e+04,
      "output_width": 1.3000000000000000e+01,
      "predicted_flops": 5.0315056783072023e+09,
      "predicted_flops_count": 3.2448000000000000e+04
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__8114687299045535362<CUDNN_ACTIVATION_RELU>/input[0]:128/input[1]:64/input[2]:111/input[3]:111/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 482,
      "real_time": 1.4522761778898258e+06,
      "cpu_time": 1.4896241307059010e+06,
      "time_unit": "ns",
      "items_per_second": 6.9500301345338974e+10,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 1.1100000000000000e+02,
      "input[3]": 1.1100000000000000e+02,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 1.1100000000000000e+02,
      "input_size": 1.0093363200000000e+08,
      "input_width": 1.1100000000000000e+02,
      "num_iterations": 4.8200000000000000e+02,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 1.1100000000000000e+02,
      "output_size": 1.0093363200000000e+08,
      "output_width": 1.1100000000000000e+02,
      "predicted_flops": 6.9500301345338974e+10,
      "predicted_flops_count": 1.0093363200000000e+08
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__8114687299045535362<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:128/input[1]:64/input[2]:111/input[3]:111/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 482,
      "real_time": 1.4525543469877688e+06,
      "cpu_time": 1.4898918651457753e+06,
      "time_unit": "ns",
      "items_per_second": 6.9486991801243698e+10,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 1.1100000000000000e+02,
      "input[3]": 1.1100000000000000e+02,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 1.1100000000000000e+02,
      "input_size": 1.0093363200000000e+08,
      "input_width": 1.1100000000000000e+02,
      "num_iterations": 4.8200000000000000e+02,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 1.1100000000000000e+02,
      "output_size": 1.0093363200000000e+08,
      "output_width": 1.1100000000000000e+02,
      "predicted_flops": 6.9486991801243698e+10,
      "predicted_flops_count": 1.0093363200000000e+08
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__13566731214077738676<CUDNN_ACTIVATION_RELU>/input[0]:1/input[1]:320/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 109687,
      "real_time": 6.3805337705167522e+03,
      "cpu_time": 1.2242731481378611e+04,
      "time_unit": "ns",
      "items_per_second": 9.8298986034393120e+09,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 3.2000000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 3.2000000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 6.2720000000000000e+04,
      "input_width": 1.4000000000000000e+01,
      "num_iterations": 1.0968700000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 3.2000000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 6.2720000000000000e+04,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 9.8298986034393120e+09,
      "predicted_flops_count": 6.2720000000000000e+04
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__13566731214077738676<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1/input[1]:320/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 109448,
      "real_time": 6.4061855849083040e+03,
      "cpu_time": 1.2249668701097436e+04,
      "time_unit": "ns",
      "items_per_second": 9.7905374686234226e+09,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 3.2000000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 3.2000000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 6.2720000000000000e+04,
      "input_width": 1.4000000000000000e+01,
      "num_iterations": 1.0944800000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 3.2000000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 6.2720000000000000e+04,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 9.7905374686234226e+09,
      "predicted_flops_count": 6.2720000000000000e+04
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__15129018207522813395<CUDNN_ACTIVATION_RELU>/input[0]:128/input[1]:144/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 12446,
      "real_time": 5.6199215536144737e+04,
      "cpu_time": 6.2411799453578271e+04,
      "time_unit": "ns",
      "items_per_second": 6.4283317223111351e+10,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 1.4400000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 1.4400000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 3.6126720000000000e+06,
      "input_width": 1.4000000000000000e+01,
      "num_iterations": 1.2446000000000000e+04,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 1.4400000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 3.6126720000000000e+06,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 6.4283317223111351e+10,
      "predicted_flops_count": 3.6126720000000000e+06
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__15129018207522813395<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:128/input[1]:144/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 12450,
      "real_time": 5.6234801331409682e+04,
      "cpu_time": 6.2465571968124117e+04,
      "time_unit": "ns",
      "items_per_second": 6.4242638267882690e+10,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 1.4400000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 1.4400000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 3.6126720000000000e+06,
      "input_width": 1.4000000000000000e+01,
      "num_iterations": 1.2450000000000000e+04,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 1.4400000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 3.6126720000000000e+06,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 6.4242638267882690e+10,
      "predicted_flops_count": 3.6126720000000000e+06
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__4660233605633977696<CUDNN_ACTIVATION_RELU>/input[0]:1/input[1]:320/input[2]:28/input[3]:28/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 96862,
      "real_time": 7.1648708727778730e+03,
      "cpu_time": 1.3124281637800530e+04,
      "time_unit": "ns",
      "items_per_second": 3.5015285614314499e+10,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 3.2000000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 3.2000000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 2.5088000000000000e+05,
      "input_width": 2.8000000000000000e+01,
      "num_iterations": 9.6862000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 3.2000000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 2.5088000000000000e+05,
      "output_width": 2.8000000000000000e+01,
      "predicted_flops": 3.5015285614314499e+10,
      "predicted_flops_count": 2.5088000000000000e+05
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__4660233605633977696<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1/input[1]:320/input[2]:28/input[3]:28/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 97030,
      "real_time": 7.2052154775112376e+03,
      "cpu_time": 1.3149837823320060e+04,
      "time_unit": "ns",
      "items_per_second": 3.4819222378989388e+10,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 3.2000000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 3.2000000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 2.5088000000000000e+05,
      "input_width": 2.8000000000000000e+01,
      "num_iterations": 9.7030000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 3.2000000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 2.5088000000000000e+05,
      "output_width": 2.8000000000000000e+01,
      "predicted_flops": 3.4819222378989388e+10,
      "predicted_flops_count": 2.5088000000000000e+05
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__1684633279113941651<CUDNN_ACTIVATION_RELU>/input[0]:1/input[1]:608/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 102846,
      "real_time": 6.8248347510448948e+03,
      "cpu_time": 1.2689851049143290e+04,
      "time_unit": "ns",
      "items_per_second": 1.7460935589943062e+10,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 6.0800000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 6.0800000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 1.1916800000000000e+05,
      "input_width": 1.4000000000000000e+01,
      "num_iterations": 1.0284600000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 6.0800000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 1.1916800000000000e+05,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 1.7460935589943062e+10,
      "predicted_flops_count": 1.1916800000000000e+05
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__1684633279113941651<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1/input[1]:608/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 103070,
      "real_time": 6.8071536110038924e+03,
      "cpu_time": 1.2653568982267949e+04,
      "time_unit": "ns",
      "items_per_second": 1.7506289237745815e+10,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 6.0800000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 6.0800000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 1.1916800000000000e+05,
      "input_width": 1.4000000000000000e+01,
      "num_iterations": 1.0307000000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 6.0800000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 1.1916800000000000e+05,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 1.7506289237745815e+10,
      "predicted_flops_count": 1.1916800000000000e+05
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__15770506917211922534<CUDNN_ACTIVATION_RELU>/input[0]:128/input[1]:96/input[2]:54/input[3]:54/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 1378,
      "real_time": 5.0771578129905404e+05,
      "cpu_time": 5.1764026487688808e+05,
      "time_unit": "ns",
      "items_per_second": 7.0574540559523010e+10,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 9.6000000000000000e+01,
      "input[2]": 5.4000000000000000e+01,
      "input[3]": 5.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 9.6000000000000000e+01,
      "input_height": 5.4000000000000000e+01,
      "input_size": 3.5831808000000000e+07,
      "input_width": 5.4000000000000000e+01,
      "num_iterations": 1.3780000000000000e+03,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 9.6000000000000000e+01,
      "output_height": 5.4000000000000000e+01,
      "output_size": 3.5831808000000000e+07,
      "output_width": 5.4000000000000000e+01,
      "predicted_flops": 7.0574540559523010e+10,
      "predicted_flops_count": 3.5831808000000000e+07
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__15770506917211922534<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:128/input[1]:96/input[2]:54/input[3]:54/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 1378,
      "real_time": 5.0784547569761419e+05,
      "cpu_time": 5.1778098548632563e+05,
      "time_unit": "ns",
      "items_per_second": 7.0556517119265015e+10,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 9.6000000000000000e+01,
      "input[2]": 5.4000000000000000e+01,
      "input[3]": 5.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 9.6000000000000000e+01,
      "input_height": 5.4000000000000000e+01,
      "input_size": 3.5831808000000000e+07,
      "input_width": 5.4000000000000000e+01,
      "num_iterations": 1.3780000000000000e+03,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 9.6000000000000000e+01,
      "output_height": 5.4000000000000000e+01,
      "output_size": 3.5831808000000000e+07,
      "output_width": 5.4000000000000000e+01,
      "predicted_flops": 7.0556517119265015e+10,
      "predicted_flops_count": 3.5831808000000000e+07
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__14137666469494555182<CUDNN_ACTIVATION_RELU>/input[0]:1/input[1]:352/input[2]:28/input[3]:28/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 96464,
      "real_time": 7.2653843975353657e+03,
      "cpu_time": 1.3177124834111381e+04,
      "time_unit": "ns",
      "items_per_second": 3.7983950318391487e+10,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 3.5200000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 3.5200000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 2.7596800000000000e+05,
      "input_width": 2.8000000000000000e+01,
      "num_iterations": 9.6464000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 3.5200000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 2.7596800000000000e+05,
      "output_width": 2.8000000000000000e+01,
      "predicted_flops": 3.7983950318391487e+10,
      "predicted_flops_count": 2.7596800000000000e+05
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__14137666469494555182<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1/input[1]:352/input[2]:28/input[3]:28/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 94990,
      "real_time": 7.3246942933919845e+03,
      "cpu_time": 1.3185634782616762e+04,
      "time_unit": "ns",
      "items_per_second": 3.7676384698944519e+10,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 3.5200000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 3.5200000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 2.7596800000000000e+05,
      "input_width": 2.8000000000000000e+01,
      "num_iterations": 9.4990000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 3.5200000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 2.7596800000000000e+05,
      "output_width": 2.8000000000000000e+01,
      "predicted_flops": 3.7676384698944519e+10,
      "predicted_flops_count": 2.7596800000000000e+05
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__4491877982492294206<CUDNN_ACTIVATION_RELU>/input[0]:128/input[1]:256/input[2]:27/input[3]:27/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 2056,
      "real_time": 3.4044544552366796e+05,
      "cpu_time": 3.4828272568044293e+05,
      "time_unit": "ns",
      "items_per_second": 7.0166519523432129e+10,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 2.7000000000000000e+01,
      "input[3]": 2.7000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 2.7000000000000000e+01,
      "input_size": 2.3887872000000000e+07,
      "input_width": 2.7000000000000000e+01,
      "num_iterations": 2.0560000000000000e+03,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 2.7000000000000000e+01,
      "output_size": 2.3887872000000000e+07,
      "output_width": 2.7000000000000000e+01,
      "predicted_flops": 7.0166519523432129e+10,
      "predicted_flops_count": 2.3887872000000000e+07
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__4491877982492294206<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:128/input[1]:256/input[2]:27/input[3]:27/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 2055,
      "real_time": 3.4065778170929826e+05,
      "cpu_time": 3.4851455912447325e+05,
      "time_unit": "ns",
      "items_per_second": 7.0122783868723755e+10,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 2.7000000000000000e+01,
      "input[3]": 2.7000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 2.7000000000000000e+01,
      "input_size": 2.3887872000000000e+07,
      "input_width": 2.7000000000000000e+01,
      "num_iterations": 2.0550000000000000e+03,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 2.7000000000000000e+01,
      "output_size": 2.3887872000000000e+07,
      "output_width": 2.7000000000000000e+01,
      "predicted_flops": 7.0122783868723755e+10,
      "predicted_flops_count": 2.3887872000000000e+07
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__3759549508981743739<CUDNN_ACTIVATION_RELU>/input[0]:128/input[1]:288/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 6591,
      "real_time": 1.0619978008982139e+05,
      "cpu_time": 1.1252955727506695e+05,
      "time_unit": "ns",
      "items_per_second": 6.8035395119358688e+10,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 2.8800000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 2.8800000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 7.2253440000000000e+06,
      "input_width": 1.4000000000000000e+01,
      "num_iterations": 6.5910000000000000e+03,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 2.8800000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 7.2253440000000000e+06,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 6.8035395119358688e+10,
      "predicted_flops_count": 7.2253440000000000e+06
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__3759549508981743739<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:128/input[1]:288/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 6592,
      "real_time": 1.0619980070948513e+05,
      "cpu_time": 1.1253244250617964e+05,
      "time_unit": "ns",
      "items_per_second": 6.8035381909663734e+10,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 2.8800000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 2.8800000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 7.2253440000000000e+06,
      "input_width": 1.4000000000000000e+01,
      "num_iterations": 6.5920000000000000e+03,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 2.8800000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 7.2253440000000000e+06,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 6.8035381909663734e+10,
      "predicted_flops_count": 7.2253440000000000e+06
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__13782369319766857365<CUDNN_ACTIVATION_RELU>/input[0]:128/input[1]:384/input[2]:12/input[3]:12/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 6724,
      "real_time": 1.0410837757214773e+05,
      "cpu_time": 1.1042745017852387e+05,
      "time_unit": "ns",
      "items_per_second": 6.7985767957002129e+10,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 3.8400000000000000e+02,
      "input[2]": 1.2000000000000000e+01,
      "input[3]": 1.2000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 3.8400000000000000e+02,
      "input_height": 1.2000000000000000e+01,
      "input_size": 7.0778880000000000e+06,
      "input_width": 1.2000000000000000e+01,
      "num_iterations": 6.7240000000000000e+03,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 3.8400000000000000e+02,
      "output_height": 1.2000000000000000e+01,
      "output_size": 7.0778880000000000e+06,
      "output_width": 1.2000000000000000e+01,
      "predicted_flops": 6.7985767957002129e+10,
      "predicted_flops_count": 7.0778880000000000e+06
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__13782369319766857365<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:128/input[1]:384/input[2]:12/input[3]:12/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 6728,
      "real_time": 1.0410645824326060e+05,
      "cpu_time": 1.1043035329979910e+05,
      "time_unit": "ns",
      "items_per_second": 6.7987021357132690e+10,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 3.8400000000000000e+02,
      "input[2]": 1.2000000000000000e+01,
      "input[3]": 1.2000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 3.8400000000000000e+02,
      "input_height": 1.2000000000000000e+01,
      "input_size": 7.0778880000000000e+06,
      "input_width": 1.2000000000000000e+01,
      "num_iterations": 6.7280000000000000e+03,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 3.8400000000000000e+02,
      "output_height": 1.2000000000000000e+01,
      "output_size": 7.0778880000000000e+06,
      "output_width": 1.2000000000000000e+01,
      "predicted_flops": 6.7987021357132690e+10,
      "predicted_flops_count": 7.0778880000000000e+06
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__14974818703643426192<CUDNN_ACTIVATION_RELU>/input[0]:1/input[1]:96/input[2]:13/input[3]:13/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 110902,
      "real_time": 6.3024641496724144e+03,
      "cpu_time": 1.2147740915355611e+04,
      "time_unit": "ns",
      "items_per_second": 2.5742312236465926e+09,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 9.6000000000000000e+01,
      "input[2]": 1.3000000000000000e+01,
      "input[3]": 1.3000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 9.6000000000000000e+01,
      "input_height": 1.3000000000000000e+01,
      "input_size": 1.6224000000000000e+04,
      "input_width": 1.3000000000000000e+01,
      "num_iterations": 1.1090200000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 9.6000000000000000e+01,
      "output_height": 1.3000000000000000e+01,
      "output_size": 1.6224000000000000e+04,
      "output_width": 1.3000000000000000e+01,
      "predicted_flops": 2.5742312236465926e+09,
      "predicted_flops_count": 1.6224000000000000e+04
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__14974818703643426192<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1/input[1]:96/input[2]:13/input[3]:13/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 111135,
      "real_time": 6.3084274009872579e+03,
      "cpu_time": 1.2157434417585970e+04,
      "time_unit": "ns",
      "items_per_second": 2.5717978457612071e+09,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 9.6000000000000000e+01,
      "input[2]": 1.3000000000000000e+01,
      "input[3]": 1.3000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 9.6000000000000000e+01,
      "input_height": 1.3000000000000000e+01,
      "input_size": 1.6224000000000000e+04,
      "input_width": 1.3000000000000000e+01,
      "num_iterations": 1.1113500000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 9.6000000000000000e+01,
      "output_height": 1.3000000000000000e+01,
      "output_size": 1.6224000000000000e+04,
      "output_width": 1.3000000000000000e+01,
      "predicted_flops": 2.5717978457612071e+09,
      "predicted_flops_count": 1.6224000000000000e+04
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__3246023937145201288<CUDNN_ACTIVATION_RELU>/input[0]:1/input[1]:640/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 102670,
      "real_time": 6.8205110232806965e+03,
      "cpu_time": 1.2671806165421664e+04,
      "time_unit": "ns",
      "items_per_second": 1.8391583793623543e+10,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 6.4000000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 6.4000000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 1.2544000000000000e+05,
      "input_width": 1.4000000000000000e+01,
      "num_iterations": 1.0267000000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 6.4000000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 1.2544000000000000e+05,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 1.8391583793623543e+10,
      "predicted_flops_count": 1.2544000000000000e+05
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__3246023937145201288<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1/input[1]:640/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 102960,
      "real_time": 6.8169819228000588e+03,
      "cpu_time": 1.2653918949103774e+04,
      "time_unit": "ns",
      "items_per_second": 1.8401104978796223e+10,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 6.4000000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 6.4000000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 1.2544000000000000e+05,
      "input_width": 1.4000000000000000e+01,
      "num_iterations": 1.0296000000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 6.4000000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 1.2544000000000000e+05,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 1.8401104978796223e+10,
      "predicted_flops_count": 1.2544000000000000e+05
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__2835781425470952885<CUDNN_ACTIVATION_RELU>/input[0]:1/input[1]:16/input[2]:13/input[3]:13/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 111996,
      "real_time": 6.2586895856530082e+03,
      "cpu_time": 1.2099435131627179e+04,
      "time_unit": "ns",
      "items_per_second": 4.3203932117011595e+08,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 1.6000000000000000e+01,
      "input[2]": 1.3000000000000000e+01,
      "input[3]": 1.3000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 1.6000000000000000e+01,
      "input_height": 1.3000000000000000e+01,
      "input_size": 2.7040000000000000e+03,
      "input_width": 1.3000000000000000e+01,
      "num_iterations": 1.1199600000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 1.6000000000000000e+01,
      "output_height": 1.3000000000000000e+01,
      "output_size": 2.7040000000000000e+03,
      "output_width": 1.3000000000000000e+01,
      "predicted_flops": 4.3203932117011595e+08,
      "predicted_flops_count": 2.7040000000000000e+03
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__2835781425470952885<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1/input[1]:16/input[2]:13/input[3]:13/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 111805,
      "real_time": 6.2559601340614372e+03,
      "cpu_time": 1.2100768239327150e+04,
      "time_unit": "ns",
      "items_per_second": 4.3222781828127378e+08,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 1.6000000000000000e+01,
      "input[2]": 1.3000000000000000e+01,
      "input[3]": 1.3000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 1.6000000000000000e+01,
      "input_height": 1.3000000000000000e+01,
      "input_size": 2.7040000000000000e+03,
      "input_width": 1.3000000000000000e+01,
      "num_iterations": 1.1180500000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 1.6000000000000000e+01,
      "output_height": 1.3000000000000000e+01,
      "output_size": 2.7040000000000000e+03,
      "output_width": 1.3000000000000000e+01,
      "predicted_flops": 4.3222781828127378e+08,
      "predicted_flops_count": 2.7040000000000000e+03
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__6935698784193640648<CUDNN_ACTIVATION_RELU>/input[0]:128/input[1]:32/input[2]:112/input[3]:112/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 960,
      "real_time": 7.2970450570816558e+05,
      "cpu_time": 7.4369844687479280e+05,
      "time_unit": "ns",
      "items_per_second": 7.0412370484318695e+10,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 3.2000000000000000e+01,
      "input[2]": 1.1200000000000000e+02,
      "input[3]": 1.1200000000000000e+02,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 3.2000000000000000e+01,
      "input_height": 1.1200000000000000e+02,
      "input_size": 5.1380224000000000e+07,
      "input_width": 1.1200000000000000e+02,
      "num_iterations": 9.6000000000000000e+02,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 3.2000000000000000e+01,
      "output_height": 1.1200000000000000e+02,
      "output_size": 5.1380224000000000e+07,
      "output_width": 1.1200000000000000e+02,
      "predicted_flops": 7.0412370484318695e+10,
      "predicted_flops_count": 5.1380224000000000e+07
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__6935698784193640648<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:128/input[1]:32/input[2]:112/input[3]:112/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 959,
      "real_time": 7.2988556976924429e+05,
      "cpu_time": 7.4384139520283835e+05,
      "time_unit": "ns",
      "items_per_second": 7.0394903157551163e+10,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 3.2000000000000000e+01,
      "input[2]": 1.1200000000000000e+02,
      "input[3]": 1.1200000000000000e+02,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 3.2000000000000000e+01,
      "input_height": 1.1200000000000000e+02,
      "input_size": 5.1380224000000000e+07,
      "input_width": 1.1200000000000000e+02,
      "num_iterations": 9.5900000000000000e+02,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 3.2000000000000000e+01,
      "output_height": 1.1200000000000000e+02,
      "output_size": 5.1380224000000000e+07,
      "output_width": 1.1200000000000000e+02,
      "predicted_flops": 7.0394903157551163e+10,
      "predicted_flops_count": 5.1380224000000000e+07
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__6649550724734871123<CUDNN_ACTIVATION_RELU>/input[0]:128/input[1]:96/input[2]:112/input[3]:112/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 311,
      "real_time": 2.2523355396266822e+06,
      "cpu_time": 2.3334462604506812e+06,
      "time_unit": "ns",
      "items_per_second": 6.8435927635164139e+10,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 9.6000000000000000e+01,
      "input[2]": 1.1200000000000000e+02,
      "input[3]": 1.1200000000000000e+02,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 9.6000000000000000e+01,
      "input_height": 1.1200000000000000e+02,
      "input_size": 1.5414067200000000e+08,
      "input_width": 1.1200000000000000e+02,
      "num_iterations": 3.1100000000000000e+02,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 9.6000000000000000e+01,
      "output_height": 1.1200000000000000e+02,
      "output_size": 1.5414067200000000e+08,
      "output_width": 1.1200000000000000e+02,
      "predicted_flops": 6.8435927635164139e+10,
      "predicted_flops_count": 1.5414067200000000e+08
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__6649550724734871123<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:128/input[1]:96/input[2]:112/input[3]:112/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 311,
      "real_time": 2.2527546175662726e+06,
      "cpu_time": 2.3341261897112080e+06,
      "time_unit": "ns",
      "items_per_second": 6.8423196560361908e+10,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 9.6000000000000000e+01,
      "input[2]": 1.1200000000000000e+02,
      "input[3]": 1.1200000000000000e+02,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 9.6000000000000000e+01,
      "input_height": 1.1200000000000000e+02,
      "input_size": 1.5414067200000000e+08,
      "input_width": 1.1200000000000000e+02,
      "num_iterations": 3.1100000000000000e+02,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 9.6000000000000000e+01,
      "output_height": 1.1200000000000000e+02,
      "output_size": 1.5414067200000000e+08,
      "output_width": 1.1200000000000000e+02,
      "predicted_flops": 6.8423196560361908e+10,
      "predicted_flops_count": 1.5414067200000000e+08
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__8530913494105235961<CUDNN_ACTIVATION_RELU>/input[0]:1/input[1]:48/input[2]:13/input[3]:13/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 111539,
      "real_time": 6.2950922573233520e+03,
      "cpu_time": 1.2147826544937183e+04,
      "time_unit": "ns",
      "items_per_second": 1.2886228935823712e+09,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 4.8000000000000000e+01,
      "input[2]": 1.3000000000000000e+01,
      "input[3]": 1.3000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 4.8000000000000000e+01,
      "input_height": 1.3000000000000000e+01,
      "input_size": 8.1120000000000000e+03,
      "input_width": 1.3000000000000000e+01,
      "num_iterations": 1.1153900000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 4.8000000000000000e+01,
      "output_height": 1.3000000000000000e+01,
      "output_size": 8.1120000000000000e+03,
      "output_width": 1.3000000000000000e+01,
      "predicted_flops": 1.2886228935823712e+09,
      "predicted_flops_count": 8.1120000000000000e+03
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__8530913494105235961<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1/input[1]:48/input[2]:13/input[3]:13/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 111198,
      "real_time": 6.2833640083442497e+03,
      "cpu_time": 1.2126507644045734e+04,
      "time_unit": "ns",
      "items_per_second": 1.2910281800047457e+09,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 4.8000000000000000e+01,
      "input[2]": 1.3000000000000000e+01,
      "input[3]": 1.3000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 4.8000000000000000e+01,
      "input_height": 1.3000000000000000e+01,
      "input_size": 8.1120000000000000e+03,
      "input_width": 1.3000000000000000e+01,
      "num_iterations": 1.1119800000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 4.8000000000000000e+01,
      "output_height": 1.3000000000000000e+01,
      "output_size": 8.1120000000000000e+03,
      "output_width": 1.3000000000000000e+01,
      "predicted_flops": 1.2910281800047457e+09,
      "predicted_flops_count": 8.1120000000000000e+03
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__5021995321031533874<CUDNN_ACTIVATION_RELU>/input[0]:1/input[1]:128/input[2]:27/input[3]:27/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 105578,
      "real_time": 6.6171153211143437e+03,
      "cpu_time": 1.2480904648684582e+04,
      "time_unit": "ns",
      "items_per_second": 1.4101613085426167e+10,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 1.2800000000000000e+02,
      "input[2]": 2.7000000000000000e+01,
      "input[3]": 2.7000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 1.2800000000000000e+02,
      "input_height": 2.7000000000000000e+01,
      "input_size": 9.3312000000000000e+04,
      "input_width": 2.7000000000000000e+01,
      "num_iterations": 1.0557800000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 2.7000000000000000e+01,
      "output_size": 9.3312000000000000e+04,
      "output_width": 2.7000000000000000e+01,
      "predicted_flops": 1.4101613085426167e+10,
      "predicted_flops_count": 9.3312000000000000e+04
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__5021995321031533874<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1/input[1]:128/input[2]:27/input[3]:27/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 105778,
      "real_time": 6.5391770002726780e+03,
      "cpu_time": 1.2405841479270794e+04,
      "time_unit": "ns",
      "items_per_second": 1.4269685618864418e+10,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 1.2800000000000000e+02,
      "input[2]": 2.7000000000000000e+01,
      "input[3]": 2.7000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 1.2800000000000000e+02,
      "input_height": 2.7000000000000000e+01,
      "input_size": 9.3312000000000000e+04,
      "input_width": 2.7000000000000000e+01,
      "num_iterations": 1.0577800000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 2.7000000000000000e+01,
      "output_size": 9.3312000000000000e+04,
      "output_width": 2.7000000000000000e+01,
      "predicted_flops": 1.4269685618864418e+10,
      "predicted_flops_count": 9.3312000000000000e+04
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__10528096359655546081<CUDNN_ACTIVATION_RELU>/input[0]:1/input[1]:672/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 102495,
      "real_time": 6.8475698800442142e+03,
      "cpu_time": 1.2695262481127558e+04,
      "time_unit": "ns",
      "items_per_second": 1.9234852992715942e+10,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 6.7200000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 6.7200000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 1.3171200000000000e+05,
      "input_width": 1.4000000000000000e+01,
      "num_iterations": 1.0249500000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 6.7200000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 1.3171200000000000e+05,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 1.9234852992715942e+10,
      "predicted_flops_count": 1.3171200000000000e+05
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__10528096359655546081<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1/input[1]:672/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 102086,
      "real_time": 6.8305293440878722e+03,
      "cpu_time": 1.2662552054191652e+04,
      "time_unit": "ns",
      "items_per_second": 1.9282839347436901e+10,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 6.7200000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 6.7200000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 1.3171200000000000e+05,
      "input_width": 1.4000000000000000e+01,
      "num_iterations": 1.0208600000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 6.7200000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 1.3171200000000000e+05,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 1.9282839347436901e+10,
      "predicted_flops_count": 1.3171200000000000e+05
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__13812236619334176983<CUDNN_ACTIVATION_RELU>/input[0]:128/input[1]:256/input[2]:12/input[3]:12/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 9801,
      "real_time": 7.1262426838768049e+04,
      "cpu_time": 7.7506554331212727e+04,
      "time_unit": "ns",
      "items_per_second": 6.6214304077460930e+10,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 1.2000000000000000e+01,
      "input[3]": 1.2000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 1.2000000000000000e+01,
      "input_size": 4.7185920000000000e+06,
      "input_width": 1.2000000000000000e+01,
      "num_iterations": 9.8010000000000000e+03,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 1.2000000000000000e+01,
      "output_size": 4.7185920000000000e+06,
      "output_width": 1.2000000000000000e+01,
      "predicted_flops": 6.6214304077460930e+10,
      "predicted_flops_count": 4.7185920000000000e+06
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__13812236619334176983<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:128/input[1]:256/input[2]:12/input[3]:12/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 9821,
      "real_time": 7.1289425249401960e+04,
      "cpu_time": 7.7541677222365892e+04,
      "time_unit": "ns",
      "items_per_second": 6.6189227693900986e+10,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 1.2000000000000000e+01,
      "input[3]": 1.2000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 1.2000000000000000e+01,
      "input_size": 4.7185920000000000e+06,
      "input_width": 1.2000000000000000e+01,
      "num_iterations": 9.8210000000000000e+03,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 1.2000000000000000e+01,
      "output_size": 4.7185920000000000e+06,
      "output_width": 1.2000000000000000e+01,
      "predicted_flops": 6.6189227693900986e+10,
      "predicted_flops_count": 4.7185920000000000e+06
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__9092731666121438591<CUDNN_ACTIVATION_RELU>/input[0]:128/input[1]:320/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 5967,
      "real_time": 1.1724178801570345e+05,
      "cpu_time": 1.2361232545657110e+05,
      "time_unit": "ns",
      "items_per_second": 6.8475243647126076e+10,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 3.2000000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 3.2000000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 8.0281600000000000e+06,
      "input_width": 1.4000000000000000e+01,
      "num_iterations": 5.9670000000000000e+03,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 3.2000000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 8.0281600000000000e+06,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 6.8475243647126076e+10,
      "predicted_flops_count": 8.0281600000000000e+06
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__9092731666121438591<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:128/input[1]:320/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 5963,
      "real_time": 1.1726930295491064e+05,
      "cpu_time": 1.2362504762701916e+05,
      "time_unit": "ns",
      "items_per_second": 6.8459177275802353e+10,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 3.2000000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 3.2000000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 8.0281600000000000e+06,
      "input_width": 1.4000000000000000e+01,
      "num_iterations": 5.9630000000000000e+03,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 3.2000000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 8.0281600000000000e+06,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 6.8459177275802353e+10,
      "predicted_flops_count": 8.0281600000000000e+06
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__12802031666541440495<CUDNN_ACTIVATION_RELU>/input[0]:128/input[1]:96/input[2]:56/input[3]:56/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 1279,
      "real_time": 5.4689398744639428e+05,
      "cpu_time": 5.5743550899109698e+05,
      "time_unit": "ns",
      "items_per_second": 7.0461860771100830e+10,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 9.6000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 9.6000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 3.8535168000000000e+07,
      "input_width": 5.6000000000000000e+01,
      "num_iterations": 1.2790000000000000e+03,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 9.6000000000000000e+01,
      "output_height": 5.6000000000000000e+01,
      "output_size": 3.8535168000000000e+07,
      "output_width": 5.6000000000000000e+01,
      "predicted_flops": 7.0461860771100830e+10,
      "predicted_flops_count": 3.8535168000000000e+07
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__12802031666541440495<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:128/input[1]:96/input[2]:56/input[3]:56/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 1279,
      "real_time": 5.4723047573983006e+05,
      "cpu_time": 5.5775233072680631e+05,
      "time_unit": "ns",
      "items_per_second": 7.0418534252688049e+10,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 9.6000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 9.6000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 3.8535168000000000e+07,
      "input_width": 5.6000000000000000e+01,
      "num_iterations": 1.2790000000000000e+03,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 9.6000000000000000e+01,
      "output_height": 5.6000000000000000e+01,
      "output_size": 3.8535168000000000e+07,
      "output_width": 5.6000000000000000e+01,
      "predicted_flops": 7.0418534252688049e+10,
      "predicted_flops_count": 3.8535168000000000e+07
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__15025665147266655593<CUDNN_ACTIVATION_RELU>/input[0]:1/input[1]:832/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 99933,
      "real_time": 6.9987891370960961e+03,
      "cpu_time": 1.2814727987708737e+04,
      "time_unit": "ns",
      "items_per_second": 2.3300030448932922e+10,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 8.3200000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 8.3200000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 1.6307200000000000e+05,
      "input_width": 1.4000000000000000e+01,
      "num_iterations": 9.9933000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 8.3200000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 1.6307200000000000e+05,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 2.3300030448932922e+10,
      "predicted_flops_count": 1.6307200000000000e+05
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__15025665147266655593<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1/input[1]:832/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 99563,
      "real_time": 7.1380860248781664e+03,
      "cpu_time": 1.3036355523627204e+04,
      "time_unit": "ns",
      "items_per_second": 2.2845339693532669e+10,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 8.3200000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 8.3200000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 1.6307200000000000e+05,
      "input_width": 1.4000000000000000e+01,
      "num_iterations": 9.9563000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 8.3200000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 1.6307200000000000e+05,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 2.2845339693532669e+10,
      "predicted_flops_count": 1.6307200000000000e+05
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__9445731292345734694<CUDNN_ACTIVATION_RELU>/input[0]:1/input[1]:352/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 108702,
      "real_time": 6.4406758297058468e+03,
      "cpu_time": 1.2300276867040629e+04,
      "time_unit": "ns",
      "items_per_second": 1.0711919342655527e+10,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 3.5200000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 3.5200000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 6.8992000000000000e+04,
      "input_width": 1.4000000000000000e+01,
      "num_iterations": 1.0870200000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 3.5200000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 6.8992000000000000e+04,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 1.0711919342655527e+10,
      "predicted_flops_count": 6.8992000000000000e+04
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__9445731292345734694<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1/input[1]:352/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 108457,
      "real_time": 6.4582339572936844e+03,
      "cpu_time": 1.2307039084628143e+04,
      "time_unit": "ns",
      "items_per_second": 1.0682796637009884e+10,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 3.5200000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 3.5200000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 6.8992000000000000e+04,
      "input_width": 1.4000000000000000e+01,
      "num_iterations": 1.0845700000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 3.5200000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 6.8992000000000000e+04,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 1.0682796637009884e+10,
      "predicted_flops_count": 6.8992000000000000e+04
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__14740440911401069196<CUDNN_ACTIVATION_RELU>/input[0]:1/input[1]:384/input[2]:28/input[3]:28/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 94357,
      "real_time": 7.4092787690593705e+03,
      "cpu_time": 1.3256667157720414e+04,
      "time_unit": "ns",
      "items_per_second": 4.0632294907999519e+10,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 3.8400000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 3.8400000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 3.0105600000000000e+05,
      "input_width": 2.8000000000000000e+01,
      "num_iterations": 9.4357000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 3.8400000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 3.0105600000000000e+05,
      "output_width": 2.8000000000000000e+01,
      "predicted_flops": 4.0632294907999519e+10,
      "predicted_flops_count": 3.0105600000000000e+05
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__14740440911401069196<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1/input[1]:384/input[2]:28/input[3]:28/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 94319,
      "real_time": 7.4277720951325618e+03,
      "cpu_time": 1.3243550748084237e+04,
      "time_unit": "ns",
      "items_per_second": 4.0531130484911186e+10,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 3.8400000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 3.8400000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 3.0105600000000000e+05,
      "input_width": 2.8000000000000000e+01,
      "num_iterations": 9.4319000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 3.8400000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 3.0105600000000000e+05,
      "output_width": 2.8000000000000000e+01,
      "predicted_flops": 4.0531130484911186e+10,
      "predicted_flops_count": 3.0105600000000000e+05
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__3544833755246448921<CUDNN_ACTIVATION_RELU>/input[0]:1/input[1]:704/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 101743,
      "real_time": 6.8144054965464438e+03,
      "cpu_time": 1.2656546809068224e+04,
      "time_unit": "ns",
      "items_per_second": 2.0248868381831783e+10,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 7.0400000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 7.0400000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 1.3798400000000000e+05,
      "input_width": 1.4000000000000000e+01,
      "num_iterations": 1.0174300000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 7.0400000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 1.3798400000000000e+05,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 2.0248868381831783e+10,
      "predicted_flops_count": 1.3798400000000000e+05
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__3544833755246448921<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1/input[1]:704/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 102050,
      "real_time": 6.8581642208006660e+03,
      "cpu_time": 1.2685678775107839e+04,
      "time_unit": "ns",
      "items_per_second": 2.0119669864640667e+10,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 7.0400000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 7.0400000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 1.3798400000000000e+05,
      "input_width": 1.4000000000000000e+01,
      "num_iterations": 1.0205000000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 7.0400000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 1.3798400000000000e+05,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 2.0119669864640667e+10,
      "predicted_flops_count": 1.3798400000000000e+05
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__17207803664042782686<CUDNN_ACTIVATION_RELU>/input[0]:1/input[1]:112/input[2]:13/input[3]:13/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 111228,
      "real_time": 6.2787882807582391e+03,
      "cpu_time": 1.2118279075352495e+04,
      "time_unit": "ns",
      "items_per_second": 3.0145944015991273e+09,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 1.1200000000000000e+02,
      "input[2]": 1.3000000000000000e+01,
      "input[3]": 1.3000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 1.1200000000000000e+02,
      "input_height": 1.3000000000000000e+01,
      "input_size": 1.8928000000000000e+04,
      "input_width": 1.3000000000000000e+01,
      "num_iterations": 1.1122800000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 1.1200000000000000e+02,
      "output_height": 1.3000000000000000e+01,
      "output_size": 1.8928000000000000e+04,
      "output_width": 1.3000000000000000e+01,
      "predicted_flops": 3.0145944015991273e+09,
      "predicted_flops_count": 1.8928000000000000e+04
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__17207803664042782686<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1/input[1]:112/input[2]:13/input[3]:13/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 111515,
      "real_time": 6.2759181719386670e+03,
      "cpu_time": 1.2112265847660230e+04,
      "time_unit": "ns",
      "items_per_second": 3.0159730387550659e+09,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 1.1200000000000000e+02,
      "input[2]": 1.3000000000000000e+01,
      "input[3]": 1.3000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 1.1200000000000000e+02,
      "input_height": 1.3000000000000000e+01,
      "input_size": 1.8928000000000000e+04,
      "input_width": 1.3000000000000000e+01,
      "num_iterations": 1.1151500000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 1.1200000000000000e+02,
      "output_height": 1.3000000000000000e+01,
      "output_size": 1.8928000000000000e+04,
      "output_width": 1.3000000000000000e+01,
      "predicted_flops": 3.0159730387550659e+09,
      "predicted_flops_count": 1.8928000000000000e+04
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__11873764108174407600<CUDNN_ACTIVATION_RELU>/input[0]:1/input[1]:416/input[2]:28/input[3]:28/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 94303,
      "real_time": 7.4540502366695991e+03,
      "cpu_time": 1.3278409859615886e+04,
      "time_unit": "ns",
      "items_per_second": 4.3753931036788681e+10,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 4.1600000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 4.1600000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 3.2614400000000000e+05,
      "input_width": 2.8000000000000000e+01,
      "num_iterations": 9.4303000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 4.1600000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 3.2614400000000000e+05,
      "output_width": 2.8000000000000000e+01,
      "predicted_flops": 4.3753931036788681e+10,
      "predicted_flops_count": 3.2614400000000000e+05
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__11873764108174407600<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1/input[1]:416/input[2]:28/input[3]:28/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 94351,
      "real_time": 7.4638373224275574e+03,
      "cpu_time": 1.3286677205340082e+04,
      "time_unit": "ns",
      "items_per_second": 4.3696557938098801e+10,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 4.1600000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 4.1600000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 3.2614400000000000e+05,
      "input_width": 2.8000000000000000e+01,
      "num_iterations": 9.4351000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 4.1600000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 3.2614400000000000e+05,
      "output_width": 2.8000000000000000e+01,
      "predicted_flops": 4.3696557938098801e+10,
      "predicted_flops_count": 3.2614400000000000e+05
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__6598087145846086276<CUDNN_ACTIVATION_RELU>/input[0]:1/input[1]:384/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 108370,
      "real_time": 6.4557991353166808e+03,
      "cpu_time": 1.2294219451788626e+04,
      "time_unit": "ns",
      "items_per_second": 1.1658355289938559e+10,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 3.8400000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 3.8400000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 7.5264000000000000e+04,
      "input_width": 1.4000000000000000e+01,
      "num_iterations": 1.0837000000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 3.8400000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 7.5264000000000000e+04,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 1.1658355289938559e+10,
      "predicted_flops_count": 7.5264000000000000e+04
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__6598087145846086276<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1/input[1]:384/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 108709,
      "real_time": 6.4321416634200486e+03,
      "cpu_time": 1.2271352298438938e+04,
      "time_unit": "ns",
      "items_per_second": 1.1701234820126955e+10,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 3.8400000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 3.8400000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 7.5264000000000000e+04,
      "input_width": 1.4000000000000000e+01,
      "num_iterations": 1.0870900000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 3.8400000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 7.5264000000000000e+04,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 1.1701234820126955e+10,
      "predicted_flops_count": 7.5264000000000000e+04
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__8085962806674819134<CUDNN_ACTIVATION_RELU>/input[0]:1/input[1]:736/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 101187,
      "real_time": 7.0935877015381120e+03,
      "cpu_time": 1.2970645992148868e+04,
      "time_unit": "ns",
      "items_per_second": 2.0336112848611259e+10,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 7.3600000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 7.3600000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 1.4425600000000000e+05,
      "input_width": 1.4000000000000000e+01,
      "num_iterations": 1.0118700000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 7.3600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 1.4425600000000000e+05,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 2.0336112848611259e+10,
      "predicted_flops_count": 1.4425600000000000e+05
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__8085962806674819134<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1/input[1]:736/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 97623,
      "real_time": 7.0294108007598579e+03,
      "cpu_time": 1.2874957714915628e+04,
      "time_unit": "ns",
      "items_per_second": 2.0521776872736813e+10,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 7.3600000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 7.3600000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 1.4425600000000000e+05,
      "input_width": 1.4000000000000000e+01,
      "num_iterations": 9.7623000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 7.3600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 1.4425600000000000e+05,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 2.0521776872736813e+10,
      "predicted_flops_count": 1.4425600000000000e+05
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__1603106815824656010<CUDNN_ACTIVATION_RELU>/input[0]:1/input[1]:4096/input[2]:-1/input[3]:-1/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 112135,
      "real_time": 6.2384656231096342e+03,
      "cpu_time": 1.2078594577971024e+04,
      "time_unit": "ns",
      "items_per_second": 6.5657170327698338e+08,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 4.0960000000000000e+03,
      "input[2]": -1.0000000000000000e+00,
      "input[3]": -1.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 4.0960000000000000e+03,
      "input_height": 1.0000000000000000e+00,
      "input_size": 4.0960000000000000e+03,
      "input_width": 1.0000000000000000e+00,
      "num_iterations": 1.1213500000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 4.0960000000000000e+03,
      "output_height": 1.0000000000000000e+00,
      "output_size": 4.0960000000000000e+03,
      "output_width": 1.0000000000000000e+00,
      "predicted_flops": 6.5657170327698338e+08,
      "predicted_flops_count": 4.0960000000000000e+03
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__1603106815824656010<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1/input[1]:4096/input[2]:-1/input[3]:-1/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 112032,
      "real_time": 6.2285181960348564e+03,
      "cpu_time": 1.2059638281788255e+04,
      "time_unit": "ns",
      "items_per_second": 6.5762029925633979e+08,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 4.0960000000000000e+03,
      "input[2]": -1.0000000000000000e+00,
      "input[3]": -1.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 4.0960000000000000e+03,
      "input_height": 1.0000000000000000e+00,
      "input_size": 4.0960000000000000e+03,
      "input_width": 1.0000000000000000e+00,
      "num_iterations": 1.1203200000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 4.0960000000000000e+03,
      "output_height": 1.0000000000000000e+00,
      "output_size": 4.0960000000000000e+03,
      "output_width": 1.0000000000000000e+00,
      "predicted_flops": 6.5762029925633979e+08,
      "predicted_flops_count": 4.0960000000000000e+03
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__5442124813259541838<CUDNN_ACTIVATION_RELU>/input[0]:1/input[1]:768/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 100470,
      "real_time": 6.9436223629358328e+03,
      "cpu_time": 1.2755284990577265e+04,
      "time_unit": "ns",
      "items_per_second": 2.1678598306771290e+10,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 7.6800000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 7.6800000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 1.5052800000000000e+05,
      "input_width": 1.4000000000000000e+01,
      "num_iterations": 1.0047000000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 7.6800000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 1.5052800000000000e+05,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 2.1678598306771290e+10,
      "predicted_flops_count": 1.5052800000000000e+05
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__5442124813259541838<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1/input[1]:768/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 100725,
      "real_time": 6.9525029426224037e+03,
      "cpu_time": 1.2751649183320284e+04,
      "time_unit": "ns",
      "items_per_second": 2.1650907772679428e+10,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 7.6800000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 7.6800000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 1.5052800000000000e+05,
      "input_width": 1.4000000000000000e+01,
      "num_iterations": 1.0072500000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 7.6800000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 1.5052800000000000e+05,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 2.1650907772679428e+10,
      "predicted_flops_count": 1.5052800000000000e+05
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__11476792763544506720<CUDNN_ACTIVATION_RELU>/input[0]:1/input[1]:416/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 107134,
      "real_time": 6.5751147648644010e+03,
      "cpu_time": 1.2424943631332715e+04,
      "time_unit": "ns",
      "items_per_second": 1.2400696096698706e+10,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 4.1600000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 4.1600000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 8.1536000000000000e+04,
      "input_width": 1.4000000000000000e+01,
      "num_iterations": 1.0713400000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 4.1600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 8.1536000000000000e+04,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 1.2400696096698706e+10,
      "predicted_flops_count": 8.1536000000000000e+04
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__11476792763544506720<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1/input[1]:416/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 107381,
      "real_time": 6.5101952171421899e+03,
      "cpu_time": 1.2346241662905337e+04,
      "time_unit": "ns",
      "items_per_second": 1.2524355611534523e+10,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 4.1600000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 4.1600000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 8.1536000000000000e+04,
      "input_width": 1.4000000000000000e+01,
      "num_iterations": 1.0738100000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 4.1600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 8.1536000000000000e+04,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 1.2524355611534523e+10,
      "predicted_flops_count": 8.1536000000000000e+04
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__14488049760001578203<CUDNN_ACTIVATION_RELU>/input[0]:128/input[1]:144/input[2]:28/input[3]:28/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 3369,
      "real_time": 2.0773729359319599e+05,
      "cpu_time": 2.1452079311358189e+05,
      "time_unit": "ns",
      "items_per_second": 6.9562319552974594e+10,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 1.4400000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 1.4400000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 1.4450688000000000e+07,
      "input_width": 2.8000000000000000e+01,
      "num_iterations": 3.3690000000000000e+03,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 1.4400000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 1.4450688000000000e+07,
      "output_width": 2.8000000000000000e+01,
      "predicted_flops": 6.9562319552974594e+10,
      "predicted_flops_count": 1.4450688000000000e+07
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__14488049760001578203<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:128/input[1]:144/input[2]:28/input[3]:28/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 3369,
      "real_time": 2.0780401010319625e+05,
      "cpu_time": 2.1460510982523891e+05,
      "time_unit": "ns",
      "items_per_second": 6.9539986224634125e+10,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 1.4400000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 1.4400000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 1.4450688000000000e+07,
      "input_width": 2.8000000000000000e+01,
      "num_iterations": 3.3690000000000000e+03,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 1.4400000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 1.4450688000000000e+07,
      "output_width": 2.8000000000000000e+01,
      "predicted_flops": 6.9539986224634125e+10,
      "predicted_flops_count": 1.4450688000000000e+07
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__11887735352365997151<CUDNN_ACTIVATION_RELU>/input[0]:128/input[1]:144/input[2]:56/input[3]:56/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 853,
      "real_time": 8.2117104926064680e+05,
      "cpu_time": 8.3723162368139077e+05,
      "time_unit": "ns",
      "items_per_second": 7.0390635485802307e+10,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 1.4400000000000000e+02,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 1.4400000000000000e+02,
      "input_height": 5.6000000000000000e+01,
      "input_size": 5.7802752000000000e+07,
      "input_width": 5.6000000000000000e+01,
      "num_iterations": 8.5300000000000000e+02,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 1.4400000000000000e+02,
      "output_height": 5.6000000000000000e+01,
      "output_size": 5.7802752000000000e+07,
      "output_width": 5.6000000000000000e+01,
      "predicted_flops": 7.0390635485802307e+10,
      "predicted_flops_count": 5.7802752000000000e+07
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__11887735352365997151<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:128/input[1]:144/input[2]:56/input[3]:56/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 852,
      "real_time": 8.2122601923683635e+05,
      "cpu_time": 8.3733839788882423e+05,
      "time_unit": "ns",
      "items_per_second": 7.0385923784679855e+10,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 1.4400000000000000e+02,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 1.4400000000000000e+02,
      "input_height": 5.6000000000000000e+01,
      "input_size": 5.7802752000000000e+07,
      "input_width": 5.6000000000000000e+01,
      "num_iterations": 8.5200000000000000e+02,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 1.4400000000000000e+02,
      "output_height": 5.6000000000000000e+01,
      "output_size": 5.7802752000000000e+07,
      "output_width": 5.6000000000000000e+01,
      "predicted_flops": 7.0385923784679855e+10,
      "predicted_flops_count": 5.7802752000000000e+07
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__18294223596520119380<CUDNN_ACTIVATION_RELU>/input[0]:128/input[1]:32/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 44439,
      "real_time": 1.5753236801590185e+04,
      "cpu_time": 2.1874776637706538e+04,
      "time_unit": "ns",
      "items_per_second": 5.0961971187975861e+10,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 3.2000000000000000e+01,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 3.2000000000000000e+01,
      "input_height": 1.4000000000000000e+01,
      "input_size": 8.0281600000000000e+05,
      "input_width": 1.4000000000000000e+01,
      "num_iterations": 4.4439000000000000e+04,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 3.2000000000000000e+01,
      "output_height": 1.4000000000000000e+01,
      "output_size": 8.0281600000000000e+05,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 5.0961971187975861e+10,
      "predicted_flops_count": 8.0281600000000000e+05
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__18294223596520119380<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:128/input[1]:32/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 44419,
      "real_time": 1.5765464197252861e+04,
      "cpu_time": 2.1885547941118333e+04,
      "time_unit": "ns",
      "items_per_second": 5.0922446047601387e+10,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 3.2000000000000000e+01,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 3.2000000000000000e+01,
      "input_height": 1.4000000000000000e+01,
      "input_size": 8.0281600000000000e+05,
      "input_width": 1.4000000000000000e+01,
      "num_iterations": 4.4419000000000000e+04,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 3.2000000000000000e+01,
      "output_height": 1.4000000000000000e+01,
      "output_size": 8.0281600000000000e+05,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 5.0922446047601387e+10,
      "predicted_flops_count": 8.0281600000000000e+05
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__8096921656341651302<CUDNN_ACTIVATION_RELU>/input[0]:128/input[1]:256/input[2]:26/input[3]:26/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 2216,
      "real_time": 3.1582342018362804e+05,
      "cpu_time": 3.2344088131764735e+05,
      "time_unit": "ns",
      "items_per_second": 7.0137825710077896e+10,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 2.6000000000000000e+01,
      "input[3]": 2.6000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 2.6000000000000000e+01,
      "input_size": 2.2151168000000000e+07,
      "input_width": 2.6000000000000000e+01,
      "num_iterations": 2.2160000000000000e+03,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 2.6000000000000000e+01,
      "output_size": 2.2151168000000000e+07,
      "output_width": 2.6000000000000000e+01,
      "predicted_flops": 7.0137825710077896e+10,
      "predicted_flops_count": 2.2151168000000000e+07
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__8096921656341651302<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:128/input[1]:256/input[2]:26/input[3]:26/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 2214,
      "real_time": 3.1597343183125940e+05,
      "cpu_time": 3.2358658626929577e+05,
      "time_unit": "ns",
      "items_per_second": 7.0104527053494415e+10,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 2.6000000000000000e+01,
      "input[3]": 2.6000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 2.6000000000000000e+01,
      "input_size": 2.2151168000000000e+07,
      "input_width": 2.6000000000000000e+01,
      "num_iterations": 2.2140000000000000e+03,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 2.6000000000000000e+01,
      "output_size": 2.2151168000000000e+07,
      "output_width": 2.6000000000000000e+01,
      "predicted_flops": 7.0104527053494415e+10,
      "predicted_flops_count": 2.2151168000000000e+07
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__18246384279302888895<CUDNN_ACTIVATION_RELU>/input[0]:1/input[1]:800/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 100068,
      "real_time": 6.9942795192097810e+03,
      "cpu_time": 1.2801998470981604e+04,
      "time_unit": "ns",
      "items_per_second": 2.2418320510261131e+10,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 8.0000000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 8.0000000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 1.5680000000000000e+05,
      "input_width": 1.4000000000000000e+01,
      "num_iterations": 1.0006800000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 8.0000000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 1.5680000000000000e+05,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 2.2418320510261131e+10,
      "predicted_flops_count": 1.5680000000000000e+05
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__18246384279302888895<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1/input[1]:800/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 99732,
      "real_time": 7.0216575110484746e+03,
      "cpu_time": 1.2831443267998366e+04,
      "time_unit": "ns",
      "items_per_second": 2.2330909725129360e+10,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 8.0000000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 8.0000000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 1.5680000000000000e+05,
      "input_width": 1.4000000000000000e+01,
      "num_iterations": 9.9732000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 8.0000000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 1.5680000000000000e+05,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 2.2330909725129360e+10,
      "predicted_flops_count": 1.5680000000000000e+05
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__2320220655716854409<CUDNN_ACTIVATION_RELU>/input[0]:1/input[1]:448/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 106253,
      "real_time": 6.5717314813293342e+03,
      "cpu_time": 1.2425031980348638e+04,
      "time_unit": "ns",
      "items_per_second": 1.3361471059715017e+10,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 4.4800000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 4.4800000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 8.7808000000000000e+04,
      "input_width": 1.4000000000000000e+01,
      "num_iterations": 1.0625300000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 4.4800000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 8.7808000000000000e+04,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 1.3361471059715017e+10,
      "predicted_flops_count": 8.7808000000000000e+04
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__2320220655716854409<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1/input[1]:448/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 107009,
      "real_time": 6.5263891521533169e+03,
      "cpu_time": 1.2356578147778559e+04,
      "time_unit": "ns",
      "items_per_second": 1.3454300372362659e+10,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 4.4800000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 4.4800000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 8.7808000000000000e+04,
      "input_width": 1.4000000000000000e+01,
      "num_iterations": 1.0700900000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 4.4800000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 8.7808000000000000e+04,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 1.3454300372362659e+10,
      "predicted_flops_count": 8.7808000000000000e+04
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__2206057058500228769<CUDNN_ACTIVATION_RELU>/input[0]:1/input[1]:480/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 105446,
      "real_time": 6.6180899547140443e+03,
      "cpu_time": 1.2474270138298683e+04,
      "time_unit": "ns",
      "items_per_second": 1.4215581934329424e+10,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 4.8000000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 4.8000000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 9.4080000000000000e+04,
      "input_width": 1.4000000000000000e+01,
      "num_iterations": 1.0544600000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 4.8000000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 9.4080000000000000e+04,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 1.4215581934329424e+10,
      "predicted_flops_count": 9.4080000000000000e+04
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__2206057058500228769<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1/input[1]:480/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 107136,
      "real_time": 6.5545009798424835e+03,
      "cpu_time": 1.2402659162089276e+04,
      "time_unit": "ns",
      "items_per_second": 1.4353495451344172e+10,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 4.8000000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 4.8000000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 9.4080000000000000e+04,
      "input_width": 1.4000000000000000e+01,
      "num_iterations": 1.0713600000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 4.8000000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 9.4080000000000000e+04,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 1.4353495451344172e+10,
      "predicted_flops_count": 9.4080000000000000e+04
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__14060889412066880601<CUDNN_ACTIVATION_RELU>/input[0]:128/input[1]:128/input[2]:400/input[3]:400/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD failed to cudnnSetTensor4dDescriptor",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__14060889412066880601<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:128/input[1]:128/input[2]:400/input[3]:400/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD failed to cudnnSetTensor4dDescriptor",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__13236108144488237476<CUDNN_ACTIVATION_RELU>/input[0]:128/input[1]:32/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 98737,
      "real_time": 7.0822809986337952e+03,
      "cpu_time": 1.2937835664381573e+04,
      "time_unit": "ns",
      "items_per_second": 2.8338892517638985e+10,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 3.2000000000000000e+01,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 3.2000000000000000e+01,
      "input_height": 7.0000000000000000e+00,
      "input_size": 2.0070400000000000e+05,
      "input_width": 7.0000000000000000e+00,
      "num_iterations": 9.8737000000000000e+04,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 3.2000000000000000e+01,
      "output_height": 7.0000000000000000e+00,
      "output_size": 2.0070400000000000e+05,
      "output_width": 7.0000000000000000e+00,
      "predicted_flops": 2.8338892517638985e+10,
      "predicted_flops_count": 2.0070400000000000e+05
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__13236108144488237476<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:128/input[1]:32/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 98674,
      "real_time": 7.1142836712110338e+03,
      "cpu_time": 1.2988175527591655e+04,
      "time_unit": "ns",
      "items_per_second": 2.8211413724220390e+10,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 3.2000000000000000e+01,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 3.2000000000000000e+01,
      "input_height": 7.0000000000000000e+00,
      "input_size": 2.0070400000000000e+05,
      "input_width": 7.0000000000000000e+00,
      "num_iterations": 9.8674000000000000e+04,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 3.2000000000000000e+01,
      "output_height": 7.0000000000000000e+00,
      "output_size": 2.0070400000000000e+05,
      "output_width": 7.0000000000000000e+00,
      "predicted_flops": 2.8211413724220390e+10,
      "predicted_flops_count": 2.0070400000000000e+05
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__16474615529544097758<CUDNN_ACTIVATION_RELU>/input[0]:1/input[1]:512/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 111004,
      "real_time": 6.3090152354959528e+03,
      "cpu_time": 1.2152392111973681e+04,
      "time_unit": "ns",
      "items_per_second": 3.9765318458654552e+09,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 2.5088000000000000e+04,
      "input_width": 7.0000000000000000e+00,
      "num_iterations": 1.1100400000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 2.5088000000000000e+04,
      "output_width": 7.0000000000000000e+00,
      "predicted_flops": 3.9765318458654552e+09,
      "predicted_flops_count": 2.5088000000000000e+04
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__16474615529544097758<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1/input[1]:512/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 110960,
      "real_time": 6.3196199645658135e+03,
      "cpu_time": 1.2160906642040753e+04,
      "time_unit": "ns",
      "items_per_second": 3.9698589694742284e+09,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 2.5088000000000000e+04,
      "input_width": 7.0000000000000000e+00,
      "num_iterations": 1.1096000000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 2.5088000000000000e+04,
      "output_width": 7.0000000000000000e+00,
      "predicted_flops": 3.9698589694742284e+09,
      "predicted_flops_count": 2.5088000000000000e+04
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__4596287659301054462<CUDNN_ACTIVATION_RELU>/input[0]:1/input[1]:576/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 110670,
      "real_time": 6.4149134479872719e+03,
      "cpu_time": 1.2301033640633092e+04,
      "time_unit": "ns",
      "items_per_second": 4.3997475926749249e+09,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 5.7600000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 5.7600000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 2.8224000000000000e+04,
      "input_width": 7.0000000000000000e+00,
      "num_iterations": 1.1067000000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 5.7600000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 2.8224000000000000e+04,
      "output_width": 7.0000000000000000e+00,
      "predicted_flops": 4.3997475926749249e+09,
      "predicted_flops_count": 2.8224000000000000e+04
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__4596287659301054462<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1/input[1]:576/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 110486,
      "real_time": 6.3288198623593644e+03,
      "cpu_time": 1.2175584363582444e+04,
      "time_unit": "ns",
      "items_per_second": 4.4595992007707701e+09,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 5.7600000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 5.7600000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 2.8224000000000000e+04,
      "input_width": 7.0000000000000000e+00,
      "num_iterations": 1.1048600000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 5.7600000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 2.8224000000000000e+04,
      "output_width": 7.0000000000000000e+00,
      "predicted_flops": 4.4595992007707701e+09,
      "predicted_flops_count": 2.8224000000000000e+04
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__1911803411335583173<CUDNN_ACTIVATION_RELU>/input[0]:1/input[1]:448/input[2]:28/input[3]:28/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 93165,
      "real_time": 7.5191183159928059e+03,
      "cpu_time": 1.3375759523525381e+04,
      "time_unit": "ns",
      "items_per_second": 4.6711859720699738e+10,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 4.4800000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 4.4800000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 3.5123200000000000e+05,
      "input_width": 2.8000000000000000e+01,
      "num_iterations": 9.3165000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 4.4800000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 3.5123200000000000e+05,
      "output_width": 2.8000000000000000e+01,
      "predicted_flops": 4.6711859720699738e+10,
      "predicted_flops_count": 3.5123200000000000e+05
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__1911803411335583173<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1/input[1]:448/input[2]:28/input[3]:28/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 92716,
      "real_time": 7.9143448857048852e+03,
      "cpu_time": 1.3821768648429457e+04,
      "time_unit": "ns",
      "items_per_second": 4.4379162782557686e+10,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 4.4800000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 4.4800000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 3.5123200000000000e+05,
      "input_width": 2.8000000000000000e+01,
      "num_iterations": 9.2716000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 4.4800000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 3.5123200000000000e+05,
      "output_width": 2.8000000000000000e+01,
      "predicted_flops": 4.4379162782557686e+10,
      "predicted_flops_count": 3.5123200000000000e+05
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__6323109827671691149<CUDNN_ACTIVATION_RELU>/input[0]:1/input[1]:896/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 98940,
      "real_time": 7.1994049995894256e+03,
      "cpu_time": 1.3056178997380919e+04,
      "time_unit": "ns",
      "items_per_second": 2.4393126933408409e+10,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 8.9600000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 8.9600000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 1.7561600000000000e+05,
      "input_width": 1.4000000000000000e+01,
      "num_iterations": 9.8940000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 8.9600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 1.7561600000000000e+05,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 2.4393126933408409e+10,
      "predicted_flops_count": 1.7561600000000000e+05
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__6323109827671691149<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1/input[1]:896/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 99375,
      "real_time": 7.0545203017682979e+03,
      "cpu_time": 1.2894005514393619e+04,
      "time_unit": "ns",
      "items_per_second": 2.4894109377781475e+10,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 8.9600000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 8.9600000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 1.7561600000000000e+05,
      "input_width": 1.4000000000000000e+01,
      "num_iterations": 9.9375000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 8.9600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 1.7561600000000000e+05,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 2.4894109377781475e+10,
      "predicted_flops_count": 1.7561600000000000e+05
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__6719237062006914636<CUDNN_ACTIVATION_RELU>/input[0]:1/input[1]:288/input[2]:13/input[3]:13/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 110078,
      "real_time": 6.3619912385405305e+03,
      "cpu_time": 1.2207503879020549e+04,
      "time_unit": "ns",
      "items_per_second": 7.6504349306783352e+09,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 2.8800000000000000e+02,
      "input[2]": 1.3000000000000000e+01,
      "input[3]": 1.3000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 2.8800000000000000e+02,
      "input_height": 1.3000000000000000e+01,
      "input_size": 4.8672000000000000e+04,
      "input_width": 1.3000000000000000e+01,
      "num_iterations": 1.1007800000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 2.8800000000000000e+02,
      "output_height": 1.3000000000000000e+01,
      "output_size": 4.8672000000000000e+04,
      "output_width": 1.3000000000000000e+01,
      "predicted_flops": 7.6504349306783352e+09,
      "predicted_flops_count": 4.8672000000000000e+04
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__6719237062006914636<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1/input[1]:288/input[2]:13/input[3]:13/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 110035,
      "real_time": 6.3666986652486021e+03,
      "cpu_time": 1.2217895324173422e+04,
      "time_unit": "ns",
      "items_per_second": 7.6447783316126986e+09,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 2.8800000000000000e+02,
      "input[2]": 1.3000000000000000e+01,
      "input[3]": 1.3000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 2.8800000000000000e+02,
      "input_height": 1.3000000000000000e+01,
      "input_size": 4.8672000000000000e+04,
      "input_width": 1.3000000000000000e+01,
      "num_iterations": 1.1003500000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 2.8800000000000000e+02,
      "output_height": 1.3000000000000000e+01,
      "output_size": 4.8672000000000000e+04,
      "output_width": 1.3000000000000000e+01,
      "predicted_flops": 7.6447783316126986e+09,
      "predicted_flops_count": 4.8672000000000000e+04
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__2588722912333944632<CUDNN_ACTIVATION_RELU>/input[0]:1/input[1]:224/input[2]:13/input[3]:13/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 110710,
      "real_time": 6.3354497278027375e+03,
      "cpu_time": 1.2167684798210288e+04,
      "time_unit": "ns",
      "items_per_second": 5.9752664177684565e+09,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 2.2400000000000000e+02,
      "input[2]": 1.3000000000000000e+01,
      "input[3]": 1.3000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 2.2400000000000000e+02,
      "input_height": 1.3000000000000000e+01,
      "input_size": 3.7856000000000000e+04,
      "input_width": 1.3000000000000000e+01,
      "num_iterations": 1.1071000000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 2.2400000000000000e+02,
      "output_height": 1.3000000000000000e+01,
      "output_size": 3.7856000000000000e+04,
      "output_width": 1.3000000000000000e+01,
      "predicted_flops": 5.9752664177684565e+09,
      "predicted_flops_count": 3.7856000000000000e+04
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__2588722912333944632<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1/input[1]:224/input[2]:13/input[3]:13/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 110566,
      "real_time": 6.3368223088430705e+03,
      "cpu_time": 1.2189330083341812e+04,
      "time_unit": "ns",
      "items_per_second": 5.9739721511792660e+09,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 2.2400000000000000e+02,
      "input[2]": 1.3000000000000000e+01,
      "input[3]": 1.3000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 2.2400000000000000e+02,
      "input_height": 1.3000000000000000e+01,
      "input_size": 3.7856000000000000e+04,
      "input_width": 1.3000000000000000e+01,
      "num_iterations": 1.1056600000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 2.2400000000000000e+02,
      "output_height": 1.3000000000000000e+01,
      "output_size": 3.7856000000000000e+04,
      "output_width": 1.3000000000000000e+01,
      "predicted_flops": 5.9739721511792660e+09,
      "predicted_flops_count": 3.7856000000000000e+04
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__4704244164941136179<CUDNN_ACTIVATION_RELU>/input[0]:128/input[1]:384/input[2]:28/input[3]:28/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 1280,
      "real_time": 5.4705530046703643e+05,
      "cpu_time": 5.5758221796966554e+05,
      "time_unit": "ns",
      "items_per_second": 7.0441083318453262e+10,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 3.8400000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 3.8400000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 3.8535168000000000e+07,
      "input_width": 2.8000000000000000e+01,
      "num_iterations": 1.2800000000000000e+03,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 3.8400000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 3.8535168000000000e+07,
      "output_width": 2.8000000000000000e+01,
      "predicted_flops": 7.0441083318453262e+10,
      "predicted_flops_count": 3.8535168000000000e+07
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__4704244164941136179<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:128/input[1]:384/input[2]:28/input[3]:28/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 1279,
      "real_time": 5.4719952633058291e+05,
      "cpu_time": 5.5774351602795452e+05,
      "time_unit": "ns",
      "items_per_second": 7.0422517099767227e+10,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 3.8400000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 3.8400000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 3.8535168000000000e+07,
      "input_width": 2.8000000000000000e+01,
      "num_iterations": 1.2790000000000000e+03,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 3.8400000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 3.8535168000000000e+07,
      "output_width": 2.8000000000000000e+01,
      "predicted_flops": 7.0422517099767227e+10,
      "predicted_flops_count": 3.8535168000000000e+07
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__9306013828847496653<CUDNN_ACTIVATION_RELU>/input[0]:1/input[1]:480/input[2]:28/input[3]:28/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 91813,
      "real_time": 7.6310357594767365e+03,
      "cpu_time": 1.3518956672900096e+04,
      "time_unit": "ns",
      "items_per_second": 4.9314406570911469e+10,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 4.8000000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 4.8000000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 3.7632000000000000e+05,
      "input_width": 2.8000000000000000e+01,
      "num_iterations": 9.1813000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 4.8000000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 3.7632000000000000e+05,
      "output_width": 2.8000000000000000e+01,
      "predicted_flops": 4.9314406570911469e+10,
      "predicted_flops_count": 3.7632000000000000e+05
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__9306013828847496653<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1/input[1]:480/input[2]:28/input[3]:28/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 91057,
      "real_time": 7.6720165715379944e+03,
      "cpu_time": 1.3545434233481792e+04,
      "time_unit": "ns",
      "items_per_second": 4.9050988940259796e+10,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 4.8000000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 4.8000000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 3.7632000000000000e+05,
      "input_width": 2.8000000000000000e+01,
      "num_iterations": 9.1057000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 4.8000000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 3.7632000000000000e+05,
      "output_width": 2.8000000000000000e+01,
      "predicted_flops": 4.9050988940259796e+10,
      "predicted_flops_count": 3.7632000000000000e+05
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__6123726645612438266<CUDNN_ACTIVATION_RELU>/input[0]:1/input[1]:24/input[2]:13/input[3]:13/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 111573,
      "real_time": 6.2748738756841112e+03,
      "cpu_time": 1.2100183001426507e+04,
      "time_unit": "ns",
      "items_per_second": 6.4638749405266726e+08,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 2.4000000000000000e+01,
      "input[2]": 1.3000000000000000e+01,
      "input[3]": 1.3000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 2.4000000000000000e+01,
      "input_height": 1.3000000000000000e+01,
      "input_size": 4.0560000000000000e+03,
      "input_width": 1.3000000000000000e+01,
      "num_iterations": 1.1157300000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 2.4000000000000000e+01,
      "output_height": 1.3000000000000000e+01,
      "output_size": 4.0560000000000000e+03,
      "output_width": 1.3000000000000000e+01,
      "predicted_flops": 6.4638749405266726e+08,
      "predicted_flops_count": 4.0560000000000000e+03
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__6123726645612438266<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1/input[1]:24/input[2]:13/input[3]:13/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 111622,
      "real_time": 6.2775054996167464e+03,
      "cpu_time": 1.2113771433857004e+04,
      "time_unit": "ns",
      "items_per_second": 6.4611651877447605e+08,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 2.4000000000000000e+01,
      "input[2]": 1.3000000000000000e+01,
      "input[3]": 1.3000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 2.4000000000000000e+01,
      "input_height": 1.3000000000000000e+01,
      "input_size": 4.0560000000000000e+03,
      "input_width": 1.3000000000000000e+01,
      "num_iterations": 1.1162200000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 2.4000000000000000e+01,
      "output_height": 1.3000000000000000e+01,
      "output_size": 4.0560000000000000e+03,
      "output_width": 1.3000000000000000e+01,
      "predicted_flops": 6.4611651877447605e+08,
      "predicted_flops_count": 4.0560000000000000e+03
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__12990107224996438020<CUDNN_ACTIVATION_RELU>/input[0]:1/input[1]:144/input[2]:13/input[3]:13/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 110999,
      "real_time": 6.3046524666583027e+03,
      "cpu_time": 1.2133699456722750e+04,
      "time_unit": "ns",
      "items_per_second": 3.8600065790619187e+09,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 1.4400000000000000e+02,
      "input[2]": 1.3000000000000000e+01,
      "input[3]": 1.3000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 1.4400000000000000e+02,
      "input_height": 1.3000000000000000e+01,
      "input_size": 2.4336000000000000e+04,
      "input_width": 1.3000000000000000e+01,
      "num_iterations": 1.1099900000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 1.4400000000000000e+02,
      "output_height": 1.3000000000000000e+01,
      "output_size": 2.4336000000000000e+04,
      "output_width": 1.3000000000000000e+01,
      "predicted_flops": 3.8600065790619187e+09,
      "predicted_flops_count": 2.4336000000000000e+04
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__12990107224996438020<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1/input[1]:144/input[2]:13/input[3]:13/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 110978,
      "real_time": 6.3131576278058365e+03,
      "cpu_time": 1.2149036538664075e+04,
      "time_unit": "ns",
      "items_per_second": 3.8548063322249207e+09,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 1.4400000000000000e+02,
      "input[2]": 1.3000000000000000e+01,
      "input[3]": 1.3000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 1.4400000000000000e+02,
      "input_height": 1.3000000000000000e+01,
      "input_size": 2.4336000000000000e+04,
      "input_width": 1.3000000000000000e+01,
      "num_iterations": 1.1097800000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 1.4400000000000000e+02,
      "output_height": 1.3000000000000000e+01,
      "output_size": 2.4336000000000000e+04,
      "output_width": 1.3000000000000000e+01,
      "predicted_flops": 3.8548063322249207e+09,
      "predicted_flops_count": 2.4336000000000000e+04
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__3006029908054728870<CUDNN_ACTIVATION_RELU>/input[0]:1/input[1]:736/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 110595,
      "real_time": 6.3314319035102762e+03,
      "cpu_time": 1.2179922021733861e+04,
      "time_unit": "ns",
      "items_per_second": 5.6960258831821871e+09,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 7.3600000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 7.3600000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 3.6064000000000000e+04,
      "input_width": 7.0000000000000000e+00,
      "num_iterations": 1.1059500000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 7.3600000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 3.6064000000000000e+04,
      "output_width": 7.0000000000000000e+00,
      "predicted_flops": 5.6960258831821871e+09,
      "predicted_flops_count": 3.6064000000000000e+04
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__3006029908054728870<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1/input[1]:736/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 110412,
      "real_time": 6.3418145077610416e+03,
      "cpu_time": 1.2187378419145633e+04,
      "time_unit": "ns",
      "items_per_second": 5.6867005422289276e+09,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 7.3600000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 7.3600000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 3.6064000000000000e+04,
      "input_width": 7.0000000000000000e+00,
      "num_iterations": 1.1041200000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 7.3600000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 3.6064000000000000e+04,
      "output_width": 7.0000000000000000e+00,
      "predicted_flops": 5.6867005422289276e+09,
      "predicted_flops_count": 3.6064000000000000e+04
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__1854157221896980618<CUDNN_ACTIVATION_RELU>/input[0]:1/input[1]:512/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 105441,
      "real_time": 6.6690834258653749e+03,
      "cpu_time": 1.2537945192024825e+04,
      "time_unit": "ns",
      "items_per_second": 1.5047345128536673e+10,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 1.0035200000000000e+05,
      "input_width": 1.4000000000000000e+01,
      "num_iterations": 1.0544100000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 1.0035200000000000e+05,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 1.5047345128536673e+10,
      "predicted_flops_count": 1.0035200000000000e+05
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__1854157221896980618<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1/input[1]:512/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 106074,
      "real_time": 6.6050644768661887e+03,
      "cpu_time": 1.2458202905494914e+04,
      "time_unit": "ns",
      "items_per_second": 1.5193190066724768e+10,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 1.0035200000000000e+05,
      "input_width": 1.4000000000000000e+01,
      "num_iterations": 1.0607400000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 1.0035200000000000e+05,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 1.5193190066724768e+10,
      "predicted_flops_count": 1.0035200000000000e+05
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__13409702507013341771<CUDNN_ACTIVATION_RELU>/input[0]:1/input[1]:608/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 109496,
      "real_time": 6.3274918465837072e+03,
      "cpu_time": 1.2166791681866247e+04,
      "time_unit": "ns",
      "items_per_second": 4.7083426928610077e+09,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 6.0800000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 6.0800000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 2.9792000000000000e+04,
      "input_width": 7.0000000000000000e+00,
      "num_iterations": 1.0949600000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 6.0800000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 2.9792000000000000e+04,
      "output_width": 7.0000000000000000e+00,
      "predicted_flops": 4.7083426928610077e+09,
      "predicted_flops_count": 2.9792000000000000e+04
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__13409702507013341771<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1/input[1]:608/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 110685,
      "real_time": 6.3373574326118069e+03,
      "cpu_time": 1.2182901215116641e+04,
      "time_unit": "ns",
      "items_per_second": 4.7010130510694361e+09,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 6.0800000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 6.0800000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 2.9792000000000000e+04,
      "input_width": 7.0000000000000000e+00,
      "num_iterations": 1.1068500000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 6.0800000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 2.9792000000000000e+04,
      "output_width": 7.0000000000000000e+00,
      "predicted_flops": 4.7010130510694361e+09,
      "predicted_flops_count": 2.9792000000000000e+04
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__3782035135739875651<CUDNN_ACTIVATION_RELU>/input[0]:1/input[1]:544/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 104072,
      "real_time": 6.7172518450299049e+03,
      "cpu_time": 1.2579000759173094e+04,
      "time_unit": "ns",
      "items_per_second": 1.5873158020551382e+10,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 5.4400000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 5.4400000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 1.0662400000000000e+05,
      "input_width": 1.4000000000000000e+01,
      "num_iterations": 1.0407200000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 5.4400000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 1.0662400000000000e+05,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 1.5873158020551382e+10,
      "predicted_flops_count": 1.0662400000000000e+05
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__3782035135739875651<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1/input[1]:544/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 104997,
      "real_time": 6.6574200175824262e+03,
      "cpu_time": 1.2518375391659356e+04,
      "time_unit": "ns",
      "items_per_second": 1.6015813891628157e+10,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 5.4400000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 5.4400000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 1.0662400000000000e+05,
      "input_width": 1.4000000000000000e+01,
      "num_iterations": 1.0499700000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 5.4400000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 1.0662400000000000e+05,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 1.6015813891628157e+10,
      "predicted_flops_count": 1.0662400000000000e+05
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__9542155896868387401<CUDNN_ACTIVATION_RELU>/input[0]:128/input[1]:64/input[2]:199/input[3]:199/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 142,
      "real_time": 4.9142638929712940e+06,
      "cpu_time": 5.2800211338037541e+06,
      "time_unit": "ns",
      "items_per_second": 6.6014239175066422e+10,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 1.9900000000000000e+02,
      "input[3]": 1.9900000000000000e+02,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 1.9900000000000000e+02,
      "input_size": 3.2441139200000000e+08,
      "input_width": 1.9900000000000000e+02,
      "num_iterations": 1.4200000000000000e+02,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 1.9900000000000000e+02,
      "output_size": 3.2441139200000000e+08,
      "output_width": 1.9900000000000000e+02,
      "predicted_flops": 6.6014239175066422e+10,
      "predicted_flops_count": 3.2441139200000000e+08
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__9542155896868387401<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:128/input[1]:64/input[2]:199/input[3]:199/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 142,
      "real_time": 4.9121996591156218e+06,
      "cpu_time": 5.2772377253498221e+06,
      "time_unit": "ns",
      "items_per_second": 6.6041980072610909e+10,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 1.9900000000000000e+02,
      "input[3]": 1.9900000000000000e+02,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 1.9900000000000000e+02,
      "input_size": 3.2441139200000000e+08,
      "input_width": 1.9900000000000000e+02,
      "num_iterations": 1.4200000000000000e+02,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 1.9900000000000000e+02,
      "output_size": 3.2441139200000000e+08,
      "output_width": 1.9900000000000000e+02,
      "predicted_flops": 6.6041980072610909e+10,
      "predicted_flops_count": 3.2441139200000000e+08
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__12845871009045495745<CUDNN_ACTIVATION_RELU>/input[0]:1/input[1]:704/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 110526,
      "real_time": 6.3207690432153286e+03,
      "cpu_time": 1.2160352451107265e+04,
      "time_unit": "ns",
      "items_per_second": 5.4575637496243868e+09,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 7.0400000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 7.0400000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 3.4496000000000000e+04,
      "input_width": 7.0000000000000000e+00,
      "num_iterations": 1.1052600000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 7.0400000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 3.4496000000000000e+04,
      "output_width": 7.0000000000000000e+00,
      "predicted_flops": 5.4575637496243868e+09,
      "predicted_flops_count": 3.4496000000000000e+04
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__12845871009045495745<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1/input[1]:704/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 111040,
      "real_time": 6.3247579909734886e+03,
      "cpu_time": 1.2171494055944904e+04,
      "time_unit": "ns",
      "items_per_second": 5.4541217307020588e+09,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 7.0400000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 7.0400000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 3.4496000000000000e+04,
      "input_width": 7.0000000000000000e+00,
      "num_iterations": 1.1104000000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 7.0400000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 3.4496000000000000e+04,
      "output_width": 7.0000000000000000e+00,
      "predicted_flops": 5.4541217307020588e+09,
      "predicted_flops_count": 3.4496000000000000e+04
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__16102228065260051246<CUDNN_ACTIVATION_RELU>/input[0]:128/input[1]:48/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 94374,
      "real_time": 7.6435791621290218e+03,
      "cpu_time": 1.3444435914506646e+04,
      "time_unit": "ns",
      "items_per_second": 3.9386783810863899e+10,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 4.8000000000000000e+01,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 4.8000000000000000e+01,
      "input_height": 7.0000000000000000e+00,
      "input_size": 3.0105600000000000e+05,
      "input_width": 7.0000000000000000e+00,
      "num_iterations": 9.4374000000000000e+04,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 4.8000000000000000e+01,
      "output_height": 7.0000000000000000e+00,
      "output_size": 3.0105600000000000e+05,
      "output_width": 7.0000000000000000e+00,
      "predicted_flops": 3.9386783810863899e+10,
      "predicted_flops_count": 3.0105600000000000e+05
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__16102228065260051246<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:128/input[1]:48/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 87435,
      "real_time": 7.6904423546923517e+03,
      "cpu_time": 1.3502468816836561e+04,
      "time_unit": "ns",
      "items_per_second": 3.9146772853229904e+10,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 4.8000000000000000e+01,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 4.8000000000000000e+01,
      "input_height": 7.0000000000000000e+00,
      "input_size": 3.0105600000000000e+05,
      "input_width": 7.0000000000000000e+00,
      "num_iterations": 8.7435000000000000e+04,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 4.8000000000000000e+01,
      "output_height": 7.0000000000000000e+00,
      "output_size": 3.0105600000000000e+05,
      "output_width": 7.0000000000000000e+00,
      "predicted_flops": 3.9146772853229904e+10,
      "predicted_flops_count": 3.0105600000000000e+05
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__5291900785675511683<CUDNN_ACTIVATION_RELU>/input[0]:128/input[1]:384/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 17689,
      "real_time": 3.9687310021098681e+04,
      "cpu_time": 4.5979970659540246e+04,
      "time_unit": "ns",
      "items_per_second": 6.0685594431056519e+10,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 3.8400000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 3.8400000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 2.4084480000000000e+06,
      "input_width": 7.0000000000000000e+00,
      "num_iterations": 1.7689000000000000e+04,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 3.8400000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 2.4084480000000000e+06,
      "output_width": 7.0000000000000000e+00,
      "predicted_flops": 6.0685594431056519e+10,
      "predicted_flops_count": 2.4084480000000000e+06
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__5291900785675511683<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:128/input[1]:384/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 17793,
      "real_time": 3.9335335629798930e+04,
      "cpu_time": 4.5529391839609365e+04,
      "time_unit": "ns",
      "items_per_second": 6.1228611919493912e+10,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 3.8400000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 3.8400000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 2.4084480000000000e+06,
      "input_width": 7.0000000000000000e+00,
      "num_iterations": 1.7793000000000000e+04,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 3.8400000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 2.4084480000000000e+06,
      "output_width": 7.0000000000000000e+00,
      "predicted_flops": 6.1228611919493912e+10,
      "predicted_flops_count": 2.4084480000000000e+06
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__14852377515649857131<CUDNN_ACTIVATION_RELU>/input[0]:128/input[1]:384/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 5005,
      "real_time": 1.3989265671162237e+05,
      "cpu_time": 1.4634111928040005e+05,
      "time_unit": "ns",
      "items_per_second": 6.8865601858282654e+10,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 3.8400000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 3.8400000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 9.6337920000000000e+06,
      "input_width": 1.4000000000000000e+01,
      "num_iterations": 5.0050000000000000e+03,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 3.8400000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 9.6337920000000000e+06,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 6.8865601858282654e+10,
      "predicted_flops_count": 9.6337920000000000e+06
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__14852377515649857131<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:128/input[1]:384/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 5002,
      "real_time": 1.3986773174350578e+05,
      "cpu_time": 1.4631336785245038e+05,
      "time_unit": "ns",
      "items_per_second": 6.8877873973582245e+10,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 3.8400000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 3.8400000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 9.6337920000000000e+06,
      "input_width": 1.4000000000000000e+01,
      "num_iterations": 5.0020000000000000e+03,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 3.8400000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 9.6337920000000000e+06,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 6.8877873973582245e+10,
      "predicted_flops_count": 9.6337920000000000e+06
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__8678841859161628557<CUDNN_ACTIVATION_RELU>/input[0]:1/input[1]:128/input[2]:28/input[3]:28/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 105094,
      "real_time": 6.6524083352017897e+03,
      "cpu_time": 1.2524756161131816e+04,
      "time_unit": "ns",
      "items_per_second": 1.5085063174636887e+10,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 1.2800000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 1.2800000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 1.0035200000000000e+05,
      "input_width": 2.8000000000000000e+01,
      "num_iterations": 1.0509400000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 1.0035200000000000e+05,
      "output_width": 2.8000000000000000e+01,
      "predicted_flops": 1.5085063174636887e+10,
      "predicted_flops_count": 1.0035200000000000e+05
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__8678841859161628557<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1/input[1]:128/input[2]:28/input[3]:28/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 106269,
      "real_time": 6.5834156825031305e+03,
      "cpu_time": 1.2432852863931146e+04,
      "time_unit": "ns",
      "items_per_second": 1.5243151099619520e+10,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 1.2800000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 1.2800000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 1.0035200000000000e+05,
      "input_width": 2.8000000000000000e+01,
      "num_iterations": 1.0626900000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 1.0035200000000000e+05,
      "output_width": 2.8000000000000000e+01,
      "predicted_flops": 1.5243151099619520e+10,
      "predicted_flops_count": 1.0035200000000000e+05
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__1114247392826806057<CUDNN_ACTIVATION_RELU>/input[0]:1/input[1]:128/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 97595,
      "real_time": 6.3167994089147669e+03,
      "cpu_time": 1.2154134689210923e+04,
      "time_unit": "ns",
      "items_per_second": 3.9716315773133197e+09,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 1.2800000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 1.2800000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 2.5088000000000000e+04,
      "input_width": 1.4000000000000000e+01,
      "num_iterations": 9.7595000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 2.5088000000000000e+04,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 3.9716315773133197e+09,
      "predicted_flops_count": 2.5088000000000000e+04
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__1114247392826806057<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1/input[1]:128/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 110850,
      "real_time": 6.4136109622666045e+03,
      "cpu_time": 1.2269897600494318e+04,
      "time_unit": "ns",
      "items_per_second": 3.9116809777831869e+09,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 1.2800000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 1.2800000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 2.5088000000000000e+04,
      "input_width": 1.4000000000000000e+01,
      "num_iterations": 1.1085000000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 2.5088000000000000e+04,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 3.9116809777831869e+09,
      "predicted_flops_count": 2.5088000000000000e+04
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__15288896826146077873<CUDNN_ACTIVATION_RELU>/input[0]:128/input[1]:576/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 3363,
      "real_time": 2.0801777411626812e+05,
      "cpu_time": 2.1352309247666912e+05,
      "time_unit": "ns",
      "items_per_second": 6.9468525280551392e+10,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 5.7600000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 5.7600000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 1.4450688000000000e+07,
      "input_width": 1.4000000000000000e+01,
      "num_iterations": 3.3630000000000000e+03,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 5.7600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 1.4450688000000000e+07,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 6.9468525280551392e+10,
      "predicted_flops_count": 1.4450688000000000e+07
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__15288896826146077873<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:128/input[1]:576/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 3348,
      "real_time": 2.0806485983198023e+05,
      "cpu_time": 2.1492710453986021e+05,
      "time_unit": "ns",
      "items_per_second": 6.9452804340288132e+10,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 5.7600000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 5.7600000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 1.4450688000000000e+07,
      "input_width": 1.4000000000000000e+01,
      "num_iterations": 3.3480000000000000e+03,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 5.7600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 1.4450688000000000e+07,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 6.9452804340288132e+10,
      "predicted_flops_count": 1.4450688000000000e+07
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__14053627354337777324<CUDNN_ACTIVATION_RELU>/input[0]:1/input[1]:960/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 99531,
      "real_time": 7.0345675911281733e+03,
      "cpu_time": 1.2865275542297895e+04,
      "time_unit": "ns",
      "items_per_second": 2.6747912727045631e+10,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 9.6000000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 9.6000000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 1.8816000000000000e+05,
      "input_width": 1.4000000000000000e+01,
      "num_iterations": 9.9531000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 9.6000000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 1.8816000000000000e+05,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 2.6747912727045631e+10,
      "predicted_flops_count": 1.8816000000000000e+05
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__14053627354337777324<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1/input[1]:960/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 99400,
      "real_time": 7.0482341554408513e+03,
      "cpu_time": 1.2907007947752145e+04,
      "time_unit": "ns",
      "items_per_second": 2.6696048378975998e+10,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 9.6000000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 9.6000000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 1.8816000000000000e+05,
      "input_width": 1.4000000000000000e+01,
      "num_iterations": 9.9400000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 9.6000000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 1.8816000000000000e+05,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 2.6696048378975998e+10,
      "predicted_flops_count": 1.8816000000000000e+05
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__7214324892851242403<CUDNN_ACTIVATION_RELU>/input[0]:1/input[1]:864/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 100066,
      "real_time": 7.0035502459954096e+03,
      "cpu_time": 1.2813597595587233e+04,
      "time_unit": "ns",
      "items_per_second": 2.4179736569581970e+10,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 8.6400000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 8.6400000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 1.6934400000000000e+05,
      "input_width": 1.4000000000000000e+01,
      "num_iterations": 1.0006600000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 8.6400000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 1.6934400000000000e+05,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 2.4179736569581970e+10,
      "predicted_flops_count": 1.6934400000000000e+05
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__7214324892851242403<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1/input[1]:864/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 99444,
      "real_time": 7.0362332469224284e+03,
      "cpu_time": 1.2867701560673813e+04,
      "time_unit": "ns",
      "items_per_second": 2.4067422732762482e+10,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 8.6400000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 8.6400000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 1.6934400000000000e+05,
      "input_width": 1.4000000000000000e+01,
      "num_iterations": 9.9444000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 8.6400000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 1.6934400000000000e+05,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 2.4067422732762482e+10,
      "predicted_flops_count": 1.6934400000000000e+05
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__12520849883310571022<CUDNN_ACTIVATION_RELU>/input[0]:1/input[1]:928/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 99441,
      "real_time": 7.0261058001196552e+03,
      "cpu_time": 1.2847892649935477e+04,
      "time_unit": "ns",
      "items_per_second": 2.5887455323673382e+10,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 9.2800000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 9.2800000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 1.8188800000000000e+05,
      "input_width": 1.4000000000000000e+01,
      "num_iterations": 9.9441000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 9.2800000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 1.8188800000000000e+05,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 2.5887455323673382e+10,
      "predicted_flops_count": 1.8188800000000000e+05
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__12520849883310571022<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1/input[1]:928/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 99738,
      "real_time": 7.0901773345453839e+03,
      "cpu_time": 1.2950078886642976e+04,
      "time_unit": "ns",
      "items_per_second": 2.5653519145958359e+10,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 9.2800000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 9.2800000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 1.8188800000000000e+05,
      "input_width": 1.4000000000000000e+01,
      "num_iterations": 9.9738000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 9.2800000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 1.8188800000000000e+05,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 2.5653519145958359e+10,
      "predicted_flops_count": 1.8188800000000000e+05
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__11670589493566310871<CUDNN_ACTIVATION_RELU>/input[0]:1/input[1]:544/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 110949,
      "real_time": 6.3129122679369148e+03,
      "cpu_time": 1.2154219488343209e+04,
      "time_unit": "ns",
      "items_per_second": 4.2224569055687652e+09,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 5.4400000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 5.4400000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 2.6656000000000000e+04,
      "input_width": 7.0000000000000000e+00,
      "num_iterations": 1.1094900000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 5.4400000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 2.6656000000000000e+04,
      "output_width": 7.0000000000000000e+00,
      "predicted_flops": 4.2224569055687652e+09,
      "predicted_flops_count": 2.6656000000000000e+04
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__11670589493566310871<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1/input[1]:544/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 110856,
      "real_time": 6.3236028662189901e+03,
      "cpu_time": 1.2168644105865545e+04,
      "time_unit": "ns",
      "items_per_second": 4.2153184764966369e+09,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 5.4400000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 5.4400000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 2.6656000000000000e+04,
      "input_width": 7.0000000000000000e+00,
      "num_iterations": 1.1085600000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 5.4400000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 2.6656000000000000e+04,
      "output_width": 7.0000000000000000e+00,
      "predicted_flops": 4.2153184764966369e+09,
      "predicted_flops_count": 2.6656000000000000e+04
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__14632120628782387106<CUDNN_ACTIVATION_RELU>/input[0]:1/input[1]:928/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 110222,
      "real_time": 6.3482308024673475e+03,
      "cpu_time": 1.2197586117245550e+04,
      "time_unit": "ns",
      "items_per_second": 7.1629405758729725e+09,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 9.2800000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 9.2800000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 4.5472000000000000e+04,
      "input_width": 7.0000000000000000e+00,
      "num_iterations": 1.1022200000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 9.2800000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 4.5472000000000000e+04,
      "output_width": 7.0000000000000000e+00,
      "predicted_flops": 7.1629405758729725e+09,
      "predicted_flops_count": 4.5472000000000000e+04
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__14632120628782387106<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1/input[1]:928/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 110054,
      "real_time": 6.3539284299390865e+03,
      "cpu_time": 1.2211508968261276e+04,
      "time_unit": "ns",
      "items_per_second": 7.1565174995897665e+09,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 9.2800000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 9.2800000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 4.5472000000000000e+04,
      "input_width": 7.0000000000000000e+00,
      "num_iterations": 1.1005400000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 9.2800000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 4.5472000000000000e+04,
      "output_width": 7.0000000000000000e+00,
      "predicted_flops": 7.1565174995897665e+09,
      "predicted_flops_count": 4.5472000000000000e+04
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__7535005013359104634<CUDNN_ACTIVATION_RELU>/input[0]:1/input[1]:1024/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 99168,
      "real_time": 7.0731030478914472e+03,
      "cpu_time": 1.2922485146332063e+04,
      "time_unit": "ns",
      "items_per_second": 2.8375664632771267e+10,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 1.0240000000000000e+03,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 1.0240000000000000e+03,
      "input_height": 1.4000000000000000e+01,
      "input_size": 2.0070400000000000e+05,
      "input_width": 1.4000000000000000e+01,
      "num_iterations": 9.9168000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 1.0240000000000000e+03,
      "output_height": 1.4000000000000000e+01,
      "output_size": 2.0070400000000000e+05,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 2.8375664632771267e+10,
      "predicted_flops_count": 2.0070400000000000e+05
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__7535005013359104634<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1/input[1]:1024/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 98660,
      "real_time": 7.1474459666706189e+03,
      "cpu_time": 1.3051484816725915e+04,
      "time_unit": "ns",
      "items_per_second": 2.8080520081705601e+10,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 1.0240000000000000e+03,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 1.0240000000000000e+03,
      "input_height": 1.4000000000000000e+01,
      "input_size": 2.0070400000000000e+05,
      "input_width": 1.4000000000000000e+01,
      "num_iterations": 9.8660000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 1.0240000000000000e+03,
      "output_height": 1.4000000000000000e+01,
      "output_size": 2.0070400000000000e+05,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 2.8080520081705601e+10,
      "predicted_flops_count": 2.0070400000000000e+05
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__14208199326932404465<CUDNN_ACTIVATION_RELU>/input[0]:128/input[1]:576/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 12417,
      "real_time": 5.6219344168596064e+04,
      "cpu_time": 6.2443959652300342e+04,
      "time_unit": "ns",
      "items_per_second": 6.4260301386049011e+10,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 5.7600000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 5.7600000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 3.6126720000000000e+06,
      "input_width": 7.0000000000000000e+00,
      "num_iterations": 1.2417000000000000e+04,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 5.7600000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 3.6126720000000000e+06,
      "output_width": 7.0000000000000000e+00,
      "predicted_flops": 6.4260301386049011e+10,
      "predicted_flops_count": 3.6126720000000000e+06
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__14208199326932404465<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:128/input[1]:576/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 12407,
      "real_time": 5.6240363387846555e+04,
      "cpu_time": 6.2454911984934704e+04,
      "time_unit": "ns",
      "items_per_second": 6.4236284802894646e+10,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 5.7600000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 5.7600000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 3.6126720000000000e+06,
      "input_width": 7.0000000000000000e+00,
      "num_iterations": 1.2407000000000000e+04,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 5.7600000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 3.6126720000000000e+06,
      "output_width": 7.0000000000000000e+00,
      "predicted_flops": 6.4236284802894646e+10,
      "predicted_flops_count": 3.6126720000000000e+06
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__8091235345273135317<CUDNN_ACTIVATION_RELU>/input[0]:1/input[1]:672/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 110695,
      "real_time": 6.3318294717452300e+03,
      "cpu_time": 1.2178137955585935e+04,
      "time_unit": "ns",
      "items_per_second": 5.2003927375075245e+09,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 6.7200000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 6.7200000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 3.2928000000000000e+04,
      "input_width": 7.0000000000000000e+00,
      "num_iterations": 1.1069500000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 6.7200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 3.2928000000000000e+04,
      "output_width": 7.0000000000000000e+00,
      "predicted_flops": 5.2003927375075245e+09,
      "predicted_flops_count": 3.2928000000000000e+04
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__8091235345273135317<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1/input[1]:672/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 110302,
      "real_time": 6.3433210588803749e+03,
      "cpu_time": 1.2183126325831316e+04,
      "time_unit": "ns",
      "items_per_second": 5.1909716841310158e+09,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 6.7200000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 6.7200000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 3.2928000000000000e+04,
      "input_width": 7.0000000000000000e+00,
      "num_iterations": 1.1030200000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 6.7200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 3.2928000000000000e+04,
      "output_width": 7.0000000000000000e+00,
      "predicted_flops": 5.1909716841310158e+09,
      "predicted_flops_count": 3.2928000000000000e+04
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__11338305390499976235<CUDNN_ACTIVATION_RELU>/input[0]:128/input[1]:960/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 7837,
      "real_time": 8.9213041922646938e+04,
      "cpu_time": 9.5506606737067050e+04,
      "time_unit": "ns",
      "items_per_second": 6.7491477369650414e+10,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 9.6000000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 9.6000000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 6.0211200000000000e+06,
      "input_width": 7.0000000000000000e+00,
      "num_iterations": 7.8370000000000000e+03,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 9.6000000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 6.0211200000000000e+06,
      "output_width": 7.0000000000000000e+00,
      "predicted_flops": 6.7491477369650414e+10,
      "predicted_flops_count": 6.0211200000000000e+06
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__11338305390499976235<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:128/input[1]:960/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 7836,
      "real_time": 8.9233288681540173e+04,
      "cpu_time": 9.5513526927400148e+04,
      "time_unit": "ns",
      "items_per_second": 6.7476163760908195e+10,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 9.6000000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 9.6000000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 6.0211200000000000e+06,
      "input_width": 7.0000000000000000e+00,
      "num_iterations": 7.8360000000000000e+03,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 9.6000000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 6.0211200000000000e+06,
      "output_width": 7.0000000000000000e+00,
      "predicted_flops": 6.7476163760908195e+10,
      "predicted_flops_count": 6.0211200000000000e+06
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__10537112639109253411<CUDNN_ACTIVATION_RELU>/input[0]:128/input[1]:64/input[2]:64/input[3]:64/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 1471,
      "real_time": 4.7567791235364118e+05,
      "cpu_time": 4.8513251733533456e+05,
      "time_unit": "ns",
      "items_per_second": 7.0540235584985641e+10,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 6.4000000000000000e+01,
      "input[3]": 6.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 6.4000000000000000e+01,
      "input_size": 3.3554432000000000e+07,
      "input_width": 6.4000000000000000e+01,
      "num_iterations": 1.4710000000000000e+03,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 6.4000000000000000e+01,
      "output_size": 3.3554432000000000e+07,
      "output_width": 6.4000000000000000e+01,
      "predicted_flops": 7.0540235584985641e+10,
      "predicted_flops_count": 3.3554432000000000e+07
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__10537112639109253411<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:128/input[1]:64/input[2]:64/input[3]:64/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 1471,
      "real_time": 4.7586956404495845e+05,
      "cpu_time": 4.8535996396971162e+05,
      "time_unit": "ns",
      "items_per_second": 7.0511826213012222e+10,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 6.4000000000000000e+01,
      "input[3]": 6.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 6.4000000000000000e+01,
      "input_size": 3.3554432000000000e+07,
      "input_width": 6.4000000000000000e+01,
      "num_iterations": 1.4710000000000000e+03,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 6.4000000000000000e+01,
      "output_size": 3.3554432000000000e+07,
      "output_width": 6.4000000000000000e+01,
      "predicted_flops": 7.0511826213012222e+10,
      "predicted_flops_count": 3.3554432000000000e+07
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__10352455638451390380<CUDNN_ACTIVATION_RELU>/input[0]:1/input[1]:640/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 110622,
      "real_time": 6.4334108520129021e+03,
      "cpu_time": 1.2287145829916866e+04,
      "time_unit": "ns",
      "items_per_second": 4.8745526628674746e+09,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 6.4000000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 6.4000000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 3.1360000000000000e+04,
      "input_width": 7.0000000000000000e+00,
      "num_iterations": 1.1062200000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 6.4000000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 3.1360000000000000e+04,
      "output_width": 7.0000000000000000e+00,
      "predicted_flops": 4.8745526628674746e+09,
      "predicted_flops_count": 3.1360000000000000e+04
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__10352455638451390380<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1/input[1]:640/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 107619,
      "real_time": 6.6256060277622337e+03,
      "cpu_time": 1.2402681106543310e+04,
      "time_unit": "ns",
      "items_per_second": 4.7331519363809328e+09,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 6.4000000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 6.4000000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 3.1360000000000000e+04,
      "input_width": 7.0000000000000000e+00,
      "num_iterations": 1.0761900000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 6.4000000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 3.1360000000000000e+04,
      "output_width": 7.0000000000000000e+00,
      "predicted_flops": 4.7331519363809328e+09,
      "predicted_flops_count": 3.1360000000000000e+04
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__16631141030050079572<CUDNN_ACTIVATION_RELU>/input[0]:1/input[1]:960/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 110270,
      "real_time": 6.3476610453545709e+03,
      "cpu_time": 1.2198426416936645e+04,
      "time_unit": "ns",
      "items_per_second": 7.4106036324081039e+09,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 9.6000000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 9.6000000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 4.7040000000000000e+04,
      "input_width": 7.0000000000000000e+00,
      "num_iterations": 1.1027000000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 9.6000000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 4.7040000000000000e+04,
      "output_width": 7.0000000000000000e+00,
      "predicted_flops": 7.4106036324081039e+09,
      "predicted_flops_count": 4.7040000000000000e+04
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__16631141030050079572<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1/input[1]:960/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 110229,
      "real_time": 6.3614885335252720e+03,
      "cpu_time": 1.2205459398184847e+04,
      "time_unit": "ns",
      "items_per_second": 7.3944957618169899e+09,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 9.6000000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 9.6000000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 4.7040000000000000e+04,
      "input_width": 7.0000000000000000e+00,
      "num_iterations": 1.1022900000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 9.6000000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 4.7040000000000000e+04,
      "output_width": 7.0000000000000000e+00,
      "predicted_flops": 7.3944957618169899e+09,
      "predicted_flops_count": 4.7040000000000000e+04
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__15785643385107570281<CUDNN_ACTIVATION_RELU>/input[0]:1/input[1]:896/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 110387,
      "real_time": 6.3554800426275560e+03,
      "cpu_time": 1.2207703271144084e+04,
      "time_unit": "ns",
      "items_per_second": 6.9080541053589249e+09,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 8.9600000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 8.9600000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 4.3904000000000000e+04,
      "input_width": 7.0000000000000000e+00,
      "num_iterations": 1.1038700000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 8.9600000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 4.3904000000000000e+04,
      "output_width": 7.0000000000000000e+00,
      "predicted_flops": 6.9080541053589249e+09,
      "predicted_flops_count": 4.3904000000000000e+04
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__15785643385107570281<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1/input[1]:896/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 110469,
      "real_time": 6.3537620103676072e+03,
      "cpu_time": 1.2207790085830220e+04,
      "time_unit": "ns",
      "items_per_second": 6.9099220160214748e+09,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 8.9600000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 8.9600000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 4.3904000000000000e+04,
      "input_width": 7.0000000000000000e+00,
      "num_iterations": 1.1046900000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 8.9600000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 4.3904000000000000e+04,
      "output_width": 7.0000000000000000e+00,
      "predicted_flops": 6.9099220160214748e+09,
      "predicted_flops_count": 4.3904000000000000e+04
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__10361111861848887604<CUDNN_ACTIVATION_RELU>/input[0]:128/input[1]:1280/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 5970,
      "real_time": 1.1723241623014468e+05,
      "cpu_time": 1.2360484221128013e+05,
      "time_unit": "ns",
      "items_per_second": 6.8480717690229362e+10,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 1.2800000000000000e+03,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 1.2800000000000000e+03,
      "input_height": 7.0000000000000000e+00,
      "input_size": 8.0281600000000000e+06,
      "input_width": 7.0000000000000000e+00,
      "num_iterations": 5.9700000000000000e+03,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 1.2800000000000000e+03,
      "output_height": 7.0000000000000000e+00,
      "output_size": 8.0281600000000000e+06,
      "output_width": 7.0000000000000000e+00,
      "predicted_flops": 6.8480717690229362e+10,
      "predicted_flops_count": 8.0281600000000000e+06
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__10361111861848887604<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:128/input[1]:1280/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 5966,
      "real_time": 1.1734867018254771e+05,
      "cpu_time": 1.2371690663731472e+05,
      "time_unit": "ns",
      "items_per_second": 6.8412875812835258e+10,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 1.2800000000000000e+03,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 1.2800000000000000e+03,
      "input_height": 7.0000000000000000e+00,
      "input_size": 8.0281600000000000e+06,
      "input_width": 7.0000000000000000e+00,
      "num_iterations": 5.9660000000000000e+03,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 1.2800000000000000e+03,
      "output_height": 7.0000000000000000e+00,
      "output_size": 8.0281600000000000e+06,
      "output_width": 7.0000000000000000e+00,
      "predicted_flops": 6.8412875812835258e+10,
      "predicted_flops_count": 8.0281600000000000e+06
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__13396873099139726196<CUDNN_ACTIVATION_RELU>/input[0]:1/input[1]:992/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 110105,
      "real_time": 6.3558037102191593e+03,
      "cpu_time": 1.2208360592224468e+04,
      "time_unit": "ns",
      "items_per_second": 7.6478132768395243e+09,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 9.9200000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 9.9200000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 4.8608000000000000e+04,
      "input_width": 7.0000000000000000e+00,
      "num_iterations": 1.1010500000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 9.9200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 4.8608000000000000e+04,
      "output_width": 7.0000000000000000e+00,
      "predicted_flops": 7.6478132768395243e+09,
      "predicted_flops_count": 4.8608000000000000e+04
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__13396873099139726196<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1/input[1]:992/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 109820,
      "real_time": 6.3618803818892147e+03,
      "cpu_time": 1.2207481141892362e+04,
      "time_unit": "ns",
      "items_per_second": 7.6405083217810259e+09,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 9.9200000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 9.9200000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 4.8608000000000000e+04,
      "input_width": 7.0000000000000000e+00,
      "num_iterations": 1.0982000000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 9.9200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 4.8608000000000000e+04,
      "output_width": 7.0000000000000000e+00,
      "predicted_flops": 7.6405083217810259e+09,
      "predicted_flops_count": 4.8608000000000000e+04
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__13427562355699918080<CUDNN_ACTIVATION_RELU>/input[0]:1/input[1]:320/input[2]:13/input[3]:13/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 109981,
      "real_time": 6.3659598621797904e+03,
      "cpu_time": 1.2221227166587238e+04,
      "time_unit": "ns",
      "items_per_second": 8.4951839425331030e+09,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 3.2000000000000000e+02,
      "input[2]": 1.3000000000000000e+01,
      "input[3]": 1.3000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 3.2000000000000000e+02,
      "input_height": 1.3000000000000000e+01,
      "input_size": 5.4080000000000000e+04,
      "input_width": 1.3000000000000000e+01,
      "num_iterations": 1.0998100000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 3.2000000000000000e+02,
      "output_height": 1.3000000000000000e+01,
      "output_size": 5.4080000000000000e+04,
      "output_width": 1.3000000000000000e+01,
      "predicted_flops": 8.4951839425331030e+09,
      "predicted_flops_count": 5.4080000000000000e+04
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__13427562355699918080<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1/input[1]:320/input[2]:13/input[3]:13/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 110060,
      "real_time": 6.3824242015315740e+03,
      "cpu_time": 1.2245149027824469e+04,
      "time_unit": "ns",
      "items_per_second": 8.4732694494080410e+09,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 3.2000000000000000e+02,
      "input[2]": 1.3000000000000000e+01,
      "input[3]": 1.3000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 3.2000000000000000e+02,
      "input_height": 1.3000000000000000e+01,
      "input_size": 5.4080000000000000e+04,
      "input_width": 1.3000000000000000e+01,
      "num_iterations": 1.1006000000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 3.2000000000000000e+02,
      "output_height": 1.3000000000000000e+01,
      "output_size": 5.4080000000000000e+04,
      "output_width": 1.3000000000000000e+01,
      "predicted_flops": 8.4732694494080410e+09,
      "predicted_flops_count": 5.4080000000000000e+04
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__13500622049652464134<CUDNN_ACTIVATION_RELU>/input[0]:128/input[1]:128/input[2]:32/input[3]:32/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 2911,
      "real_time": 2.4032727074967738e+05,
      "cpu_time": 2.4734803710033724e+05,
      "time_unit": "ns",
      "items_per_second": 6.9809871961950546e+10,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 1.2800000000000000e+02,
      "input[2]": 3.2000000000000000e+01,
      "input[3]": 3.2000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 1.2800000000000000e+02,
      "input_height": 3.2000000000000000e+01,
      "input_size": 1.6777216000000000e+07,
      "input_width": 3.2000000000000000e+01,
      "num_iterations": 2.9110000000000000e+03,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 3.2000000000000000e+01,
      "output_size": 1.6777216000000000e+07,
      "output_width": 3.2000000000000000e+01,
      "predicted_flops": 6.9809871961950546e+10,
      "predicted_flops_count": 1.6777216000000000e+07
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__13500622049652464134<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:128/input[1]:128/input[2]:32/input[3]:32/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 2912,
      "real_time": 2.4040389433259287e+05,
      "cpu_time": 2.4739473042470147e+05,
      "time_unit": "ns",
      "items_per_second": 6.9787621563189545e+10,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 1.2800000000000000e+02,
      "input[2]": 3.2000000000000000e+01,
      "input[3]": 3.2000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 1.2800000000000000e+02,
      "input_height": 3.2000000000000000e+01,
      "input_size": 1.6777216000000000e+07,
      "input_width": 3.2000000000000000e+01,
      "num_iterations": 2.9120000000000000e+03,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 3.2000000000000000e+01,
      "output_size": 1.6777216000000000e+07,
      "output_width": 3.2000000000000000e+01,
      "predicted_flops": 6.9787621563189545e+10,
      "predicted_flops_count": 1.6777216000000000e+07
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__11437836186997684138<CUDNN_ACTIVATION_RELU>/input[0]:1/input[1]:1024/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 110190,
      "real_time": 6.3596883162185750e+03,
      "cpu_time": 1.2216609765037441e+04,
      "time_unit": "ns",
      "items_per_second": 7.8896948254587240e+09,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 1.0240000000000000e+03,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 1.0240000000000000e+03,
      "input_height": 7.0000000000000000e+00,
      "input_size": 5.0176000000000000e+04,
      "input_width": 7.0000000000000000e+00,
      "num_iterations": 1.1019000000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 1.0240000000000000e+03,
      "output_height": 7.0000000000000000e+00,
      "output_size": 5.0176000000000000e+04,
      "output_width": 7.0000000000000000e+00,
      "predicted_flops": 7.8896948254587240e+09,
      "predicted_flops_count": 5.0176000000000000e+04
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__11437836186997684138<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1/input[1]:1024/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 110163,
      "real_time": 6.4921654582868823e+03,
      "cpu_time": 1.2373217032962819e+04,
      "time_unit": "ns",
      "items_per_second": 7.7287001266970444e+09,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 1.0240000000000000e+03,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 1.0240000000000000e+03,
      "input_height": 7.0000000000000000e+00,
      "input_size": 5.0176000000000000e+04,
      "input_width": 7.0000000000000000e+00,
      "num_iterations": 1.1016300000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 1.0240000000000000e+03,
      "output_height": 7.0000000000000000e+00,
      "output_size": 5.0176000000000000e+04,
      "output_width": 7.0000000000000000e+00,
      "predicted_flops": 7.7287001266970444e+09,
      "predicted_flops_count": 5.0176000000000000e+04
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__7131927949494240285<CUDNN_ACTIVATION_RELU>/input[0]:1/input[1]:128/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 111674,
      "real_time": 6.2693609512936482e+03,
      "cpu_time": 1.2103103058849680e+04,
      "time_unit": "ns",
      "items_per_second": 1.0004209438133894e+09,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 1.2800000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 1.2800000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 6.2720000000000000e+03,
      "input_width": 7.0000000000000000e+00,
      "num_iterations": 1.1167400000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 6.2720000000000000e+03,
      "output_width": 7.0000000000000000e+00,
      "predicted_flops": 1.0004209438133894e+09,
      "predicted_flops_count": 6.2720000000000000e+03
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__7131927949494240285<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1/input[1]:128/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 111665,
      "real_time": 6.4070717843989705e+03,
      "cpu_time": 1.2179193668724480e+04,
      "time_unit": "ns",
      "items_per_second": 9.7891832822478020e+08,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 1.2800000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 1.2800000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 6.2720000000000000e+03,
      "input_width": 7.0000000000000000e+00,
      "num_iterations": 1.1166500000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 6.2720000000000000e+03,
      "output_width": 7.0000000000000000e+00,
      "predicted_flops": 9.7891832822478020e+08,
      "predicted_flops_count": 6.2720000000000000e+03
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__10544100885689436639<CUDNN_ACTIVATION_RELU>/input[0]:1/input[1]:32/input[2]:13/input[3]:13/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 105856,
      "real_time": 6.4367273898982439e+03,
      "cpu_time": 1.2313668464797345e+04,
      "time_unit": "ns",
      "items_per_second": 8.4017850569332457e+08,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 3.2000000000000000e+01,
      "input[2]": 1.3000000000000000e+01,
      "input[3]": 1.3000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 3.2000000000000000e+01,
      "input_height": 1.3000000000000000e+01,
      "input_size": 5.4080000000000000e+03,
      "input_width": 1.3000000000000000e+01,
      "num_iterations": 1.0585600000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 3.2000000000000000e+01,
      "output_height": 1.3000000000000000e+01,
      "output_size": 5.4080000000000000e+03,
      "output_width": 1.3000000000000000e+01,
      "predicted_flops": 8.4017850569332457e+08,
      "predicted_flops_count": 5.4080000000000000e+03
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__10544100885689436639<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1/input[1]:32/input[2]:13/input[3]:13/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 111788,
      "real_time": 6.2679200530691487e+03,
      "cpu_time": 1.2112119118304079e+04,
      "time_unit": "ns",
      "items_per_second": 8.6280615486662436e+08,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 3.2000000000000000e+01,
      "input[2]": 1.3000000000000000e+01,
      "input[3]": 1.3000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 3.2000000000000000e+01,
      "input_height": 1.3000000000000000e+01,
      "input_size": 5.4080000000000000e+03,
      "input_width": 1.3000000000000000e+01,
      "num_iterations": 1.1178800000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 3.2000000000000000e+01,
      "output_height": 1.3000000000000000e+01,
      "output_size": 5.4080000000000000e+03,
      "output_width": 1.3000000000000000e+01,
      "predicted_flops": 8.6280615486662436e+08,
      "predicted_flops_count": 5.4080000000000000e+03
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__688985642208744754<CUDNN_ACTIVATION_RELU>/input[0]:128/input[1]:16/input[2]:28/input[3]:28/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 24782,
      "real_time": 2.8213350191637448e+04,
      "cpu_time": 3.4403943588001894e+04,
      "time_unit": "ns",
      "items_per_second": 5.6910362969794205e+10,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 1.6000000000000000e+01,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 1.6000000000000000e+01,
      "input_height": 2.8000000000000000e+01,
      "input_size": 1.6056320000000000e+06,
      "input_width": 2.8000000000000000e+01,
      "num_iterations": 2.4782000000000000e+04,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 1.6000000000000000e+01,
      "output_height": 2.8000000000000000e+01,
      "output_size": 1.6056320000000000e+06,
      "output_width": 2.8000000000000000e+01,
      "predicted_flops": 5.6910362969794205e+10,
      "predicted_flops_count": 1.6056320000000000e+06
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__688985642208744754<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:128/input[1]:16/input[2]:28/input[3]:28/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 24721,
      "real_time": 2.8290491023736442e+04,
      "cpu_time": 3.4479881315636347e+04,
      "time_unit": "ns",
      "items_per_second": 5.6755183169243469e+10,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 1.6000000000000000e+01,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 1.6000000000000000e+01,
      "input_height": 2.8000000000000000e+01,
      "input_size": 1.6056320000000000e+06,
      "input_width": 2.8000000000000000e+01,
      "num_iterations": 2.4721000000000000e+04,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 1.6000000000000000e+01,
      "output_height": 2.8000000000000000e+01,
      "output_size": 1.6056320000000000e+06,
      "output_width": 2.8000000000000000e+01,
      "predicted_flops": 5.6755183169243469e+10,
      "predicted_flops_count": 1.6056320000000000e+06
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__15564522690150313013<CUDNN_ACTIVATION_RELU>/input[0]:128/input[1]:256/input[2]:199/input[3]:199/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 34,
      "real_time": 2.0840719944852240e+07,
      "cpu_time": 2.7215896088233981e+07,
      "time_unit": "ns",
      "items_per_second": 6.2264910782054092e+10,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 1.9900000000000000e+02,
      "input[3]": 1.9900000000000000e+02,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 1.9900000000000000e+02,
      "input_size": 1.2976455680000000e+09,
      "input_width": 1.9900000000000000e+02,
      "num_iterations": 3.4000000000000000e+01,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 1.9900000000000000e+02,
      "output_size": 1.2976455680000000e+09,
      "output_width": 1.9900000000000000e+02,
      "predicted_flops": 6.2264910782054092e+10,
      "predicted_flops_count": 1.2976455680000000e+09
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__15564522690150313013<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:128/input[1]:256/input[2]:199/input[3]:199/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 34,
      "real_time": 2.0838702152318813e+07,
      "cpu_time": 2.7203324294119697e+07,
      "time_unit": "ns",
      "items_per_second": 6.2270939836606148e+10,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 1.9900000000000000e+02,
      "input[3]": 1.9900000000000000e+02,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 1.9900000000000000e+02,
      "input_size": 1.2976455680000000e+09,
      "input_width": 1.9900000000000000e+02,
      "num_iterations": 3.4000000000000000e+01,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 1.9900000000000000e+02,
      "output_size": 1.2976455680000000e+09,
      "output_width": 1.9900000000000000e+02,
      "predicted_flops": 6.2270939836606148e+10,
      "predicted_flops_count": 1.2976455680000000e+09
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__18338656442900607191<CUDNN_ACTIVATION_RELU>/input[0]:1/input[1]:800/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 110285,
      "real_time": 6.3288035845713011e+03,
      "cpu_time": 1.2186996980549906e+04,
      "time_unit": "ns",
      "items_per_second": 6.1939037096306601e+09,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 8.0000000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 8.0000000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 3.9200000000000000e+04,
      "input_width": 7.0000000000000000e+00,
      "num_iterations": 1.1028500000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 8.0000000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 3.9200000000000000e+04,
      "output_width": 7.0000000000000000e+00,
      "predicted_flops": 6.1939037096306601e+09,
      "predicted_flops_count": 3.9200000000000000e+04
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__18338656442900607191<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1/input[1]:800/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 110264,
      "real_time": 6.3483581900496647e+03,
      "cpu_time": 1.2191073314915520e+04,
      "time_unit": "ns",
      "items_per_second": 6.1748248643943214e+09,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 8.0000000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 8.0000000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 3.9200000000000000e+04,
      "input_width": 7.0000000000000000e+00,
      "num_iterations": 1.1026400000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 8.0000000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 3.9200000000000000e+04,
      "output_width": 7.0000000000000000e+00,
      "predicted_flops": 6.1748248643943214e+09,
      "predicted_flops_count": 3.9200000000000000e+04
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__8337023137083059825<CUDNN_ACTIVATION_RELU>/input[0]:128/input[1]:64/input[2]:28/input[3]:28/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 7363,
      "real_time": 9.4888685843496860e+04,
      "cpu_time": 1.0118011761508127e+05,
      "time_unit": "ns",
      "items_per_second": 6.7684866145083885e+10,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 2.8000000000000000e+01,
      "input_size": 6.4225280000000000e+06,
      "input_width": 2.8000000000000000e+01,
      "num_iterations": 7.3630000000000000e+03,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 2.8000000000000000e+01,
      "output_size": 6.4225280000000000e+06,
      "output_width": 2.8000000000000000e+01,
      "predicted_flops": 6.7684866145083885e+10,
      "predicted_flops_count": 6.4225280000000000e+06
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__8337023137083059825<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:128/input[1]:64/input[2]:28/input[3]:28/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 7375,
      "real_time": 9.4898820606107678e+04,
      "cpu_time": 1.0119928894918133e+05,
      "time_unit": "ns",
      "items_per_second": 6.7677637709089149e+10,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 2.8000000000000000e+01,
      "input_size": 6.4225280000000000e+06,
      "input_width": 2.8000000000000000e+01,
      "num_iterations": 7.3750000000000000e+03,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 2.8000000000000000e+01,
      "output_size": 6.4225280000000000e+06,
      "output_width": 2.8000000000000000e+01,
      "predicted_flops": 6.7677637709089149e+10,
      "predicted_flops_count": 6.4225280000000000e+06
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__17308865387622888974<CUDNN_ACTIVATION_RELU>/input[0]:1/input[1]:256/input[2]:13/input[3]:13/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 110410,
      "real_time": 6.3443514845941891e+03,
      "cpu_time": 1.2192349388584682e+04,
      "time_unit": "ns",
      "items_per_second": 6.8192943132259874e+09,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 1.3000000000000000e+01,
      "input[3]": 1.3000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 1.3000000000000000e+01,
      "input_size": 4.3264000000000000e+04,
      "input_width": 1.3000000000000000e+01,
      "num_iterations": 1.1041000000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 1.3000000000000000e+01,
      "output_size": 4.3264000000000000e+04,
      "output_width": 1.3000000000000000e+01,
      "predicted_flops": 6.8192943132259874e+09,
      "predicted_flops_count": 4.3264000000000000e+04
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__17308865387622888974<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1/input[1]:256/input[2]:13/input[3]:13/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 110187,
      "real_time": 6.3466951949825852e+03,
      "cpu_time": 1.2193623739623659e+04,
      "time_unit": "ns",
      "items_per_second": 6.8167760812276907e+09,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 1.3000000000000000e+01,
      "input[3]": 1.3000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 1.3000000000000000e+01,
      "input_size": 4.3264000000000000e+04,
      "input_width": 1.3000000000000000e+01,
      "num_iterations": 1.1018700000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 1.3000000000000000e+01,
      "output_size": 4.3264000000000000e+04,
      "output_width": 1.3000000000000000e+01,
      "predicted_flops": 6.8167760812276907e+09,
      "predicted_flops_count": 4.3264000000000000e+04
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__16368529060455175510<CUDNN_ACTIVATION_RELU>/input[0]:128/input[1]:64/input[2]:400/input[3]:400/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 33,
      "real_time": 2.1069328723983333e+07,
      "cpu_time": 2.7706535181817852e+07,
      "time_unit": "ns",
      "items_per_second": 6.2209860464514954e+10,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 4.0000000000000000e+02,
      "input[3]": 4.0000000000000000e+02,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 4.0000000000000000e+02,
      "input_size": 1.3107200000000000e+09,
      "input_width": 4.0000000000000000e+02,
      "num_iterations": 3.3000000000000000e+01,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 4.0000000000000000e+02,
      "output_size": 1.3107200000000000e+09,
      "output_width": 4.0000000000000000e+02,
      "predicted_flops": 6.2209860464514954e+10,
      "predicted_flops_count": 1.3107200000000000e+09
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__16368529060455175510<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:128/input[1]:64/input[2]:400/input[3]:400/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 33,
      "real_time": 2.1057628941806879e+07,
      "cpu_time": 2.7681561090909753e+07,
      "time_unit": "ns",
      "items_per_second": 6.2244424746119202e+10,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 4.0000000000000000e+02,
      "input[3]": 4.0000000000000000e+02,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 4.0000000000000000e+02,
      "input_size": 1.3107200000000000e+09,
      "input_width": 4.0000000000000000e+02,
      "num_iterations": 3.3000000000000000e+01,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 4.0000000000000000e+02,
      "output_size": 1.3107200000000000e+09,
      "output_width": 4.0000000000000000e+02,
      "predicted_flops": 6.2244424746119202e+10,
      "predicted_flops_count": 1.3107200000000000e+09
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__5491702308704442244<CUDNN_ACTIVATION_RELU>/input[0]:1/input[1]:992/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 98881,
      "real_time": 7.2120449715080795e+03,
      "cpu_time": 1.3014456255498066e+04,
      "time_unit": "ns",
      "items_per_second": 2.6959343815536854e+10,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 9.9200000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 9.9200000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 1.9443200000000000e+05,
      "input_width": 1.4000000000000000e+01,
      "num_iterations": 9.8881000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 9.9200000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 1.9443200000000000e+05,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 2.6959343815536854e+10,
      "predicted_flops_count": 1.9443200000000000e+05
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__5491702308704442244<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1/input[1]:992/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 97594,
      "real_time": 7.1883243116621388e+03,
      "cpu_time": 1.3069121267861707e+04,
      "time_unit": "ns",
      "items_per_second": 2.7048306610840988e+10,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 9.9200000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 9.9200000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 1.9443200000000000e+05,
      "input_width": 1.4000000000000000e+01,
      "num_iterations": 9.7594000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 9.9200000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 1.9443200000000000e+05,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 2.7048306610840988e+10,
      "predicted_flops_count": 1.9443200000000000e+05
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__14170837469975180193<CUDNN_ACTIVATION_RELU>/input[0]:1/input[1]:832/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 110391,
      "real_time": 6.3471151761557558e+03,
      "cpu_time": 1.2197560869935947e+04,
      "time_unit": "ns",
      "items_per_second": 6.4230755025768843e+09,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 8.3200000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 8.3200000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 4.0768000000000000e+04,
      "input_width": 7.0000000000000000e+00,
      "num_iterations": 1.1039100000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 8.3200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 4.0768000000000000e+04,
      "output_width": 7.0000000000000000e+00,
      "predicted_flops": 6.4230755025768843e+09,
      "predicted_flops_count": 4.0768000000000000e+04
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__14170837469975180193<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1/input[1]:832/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 110554,
      "real_time": 6.3459137748905605e+03,
      "cpu_time": 1.2199185520228566e+04,
      "time_unit": "ns",
      "items_per_second": 6.4242915120136614e+09,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 8.3200000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 8.3200000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 4.0768000000000000e+04,
      "input_width": 7.0000000000000000e+00,
      "num_iterations": 1.1055400000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 8.3200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 4.0768000000000000e+04,
      "output_width": 7.0000000000000000e+00,
      "predicted_flops": 6.4242915120136614e+09,
      "predicted_flops_count": 4.0768000000000000e+04
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__158707808943489313<CUDNN_ACTIVATION_RELU>/input[0]:128/input[1]:256/input[2]:13/input[3]:13/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 8476,
      "real_time": 8.2560813236303569e+04,
      "cpu_time": 8.8834113851188973e+04,
      "time_unit": "ns",
      "items_per_second": 6.7075308283965965e+10,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 1.3000000000000000e+01,
      "input[3]": 1.3000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 1.3000000000000000e+01,
      "input_size": 5.5377920000000000e+06,
      "input_width": 1.3000000000000000e+01,
      "num_iterations": 8.4760000000000000e+03,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 1.3000000000000000e+01,
      "output_size": 5.5377920000000000e+06,
      "output_width": 1.3000000000000000e+01,
      "predicted_flops": 6.7075308283965965e+10,
      "predicted_flops_count": 5.5377920000000000e+06
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__158707808943489313<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:128/input[1]:256/input[2]:13/input[3]:13/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 8475,
      "real_time": 8.2588531525914106e+04,
      "cpu_time": 8.8837404483586448e+04,
      "time_unit": "ns",
      "items_per_second": 6.7052796528563850e+10,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 1.3000000000000000e+01,
      "input[3]": 1.3000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 1.3000000000000000e+01,
      "input_size": 5.5377920000000000e+06,
      "input_width": 1.3000000000000000e+01,
      "num_iterations": 8.4750000000000000e+03,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 1.3000000000000000e+01,
      "output_size": 5.5377920000000000e+06,
      "output_width": 1.3000000000000000e+01,
      "predicted_flops": 6.7052796528563850e+10,
      "predicted_flops_count": 5.5377920000000000e+06
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__14567914788867635507<CUDNN_ACTIVATION_RELU>/input[0]:128/input[1]:192/input[2]:56/input[3]:56/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 636,
      "real_time": 1.0994752774193718e+06,
      "cpu_time": 1.1235000849064360e+06,
      "time_unit": "ns",
      "items_per_second": 7.0097379707250229e+10,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 1.9200000000000000e+02,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 1.9200000000000000e+02,
      "input_height": 5.6000000000000000e+01,
      "input_size": 7.7070336000000000e+07,
      "input_width": 5.6000000000000000e+01,
      "num_iterations": 6.3600000000000000e+02,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 1.9200000000000000e+02,
      "output_height": 5.6000000000000000e+01,
      "output_size": 7.7070336000000000e+07,
      "output_width": 5.6000000000000000e+01,
      "predicted_flops": 7.0097379707250229e+10,
      "predicted_flops_count": 7.7070336000000000e+07
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__14567914788867635507<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:128/input[1]:192/input[2]:56/input[3]:56/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 637,
      "real_time": 1.0999353581328921e+06,
      "cpu_time": 1.1238958853992724e+06,
      "time_unit": "ns",
      "items_per_second": 7.0068059391076050e+10,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 1.9200000000000000e+02,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 1.9200000000000000e+02,
      "input_height": 5.6000000000000000e+01,
      "input_size": 7.7070336000000000e+07,
      "input_width": 5.6000000000000000e+01,
      "num_iterations": 6.3700000000000000e+02,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 1.9200000000000000e+02,
      "output_height": 5.6000000000000000e+01,
      "output_size": 7.7070336000000000e+07,
      "output_width": 5.6000000000000000e+01,
      "predicted_flops": 7.0068059391076050e+10,
      "predicted_flops_count": 7.7070336000000000e+07
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__3460075133082350086<CUDNN_ACTIVATION_RELU>/input[0]:1/input[1]:256/input[2]:6/input[3]:6/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 111512,
      "real_time": 6.2769074443745903e+03,
      "cpu_time": 1.2104518939651793e+04,
      "time_unit": "ns",
      "items_per_second": 1.4682389507367110e+09,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 6.0000000000000000e+00,
      "input[3]": 6.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 6.0000000000000000e+00,
      "input_size": 9.2160000000000000e+03,
      "input_width": 6.0000000000000000e+00,
      "num_iterations": 1.1151200000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 6.0000000000000000e+00,
      "output_size": 9.2160000000000000e+03,
      "output_width": 6.0000000000000000e+00,
      "predicted_flops": 1.4682389507367110e+09,
      "predicted_flops_count": 9.2160000000000000e+03
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__3460075133082350086<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1/input[1]:256/input[2]:6/input[3]:6/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 111525,
      "real_time": 6.2833677018475955e+03,
      "cpu_time": 1.2129255637726494e+04,
      "time_unit": "ns",
      "items_per_second": 1.4667293778287206e+09,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 6.0000000000000000e+00,
      "input[3]": 6.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 6.0000000000000000e+00,
      "input_size": 9.2160000000000000e+03,
      "input_width": 6.0000000000000000e+00,
      "num_iterations": 1.1152500000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 6.0000000000000000e+00,
      "output_size": 9.2160000000000000e+03,
      "output_width": 6.0000000000000000e+00,
      "predicted_flops": 1.4667293778287206e+09,
      "predicted_flops_count": 9.2160000000000000e+03
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__14244930242321980192<CUDNN_ACTIVATION_RELU>/input[0]:1/input[1]:160/input[2]:6/input[3]:6/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 111554,
      "real_time": 6.3057450096519706e+03,
      "cpu_time": 1.2142282311782836e+04,
      "time_unit": "ns",
      "items_per_second": 9.1345273099108529e+08,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 1.6000000000000000e+02,
      "input[2]": 6.0000000000000000e+00,
      "input[3]": 6.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 1.6000000000000000e+02,
      "input_height": 6.0000000000000000e+00,
      "input_size": 5.7600000000000000e+03,
      "input_width": 6.0000000000000000e+00,
      "num_iterations": 1.1155400000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 1.6000000000000000e+02,
      "output_height": 6.0000000000000000e+00,
      "output_size": 5.7600000000000000e+03,
      "output_width": 6.0000000000000000e+00,
      "predicted_flops": 9.1345273099108529e+08,
      "predicted_flops_count": 5.7600000000000000e+03
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__14244930242321980192<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1/input[1]:160/input[2]:6/input[3]:6/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 106140,
      "real_time": 6.5234496961343675e+03,
      "cpu_time": 1.2336426257765026e+04,
      "time_unit": "ns",
      "items_per_second": 8.8296840909392333e+08,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 1.6000000000000000e+02,
      "input[2]": 6.0000000000000000e+00,
      "input[3]": 6.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 1.6000000000000000e+02,
      "input_height": 6.0000000000000000e+00,
      "input_size": 5.7600000000000000e+03,
      "input_width": 6.0000000000000000e+00,
      "num_iterations": 1.0614000000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 1.6000000000000000e+02,
      "output_height": 6.0000000000000000e+00,
      "output_size": 5.7600000000000000e+03,
      "output_width": 6.0000000000000000e+00,
      "predicted_flops": 8.8296840909392333e+08,
      "predicted_flops_count": 5.7600000000000000e+03
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__16783576863349565363<CUDNN_ACTIVATION_RELU>/input[0]:1/input[1]:864/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 110509,
      "real_time": 6.3405920551754652e+03,
      "cpu_time": 1.2177734718481919e+04,
      "time_unit": "ns",
      "items_per_second": 6.6769790000041914e+09,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 8.6400000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 8.6400000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 4.2336000000000000e+04,
      "input_width": 7.0000000000000000e+00,
      "num_iterations": 1.1050900000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 8.6400000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 4.2336000000000000e+04,
      "output_width": 7.0000000000000000e+00,
      "predicted_flops": 6.6769790000041914e+09,
      "predicted_flops_count": 4.2336000000000000e+04
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__16783576863349565363<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1/input[1]:864/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 110160,
      "real_time": 6.3408302780872637e+03,
      "cpu_time": 1.2194651334427339e+04,
      "time_unit": "ns",
      "items_per_second": 6.6767281480952702e+09,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 8.6400000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 8.6400000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 4.2336000000000000e+04,
      "input_width": 7.0000000000000000e+00,
      "num_iterations": 1.1016000000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 8.6400000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 4.2336000000000000e+04,
      "output_width": 7.0000000000000000e+00,
      "predicted_flops": 6.6767281480952702e+09,
      "predicted_flops_count": 4.2336000000000000e+04
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__6116020220632206068<CUDNN_ACTIVATION_RELU>/input[0]:1/input[1]:320/input[2]:6/input[3]:6/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 111497,
      "real_time": 6.2930032475768685e+03,
      "cpu_time": 1.2114136362434967e+04,
      "time_unit": "ns",
      "items_per_second": 1.8306044899048471e+09,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 3.2000000000000000e+02,
      "input[2]": 6.0000000000000000e+00,
      "input[3]": 6.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 3.2000000000000000e+02,
      "input_height": 6.0000000000000000e+00,
      "input_size": 1.1520000000000000e+04,
      "input_width": 6.0000000000000000e+00,
      "num_iterations": 1.1149700000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 3.2000000000000000e+02,
      "output_height": 6.0000000000000000e+00,
      "output_size": 1.1520000000000000e+04,
      "output_width": 6.0000000000000000e+00,
      "predicted_flops": 1.8306044899048471e+09,
      "predicted_flops_count": 1.1520000000000000e+04
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__6116020220632206068<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1/input[1]:320/input[2]:6/input[3]:6/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 111314,
      "real_time": 6.3972523752018651e+03,
      "cpu_time": 1.2181766875611987e+04,
      "time_unit": "ns",
      "items_per_second": 1.8007731013795569e+09,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 3.2000000000000000e+02,
      "input[2]": 6.0000000000000000e+00,
      "input[3]": 6.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 3.2000000000000000e+02,
      "input_height": 6.0000000000000000e+00,
      "input_size": 1.1520000000000000e+04,
      "input_width": 6.0000000000000000e+00,
      "num_iterations": 1.1131400000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 3.2000000000000000e+02,
      "output_height": 6.0000000000000000e+00,
      "output_size": 1.1520000000000000e+04,
      "output_width": 6.0000000000000000e+00,
      "predicted_flops": 1.8007731013795569e+09,
      "predicted_flops_count": 1.1520000000000000e+04
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__16190918981699667463<CUDNN_ACTIVATION_RELU>/input[0]:128/input[1]:128/input[2]:100/input[3]:100/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 291,
      "real_time": 2.4035211958157546e+06,
      "cpu_time": 2.4952555292107761e+06,
      "time_unit": "ns",
      "items_per_second": 6.8166654941602356e+10,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 1.2800000000000000e+02,
      "input[2]": 1.0000000000000000e+02,
      "input[3]": 1.0000000000000000e+02,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 1.2800000000000000e+02,
      "input_height": 1.0000000000000000e+02,
      "input_size": 1.6384000000000000e+08,
      "input_width": 1.0000000000000000e+02,
      "num_iterations": 2.9100000000000000e+02,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 1.0000000000000000e+02,
      "output_size": 1.6384000000000000e+08,
      "output_width": 1.0000000000000000e+02,
      "predicted_flops": 6.8166654941602356e+10,
      "predicted_flops_count": 1.6384000000000000e+08
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__16190918981699667463<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:128/input[1]:128/input[2]:100/input[3]:100/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 291,
      "real_time": 2.4048902680041250e+06,
      "cpu_time": 2.4967095085889222e+06,
      "time_unit": "ns",
      "items_per_second": 6.8127848567483566e+10,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 1.2800000000000000e+02,
      "input[2]": 1.0000000000000000e+02,
      "input[3]": 1.0000000000000000e+02,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 1.2800000000000000e+02,
      "input_height": 1.0000000000000000e+02,
      "input_size": 1.6384000000000000e+08,
      "input_width": 1.0000000000000000e+02,
      "num_iterations": 2.9100000000000000e+02,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 1.0000000000000000e+02,
      "output_size": 1.6384000000000000e+08,
      "output_width": 1.0000000000000000e+02,
      "predicted_flops": 6.8127848567483566e+10,
      "predicted_flops_count": 1.6384000000000000e+08
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__16182859776298916712<CUDNN_ACTIVATION_RELU>/input[0]:1/input[1]:160/input[2]:13/input[3]:13/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 110860,
      "real_time": 6.3068909177852556e+03,
      "cpu_time": 1.2140557974075948e+04,
      "time_unit": "ns",
      "items_per_second": 4.2873739775247989e+09,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 1.6000000000000000e+02,
      "input[2]": 1.3000000000000000e+01,
      "input[3]": 1.3000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 1.6000000000000000e+02,
      "input_height": 1.3000000000000000e+01,
      "input_size": 2.7040000000000000e+04,
      "input_width": 1.3000000000000000e+01,
      "num_iterations": 1.1086000000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 1.6000000000000000e+02,
      "output_height": 1.3000000000000000e+01,
      "output_size": 2.7040000000000000e+04,
      "output_width": 1.3000000000000000e+01,
      "predicted_flops": 4.2873739775247989e+09,
      "predicted_flops_count": 2.7040000000000000e+04
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__16182859776298916712<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1/input[1]:160/input[2]:13/input[3]:13/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 111095,
      "real_time": 6.3633421433754247e+03,
      "cpu_time": 1.2242296719047908e+04,
      "time_unit": "ns",
      "items_per_second": 4.2493393236995864e+09,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 1.6000000000000000e+02,
      "input[2]": 1.3000000000000000e+01,
      "input[3]": 1.3000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 1.6000000000000000e+02,
      "input_height": 1.3000000000000000e+01,
      "input_size": 2.7040000000000000e+04,
      "input_width": 1.3000000000000000e+01,
      "num_iterations": 1.1109500000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 1.6000000000000000e+02,
      "output_height": 1.3000000000000000e+01,
      "output_size": 2.7040000000000000e+04,
      "output_width": 1.3000000000000000e+01,
      "predicted_flops": 4.2493393236995864e+09,
      "predicted_flops_count": 2.7040000000000000e+04
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__17209248717076149071<CUDNN_ACTIVATION_RELU>/input[0]:128/input[1]:160/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 11319,
      "real_time": 6.1697189328320266e+04,
      "cpu_time": 6.7926605265581689e+04,
      "time_unit": "ns",
      "items_per_second": 6.5060986467943611e+10,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 1.6000000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 1.6000000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 4.0140800000000000e+06,
      "input_width": 1.4000000000000000e+01,
      "num_iterations": 1.1319000000000000e+04,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 1.6000000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 4.0140800000000000e+06,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 6.5060986467943611e+10,
      "predicted_flops_count": 4.0140800000000000e+06
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__17209248717076149071<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:128/input[1]:160/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 11344,
      "real_time": 6.1686399681061390e+04,
      "cpu_time": 6.7918610808045327e+04,
      "time_unit": "ns",
      "items_per_second": 6.5072366368504074e+10,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 1.6000000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 1.6000000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 4.0140800000000000e+06,
      "input_width": 1.4000000000000000e+01,
      "num_iterations": 1.1344000000000000e+04,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 1.6000000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 4.0140800000000000e+06,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 6.5072366368504074e+10,
      "predicted_flops_count": 4.0140800000000000e+06
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__6030931145330442278<CUDNN_ACTIVATION_RELU>/input[0]:1/input[1]:768/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 110424,
      "real_time": 6.3317954734673112e+03,
      "cpu_time": 1.2182235836277525e+04,
      "time_unit": "ns",
      "items_per_second": 5.9433378980247765e+09,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 7.6800000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 7.6800000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 3.7632000000000000e+04,
      "input_width": 7.0000000000000000e+00,
      "num_iterations": 1.1042400000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 7.6800000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 3.7632000000000000e+04,
      "output_width": 7.0000000000000000e+00,
      "predicted_flops": 5.9433378980247765e+09,
      "predicted_flops_count": 3.7632000000000000e+04
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__6030931145330442278<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1/input[1]:768/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 110479,
      "real_time": 6.4886097031112886e+03,
      "cpu_time": 1.2429232985154980e+04,
      "time_unit": "ns",
      "items_per_second": 5.7997015881469107e+09,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 7.6800000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 7.6800000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 3.7632000000000000e+04,
      "input_width": 7.0000000000000000e+00,
      "num_iterations": 1.1047900000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 7.6800000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 3.7632000000000000e+04,
      "output_width": 7.0000000000000000e+00,
      "predicted_flops": 5.7997015881469107e+09,
      "predicted_flops_count": 3.7632000000000000e+04
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__16840264435767396395<CUDNN_ACTIVATION_RELU>/input[0]:128/input[1]:96/input[2]:28/input[3]:28/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 5003,
      "real_time": 1.3991369554470846e+05,
      "cpu_time": 1.4637336058433403e+05,
      "time_unit": "ns",
      "items_per_second": 6.8855246532471069e+10,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 9.6000000000000000e+01,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 9.6000000000000000e+01,
      "input_height": 2.8000000000000000e+01,
      "input_size": 9.6337920000000000e+06,
      "input_width": 2.8000000000000000e+01,
      "num_iterations": 5.0030000000000000e+03,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 9.6000000000000000e+01,
      "output_height": 2.8000000000000000e+01,
      "output_size": 9.6337920000000000e+06,
      "output_width": 2.8000000000000000e+01,
      "predicted_flops": 6.8855246532471069e+10,
      "predicted_flops_count": 9.6337920000000000e+06
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__16840264435767396395<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:128/input[1]:96/input[2]:28/input[3]:28/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 5005,
      "real_time": 1.3993954750942765e+05,
      "cpu_time": 1.4637881198703800e+05,
      "time_unit": "ns",
      "items_per_second": 6.8842526444148880e+10,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 9.6000000000000000e+01,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 9.6000000000000000e+01,
      "input_height": 2.8000000000000000e+01,
      "input_size": 9.6337920000000000e+06,
      "input_width": 2.8000000000000000e+01,
      "num_iterations": 5.0050000000000000e+03,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 9.6000000000000000e+01,
      "output_height": 2.8000000000000000e+01,
      "output_size": 9.6337920000000000e+06,
      "output_width": 2.8000000000000000e+01,
      "predicted_flops": 6.8842526444148880e+10,
      "predicted_flops_count": 9.6337920000000000e+06
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__15589547768943294586<CUDNN_ACTIVATION_RELU>/input[0]:128/input[1]:128/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 13810,
      "real_time": 5.0444197149693631e+04,
      "cpu_time": 5.6650097320809611e+04,
      "time_unit": "ns",
      "items_per_second": 6.3659730582499779e+10,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 1.2800000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 1.2800000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 3.2112640000000000e+06,
      "input_width": 1.4000000000000000e+01,
      "num_iterations": 1.3810000000000000e+04,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 3.2112640000000000e+06,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 6.3659730582499779e+10,
      "predicted_flops_count": 3.2112640000000000e+06
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__15589547768943294586<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:128/input[1]:128/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 13839,
      "real_time": 5.0456877709661989e+04,
      "cpu_time": 5.6666464774108441e+04,
      "time_unit": "ns",
      "items_per_second": 6.3643731950244621e+10,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 1.2800000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 1.2800000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 3.2112640000000000e+06,
      "input_width": 1.4000000000000000e+01,
      "num_iterations": 1.3839000000000000e+04,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 3.2112640000000000e+06,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 6.3643731950244621e+10,
      "predicted_flops_count": 3.2112640000000000e+06
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__3554457459958890736<CUDNN_ACTIVATION_RELU>/input[0]:128/input[1]:256/input[2]:100/input[3]:100/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 141,
      "real_time": 4.9805773937321724e+06,
      "cpu_time": 5.3536029574456252e+06,
      "time_unit": "ns",
      "items_per_second": 6.5791568747103539e+10,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 1.0000000000000000e+02,
      "input[3]": 1.0000000000000000e+02,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 1.0000000000000000e+02,
      "input_size": 3.2768000000000000e+08,
      "input_width": 1.0000000000000000e+02,
      "num_iterations": 1.4100000000000000e+02,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 1.0000000000000000e+02,
      "output_size": 3.2768000000000000e+08,
      "output_width": 1.0000000000000000e+02,
      "predicted_flops": 6.5791568747103539e+10,
      "predicted_flops_count": 3.2768000000000000e+08
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__3554457459958890736<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:128/input[1]:256/input[2]:100/input[3]:100/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 140,
      "real_time": 4.9789961360927140e+06,
      "cpu_time": 5.3538683499920936e+06,
      "time_unit": "ns",
      "items_per_second": 6.5812463204108475e+10,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 1.0000000000000000e+02,
      "input[3]": 1.0000000000000000e+02,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 1.0000000000000000e+02,
      "input_size": 3.2768000000000000e+08,
      "input_width": 1.0000000000000000e+02,
      "num_iterations": 1.4000000000000000e+02,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 1.0000000000000000e+02,
      "output_size": 3.2768000000000000e+08,
      "output_width": 1.0000000000000000e+02,
      "predicted_flops": 6.5812463204108475e+10,
      "predicted_flops_count": 3.2768000000000000e+08
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__12714539637107237701<CUDNN_ACTIVATION_RELU>/input[0]:128/input[1]:256/input[2]:8/input[3]:8/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 19975,
      "real_time": 3.5116427728796414e+04,
      "cpu_time": 4.1330791088554455e+04,
      "time_unit": "ns",
      "items_per_second": 5.9719969701823601e+10,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 8.0000000000000000e+00,
      "input[3]": 8.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 8.0000000000000000e+00,
      "input_size": 2.0971520000000000e+06,
      "input_width": 8.0000000000000000e+00,
      "num_iterations": 1.9975000000000000e+04,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 8.0000000000000000e+00,
      "output_size": 2.0971520000000000e+06,
      "output_width": 8.0000000000000000e+00,
      "predicted_flops": 5.9719969701823601e+10,
      "predicted_flops_count": 2.0971520000000000e+06
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__12714539637107237701<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:128/input[1]:256/input[2]:8/input[3]:8/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 19955,
      "real_time": 3.5082810911168752e+04,
      "cpu_time": 4.1276779453738476e+04,
      "time_unit": "ns",
      "items_per_second": 5.9777194173810158e+10,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 8.0000000000000000e+00,
      "input[3]": 8.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 8.0000000000000000e+00,
      "input_size": 2.0971520000000000e+06,
      "input_width": 8.0000000000000000e+00,
      "num_iterations": 1.9955000000000000e+04,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 8.0000000000000000e+00,
      "output_size": 2.0971520000000000e+06,
      "output_width": 8.0000000000000000e+00,
      "predicted_flops": 5.9777194173810158e+10,
      "predicted_flops_count": 2.0971520000000000e+06
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__11346742453623308887<CUDNN_ACTIVATION_RELU>/input[0]:128/input[1]:224/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 8349,
      "real_time": 8.3870794678330887e+04,
      "cpu_time": 9.0148119175909073e+04,
      "time_unit": "ns",
      "items_per_second": 6.7004396721805779e+10,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 2.2400000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 2.2400000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 5.6197120000000000e+06,
      "input_width": 1.4000000000000000e+01,
      "num_iterations": 8.3490000000000000e+03,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 2.2400000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 5.6197120000000000e+06,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 6.7004396721805779e+10,
      "predicted_flops_count": 5.6197120000000000e+06
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__11346742453623308887<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:128/input[1]:224/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 8331,
      "real_time": 8.3884404896744352e+04,
      "cpu_time": 9.0147181251581293e+04,
      "time_unit": "ns",
      "items_per_second": 6.6993525279430183e+10,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 2.2400000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 2.2400000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 5.6197120000000000e+06,
      "input_width": 1.4000000000000000e+01,
      "num_iterations": 8.3310000000000000e+03,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 2.2400000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 5.6197120000000000e+06,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 6.6993525279430183e+10,
      "predicted_flops_count": 5.6197120000000000e+06
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__3740040012013082923<CUDNN_ACTIVATION_RELU>/input[0]:128/input[1]:96/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 17786,
      "real_time": 3.9321844760582106e+04,
      "cpu_time": 4.5523563026742173e+04,
      "time_unit": "ns",
      "items_per_second": 6.1249618746634460e+10,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 9.6000000000000000e+01,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 9.6000000000000000e+01,
      "input_height": 1.4000000000000000e+01,
      "input_size": 2.4084480000000000e+06,
      "input_width": 1.4000000000000000e+01,
      "num_iterations": 1.7786000000000000e+04,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 9.6000000000000000e+01,
      "output_height": 1.4000000000000000e+01,
      "output_size": 2.4084480000000000e+06,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 6.1249618746634460e+10,
      "predicted_flops_count": 2.4084480000000000e+06
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__3740040012013082923<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:128/input[1]:96/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 17788,
      "real_time": 3.9362176450432751e+04,
      "cpu_time": 4.5572896334325298e+04,
      "time_unit": "ns",
      "items_per_second": 6.1186860513997849e+10,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 9.6000000000000000e+01,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 9.6000000000000000e+01,
      "input_height": 1.4000000000000000e+01,
      "input_size": 2.4084480000000000e+06,
      "input_width": 1.4000000000000000e+01,
      "num_iterations": 1.7788000000000000e+04,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 9.6000000000000000e+01,
      "output_height": 1.4000000000000000e+01,
      "output_size": 2.4084480000000000e+06,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 6.1186860513997849e+10,
      "predicted_flops_count": 2.4084480000000000e+06
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__6698331834156115781<CUDNN_ACTIVATION_RELU>/input[0]:128/input[1]:64/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 24812,
      "real_time": 2.8277657127318413e+04,
      "cpu_time": 3.4472005964309326e+04,
      "time_unit": "ns",
      "items_per_second": 5.6780941673164101e+10,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 1.4000000000000000e+01,
      "input_size": 1.6056320000000000e+06,
      "input_width": 1.4000000000000000e+01,
      "num_iterations": 2.4812000000000000e+04,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 1.4000000000000000e+01,
      "output_size": 1.6056320000000000e+06,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 5.6780941673164101e+10,
      "predicted_flops_count": 1.6056320000000000e+06
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__6698331834156115781<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:128/input[1]:64/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 24736,
      "real_time": 2.8269596885764167e+04,
      "cpu_time": 3.4459365095856432e+04,
      "time_unit": "ns",
      "items_per_second": 5.6797131083554794e+10,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 1.4000000000000000e+01,
      "input_size": 1.6056320000000000e+06,
      "input_width": 1.4000000000000000e+01,
      "num_iterations": 2.4736000000000000e+04,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 1.4000000000000000e+01,
      "output_size": 1.6056320000000000e+06,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 5.6797131083554794e+10,
      "predicted_flops_count": 1.6056320000000000e+06
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__10240466360025027105<CUDNN_ACTIVATION_RELU>/input[0]:128/input[1]:352/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 19111,
      "real_time": 3.6648978511937901e+04,
      "cpu_time": 4.2839838471001276e+04,
      "time_unit": "ns",
      "items_per_second": 6.0240260155705505e+10,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 3.5200000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 3.5200000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 2.2077440000000000e+06,
      "input_width": 7.0000000000000000e+00,
      "num_iterations": 1.9111000000000000e+04,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 3.5200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 2.2077440000000000e+06,
      "output_width": 7.0000000000000000e+00,
      "predicted_flops": 6.0240260155705505e+10,
      "predicted_flops_count": 2.2077440000000000e+06
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__10240466360025027105<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:128/input[1]:352/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 19101,
      "real_time": 3.6652554965087795e+04,
      "cpu_time": 4.2836865609080443e+04,
      "time_unit": "ns",
      "items_per_second": 6.0234382080673912e+10,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 3.5200000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 3.5200000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 2.2077440000000000e+06,
      "input_width": 7.0000000000000000e+00,
      "num_iterations": 1.9101000000000000e+04,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 3.5200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 2.2077440000000000e+06,
      "output_width": 7.0000000000000000e+00,
      "predicted_flops": 6.0234382080673912e+10,
      "predicted_flops_count": 2.2077440000000000e+06
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__13390799428213926816<CUDNN_ACTIVATION_RELU>/input[0]:128/input[1]:1024/input[2]:100/input[3]:100/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 33,
      "real_time": 2.1040248995025951e+07,
      "cpu_time": 2.7653044303027246e+07,
      "time_unit": "ns",
      "items_per_second": 6.2295840715091461e+10,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 1.0240000000000000e+03,
      "input[2]": 1.0000000000000000e+02,
      "input[3]": 1.0000000000000000e+02,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 1.0240000000000000e+03,
      "input_height": 1.0000000000000000e+02,
      "input_size": 1.3107200000000000e+09,
      "input_width": 1.0000000000000000e+02,
      "num_iterations": 3.3000000000000000e+01,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 1.0240000000000000e+03,
      "output_height": 1.0000000000000000e+02,
      "output_size": 1.3107200000000000e+09,
      "output_width": 1.0000000000000000e+02,
      "predicted_flops": 6.2295840715091461e+10,
      "predicted_flops_count": 1.3107200000000000e+09
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__13390799428213926816<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:128/input[1]:1024/input[2]:100/input[3]:100/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 33,
      "real_time": 2.1042889492078260e+07,
      "cpu_time": 2.7665890212123293e+07,
      "time_unit": "ns",
      "items_per_second": 6.2288023728558258e+10,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 1.0240000000000000e+03,
      "input[2]": 1.0000000000000000e+02,
      "input[3]": 1.0000000000000000e+02,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 1.0240000000000000e+03,
      "input_height": 1.0000000000000000e+02,
      "input_size": 1.3107200000000000e+09,
      "input_width": 1.0000000000000000e+02,
      "num_iterations": 3.3000000000000000e+01,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 1.0240000000000000e+03,
      "output_height": 1.0000000000000000e+02,
      "output_size": 1.3107200000000000e+09,
      "output_width": 1.0000000000000000e+02,
      "predicted_flops": 6.2288023728558258e+10,
      "predicted_flops_count": 1.3107200000000000e+09
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__5485937294812110399<CUDNN_ACTIVATION_RELU>/input[0]:128/input[1]:160/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 34073,
      "real_time": 2.0006544794122488e+04,
      "cpu_time": 2.6191224077116665e+04,
      "time_unit": "ns",
      "items_per_second": 5.0159585791886139e+10,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 1.6000000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 1.6000000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 1.0035200000000000e+06,
      "input_width": 7.0000000000000000e+00,
      "num_iterations": 3.4073000000000000e+04,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 1.6000000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 1.0035200000000000e+06,
      "output_width": 7.0000000000000000e+00,
      "predicted_flops": 5.0159585791886139e+10,
      "predicted_flops_count": 1.0035200000000000e+06
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__5485937294812110399<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:128/input[1]:160/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 34933,
      "real_time": 2.0027196080640137e+04,
      "cpu_time": 2.6212690378427189e+04,
      "time_unit": "ns",
      "items_per_second": 5.0107863125686447e+10,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 1.6000000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 1.6000000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 1.0035200000000000e+06,
      "input_width": 7.0000000000000000e+00,
      "num_iterations": 3.4933000000000000e+04,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 1.6000000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 1.0035200000000000e+06,
      "output_width": 7.0000000000000000e+00,
      "predicted_flops": 5.0107863125686447e+10,
      "predicted_flops_count": 1.0035200000000000e+06
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__3311159043309202149<CUDNN_ACTIVATION_RELU>/input[0]:128/input[1]:256/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 24762,
      "real_time": 2.8231016416381743e+04,
      "cpu_time": 3.4424276149458870e+04,
      "time_unit": "ns",
      "items_per_second": 5.6874749967142250e+10,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 1.6056320000000000e+06,
      "input_width": 7.0000000000000000e+00,
      "num_iterations": 2.4762000000000000e+04,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 1.6056320000000000e+06,
      "output_width": 7.0000000000000000e+00,
      "predicted_flops": 5.6874749967142250e+10,
      "predicted_flops_count": 1.6056320000000000e+06
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__3311159043309202149<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:128/input[1]:256/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 24715,
      "real_time": 2.8299092721436984e+04,
      "cpu_time": 3.4474774752176687e+04,
      "time_unit": "ns",
      "items_per_second": 5.6737932053337868e+10,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 1.6056320000000000e+06,
      "input_width": 7.0000000000000000e+00,
      "num_iterations": 2.4715000000000000e+04,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 1.6056320000000000e+06,
      "output_width": 7.0000000000000000e+00,
      "predicted_flops": 5.6737932053337868e+10,
      "predicted_flops_count": 1.6056320000000000e+06
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__14409018036447111975<CUDNN_ACTIVATION_RELU>/input[0]:128/input[1]:192/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 9615,
      "real_time": 7.2827479720405754e+04,
      "cpu_time": 7.9063535101850997e+04,
      "time_unit": "ns",
      "items_per_second": 6.6141187618913834e+10,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 1.9200000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 1.9200000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 4.8168960000000000e+06,
      "input_width": 1.4000000000000000e+01,
      "num_iterations": 9.6150000000000000e+03,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 1.9200000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 4.8168960000000000e+06,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 6.6141187618913834e+10,
      "predicted_flops_count": 4.8168960000000000e+06
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__14409018036447111975<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:128/input[1]:192/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 9612,
      "real_time": 7.2841936907230745e+04,
      "cpu_time": 7.9093057636936413e+04,
      "time_unit": "ns",
      "items_per_second": 6.6128060352577538e+10,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 1.9200000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 1.9200000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 4.8168960000000000e+06,
      "input_width": 1.4000000000000000e+01,
      "num_iterations": 9.6120000000000000e+03,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 1.9200000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 4.8168960000000000e+06,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 6.6128060352577538e+10,
      "predicted_flops_count": 4.8168960000000000e+06
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__7982439705678190339<CUDNN_ACTIVATION_RELU>/input[0]:128/input[1]:224/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 27473,
      "real_time": 2.5488343236381577e+04,
      "cpu_time": 3.1666044552793945e+04,
      "time_unit": "ns",
      "items_per_second": 5.5120412769498192e+10,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 2.2400000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 2.2400000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 1.4049280000000000e+06,
      "input_width": 7.0000000000000000e+00,
      "num_iterations": 2.7473000000000000e+04,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 2.2400000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 1.4049280000000000e+06,
      "output_width": 7.0000000000000000e+00,
      "predicted_flops": 5.5120412769498192e+10,
      "predicted_flops_count": 1.4049280000000000e+06
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__7982439705678190339<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:128/input[1]:224/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 26969,
      "real_time": 2.5630159874942128e+04,
      "cpu_time": 3.1788952797727372e+04,
      "time_unit": "ns",
      "items_per_second": 5.4815420850088333e+10,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 2.2400000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 2.2400000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 1.4049280000000000e+06,
      "input_width": 7.0000000000000000e+00,
      "num_iterations": 2.6969000000000000e+04,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 2.2400000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 1.4049280000000000e+06,
      "output_width": 7.0000000000000000e+00,
      "predicted_flops": 5.4815420850088333e+10,
      "predicted_flops_count": 1.4049280000000000e+06
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__16112820294470647347<CUDNN_ACTIVATION_RELU>/input[0]:128/input[1]:192/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 30829,
      "real_time": 2.2732244119672228e+04,
      "cpu_time": 2.8931699081783336e+04,
      "time_unit": "ns",
      "items_per_second": 5.2974268341499901e+10,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 1.9200000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 1.9200000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 1.2042240000000000e+06,
      "input_width": 7.0000000000000000e+00,
      "num_iterations": 3.0829000000000000e+04,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 1.9200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 1.2042240000000000e+06,
      "output_width": 7.0000000000000000e+00,
      "predicted_flops": 5.2974268341499901e+10,
      "predicted_flops_count": 1.2042240000000000e+06
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__16112820294470647347<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:128/input[1]:192/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 30837,
      "real_time": 2.2711687970119267e+04,
      "cpu_time": 2.8899746700411426e+04,
      "time_unit": "ns",
      "items_per_second": 5.3022214887081169e+10,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 1.9200000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 1.9200000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 1.2042240000000000e+06,
      "input_width": 7.0000000000000000e+00,
      "num_iterations": 3.0837000000000000e+04,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 1.9200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 1.2042240000000000e+06,
      "output_width": 7.0000000000000000e+00,
      "predicted_flops": 5.3022214887081169e+10,
      "predicted_flops_count": 1.2042240000000000e+06
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__2469186169906215506<CUDNN_ACTIVATION_RELU>/input[0]:128/input[1]:128/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 44453,
      "real_time": 1.5722055974339497e+04,
      "cpu_time": 2.1847837581021664e+04,
      "time_unit": "ns",
      "items_per_second": 5.1063041710976181e+10,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 1.2800000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 1.2800000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 8.0281600000000000e+05,
      "input_width": 7.0000000000000000e+00,
      "num_iterations": 4.4453000000000000e+04,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 8.0281600000000000e+05,
      "output_width": 7.0000000000000000e+00,
      "predicted_flops": 5.1063041710976181e+10,
      "predicted_flops_count": 8.0281600000000000e+05
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__2469186169906215506<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:128/input[1]:128/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 44275,
      "real_time": 1.5791157140107931e+04,
      "cpu_time": 2.1919709068141125e+04,
      "time_unit": "ns",
      "items_per_second": 5.0839592873211884e+10,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 1.2800000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 1.2800000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 8.0281600000000000e+05,
      "input_width": 7.0000000000000000e+00,
      "num_iterations": 4.4275000000000000e+04,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 8.0281600000000000e+05,
      "output_width": 7.0000000000000000e+00,
      "predicted_flops": 5.0839592873211884e+10,
      "predicted_flops_count": 8.0281600000000000e+05
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__11162441852474213005<CUDNN_ACTIVATION_RELU>/input[0]:1/input[1]:192/input[2]:55/input[3]:55/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 79661,
      "real_time": 8.7968244602900559e+03,
      "cpu_time": 1.4797711339159399e+04,
      "time_unit": "ns",
      "items_per_second": 6.6023825145289925e+10,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 1.9200000000000000e+02,
      "input[2]": 5.5000000000000000e+01,
      "input[3]": 5.5000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 1.9200000000000000e+02,
      "input_height": 5.5000000000000000e+01,
      "input_size": 5.8080000000000000e+05,
      "input_width": 5.5000000000000000e+01,
      "num_iterations": 7.9661000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 1.9200000000000000e+02,
      "output_height": 5.5000000000000000e+01,
      "output_size": 5.8080000000000000e+05,
      "output_width": 5.5000000000000000e+01,
      "predicted_flops": 6.6023825145289925e+10,
      "predicted_flops_count": 5.8080000000000000e+05
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__11162441852474213005<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1/input[1]:192/input[2]:55/input[3]:55/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 79107,
      "real_time": 8.8238271074886688e+03,
      "cpu_time": 1.4810192814643522e+04,
      "time_unit": "ns",
      "items_per_second": 6.5821779248947716e+10,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 1.9200000000000000e+02,
      "input[2]": 5.5000000000000000e+01,
      "input[3]": 5.5000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 1.9200000000000000e+02,
      "input_height": 5.5000000000000000e+01,
      "input_size": 5.8080000000000000e+05,
      "input_width": 5.5000000000000000e+01,
      "num_iterations": 7.9107000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 1.9200000000000000e+02,
      "output_height": 5.5000000000000000e+01,
      "output_size": 5.8080000000000000e+05,
      "output_width": 5.5000000000000000e+01,
      "predicted_flops": 6.5821779248947716e+10,
      "predicted_flops_count": 5.8080000000000000e+05
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__13811507302503856802<CUDNN_ACTIVATION_RELU>/input[0]:128/input[1]:16/input[2]:416/input[3]:416/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 130,
      "real_time": 5.4014424542681528e+06,
      "cpu_time": 5.8381983846183727e+06,
      "time_unit": "ns",
      "items_per_second": 6.5615563064999931e+10,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 1.6000000000000000e+01,
      "input[2]": 4.1600000000000000e+02,
      "input[3]": 4.1600000000000000e+02,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 1.6000000000000000e+01,
      "input_height": 4.1600000000000000e+02,
      "input_size": 3.5441868800000000e+08,
      "input_width": 4.1600000000000000e+02,
      "num_iterations": 1.3000000000000000e+02,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 1.6000000000000000e+01,
      "output_height": 4.1600000000000000e+02,
      "output_size": 3.5441868800000000e+08,
      "output_width": 4.1600000000000000e+02,
      "predicted_flops": 6.5615563064999931e+10,
      "predicted_flops_count": 3.5441868800000000e+08
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__248974903914619304<CUDNN_ACTIVATION_RELU>/input[0]:128/input[1]:512/input[2]:100/input[3]:100/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 68,
      "real_time": 1.0258641436367350e+07,
      "cpu_time": 1.1830540970578341e+07,
      "time_unit": "ns",
      "items_per_second": 6.3883702736379791e+10,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 1.0000000000000000e+02,
      "input[3]": 1.0000000000000000e+02,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 1.0000000000000000e+02,
      "input_size": 6.5536000000000000e+08,
      "input_width": 1.0000000000000000e+02,
      "num_iterations": 6.8000000000000000e+01,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 1.0000000000000000e+02,
      "output_size": 6.5536000000000000e+08,
      "output_width": 1.0000000000000000e+02,
      "predicted_flops": 6.3883702736379791e+10,
      "predicted_flops_count": 6.5536000000000000e+08
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__248974903914619304<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:128/input[1]:512/input[2]:100/input[3]:100/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 68,
      "real_time": 1.0257709278341603e+07,
      "cpu_time": 1.1827197426470092e+07,
      "time_unit": "ns",
      "items_per_second": 6.3889508097460358e+10,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 1.0000000000000000e+02,
      "input[3]": 1.0000000000000000e+02,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 1.0000000000000000e+02,
      "input_size": 6.5536000000000000e+08,
      "input_width": 1.0000000000000000e+02,
      "num_iterations": 6.8000000000000000e+01,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 1.0000000000000000e+02,
      "output_size": 6.5536000000000000e+08,
      "output_width": 1.0000000000000000e+02,
      "predicted_flops": 6.3889508097460358e+10,
      "predicted_flops_count": 6.5536000000000000e+08
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__6951535212333613489<CUDNN_ACTIVATION_RELU>/input[0]:128/input[1]:24/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 64033,
      "real_time": 9.6736149038137974e+03,
      "cpu_time": 1.5600360642148531e+04,
      "time_unit": "ns",
      "items_per_second": 6.2242709265035866e+10,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 2.4000000000000000e+01,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 2.4000000000000000e+01,
      "input_height": 1.4000000000000000e+01,
      "input_size": 6.0211200000000000e+05,
      "input_width": 1.4000000000000000e+01,
      "num_iterations": 6.4033000000000000e+04,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 2.4000000000000000e+01,
      "output_height": 1.4000000000000000e+01,
      "output_size": 6.0211200000000000e+05,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 6.2242709265035866e+10,
      "predicted_flops_count": 6.0211200000000000e+05
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__6951535212333613489<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:128/input[1]:24/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 71913,
      "real_time": 9.7242495724058535e+03,
      "cpu_time": 1.5648150543269199e+04,
      "time_unit": "ns",
      "items_per_second": 6.1918608270667091e+10,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 2.4000000000000000e+01,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 2.4000000000000000e+01,
      "input_height": 1.4000000000000000e+01,
      "input_size": 6.0211200000000000e+05,
      "input_width": 1.4000000000000000e+01,
      "num_iterations": 7.1913000000000000e+04,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 2.4000000000000000e+01,
      "output_height": 1.4000000000000000e+01,
      "output_size": 6.0211200000000000e+05,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 6.1918608270667091e+10,
      "predicted_flops_count": 6.0211200000000000e+05
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__3553234332425407226<CUDNN_ACTIVATION_RELU>/input[0]:128/input[1]:256/input[2]:16/input[3]:16/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 5719,
      "real_time": 1.2237510976255109e+05,
      "cpu_time": 1.2876375345377412e+05,
      "time_unit": "ns",
      "items_per_second": 6.8548318496111862e+10,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 1.6000000000000000e+01,
      "input[3]": 1.6000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 1.6000000000000000e+01,
      "input_size": 8.3886080000000000e+06,
      "input_width": 1.6000000000000000e+01,
      "num_iterations": 5.7190000000000000e+03,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 1.6000000000000000e+01,
      "output_size": 8.3886080000000000e+06,
      "output_width": 1.6000000000000000e+01,
      "predicted_flops": 6.8548318496111862e+10,
      "predicted_flops_count": 8.3886080000000000e+06
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__3553234332425407226<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:128/input[1]:256/input[2]:16/input[3]:16/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 5718,
      "real_time": 1.2236414773713575e+05,
      "cpu_time": 1.2874661052831577e+05,
      "time_unit": "ns",
      "items_per_second": 6.8554459415845535e+10,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 1.6000000000000000e+01,
      "input[3]": 1.6000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 1.6000000000000000e+01,
      "input_size": 8.3886080000000000e+06,
      "input_width": 1.6000000000000000e+01,
      "num_iterations": 5.7180000000000000e+03,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 1.6000000000000000e+01,
      "output_size": 8.3886080000000000e+06,
      "output_width": 1.6000000000000000e+01,
      "predicted_flops": 6.8554459415845535e+10,
      "predicted_flops_count": 8.3886080000000000e+06
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__905413646176338360<CUDNN_ACTIVATION_RELU>/input[0]:128/input[1]:32/input[2]:28/input[3]:28/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 13810,
      "real_time": 5.0467665360573796e+04,
      "cpu_time": 5.6682800434424389e+04,
      "time_unit": "ns",
      "items_per_second": 6.3630127866162292e+10,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 3.2000000000000000e+01,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 3.2000000000000000e+01,
      "input_height": 2.8000000000000000e+01,
      "input_size": 3.2112640000000000e+06,
      "input_width": 2.8000000000000000e+01,
      "num_iterations": 1.3810000000000000e+04,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 3.2000000000000000e+01,
      "output_height": 2.8000000000000000e+01,
      "output_size": 3.2112640000000000e+06,
      "output_width": 2.8000000000000000e+01,
      "predicted_flops": 6.3630127866162292e+10,
      "predicted_flops_count": 3.2112640000000000e+06
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__905413646176338360<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:128/input[1]:32/input[2]:28/input[3]:28/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 13860,
      "real_time": 5.0494533504454674e+04,
      "cpu_time": 5.6705521932951095e+04,
      "time_unit": "ns",
      "items_per_second": 6.3596270271844368e+10,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 3.2000000000000000e+01,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 3.2000000000000000e+01,
      "input_height": 2.8000000000000000e+01,
      "input_size": 3.2112640000000000e+06,
      "input_width": 2.8000000000000000e+01,
      "num_iterations": 1.3860000000000000e+04,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 3.2000000000000000e+01,
      "output_height": 2.8000000000000000e+01,
      "output_size": 3.2112640000000000e+06,
      "output_width": 2.8000000000000000e+01,
      "predicted_flops": 6.3596270271844368e+10,
      "predicted_flops_count": 3.2112640000000000e+06
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__16209224632504742210<CUDNN_ACTIVATION_RELU>/input[0]:128/input[1]:32/input[2]:208/input[3]:208/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 269,
      "real_time": 2.6064493778234408e+06,
      "cpu_time": 2.7131129591099601e+06,
      "time_unit": "ns",
      "items_per_second": 6.7988791766975204e+10,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 3.2000000000000000e+01,
      "input[2]": 2.0800000000000000e+02,
      "input[3]": 2.0800000000000000e+02,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 3.2000000000000000e+01,
      "input_height": 2.0800000000000000e+02,
      "input_size": 1.7720934400000000e+08,
      "input_width": 2.0800000000000000e+02,
      "num_iterations": 2.6900000000000000e+02,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 3.2000000000000000e+01,
      "output_height": 2.0800000000000000e+02,
      "output_size": 1.7720934400000000e+08,
      "output_width": 2.0800000000000000e+02,
      "predicted_flops": 6.7988791766975204e+10,
      "predicted_flops_count": 1.7720934400000000e+08
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__1604481517759940826<CUDNN_ACTIVATION_RELU>/input[0]:128/input[1]:1024/input[2]:12/input[3]:12/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 2597,
      "real_time": 2.6960666370086808e+05,
      "cpu_time": 2.7681123411615955e+05,
      "time_unit": "ns",
      "items_per_second": 7.0007053019065369e+10,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 1.0240000000000000e+03,
      "input[2]": 1.2000000000000000e+01,
      "input[3]": 1.2000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 1.0240000000000000e+03,
      "input_height": 1.2000000000000000e+01,
      "input_size": 1.8874368000000000e+07,
      "input_width": 1.2000000000000000e+01,
      "num_iterations": 2.5970000000000000e+03,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 1.0240000000000000e+03,
      "output_height": 1.2000000000000000e+01,
      "output_size": 1.8874368000000000e+07,
      "output_width": 1.2000000000000000e+01,
      "predicted_flops": 7.0007053019065369e+10,
      "predicted_flops_count": 1.8874368000000000e+07
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__11404165245588578937<CUDNN_ACTIVATION_RELU>/input[0]:128/input[1]:128/input[2]:52/input[3]:52/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 1113,
      "real_time": 6.2927132307552639e+05,
      "cpu_time": 6.4124980593101657e+05,
      "time_unit": "ns",
      "items_per_second": 7.0402598013643707e+10,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 1.2800000000000000e+02,
      "input[2]": 5.2000000000000000e+01,
      "input[3]": 5.2000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 1.2800000000000000e+02,
      "input_height": 5.2000000000000000e+01,
      "input_size": 4.4302336000000000e+07,
      "input_width": 5.2000000000000000e+01,
      "num_iterations": 1.1130000000000000e+03,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 5.2000000000000000e+01,
      "output_size": 4.4302336000000000e+07,
      "output_width": 5.2000000000000000e+01,
      "predicted_flops": 7.0402598013643707e+10,
      "predicted_flops_count": 4.4302336000000000e+07
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__9620316750620623884<CUDNN_ACTIVATION_RELU>/input[0]:128/input[1]:512/input[2]:13/input[3]:13/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 4372,
      "real_time": 1.6012968944320889e+05,
      "cpu_time": 1.6666378225109816e+05,
      "time_unit": "ns",
      "items_per_second": 6.9166336601983063e+10,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 1.3000000000000000e+01,
      "input[3]": 1.3000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 1.3000000000000000e+01,
      "input_size": 1.1075584000000000e+07,
      "input_width": 1.3000000000000000e+01,
      "num_iterations": 4.3720000000000000e+03,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 1.3000000000000000e+01,
      "output_size": 1.1075584000000000e+07,
      "output_width": 1.3000000000000000e+01,
      "predicted_flops": 6.9166336601983063e+10,
      "predicted_flops_count": 1.1075584000000000e+07
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__7523049824865877230<CUDNN_ACTIVATION_RELU>/input[0]:128/input[1]:64/input[2]:104/input[3]:104/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 552,
      "real_time": 1.2687860272716784e+06,
      "cpu_time": 1.2987149637695395e+06,
      "time_unit": "ns",
      "items_per_second": 6.9834211675967285e+10,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 1.0400000000000000e+02,
      "input[3]": 1.0400000000000000e+02,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 1.0400000000000000e+02,
      "input_size": 8.8604672000000000e+07,
      "input_width": 1.0400000000000000e+02,
      "num_iterations": 5.5200000000000000e+02,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 1.0400000000000000e+02,
      "output_size": 8.8604672000000000e+07,
      "output_width": 1.0400000000000000e+02,
      "predicted_flops": 6.9834211675967285e+10,
      "predicted_flops_count": 8.8604672000000000e+07
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__13641513767584415507<CUDNN_ACTIVATION_RELU>/input[0]:128/input[1]:2048/input[2]:100/input[3]:100/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD failed to cudnnSetTensor4dDescriptor",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__13641513767584415507<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:128/input[1]:2048/input[2]:100/input[3]:100/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD failed to cudnnSetTensor4dDescriptor",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__11705896087681706035<CUDNN_ACTIVATION_RELU>/input[0]:128/input[1]:320/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 20683,
      "real_time": 3.3790574231355982e+04,
      "cpu_time": 3.9985079969379331e+04,
      "time_unit": "ns",
      "items_per_second": 5.9396445477909821e+10,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 3.2000000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 3.2000000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 2.0070400000000000e+06,
      "input_width": 7.0000000000000000e+00,
      "num_iterations": 2.0683000000000000e+04,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 3.2000000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 2.0070400000000000e+06,
      "output_width": 7.0000000000000000e+00,
      "predicted_flops": 5.9396445477909821e+10,
      "predicted_flops_count": 2.0070400000000000e+06
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__11705896087681706035<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:128/input[1]:320/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 20670,
      "real_time": 3.3814869802802525e+04,
      "cpu_time": 4.0005505854064708e+04,
      "time_unit": "ns",
      "items_per_second": 5.9353769856409721e+10,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 3.2000000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 3.2000000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 2.0070400000000000e+06,
      "input_width": 7.0000000000000000e+00,
      "num_iterations": 2.0670000000000000e+04,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 3.2000000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 2.0070400000000000e+06,
      "output_width": 7.0000000000000000e+00,
      "predicted_flops": 5.9353769856409721e+10,
      "predicted_flops_count": 2.0070400000000000e+06
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__1481627139142729746<CUDNN_ACTIVATION_RELU>/input[0]:128/input[1]:128/input[2]:56/input[3]:56/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 959,
      "real_time": 7.2991153014322685e+05,
      "cpu_time": 7.4393151094919827e+05,
      "time_unit": "ns",
      "items_per_second": 7.0392399459586441e+10,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 1.2800000000000000e+02,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 1.2800000000000000e+02,
      "input_height": 5.6000000000000000e+01,
      "input_size": 5.1380224000000000e+07,
      "input_width": 5.6000000000000000e+01,
      "num_iterations": 9.5900000000000000e+02,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 5.6000000000000000e+01,
      "output_size": 5.1380224000000000e+07,
      "output_width": 5.6000000000000000e+01,
      "predicted_flops": 7.0392399459586441e+10,
      "predicted_flops_count": 5.1380224000000000e+07
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__1481627139142729746<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:128/input[1]:128/input[2]:56/input[3]:56/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 959,
      "real_time": 7.3021321049556369e+05,
      "cpu_time": 7.4417560479705152e+05,
      "time_unit": "ns",
      "items_per_second": 7.0363317537258057e+10,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 1.2800000000000000e+02,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 1.2800000000000000e+02,
      "input_height": 5.6000000000000000e+01,
      "input_size": 5.1380224000000000e+07,
      "input_width": 5.6000000000000000e+01,
      "num_iterations": 9.5900000000000000e+02,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 5.6000000000000000e+01,
      "output_size": 5.1380224000000000e+07,
      "output_width": 5.6000000000000000e+01,
      "predicted_flops": 7.0363317537258057e+10,
      "predicted_flops_count": 5.1380224000000000e+07
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__8242555014862608825<CUDNN_ACTIVATION_RELU>/input[0]:128/input[1]:256/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 7365,
      "real_time": 9.4911872094298873e+04,
      "cpu_time": 1.0122452450755378e+05,
      "time_unit": "ns",
      "items_per_second": 6.7668331245420517e+10,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 6.4225280000000000e+06,
      "input_width": 1.4000000000000000e+01,
      "num_iterations": 7.3650000000000000e+03,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 6.4225280000000000e+06,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 6.7668331245420517e+10,
      "predicted_flops_count": 6.4225280000000000e+06
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__8242555014862608825<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:128/input[1]:256/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 7377,
      "real_time": 9.4909217596264658e+04,
      "cpu_time": 1.0118338836801796e+05,
      "time_unit": "ns",
      "items_per_second": 6.7670223848234222e+10,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 6.4225280000000000e+06,
      "input_width": 1.4000000000000000e+01,
      "num_iterations": 7.3770000000000000e+03,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 6.4225280000000000e+06,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 6.7670223848234222e+10,
      "predicted_flops_count": 6.4225280000000000e+06
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__6387969106677877641<CUDNN_ACTIVATION_RELU>/input[0]:128/input[1]:1024/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 1921,
      "real_time": 3.6450738818997995e+05,
      "cpu_time": 3.7262637115943851e+05,
      "time_unit": "ns",
      "items_per_second": 7.0478988444015869e+10,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 1.0240000000000000e+03,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 1.0240000000000000e+03,
      "input_height": 1.4000000000000000e+01,
      "input_size": 2.5690112000000000e+07,
      "input_width": 1.4000000000000000e+01,
      "num_iterations": 1.9210000000000000e+03,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 1.0240000000000000e+03,
      "output_height": 1.4000000000000000e+01,
      "output_size": 2.5690112000000000e+07,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 7.0478988444015869e+10,
      "predicted_flops_count": 2.5690112000000000e+07
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__6387969106677877641<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:128/input[1]:1024/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 1920,
      "real_time": 3.6458820239507384e+05,
      "cpu_time": 3.7268156198049238e+05,
      "time_unit": "ns",
      "items_per_second": 7.0463366151825638e+10,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 1.0240000000000000e+03,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 1.0240000000000000e+03,
      "input_height": 1.4000000000000000e+01,
      "input_size": 2.5690112000000000e+07,
      "input_width": 1.4000000000000000e+01,
      "num_iterations": 1.9200000000000000e+03,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 1.0240000000000000e+03,
      "output_height": 1.4000000000000000e+01,
      "output_size": 2.5690112000000000e+07,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 7.0463366151825638e+10,
      "predicted_flops_count": 2.5690112000000000e+07
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__6799485797667927710<CUDNN_ACTIVATION_RELU>/input[0]:128/input[1]:128/input[2]:28/input[3]:28/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 3788,
      "real_time": 1.8475166822424324e+05,
      "cpu_time": 1.9141510216348711e+05,
      "time_unit": "ns",
      "items_per_second": 6.9526062327130127e+10,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 1.2800000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 1.2800000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 1.2845056000000000e+07,
      "input_width": 2.8000000000000000e+01,
      "num_iterations": 3.7880000000000000e+03,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 1.2845056000000000e+07,
      "output_width": 2.8000000000000000e+01,
      "predicted_flops": 6.9526062327130127e+10,
      "predicted_flops_count": 1.2845056000000000e+07
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__6799485797667927710<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:128/input[1]:128/input[2]:28/input[3]:28/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 3787,
      "real_time": 1.8478166120848517e+05,
      "cpu_time": 1.9144368207112377e+05,
      "time_unit": "ns",
      "items_per_second": 6.9514777148297211e+10,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 1.2800000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 1.2800000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 1.2845056000000000e+07,
      "input_width": 2.8000000000000000e+01,
      "num_iterations": 3.7870000000000000e+03,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 1.2845056000000000e+07,
      "output_width": 2.8000000000000000e+01,
      "predicted_flops": 6.9514777148297211e+10,
      "predicted_flops_count": 1.2845056000000000e+07
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__16061700958344977745<CUDNN_ACTIVATION_RELU>/input[0]:128/input[1]:512/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 13863,
      "real_time": 5.0495858786558179e+04,
      "cpu_time": 5.6696622880603500e+04,
      "time_unit": "ns",
      "items_per_second": 6.3594601164696434e+10,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 3.2112640000000000e+06,
      "input_width": 7.0000000000000000e+00,
      "num_iterations": 1.3863000000000000e+04,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 3.2112640000000000e+06,
      "output_width": 7.0000000000000000e+00,
      "predicted_flops": 6.3594601164696434e+10,
      "predicted_flops_count": 3.2112640000000000e+06
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__16061700958344977745<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:128/input[1]:512/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 13840,
      "real_time": 5.0504293248894821e+04,
      "cpu_time": 5.6713932442687365e+04,
      "time_unit": "ns",
      "items_per_second": 6.3583980557341469e+10,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 3.2112640000000000e+06,
      "input_width": 7.0000000000000000e+00,
      "num_iterations": 1.3840000000000000e+04,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 3.2112640000000000e+06,
      "output_width": 7.0000000000000000e+00,
      "predicted_flops": 6.3583980557341469e+10,
      "predicted_flops_count": 3.2112640000000000e+06
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__5319246877271560707<CUDNN_ACTIVATION_RELU>/input[0]:128/input[1]:64/input[2]:224/input[3]:224/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 111,
      "real_time": 6.3026900663300678e+06,
      "cpu_time": 6.8979717747811871e+06,
      "time_unit": "ns",
      "items_per_second": 6.5216881628980614e+10,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 2.2400000000000000e+02,
      "input[3]": 2.2400000000000000e+02,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 2.2400000000000000e+02,
      "input_size": 4.1104179200000000e+08,
      "input_width": 2.2400000000000000e+02,
      "num_iterations": 1.1100000000000000e+02,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 2.2400000000000000e+02,
      "output_size": 4.1104179200000000e+08,
      "output_width": 2.2400000000000000e+02,
      "predicted_flops": 6.5216881628980614e+10,
      "predicted_flops_count": 4.1104179200000000e+08
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__5319246877271560707<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:128/input[1]:64/input[2]:224/input[3]:224/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 111,
      "real_time": 6.3065389582367092e+06,
      "cpu_time": 6.9014962522485582e+06,
      "time_unit": "ns",
      "items_per_second": 6.5177079650503914e+10,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 2.2400000000000000e+02,
      "input[3]": 2.2400000000000000e+02,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 2.2400000000000000e+02,
      "input_size": 4.1104179200000000e+08,
      "input_width": 2.2400000000000000e+02,
      "num_iterations": 1.1100000000000000e+02,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 2.2400000000000000e+02,
      "output_size": 4.1104179200000000e+08,
      "output_width": 2.2400000000000000e+02,
      "predicted_flops": 6.5177079650503914e+10,
      "predicted_flops_count": 4.1104179200000000e+08
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__206422828309295546<CUDNN_ACTIVATION_RELU>/input[0]:128/input[1]:2048/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 3788,
      "real_time": 1.8475759842165909e+05,
      "cpu_time": 1.9140870802602312e+05,
      "time_unit": "ns",
      "items_per_second": 6.9523830736772446e+10,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 2.0480000000000000e+03,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 2.0480000000000000e+03,
      "input_height": 7.0000000000000000e+00,
      "input_size": 1.2845056000000000e+07,
      "input_width": 7.0000000000000000e+00,
      "num_iterations": 3.7880000000000000e+03,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 2.0480000000000000e+03,
      "output_height": 7.0000000000000000e+00,
      "output_size": 1.2845056000000000e+07,
      "output_width": 7.0000000000000000e+00,
      "predicted_flops": 6.9523830736772446e+10,
      "predicted_flops_count": 1.2845056000000000e+07
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__206422828309295546<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:128/input[1]:2048/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 3790,
      "real_time": 1.8485912573287301e+05,
      "cpu_time": 1.9152021688595015e+05,
      "time_unit": "ns",
      "items_per_second": 6.9485647241248398e+10,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 2.0480000000000000e+03,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 2.0480000000000000e+03,
      "input_height": 7.0000000000000000e+00,
      "input_size": 1.2845056000000000e+07,
      "input_width": 7.0000000000000000e+00,
      "num_iterations": 3.7900000000000000e+03,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 2.0480000000000000e+03,
      "output_height": 7.0000000000000000e+00,
      "output_size": 1.2845056000000000e+07,
      "output_width": 7.0000000000000000e+00,
      "predicted_flops": 6.9485647241248398e+10,
      "predicted_flops_count": 1.2845056000000000e+07
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__9583543823496601561<CUDNN_ACTIVATION_RELU>/input[0]:128/input[1]:64/input[2]:112/input[3]:112/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 475,
      "real_time": 1.4756438959585994e+06,
      "cpu_time": 1.5138867305258350e+06,
      "time_unit": "ns",
      "items_per_second": 6.9637700722670181e+10,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 1.1200000000000000e+02,
      "input[3]": 1.1200000000000000e+02,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 1.1200000000000000e+02,
      "input_size": 1.0276044800000000e+08,
      "input_width": 1.1200000000000000e+02,
      "num_iterations": 4.7500000000000000e+02,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 1.1200000000000000e+02,
      "output_size": 1.0276044800000000e+08,
      "output_width": 1.1200000000000000e+02,
      "predicted_flops": 6.9637700722670181e+10,
      "predicted_flops_count": 1.0276044800000000e+08
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__9583543823496601561<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:128/input[1]:64/input[2]:112/input[3]:112/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 474,
      "real_time": 1.4755736067812529e+06,
      "cpu_time": 1.5139215949376244e+06,
      "time_unit": "ns",
      "items_per_second": 6.9641017925331985e+10,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 1.1200000000000000e+02,
      "input[3]": 1.1200000000000000e+02,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 1.1200000000000000e+02,
      "input_size": 1.0276044800000000e+08,
      "input_width": 1.1200000000000000e+02,
      "num_iterations": 4.7400000000000000e+02,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 1.1200000000000000e+02,
      "output_size": 1.0276044800000000e+08,
      "output_width": 1.1200000000000000e+02,
      "predicted_flops": 6.9641017925331985e+10,
      "predicted_flops_count": 1.0276044800000000e+08
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__17023923929730144393<CUDNN_ACTIVATION_RELU>/input[0]:128/input[1]:256/input[2]:28/input[3]:28/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 1921,
      "real_time": 3.6445531504384335e+05,
      "cpu_time": 3.7253875117170287e+05,
      "time_unit": "ns",
      "items_per_second": 7.0489058437546783e+10,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 2.5690112000000000e+07,
      "input_width": 2.8000000000000000e+01,
      "num_iterations": 1.9210000000000000e+03,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 2.5690112000000000e+07,
      "output_width": 2.8000000000000000e+01,
      "predicted_flops": 7.0489058437546783e+10,
      "predicted_flops_count": 2.5690112000000000e+07
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__17023923929730144393<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:128/input[1]:256/input[2]:28/input[3]:28/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 1920,
      "real_time": 3.6456008610912249e+05,
      "cpu_time": 3.7265292499958730e+05,
      "time_unit": "ns",
      "items_per_second": 7.0468800559560623e+10,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 2.5690112000000000e+07,
      "input_width": 2.8000000000000000e+01,
      "num_iterations": 1.9200000000000000e+03,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 2.5690112000000000e+07,
      "output_width": 2.8000000000000000e+01,
      "predicted_flops": 7.0468800559560623e+10,
      "predicted_flops_count": 2.5690112000000000e+07
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__13496529203017699962<CUDNN_ACTIVATION_RELU>/input[0]:128/input[1]:128/input[2]:112/input[3]:112/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 230,
      "real_time": 3.0459318279653140e+06,
      "cpu_time": 3.1896678956523710e+06,
      "time_unit": "ns",
      "items_per_second": 6.7473898828946609e+10,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 1.2800000000000000e+02,
      "input[2]": 1.1200000000000000e+02,
      "input[3]": 1.1200000000000000e+02,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 1.2800000000000000e+02,
      "input_height": 1.1200000000000000e+02,
      "input_size": 2.0552089600000000e+08,
      "input_width": 1.1200000000000000e+02,
      "num_iterations": 2.3000000000000000e+02,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 1.1200000000000000e+02,
      "output_size": 2.0552089600000000e+08,
      "output_width": 1.1200000000000000e+02,
      "predicted_flops": 6.7473898828946609e+10,
      "predicted_flops_count": 2.0552089600000000e+08
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__13496529203017699962<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:128/input[1]:128/input[2]:112/input[3]:112/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 230,
      "real_time": 3.0461551510202498e+06,
      "cpu_time": 3.1894445130433268e+06,
      "time_unit": "ns",
      "items_per_second": 6.7468952108747589e+10,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 1.2800000000000000e+02,
      "input[2]": 1.1200000000000000e+02,
      "input[3]": 1.1200000000000000e+02,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 1.2800000000000000e+02,
      "input_height": 1.1200000000000000e+02,
      "input_size": 2.0552089600000000e+08,
      "input_width": 1.1200000000000000e+02,
      "num_iterations": 2.3000000000000000e+02,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 1.1200000000000000e+02,
      "output_size": 2.0552089600000000e+08,
      "output_width": 1.1200000000000000e+02,
      "predicted_flops": 6.7468952108747589e+10,
      "predicted_flops_count": 2.0552089600000000e+08
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__17872007209646640521<CUDNN_ACTIVATION_RELU>/input[0]:128/input[1]:512/input[2]:28/input[3]:28/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 959,
      "real_time": 7.2984245816504001e+05,
      "cpu_time": 7.4378924713487003e+05,
      "time_unit": "ns",
      "items_per_second": 7.0399061366174103e+10,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 5.1380224000000000e+07,
      "input_width": 2.8000000000000000e+01,
      "num_iterations": 9.5900000000000000e+02,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 5.1380224000000000e+07,
      "output_width": 2.8000000000000000e+01,
      "predicted_flops": 7.0399061366174103e+10,
      "predicted_flops_count": 5.1380224000000000e+07
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__17872007209646640521<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:128/input[1]:512/input[2]:28/input[3]:28/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 959,
      "real_time": 7.3015131274815090e+05,
      "cpu_time": 7.4418305317930784e+05,
      "time_unit": "ns",
      "items_per_second": 7.0369282507504639e+10,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 5.1380224000000000e+07,
      "input_width": 2.8000000000000000e+01,
      "num_iterations": 9.5900000000000000e+02,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 5.1380224000000000e+07,
      "output_width": 2.8000000000000000e+01,
      "predicted_flops": 7.0369282507504639e+10,
      "predicted_flops_count": 5.1380224000000000e+07
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__9242866265924482173<CUDNN_ACTIVATION_RELU>/input[0]:128/input[1]:64/input[2]:56/input[3]:56/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 1921,
      "real_time": 3.6452897705083434e+05,
      "cpu_time": 3.7261180530813325e+05,
      "time_unit": "ns",
      "items_per_second": 7.0474814397038895e+10,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 2.5690112000000000e+07,
      "input_width": 5.6000000000000000e+01,
      "num_iterations": 1.9210000000000000e+03,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 5.6000000000000000e+01,
      "output_size": 2.5690112000000000e+07,
      "output_width": 5.6000000000000000e+01,
      "predicted_flops": 7.0474814397038895e+10,
      "predicted_flops_count": 2.5690112000000000e+07
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__9242866265924482173<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:128/input[1]:64/input[2]:56/input[3]:56/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 1920,
      "real_time": 3.6458283577000356e+05,
      "cpu_time": 3.7265446249854506e+05,
      "time_unit": "ns",
      "items_per_second": 7.0464403365951553e+10,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 2.5690112000000000e+07,
      "input_width": 5.6000000000000000e+01,
      "num_iterations": 1.9200000000000000e+03,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 5.6000000000000000e+01,
      "output_size": 2.5690112000000000e+07,
      "output_width": 5.6000000000000000e+01,
      "predicted_flops": 7.0464403365951553e+10,
      "predicted_flops_count": 2.5690112000000000e+07
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__3352989603140871193<CUDNN_ACTIVATION_RELU>/input[0]:128/input[1]:256/input[2]:56/input[3]:56/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 475,
      "real_time": 1.4756188982803570e+06,
      "cpu_time": 1.5139473178997401e+06,
      "time_unit": "ns",
      "items_per_second": 6.9638880418076782e+10,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 5.6000000000000000e+01,
      "input_size": 1.0276044800000000e+08,
      "input_width": 5.6000000000000000e+01,
      "num_iterations": 4.7500000000000000e+02,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 5.6000000000000000e+01,
      "output_size": 1.0276044800000000e+08,
      "output_width": 5.6000000000000000e+01,
      "predicted_flops": 6.9638880418076782e+10,
      "predicted_flops_count": 1.0276044800000000e+08
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__3352989603140871193<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:128/input[1]:256/input[2]:56/input[3]:56/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 475,
      "real_time": 1.4756644414247652e+06,
      "cpu_time": 1.5139704400036482e+06,
      "time_unit": "ns",
      "items_per_second": 6.9636731166866104e+10,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 5.6000000000000000e+01,
      "input_size": 1.0276044800000000e+08,
      "input_width": 5.6000000000000000e+01,
      "num_iterations": 4.7500000000000000e+02,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 5.6000000000000000e+01,
      "output_size": 1.0276044800000000e+08,
      "output_width": 5.6000000000000000e+01,
      "predicted_flops": 6.9636731166866104e+10,
      "predicted_flops_count": 1.0276044800000000e+08
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__12060485571192749417<CUDNN_ACTIVATION_RELU>/input[0]:128/input[1]:512/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 3787,
      "real_time": 1.8475599020057620e+05,
      "cpu_time": 1.9142144837757849e+05,
      "time_unit": "ns",
      "items_per_second": 6.9524435911685760e+10,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 1.2845056000000000e+07,
      "input_width": 1.4000000000000000e+01,
      "num_iterations": 3.7870000000000000e+03,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 1.2845056000000000e+07,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 6.9524435911685760e+10,
      "predicted_flops_count": 1.2845056000000000e+07
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__12060485571192749417<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:128/input[1]:512/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 3786,
      "real_time": 1.8481720621040562e+05,
      "cpu_time": 1.9148388378336566e+05,
      "time_unit": "ns",
      "items_per_second": 6.9501407706469238e+10,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 1.2845056000000000e+07,
      "input_width": 1.4000000000000000e+01,
      "num_iterations": 3.7860000000000000e+03,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 1.2845056000000000e+07,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 6.9501407706469238e+10,
      "predicted_flops_count": 1.2845056000000000e+07
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__11751377051572972149<CUDNN_ACTIVATION_RELU>/input[0]:128/input[1]:4096/input[2]:-1/input[3]:-1/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 86215,
      "real_time": 8.1379140523117921e+03,
      "cpu_time": 1.3995439378287227e+04,
      "time_unit": "ns",
      "items_per_second": 6.4425354781310577e+10,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 4.0960000000000000e+03,
      "input[2]": -1.0000000000000000e+00,
      "input[3]": -1.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 4.0960000000000000e+03,
      "input_height": 1.0000000000000000e+00,
      "input_size": 5.2428800000000000e+05,
      "input_width": 1.0000000000000000e+00,
      "num_iterations": 8.6215000000000000e+04,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 4.0960000000000000e+03,
      "output_height": 1.0000000000000000e+00,
      "output_size": 5.2428800000000000e+05,
      "output_width": 1.0000000000000000e+00,
      "predicted_flops": 6.4425354781310577e+10,
      "predicted_flops_count": 5.2428800000000000e+05
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__11751377051572972149<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:128/input[1]:4096/input[2]:-1/input[3]:-1/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 85719,
      "real_time": 8.1670147808394786e+03,
      "cpu_time": 1.4019141170553872e+04,
      "time_unit": "ns",
      "items_per_second": 6.4195794187862236e+10,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 4.0960000000000000e+03,
      "input[2]": -1.0000000000000000e+00,
      "input[3]": -1.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 4.0960000000000000e+03,
      "input_height": 1.0000000000000000e+00,
      "input_size": 5.2428800000000000e+05,
      "input_width": 1.0000000000000000e+00,
      "num_iterations": 8.5719000000000000e+04,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 4.0960000000000000e+03,
      "output_height": 1.0000000000000000e+00,
      "output_size": 5.2428800000000000e+05,
      "output_width": 1.0000000000000000e+00,
      "predicted_flops": 6.4195794187862236e+10,
      "predicted_flops_count": 5.2428800000000000e+05
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_128__14635279133322201344<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:1/input[1]:112/input[2]:28/input[3]:28/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 98084,
      "real_time": 7.2027422471186956e+03,
      "cpu_time": 1.3007773734794215e+04,
      "time_unit": "ns",
      "items_per_second": 1.2190912431320963e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = false]": 1.4627515035010154e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 1.1200000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 1.1200000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 8.7808000000000000e+04,
      "input_width": 2.8000000000000000e+01,
      "is_training": 0.0000000000000000e+00,
      "num_iterations": 9.8084000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 1.1200000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 8.7808000000000000e+04,
      "output_width": 2.8000000000000000e+01,
      "predicted_flops": 1.2190912431320963e+10,
      "predicted_flops_count": 8.7808000000000000e+04
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_128__2608648416314068011<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:1/input[1]:112/input[2]:28/input[3]:28/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 53138,
      "real_time": 1.3287266345646225e+04,
      "cpu_time": 1.8965761696162001e+04,
      "time_unit": "ns",
      "items_per_second": 6.6084322926793451e+09,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = true]": 9.0033003156525926e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 1.1200000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 1.1200000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 8.7808000000000000e+04,
      "input_width": 2.8000000000000000e+01,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 5.3138000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 1.1200000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 8.7808000000000000e+04,
      "output_width": 2.8000000000000000e+01,
      "predicted_flops": 6.6084322926793451e+09,
      "predicted_flops_count": 8.7808000000000000e+04
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_128__12759236022740069797<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:1/input[1]:136/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 116612,
      "real_time": 6.0050517347802843e+03,
      "cpu_time": 1.1817090736660681e+04,
      "time_unit": "ns",
      "items_per_second": 4.4389292844244413e+09,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = false]": 1.4627515035010154e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 1.3600000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 1.3600000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 2.6656000000000000e+04,
      "input_width": 1.4000000000000000e+01,
      "is_training": 0.0000000000000000e+00,
      "num_iterations": 1.1661200000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 1.3600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 2.6656000000000000e+04,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 4.4389292844244413e+09,
      "predicted_flops_count": 2.6656000000000000e+04
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_128__6789416899669682318<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:1/input[1]:136/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 67454,
      "real_time": 1.0392162423798145e+04,
      "cpu_time": 1.6215335428689797e+04,
      "time_unit": "ns",
      "items_per_second": 2.5650099481660838e+09,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = true]": 9.0033003156525926e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 1.3600000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 1.3600000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 2.6656000000000000e+04,
      "input_width": 1.4000000000000000e+01,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 6.7454000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 1.3600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 2.6656000000000000e+04,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 2.5650099481660838e+09,
      "predicted_flops_count": 2.6656000000000000e+04
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_128__249465507809891955<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:128/input[1]:112/input[2]:56/input[3]:56/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 494,
      "real_time": 1.4168848309511328e+06,
      "cpu_time": 1.4519672408913434e+06,
      "time_unit": "ns",
      "items_per_second": 3.1729957875136967e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = false]": 1.4627515035010154e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 1.1200000000000000e+02,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 1.1200000000000000e+02,
      "input_height": 5.6000000000000000e+01,
      "input_size": 4.4957696000000000e+07,
      "input_width": 5.6000000000000000e+01,
      "is_training": 0.0000000000000000e+00,
      "num_iterations": 4.9400000000000000e+02,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 1.1200000000000000e+02,
      "output_height": 5.6000000000000000e+01,
      "output_size": 4.4957696000000000e+07,
      "output_width": 5.6000000000000000e+01,
      "predicted_flops": 3.1729957875136967e+10,
      "predicted_flops_count": 4.4957696000000000e+07
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_128__17032460631051785048<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:128/input[1]:112/input[2]:56/input[3]:56/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 346,
      "real_time": 2.0241320545036842e+06,
      "cpu_time": 2.0890066820842514e+06,
      "time_unit": "ns",
      "items_per_second": 2.2210851263369572e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = true]": 9.0033003156525926e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 1.1200000000000000e+02,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 1.1200000000000000e+02,
      "input_height": 5.6000000000000000e+01,
      "input_size": 4.4957696000000000e+07,
      "input_width": 5.6000000000000000e+01,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 3.4600000000000000e+02,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 1.1200000000000000e+02,
      "output_height": 5.6000000000000000e+01,
      "output_size": 4.4957696000000000e+07,
      "output_width": 5.6000000000000000e+01,
      "predicted_flops": 2.2210851263369572e+10,
      "predicted_flops_count": 4.4957696000000000e+07
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_128__1206941806307629707<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:128/input[1]:24/input[2]:112/input[3]:112/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 575,
      "real_time": 1.2174396909287442e+06,
      "cpu_time": 1.2449097478247494e+06,
      "time_unit": "ns",
      "items_per_second": 3.1652629930771194e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = false]": 1.4627515035010154e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 2.4000000000000000e+01,
      "input[2]": 1.1200000000000000e+02,
      "input[3]": 1.1200000000000000e+02,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 2.4000000000000000e+01,
      "input_height": 1.1200000000000000e+02,
      "input_size": 3.8535168000000000e+07,
      "input_width": 1.1200000000000000e+02,
      "is_training": 0.0000000000000000e+00,
      "num_iterations": 5.7500000000000000e+02,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 2.4000000000000000e+01,
      "output_height": 1.1200000000000000e+02,
      "output_size": 3.8535168000000000e+07,
      "output_width": 1.1200000000000000e+02,
      "predicted_flops": 3.1652629930771194e+10,
      "predicted_flops_count": 3.8535168000000000e+07
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_128__18417145293194305440<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:128/input[1]:24/input[2]:112/input[3]:112/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 403,
      "real_time": 1.7364785071143478e+06,
      "cpu_time": 1.7858602233252188e+06,
      "time_unit": "ns",
      "items_per_second": 2.2191560587776653e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = true]": 9.0033003156525926e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 2.4000000000000000e+01,
      "input[2]": 1.1200000000000000e+02,
      "input[3]": 1.1200000000000000e+02,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 2.4000000000000000e+01,
      "input_height": 1.1200000000000000e+02,
      "input_size": 3.8535168000000000e+07,
      "input_width": 1.1200000000000000e+02,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 4.0300000000000000e+02,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 2.4000000000000000e+01,
      "output_height": 1.1200000000000000e+02,
      "output_size": 3.8535168000000000e+07,
      "output_width": 1.1200000000000000e+02,
      "predicted_flops": 2.2191560587776653e+10,
      "predicted_flops_count": 3.8535168000000000e+07
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_128__1431259546713732813<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:1/input[1]:136/input[2]:28/input[3]:28/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 91486,
      "real_time": 7.6696772489132727e+03,
      "cpu_time": 1.3471978061980930e+04,
      "time_unit": "ns",
      "items_per_second": 1.3902019151471817e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = false]": 1.4627515035010154e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 1.3600000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 1.3600000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 1.0662400000000000e+05,
      "input_width": 2.8000000000000000e+01,
      "is_training": 0.0000000000000000e+00,
      "num_iterations": 9.1486000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 1.3600000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 1.0662400000000000e+05,
      "output_width": 2.8000000000000000e+01,
      "predicted_flops": 1.3902019151471817e+10,
      "predicted_flops_count": 1.0662400000000000e+05
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_128__18227732094930416614<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:1/input[1]:136/input[2]:28/input[3]:28/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 47467,
      "real_time": 1.4777751914977545e+04,
      "cpu_time": 2.0590653906705673e+04,
      "time_unit": "ns",
      "items_per_second": 7.2151705221099606e+09,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = true]": 9.0033003156525926e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 1.3600000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 1.3600000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 1.0662400000000000e+05,
      "input_width": 2.8000000000000000e+01,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 4.7467000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 1.3600000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 1.0662400000000000e+05,
      "output_width": 2.8000000000000000e+01,
      "predicted_flops": 7.2151705221099606e+09,
      "predicted_flops_count": 1.0662400000000000e+05
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_128__2839155807307719424<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:1/input[1]:272/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 106313,
      "real_time": 6.8173888983182642e+03,
      "cpu_time": 1.2779439372250990e+04,
      "time_unit": "ns",
      "items_per_second": 7.8200027598764639e+09,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = false]": 1.4627515035010154e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 2.7200000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 2.7200000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 5.3312000000000000e+04,
      "input_width": 1.4000000000000000e+01,
      "is_training": 0.0000000000000000e+00,
      "num_iterations": 1.0631300000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 2.7200000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 5.3312000000000000e+04,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 7.8200027598764639e+09,
      "predicted_flops_count": 5.3312000000000000e+04
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_128__14433902765975676459<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:1/input[1]:272/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 57851,
      "real_time": 1.1903137709104576e+04,
      "cpu_time": 1.7809226098029201e+04,
      "time_unit": "ns",
      "items_per_second": 4.4788190561907263e+09,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = true]": 9.0033003156525926e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 2.7200000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 2.7200000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 5.3312000000000000e+04,
      "input_width": 1.4000000000000000e+01,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 5.7851000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 2.7200000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 5.3312000000000000e+04,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 4.4788190561907263e+09,
      "predicted_flops_count": 5.3312000000000000e+04
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_128__9587979371344587824<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:1/input[1]:272/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 121784,
      "real_time": 5.7537923092518995e+03,
      "cpu_time": 1.1642471662930691e+04,
      "time_unit": "ns",
      "items_per_second": 2.3163853131384387e+09,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = false]": 1.4627515035010154e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 2.7200000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 2.7200000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 1.3328000000000000e+04,
      "input_width": 7.0000000000000000e+00,
      "is_training": 0.0000000000000000e+00,
      "num_iterations": 1.2178400000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 2.7200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 1.3328000000000000e+04,
      "output_width": 7.0000000000000000e+00,
      "predicted_flops": 2.3163853131384387e+09,
      "predicted_flops_count": 1.3328000000000000e+04
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_128__7648918996176480539<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:1/input[1]:272/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 70042,
      "real_time": 1.0084640008985503e+04,
      "cpu_time": 1.5938462051143011e+04,
      "time_unit": "ns",
      "items_per_second": 1.3216138591089652e+09,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = true]": 9.0033003156525926e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 2.7200000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 2.7200000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 1.3328000000000000e+04,
      "input_width": 7.0000000000000000e+00,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 7.0042000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 2.7200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 1.3328000000000000e+04,
      "output_width": 7.0000000000000000e+00,
      "predicted_flops": 1.3216138591089652e+09,
      "predicted_flops_count": 1.3328000000000000e+04
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_128__8517350207404045870<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:1/input[1]:192/input[2]:28/input[3]:28/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 81746,
      "real_time": 8.7888236698150558e+03,
      "cpu_time": 1.4802402930753653e+04,
      "time_unit": "ns",
      "items_per_second": 1.7127206740645370e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = false]": 1.4627515035010154e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 1.9200000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 1.9200000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 1.5052800000000000e+05,
      "input_width": 2.8000000000000000e+01,
      "is_training": 0.0000000000000000e+00,
      "num_iterations": 8.1746000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 1.9200000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 1.5052800000000000e+05,
      "output_width": 2.8000000000000000e+01,
      "predicted_flops": 1.7127206740645370e+10,
      "predicted_flops_count": 1.5052800000000000e+05
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_128__11032279626896945925<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:1/input[1]:192/input[2]:28/input[3]:28/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 35194,
      "real_time": 1.9863106446910973e+04,
      "cpu_time": 2.6048335568332110e+04,
      "time_unit": "ns",
      "items_per_second": 7.5782708209475193e+09,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = true]": 9.0033003156525926e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 1.9200000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 1.9200000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 1.5052800000000000e+05,
      "input_width": 2.8000000000000000e+01,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 3.5194000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 1.9200000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 1.5052800000000000e+05,
      "output_width": 2.8000000000000000e+01,
      "predicted_flops": 7.5782708209475193e+09,
      "predicted_flops_count": 1.5052800000000000e+05
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_128__17623692984078297832<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:1/input[1]:512/input[2]:28/input[3]:28/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 29852,
      "real_time": 2.3443741263126023e+04,
      "cpu_time": 2.9585829425233602e+04,
      "time_unit": "ns",
      "items_per_second": 1.7122181800878469e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = false]": 1.4627515035010154e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 4.0140800000000000e+05,
      "input_width": 2.8000000000000000e+01,
      "is_training": 0.0000000000000000e+00,
      "num_iterations": 2.9852000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 4.0140800000000000e+05,
      "output_width": 2.8000000000000000e+01,
      "predicted_flops": 1.7122181800878469e+10,
      "predicted_flops_count": 4.0140800000000000e+05
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_128__1998151657196990403<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:1/input[1]:512/input[2]:28/input[3]:28/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 14582,
      "real_time": 4.8114137763783772e+04,
      "cpu_time": 5.4344855643277355e+04,
      "time_unit": "ns",
      "items_per_second": 8.3428285043932714e+09,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = true]": 9.0033003156525926e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 4.0140800000000000e+05,
      "input_width": 2.8000000000000000e+01,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 1.4582000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 4.0140800000000000e+05,
      "output_width": 2.8000000000000000e+01,
      "predicted_flops": 8.3428285043932714e+09,
      "predicted_flops_count": 4.0140800000000000e+05
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_128__572067854669450898<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:1/input[1]:224/input[2]:28/input[3]:28/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 71038,
      "real_time": 9.8568299967182575e+03,
      "cpu_time": 1.5709056589451398e+04,
      "time_unit": "ns",
      "items_per_second": 1.7816681433936649e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = false]": 1.4627515035010154e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 2.2400000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 2.2400000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 1.7561600000000000e+05,
      "input_width": 2.8000000000000000e+01,
      "is_training": 0.0000000000000000e+00,
      "num_iterations": 7.1038000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 2.2400000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 1.7561600000000000e+05,
      "output_width": 2.8000000000000000e+01,
      "predicted_flops": 1.7816681433936649e+10,
      "predicted_flops_count": 1.7561600000000000e+05
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_128__16778538178518469561<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:1/input[1]:224/input[2]:28/input[3]:28/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 31841,
      "real_time": 2.1998817623686937e+04,
      "cpu_time": 2.8181977984767702e+04,
      "time_unit": "ns",
      "items_per_second": 7.9829744945431871e+09,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = true]": 9.0033003156525926e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 2.2400000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 2.2400000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 1.7561600000000000e+05,
      "input_width": 2.8000000000000000e+01,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 3.1841000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 2.2400000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 1.7561600000000000e+05,
      "output_width": 2.8000000000000000e+01,
      "predicted_flops": 7.9829744945431871e+09,
      "predicted_flops_count": 1.7561600000000000e+05
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_128__15084625692151911196<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:1/input[1]:64/input[2]:112/input[3]:112/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 17650,
      "real_time": 3.9658283162177751e+04,
      "cpu_time": 4.5853236713297760e+04,
      "time_unit": "ns",
      "items_per_second": 2.0243337229626938e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = false]": 1.4627515035010154e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 1.1200000000000000e+02,
      "input[3]": 1.1200000000000000e+02,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 1.1200000000000000e+02,
      "input_size": 8.0281600000000000e+05,
      "input_width": 1.1200000000000000e+02,
      "is_training": 0.0000000000000000e+00,
      "num_iterations": 1.7650000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 1.1200000000000000e+02,
      "output_size": 8.0281600000000000e+05,
      "output_width": 1.1200000000000000e+02,
      "predicted_flops": 2.0243337229626938e+10,
      "predicted_flops_count": 8.0281600000000000e+05
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_128__4503151131087623735<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:1/input[1]:64/input[2]:112/input[3]:112/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 8174,
      "real_time": 8.5637498490837883e+04,
      "cpu_time": 9.1928407388599036e+04,
      "time_unit": "ns",
      "items_per_second": 9.3745848973611832e+09,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = true]": 9.0033003156525926e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 1.1200000000000000e+02,
      "input[3]": 1.1200000000000000e+02,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 1.1200000000000000e+02,
      "input_size": 8.0281600000000000e+05,
      "input_width": 1.1200000000000000e+02,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 8.1740000000000000e+03,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 1.1200000000000000e+02,
      "output_size": 8.0281600000000000e+05,
      "output_width": 1.1200000000000000e+02,
      "predicted_flops": 9.3745848973611832e+09,
      "predicted_flops_count": 8.0281600000000000e+05
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_128__4539858465689264992<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:1/input[1]:64/input[2]:56/input[3]:56/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 50349,
      "real_time": 1.3876847968464535e+04,
      "cpu_time": 1.9798062245446377e+04,
      "time_unit": "ns",
      "items_per_second": 1.4463226840569601e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = false]": 1.4627515035010154e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 2.0070400000000000e+05,
      "input_width": 5.6000000000000000e+01,
      "is_training": 0.0000000000000000e+00,
      "num_iterations": 5.0349000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 5.6000000000000000e+01,
      "output_size": 2.0070400000000000e+05,
      "output_width": 5.6000000000000000e+01,
      "predicted_flops": 1.4463226840569601e+10,
      "predicted_flops_count": 2.0070400000000000e+05
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_128__14999768548625557067<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:1/input[1]:64/input[2]:56/input[3]:56/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 27387,
      "real_time": 2.5591034707418879e+04,
      "cpu_time": 3.1772462226239877e+04,
      "time_unit": "ns",
      "items_per_second": 7.8427465827247534e+09,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = true]": 9.0033003156525926e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 2.0070400000000000e+05,
      "input_width": 5.6000000000000000e+01,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 2.7387000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 5.6000000000000000e+01,
      "output_size": 2.0070400000000000e+05,
      "output_width": 5.6000000000000000e+01,
      "predicted_flops": 7.8427465827247534e+09,
      "predicted_flops_count": 2.0070400000000000e+05
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_128__5688711566377727730<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:1/input[1]:96/input[2]:56/input[3]:56/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 36471,
      "real_time": 1.9323097297404565e+04,
      "cpu_time": 2.5465023415979493e+04,
      "time_unit": "ns",
      "items_per_second": 1.5580110960805294e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = false]": 1.4627515035010154e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 9.6000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 9.6000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 3.0105600000000000e+05,
      "input_width": 5.6000000000000000e+01,
      "is_training": 0.0000000000000000e+00,
      "num_iterations": 3.6471000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 9.6000000000000000e+01,
      "output_height": 5.6000000000000000e+01,
      "output_size": 3.0105600000000000e+05,
      "output_width": 5.6000000000000000e+01,
      "predicted_flops": 1.5580110960805294e+10,
      "predicted_flops_count": 3.0105600000000000e+05
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_128__11663036859479225305<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:1/input[1]:96/input[2]:56/input[3]:56/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 18170,
      "real_time": 3.8021301642400751e+04,
      "cpu_time": 4.4222650908387914e+04,
      "time_unit": "ns",
      "items_per_second": 7.9180876770475197e+09,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = true]": 9.0033003156525926e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 9.6000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 9.6000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 3.0105600000000000e+05,
      "input_width": 5.6000000000000000e+01,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 1.8170000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 9.6000000000000000e+01,
      "output_height": 5.6000000000000000e+01,
      "output_size": 3.0105600000000000e+05,
      "output_width": 5.6000000000000000e+01,
      "predicted_flops": 7.9180876770475197e+09,
      "predicted_flops_count": 3.0105600000000000e+05
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_128__16976950614874946274<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:1/input[1]:160/input[2]:56/input[3]:56/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 25575,
      "real_time": 2.7373433501647087e+04,
      "cpu_time": 3.3537552218635668e+04,
      "time_unit": "ns",
      "items_per_second": 1.8330181340598309e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = false]": 1.4627515035010154e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 1.6000000000000000e+02,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 1.6000000000000000e+02,
      "input_height": 5.6000000000000000e+01,
      "input_size": 5.0176000000000000e+05,
      "input_width": 5.6000000000000000e+01,
      "is_training": 0.0000000000000000e+00,
      "num_iterations": 2.5575000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 1.6000000000000000e+02,
      "output_height": 5.6000000000000000e+01,
      "output_size": 5.0176000000000000e+05,
      "output_width": 5.6000000000000000e+01,
      "predicted_flops": 1.8330181340598309e+10,
      "predicted_flops_count": 5.0176000000000000e+05
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_128__338629375898042313<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:1/input[1]:160/input[2]:56/input[3]:56/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 12181,
      "real_time": 5.7261666967643148e+04,
      "cpu_time": 6.3510607338930655e+04,
      "time_unit": "ns",
      "items_per_second": 8.7625810873359585e+09,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = true]": 9.0033003156525926e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 1.6000000000000000e+02,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 1.6000000000000000e+02,
      "input_height": 5.6000000000000000e+01,
      "input_size": 5.0176000000000000e+05,
      "input_width": 5.6000000000000000e+01,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 1.2181000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 1.6000000000000000e+02,
      "output_height": 5.6000000000000000e+01,
      "output_size": 5.0176000000000000e+05,
      "output_width": 5.6000000000000000e+01,
      "predicted_flops": 8.7625810873359585e+09,
      "predicted_flops_count": 5.0176000000000000e+05
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_128__11981179330518706970<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:1/input[1]:192/input[2]:56/input[3]:56/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 22326,
      "real_time": 3.1352101437405563e+04,
      "cpu_time": 3.7507651393098538e+04,
      "time_unit": "ns",
      "items_per_second": 1.9204837072950787e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = false]": 1.4627515035010154e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 1.9200000000000000e+02,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 1.9200000000000000e+02,
      "input_height": 5.6000000000000000e+01,
      "input_size": 6.0211200000000000e+05,
      "input_width": 5.6000000000000000e+01,
      "is_training": 0.0000000000000000e+00,
      "num_iterations": 2.2326000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 1.9200000000000000e+02,
      "output_height": 5.6000000000000000e+01,
      "output_size": 6.0211200000000000e+05,
      "output_width": 5.6000000000000000e+01,
      "predicted_flops": 1.9204837072950787e+10,
      "predicted_flops_count": 6.0211200000000000e+05
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_128__5290744546806967857<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:1/input[1]:192/input[2]:56/input[3]:56/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 10424,
      "real_time": 6.6753492739745285e+04,
      "cpu_time": 7.2988664428269432e+04,
      "time_unit": "ns",
      "items_per_second": 9.0199325201975555e+09,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = true]": 9.0033003156525926e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 1.9200000000000000e+02,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 1.9200000000000000e+02,
      "input_height": 5.6000000000000000e+01,
      "input_size": 6.0211200000000000e+05,
      "input_width": 5.6000000000000000e+01,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 1.0424000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 1.9200000000000000e+02,
      "output_height": 5.6000000000000000e+01,
      "output_size": 6.0211200000000000e+05,
      "output_width": 5.6000000000000000e+01,
      "predicted_flops": 9.0199325201975555e+09,
      "predicted_flops_count": 6.0211200000000000e+05
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_128__755123416777754502<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:1/input[1]:224/input[2]:56/input[3]:56/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 19693,
      "real_time": 3.5610530038387951e+04,
      "cpu_time": 4.1784827806671150e+04,
      "time_unit": "ns",
      "items_per_second": 1.9726300036611301e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = false]": 1.4627515035010154e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 2.2400000000000000e+02,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 2.2400000000000000e+02,
      "input_height": 5.6000000000000000e+01,
      "input_size": 7.0246400000000000e+05,
      "input_width": 5.6000000000000000e+01,
      "is_training": 0.0000000000000000e+00,
      "num_iterations": 1.9693000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 2.2400000000000000e+02,
      "output_height": 5.6000000000000000e+01,
      "output_size": 7.0246400000000000e+05,
      "output_width": 5.6000000000000000e+01,
      "predicted_flops": 1.9726300036611301e+10,
      "predicted_flops_count": 7.0246400000000000e+05
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_128__16524709247713034925<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:1/input[1]:224/input[2]:56/input[3]:56/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 9189,
      "real_time": 7.6356520925000674e+04,
      "cpu_time": 8.2616526933323519e+04,
      "time_unit": "ns",
      "items_per_second": 9.1997905547579632e+09,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = true]": 9.0033003156525926e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 2.2400000000000000e+02,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 2.2400000000000000e+02,
      "input_height": 5.6000000000000000e+01,
      "input_size": 7.0246400000000000e+05,
      "input_width": 5.6000000000000000e+01,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 9.1890000000000000e+03,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 2.2400000000000000e+02,
      "output_height": 5.6000000000000000e+01,
      "output_size": 7.0246400000000000e+05,
      "output_width": 5.6000000000000000e+01,
      "predicted_flops": 9.1997905547579632e+09,
      "predicted_flops_count": 7.0246400000000000e+05
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_128__7133708088482491164<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:1/input[1]:256/input[2]:28/input[3]:28/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 50309,
      "real_time": 1.3896105632093228e+04,
      "cpu_time": 1.9816696714329133e+04,
      "time_unit": "ns",
      "items_per_second": 1.4443183242395021e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = false]": 1.4627515035010154e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 2.0070400000000000e+05,
      "input_width": 2.8000000000000000e+01,
      "is_training": 0.0000000000000000e+00,
      "num_iterations": 5.0309000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 2.0070400000000000e+05,
      "output_width": 2.8000000000000000e+01,
      "predicted_flops": 1.4443183242395021e+10,
      "predicted_flops_count": 2.0070400000000000e+05
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_128__10099663599737122359<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:1/input[1]:256/input[2]:28/input[3]:28/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 27380,
      "real_time": 2.5594909094511975e+04,
      "cpu_time": 3.1778111139777993e+04,
      "time_unit": "ns",
      "items_per_second": 7.8415593999134245e+09,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = true]": 9.0033003156525926e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 2.0070400000000000e+05,
      "input_width": 2.8000000000000000e+01,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 2.7380000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 2.0070400000000000e+05,
      "output_width": 2.8000000000000000e+01,
      "predicted_flops": 7.8415593999134245e+09,
      "predicted_flops_count": 2.0070400000000000e+05
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_128__15548626810074999671<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:1/input[1]:128/input[2]:56/input[3]:56/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 29854,
      "real_time": 2.3445780805505496e+04,
      "cpu_time": 2.9594056407813197e+04,
      "time_unit": "ns",
      "items_per_second": 1.7120692346733110e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = false]": 1.4627515035010154e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 1.2800000000000000e+02,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 1.2800000000000000e+02,
      "input_height": 5.6000000000000000e+01,
      "input_size": 4.0140800000000000e+05,
      "input_width": 5.6000000000000000e+01,
      "is_training": 0.0000000000000000e+00,
      "num_iterations": 2.9854000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 5.6000000000000000e+01,
      "output_size": 4.0140800000000000e+05,
      "output_width": 5.6000000000000000e+01,
      "predicted_flops": 1.7120692346733110e+10,
      "predicted_flops_count": 4.0140800000000000e+05
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_128__4102465390292037212<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:1/input[1]:128/input[2]:56/input[3]:56/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 14583,
      "real_time": 4.8115213938564622e+04,
      "cpu_time": 5.4343930809938414e+04,
      "time_unit": "ns",
      "items_per_second": 8.3426419035054760e+09,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = true]": 9.0033003156525926e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 1.2800000000000000e+02,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 1.2800000000000000e+02,
      "input_height": 5.6000000000000000e+01,
      "input_size": 4.0140800000000000e+05,
      "input_width": 5.6000000000000000e+01,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 1.4583000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 5.6000000000000000e+01,
      "output_size": 4.0140800000000000e+05,
      "output_width": 5.6000000000000000e+01,
      "predicted_flops": 8.3426419035054760e+09,
      "predicted_flops_count": 4.0140800000000000e+05
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_128__6929638820680760088<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:1/input[1]:256/input[2]:56/input[3]:56/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 17648,
      "real_time": 3.9651609805973239e+04,
      "cpu_time": 4.5836602900522710e+04,
      "time_unit": "ns",
      "items_per_second": 2.0246744178317352e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = false]": 1.4627515035010154e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 5.6000000000000000e+01,
      "input_size": 8.0281600000000000e+05,
      "input_width": 5.6000000000000000e+01,
      "is_training": 0.0000000000000000e+00,
      "num_iterations": 1.7648000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 5.6000000000000000e+01,
      "output_size": 8.0281600000000000e+05,
      "output_width": 5.6000000000000000e+01,
      "predicted_flops": 2.0246744178317352e+10,
      "predicted_flops_count": 8.0281600000000000e+05
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_128__10304859334353141299<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:1/input[1]:256/input[2]:56/input[3]:56/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 8172,
      "real_time": 8.5492089827105607e+04,
      "cpu_time": 9.1772980665638723e+04,
      "time_unit": "ns",
      "items_per_second": 9.3905295989789238e+09,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = true]": 9.0033003156525926e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 5.6000000000000000e+01,
      "input_size": 8.0281600000000000e+05,
      "input_width": 5.6000000000000000e+01,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 8.1720000000000000e+03,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 5.6000000000000000e+01,
      "output_size": 8.0281600000000000e+05,
      "output_width": 5.6000000000000000e+01,
      "predicted_flops": 9.3905295989789238e+09,
      "predicted_flops_count": 8.0281600000000000e+05
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_128__14813349769926507190<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:1/input[1]:288/input[2]:28/input[3]:28/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 43895,
      "real_time": 1.5927281977548279e+04,
      "cpu_time": 2.1876467570728841e+04,
      "time_unit": "ns",
      "items_per_second": 1.4176430122746948e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = false]": 1.4627515035010154e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 2.8800000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 2.8800000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 2.2579200000000000e+05,
      "input_width": 2.8000000000000000e+01,
      "is_training": 0.0000000000000000e+00,
      "num_iterations": 4.3895000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 2.8800000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 2.2579200000000000e+05,
      "output_width": 2.8000000000000000e+01,
      "predicted_flops": 1.4176430122746948e+10,
      "predicted_flops_count": 2.2579200000000000e+05
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_128__2502492986983006109<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:1/input[1]:288/input[2]:28/input[3]:28/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 24343,
      "real_time": 2.8766969947584083e+04,
      "cpu_time": 3.4962747401595385e+04,
      "time_unit": "ns",
      "items_per_second": 7.8490018382684250e+09,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = true]": 9.0033003156525926e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 2.8800000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 2.8800000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 2.2579200000000000e+05,
      "input_width": 2.8000000000000000e+01,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 2.4343000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 2.8800000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 2.2579200000000000e+05,
      "output_width": 2.8000000000000000e+01,
      "predicted_flops": 7.8490018382684250e+09,
      "predicted_flops_count": 2.2579200000000000e+05
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_128__6305378961443721110<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:1/input[1]:160/input[2]:28/input[3]:28/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 88418,
      "real_time": 7.9207863270703392e+03,
      "cpu_time": 1.3736212501789081e+04,
      "time_unit": "ns",
      "items_per_second": 1.5836811500809223e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = false]": 1.4627515035010154e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 1.6000000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 1.6000000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 1.2544000000000000e+05,
      "input_width": 2.8000000000000000e+01,
      "is_training": 0.0000000000000000e+00,
      "num_iterations": 8.8418000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 1.6000000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 1.2544000000000000e+05,
      "output_width": 2.8000000000000000e+01,
      "predicted_flops": 1.5836811500809223e+10,
      "predicted_flops_count": 1.2544000000000000e+05
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_128__13305893892726540989<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:1/input[1]:160/input[2]:28/input[3]:28/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 41160,
      "real_time": 1.7103872195936336e+04,
      "cpu_time": 2.2967984767050733e+04,
      "time_unit": "ns",
      "items_per_second": 7.3340117701419077e+09,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = true]": 9.0033003156525926e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 1.6000000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 1.6000000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 1.2544000000000000e+05,
      "input_width": 2.8000000000000000e+01,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 4.1160000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 1.6000000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 1.2544000000000000e+05,
      "output_width": 2.8000000000000000e+01,
      "predicted_flops": 7.3340117701419077e+09,
      "predicted_flops_count": 1.2544000000000000e+05
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_128__1409096752283171396<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:1/input[1]:256/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 106967,
      "real_time": 6.5244885697396276e+03,
      "cpu_time": 1.2333134359242436e+04,
      "time_unit": "ns",
      "items_per_second": 7.6904112044451580e+09,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = false]": 1.4627515035010154e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 5.0176000000000000e+04,
      "input_width": 1.4000000000000000e+01,
      "is_training": 0.0000000000000000e+00,
      "num_iterations": 1.0696700000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 5.0176000000000000e+04,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 7.6904112044451580e+09,
      "predicted_flops_count": 5.0176000000000000e+04
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_128__18205569748784971631<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:1/input[1]:256/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 61151,
      "real_time": 1.1523926335544225e+04,
      "cpu_time": 1.7482093064525743e+04,
      "time_unit": "ns",
      "items_per_second": 4.3540715671912880e+09,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = true]": 9.0033003156525926e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 5.0176000000000000e+04,
      "input_width": 1.4000000000000000e+01,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 6.1151000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 5.0176000000000000e+04,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 4.3540715671912880e+09,
      "predicted_flops_count": 5.0176000000000000e+04
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_128__13062329519576575002<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:1/input[1]:288/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 105219,
      "real_time": 6.6195181613967834e+03,
      "cpu_time": 1.2428354736262525e+04,
      "time_unit": "ns",
      "items_per_second": 8.5275088947091751e+09,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = false]": 1.4627515035010154e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 2.8800000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 2.8800000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 5.6448000000000000e+04,
      "input_width": 1.4000000000000000e+01,
      "is_training": 0.0000000000000000e+00,
      "num_iterations": 1.0521900000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 2.8800000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 5.6448000000000000e+04,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 8.5275088947091751e+09,
      "predicted_flops_count": 5.6448000000000000e+04
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_128__6516572599821510961<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:1/input[1]:288/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 57776,
      "real_time": 1.2059926986320439e+04,
      "cpu_time": 1.7909591871885332e+04,
      "time_unit": "ns",
      "items_per_second": 4.6806253523780785e+09,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = true]": 9.0033003156525926e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 2.8800000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 2.8800000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 5.6448000000000000e+04,
      "input_width": 1.4000000000000000e+01,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 5.7776000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 2.8800000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 5.6448000000000000e+04,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 4.6806253523780785e+09,
      "predicted_flops_count": 5.6448000000000000e+04
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_128__65304553759942324<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:1/input[1]:768/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 81523,
      "real_time": 8.5656460375151000e+03,
      "cpu_time": 1.4448179188803002e+04,
      "time_unit": "ns",
      "items_per_second": 1.7573455561989140e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = false]": 1.4627515035010154e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 7.6800000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 7.6800000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 1.5052800000000000e+05,
      "input_width": 1.4000000000000000e+01,
      "is_training": 0.0000000000000000e+00,
      "num_iterations": 8.1523000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 7.6800000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 1.5052800000000000e+05,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 1.7573455561989140e+10,
      "predicted_flops_count": 1.5052800000000000e+05
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_128__17276143625608225695<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:1/input[1]:768/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 35238,
      "real_time": 1.9853260011297341e+04,
      "cpu_time": 2.6022685510067586e+04,
      "time_unit": "ns",
      "items_per_second": 7.5820293450215845e+09,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = true]": 9.0033003156525926e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 7.6800000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 7.6800000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 1.5052800000000000e+05,
      "input_width": 1.4000000000000000e+01,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 3.5238000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 7.6800000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 1.5052800000000000e+05,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 7.5820293450215845e+09,
      "predicted_flops_count": 1.5052800000000000e+05
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_128__6878402469592448704<CUDNN_BATCHNORM_SPATIAL>/input[0]:128/input[1]:32/input[2]:112/input[3]:112/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 955,
      "real_time": 7.3276041995938774e+05,
      "cpu_time": 7.4650907539314951e+05,
      "time_unit": "ns",
      "items_per_second": 7.0118721754714432e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 1.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)1; bool is_training = false]": 7.0429798546002954e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 3.2000000000000000e+01,
      "input[2]": 1.1200000000000000e+02,
      "input[3]": 1.1200000000000000e+02,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 3.2000000000000000e+01,
      "input_height": 1.1200000000000000e+02,
      "input_size": 5.1380224000000000e+07,
      "input_width": 1.1200000000000000e+02,
      "is_training": 0.0000000000000000e+00,
      "num_iterations": 9.5500000000000000e+02,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 3.2000000000000000e+01,
      "output_height": 1.1200000000000000e+02,
      "output_size": 5.1380224000000000e+07,
      "output_width": 1.1200000000000000e+02,
      "predicted_flops": 7.0118721754714432e+10,
      "predicted_flops_count": 5.1380224000000000e+07
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_128__6878402469592448704<CUDNN_BATCHNORM_SPATIAL_PERSISTENT>/input[0]:128/input[1]:32/input[2]:112/input[3]:112/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/BATCHNORM_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_128__16691266168801636191<CUDNN_BATCHNORM_SPATIAL>/input[0]:128/input[1]:32/input[2]:112/input[3]:112/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 532,
      "real_time": 1.3143847750314281e+06,
      "cpu_time": 1.3177189511286269e+06,
      "time_unit": "ns",
      "items_per_second": 3.9090702339253326e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 1.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)1; bool is_training = true]": 1.2389518253260638e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 3.2000000000000000e+01,
      "input[2]": 1.1200000000000000e+02,
      "input[3]": 1.1200000000000000e+02,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 3.2000000000000000e+01,
      "input_height": 1.1200000000000000e+02,
      "input_size": 5.1380224000000000e+07,
      "input_width": 1.1200000000000000e+02,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 5.3200000000000000e+02,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 3.2000000000000000e+01,
      "output_height": 1.1200000000000000e+02,
      "output_size": 5.1380224000000000e+07,
      "output_width": 1.1200000000000000e+02,
      "predicted_flops": 3.9090702339253326e+10,
      "predicted_flops_count": 5.1380224000000000e+07
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_128__16691266168801636191<CUDNN_BATCHNORM_SPATIAL_PERSISTENT>/input[0]:128/input[1]:32/input[2]:112/input[3]:112/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 693,
      "real_time": 1.0104727318838324e+06,
      "cpu_time": 1.0310846998571168e+06,
      "time_unit": "ns",
      "items_per_second": 5.0847709570758461e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 2.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)2; bool is_training = true]": 8.6489340726076344e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 3.2000000000000000e+01,
      "input[2]": 1.1200000000000000e+02,
      "input[3]": 1.1200000000000000e+02,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 3.2000000000000000e+01,
      "input_height": 1.1200000000000000e+02,
      "input_size": 5.1380224000000000e+07,
      "input_width": 1.1200000000000000e+02,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 6.9300000000000000e+02,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 3.2000000000000000e+01,
      "output_height": 1.1200000000000000e+02,
      "output_size": 5.1380224000000000e+07,
      "output_width": 1.1200000000000000e+02,
      "predicted_flops": 5.0847709570758461e+10,
      "predicted_flops_count": 5.1380224000000000e+07
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_128__15482928056355911880<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:1/input[1]:576/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 90643,
      "real_time": 7.7281533335051981e+03,
      "cpu_time": 1.3507985293981126e+04,
      "time_unit": "ns",
      "items_per_second": 1.4608405802527555e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = false]": 1.4627515035010154e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 5.7600000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 5.7600000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 1.1289600000000000e+05,
      "input_width": 1.4000000000000000e+01,
      "is_training": 0.0000000000000000e+00,
      "num_iterations": 9.0643000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 5.7600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 1.1289600000000000e+05,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 1.4608405802527555e+10,
      "predicted_flops_count": 1.1289600000000000e+05
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_128__4176906360909708771<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:1/input[1]:576/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 45054,
      "real_time": 1.5853870849896039e+04,
      "cpu_time": 2.1742924090844994e+04,
      "time_unit": "ns",
      "items_per_second": 7.1210369422645016e+09,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = true]": 9.0033003156525926e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 5.7600000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 5.7600000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 1.1289600000000000e+05,
      "input_width": 1.4000000000000000e+01,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 4.5054000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 5.7600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 1.1289600000000000e+05,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 7.1210369422645016e+09,
      "predicted_flops_count": 1.1289600000000000e+05
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_128__10330511206834743764<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:1/input[1]:352/input[2]:28/input[3]:28/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 38805,
      "real_time": 1.8165795683542463e+04,
      "cpu_time": 2.4345802293695964e+04,
      "time_unit": "ns",
      "items_per_second": 1.5191627430336937e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = false]": 1.4627515035010154e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 3.5200000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 3.5200000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 2.7596800000000000e+05,
      "input_width": 2.8000000000000000e+01,
      "is_training": 0.0000000000000000e+00,
      "num_iterations": 3.8805000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 3.5200000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 2.7596800000000000e+05,
      "output_width": 2.8000000000000000e+01,
      "predicted_flops": 1.5191627430336937e+10,
      "predicted_flops_count": 2.7596800000000000e+05
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_128__6950296711617178879<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:1/input[1]:352/input[2]:28/input[3]:28/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 20136,
      "real_time": 3.4747503479266779e+04,
      "cpu_time": 4.0945416169881762e+04,
      "time_unit": "ns",
      "items_per_second": 7.9420957584669418e+09,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = true]": 9.0033003156525926e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 3.5200000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 3.5200000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 2.7596800000000000e+05,
      "input_width": 2.8000000000000000e+01,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 2.0136000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 3.5200000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 2.7596800000000000e+05,
      "output_width": 2.8000000000000000e+01,
      "predicted_flops": 7.9420957584669418e+09,
      "predicted_flops_count": 2.7596800000000000e+05
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_128__6633600494606252393<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:1/input[1]:608/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 89476,
      "real_time": 7.7937509158815465e+03,
      "cpu_time": 1.3571484912479495e+04,
      "time_unit": "ns",
      "items_per_second": 1.5290198684329006e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = false]": 1.4627515035010154e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 6.0800000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 6.0800000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 1.1916800000000000e+05,
      "input_width": 1.4000000000000000e+01,
      "is_training": 0.0000000000000000e+00,
      "num_iterations": 8.9476000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 6.0800000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 1.1916800000000000e+05,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 1.5290198684329006e+10,
      "predicted_flops_count": 1.1916800000000000e+05
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_128__12909141436180347970<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:1/input[1]:608/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 42185,
      "real_time": 1.6521113735995354e+04,
      "cpu_time": 2.2386898091920491e+04,
      "time_unit": "ns",
      "items_per_second": 7.2130730351648684e+09,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = true]": 9.0033003156525926e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 6.0800000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 6.0800000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 1.1916800000000000e+05,
      "input_width": 1.4000000000000000e+01,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 4.2185000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 6.0800000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 1.1916800000000000e+05,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 7.2130730351648684e+09,
      "predicted_flops_count": 1.1916800000000000e+05
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_128__7166213206480855131<CUDNN_BATCHNORM_SPATIAL>/input[0]:128/input[1]:96/input[2]:112/input[3]:112/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 324,
      "real_time": 2.1628939782349784e+06,
      "cpu_time": 2.2355869660467915e+06,
      "time_unit": "ns",
      "items_per_second": 7.1265939778419434e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 1.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)1; bool is_training = false]": 7.0429798546002954e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 9.6000000000000000e+01,
      "input[2]": 1.1200000000000000e+02,
      "input[3]": 1.1200000000000000e+02,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 9.6000000000000000e+01,
      "input_height": 1.1200000000000000e+02,
      "input_size": 1.5414067200000000e+08,
      "input_width": 1.1200000000000000e+02,
      "is_training": 0.0000000000000000e+00,
      "num_iterations": 3.2400000000000000e+02,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 9.6000000000000000e+01,
      "output_height": 1.1200000000000000e+02,
      "output_size": 1.5414067200000000e+08,
      "output_width": 1.1200000000000000e+02,
      "predicted_flops": 7.1265939778419434e+10,
      "predicted_flops_count": 1.5414067200000000e+08
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_128__7166213206480855131<CUDNN_BATCHNORM_SPATIAL_PERSISTENT>/input[0]:128/input[1]:96/input[2]:112/input[3]:112/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/BATCHNORM_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_128__15826832501605773764<CUDNN_BATCHNORM_SPATIAL>/input[0]:128/input[1]:96/input[2]:112/input[3]:112/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 218,
      "real_time": 3.2050454585360140e+06,
      "cpu_time": 3.3579712614686987e+06,
      "time_unit": "ns",
      "items_per_second": 4.8093131281329056e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 1.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)1; bool is_training = true]": 1.2389518253260638e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 9.6000000000000000e+01,
      "input[2]": 1.1200000000000000e+02,
      "input[3]": 1.1200000000000000e+02,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 9.6000000000000000e+01,
      "input_height": 1.1200000000000000e+02,
      "input_size": 1.5414067200000000e+08,
      "input_width": 1.1200000000000000e+02,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 2.1800000000000000e+02,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 9.6000000000000000e+01,
      "output_height": 1.1200000000000000e+02,
      "output_size": 1.5414067200000000e+08,
      "output_width": 1.1200000000000000e+02,
      "predicted_flops": 4.8093131281329056e+10,
      "predicted_flops_count": 1.5414067200000000e+08
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_128__15826832501605773764<CUDNN_BATCHNORM_SPATIAL_PERSISTENT>/input[0]:128/input[1]:96/input[2]:112/input[3]:112/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 228,
      "real_time": 3.0637907074650000e+06,
      "cpu_time": 3.2040030394758410e+06,
      "time_unit": "ns",
      "items_per_second": 5.0310444386567444e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 2.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)2; bool is_training = true]": 8.6489340726076344e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 9.6000000000000000e+01,
      "input[2]": 1.1200000000000000e+02,
      "input[3]": 1.1200000000000000e+02,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 9.6000000000000000e+01,
      "input_height": 1.1200000000000000e+02,
      "input_size": 1.5414067200000000e+08,
      "input_width": 1.1200000000000000e+02,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 2.2800000000000000e+02,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 9.6000000000000000e+01,
      "output_height": 1.1200000000000000e+02,
      "output_size": 1.5414067200000000e+08,
      "output_width": 1.1200000000000000e+02,
      "predicted_flops": 5.0310444386567444e+10,
      "predicted_flops_count": 1.5414067200000000e+08
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_128__14446341555250806236<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:1/input[1]:352/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 101854,
      "real_time": 6.8662841619952842e+03,
      "cpu_time": 1.2702541726454605e+04,
      "time_unit": "ns",
      "items_per_second": 1.0047938356799889e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = false]": 1.4627515035010154e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 3.5200000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 3.5200000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 6.8992000000000000e+04,
      "input_width": 1.4000000000000000e+01,
      "is_training": 0.0000000000000000e+00,
      "num_iterations": 1.0185400000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 3.5200000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 6.8992000000000000e+04,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 1.0047938356799889e+10,
      "predicted_flops_count": 6.8992000000000000e+04
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_128__2833472421772818679<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:1/input[1]:352/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 56184,
      "real_time": 1.2391057486301766e+04,
      "cpu_time": 1.8314017959027493e+04,
      "time_unit": "ns",
      "items_per_second": 5.5678863629089136e+09,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = true]": 9.0033003156525926e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 3.5200000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 3.5200000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 6.8992000000000000e+04,
      "input_width": 1.4000000000000000e+01,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 5.6184000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 3.5200000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 6.8992000000000000e+04,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 5.5678863629089136e+09,
      "predicted_flops_count": 6.8992000000000000e+04
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_128__7377595585551616370<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:1/input[1]:640/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 88625,
      "real_time": 7.9041410618271120e+03,
      "cpu_time": 1.3714185297459178e+04,
      "time_unit": "ns",
      "items_per_second": 1.5870162111074905e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = false]": 1.4627515035010154e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 6.4000000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 6.4000000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 1.2544000000000000e+05,
      "input_width": 1.4000000000000000e+01,
      "is_training": 0.0000000000000000e+00,
      "num_iterations": 8.8625000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 6.4000000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 1.2544000000000000e+05,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 1.5870162111074905e+10,
      "predicted_flops_count": 1.2544000000000000e+05
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_128__9893088029757213785<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:1/input[1]:640/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 40938,
      "real_time": 1.7014899467989304e+04,
      "cpu_time": 2.2866724192564641e+04,
      "time_unit": "ns",
      "items_per_second": 7.3723621015801144e+09,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = true]": 9.0033003156525926e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 6.4000000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 6.4000000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 1.2544000000000000e+05,
      "input_width": 1.4000000000000000e+01,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 4.0938000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 6.4000000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 1.2544000000000000e+05,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 7.3723621015801144e+09,
      "predicted_flops_count": 1.2544000000000000e+05
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_128__17809761402038097230<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:1/input[1]:320/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 102866,
      "real_time": 6.7582024997896469e+03,
      "cpu_time": 1.2594541558893692e+04,
      "time_unit": "ns",
      "items_per_second": 9.2805742358196869e+09,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = false]": 1.4627515035010154e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 3.2000000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 3.2000000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 6.2720000000000000e+04,
      "input_width": 1.4000000000000000e+01,
      "is_training": 0.0000000000000000e+00,
      "num_iterations": 1.0286600000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 3.2000000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 6.2720000000000000e+04,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 9.2805742358196869e+09,
      "predicted_flops_count": 6.2720000000000000e+04
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_128__1729884321187352677<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:1/input[1]:320/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 58455,
      "real_time": 1.1993103584494178e+04,
      "cpu_time": 1.7807506303747959e+04,
      "time_unit": "ns",
      "items_per_second": 5.2296721660180082e+09,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = true]": 9.0033003156525926e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 3.2000000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 3.2000000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 6.2720000000000000e+04,
      "input_width": 1.4000000000000000e+01,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 5.8455000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 3.2000000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 6.2720000000000000e+04,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 5.2296721660180082e+09,
      "predicted_flops_count": 6.2720000000000000e+04
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_128__13446777369765777870<CUDNN_BATCHNORM_SPATIAL>/input[0]:128/input[1]:16/input[2]:112/input[3]:112/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 1888,
      "real_time": 3.7068516449850862e+05,
      "cpu_time": 3.7875737394112645e+05,
      "time_unit": "ns",
      "items_per_second": 6.9304397533026611e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 1.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)1; bool is_training = false]": 7.0429798546002954e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 1.6000000000000000e+01,
      "input[2]": 1.1200000000000000e+02,
      "input[3]": 1.1200000000000000e+02,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 1.6000000000000000e+01,
      "input_height": 1.1200000000000000e+02,
      "input_size": 2.5690112000000000e+07,
      "input_width": 1.1200000000000000e+02,
      "is_training": 0.0000000000000000e+00,
      "num_iterations": 1.8880000000000000e+03,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 1.6000000000000000e+01,
      "output_height": 1.1200000000000000e+02,
      "output_size": 2.5690112000000000e+07,
      "output_width": 1.1200000000000000e+02,
      "predicted_flops": 6.9304397533026611e+10,
      "predicted_flops_count": 2.5690112000000000e+07
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_128__13446777369765777870<CUDNN_BATCHNORM_SPATIAL_PERSISTENT>/input[0]:128/input[1]:16/input[2]:112/input[3]:112/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/BATCHNORM_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_128__165287904316620881<CUDNN_BATCHNORM_SPATIAL>/input[0]:128/input[1]:16/input[2]:112/input[3]:112/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 647,
      "real_time": 1.0820290099302598e+06,
      "cpu_time": 1.1048143415773229e+06,
      "time_unit": "ns",
      "items_per_second": 2.3742535333369492e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 1.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)1; bool is_training = true]": 1.2389518253260638e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 1.6000000000000000e+01,
      "input[2]": 1.1200000000000000e+02,
      "input[3]": 1.1200000000000000e+02,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 1.6000000000000000e+01,
      "input_height": 1.1200000000000000e+02,
      "input_size": 2.5690112000000000e+07,
      "input_width": 1.1200000000000000e+02,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 6.4700000000000000e+02,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 1.6000000000000000e+01,
      "output_height": 1.1200000000000000e+02,
      "output_size": 2.5690112000000000e+07,
      "output_width": 1.1200000000000000e+02,
      "predicted_flops": 2.3742535333369492e+10,
      "predicted_flops_count": 2.5690112000000000e+07
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_128__165287904316620881<CUDNN_BATCHNORM_SPATIAL_PERSISTENT>/input[0]:128/input[1]:16/input[2]:112/input[3]:112/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 1370,
      "real_time": 5.1112721455759322e+05,
      "cpu_time": 5.2093534963509173e+05,
      "time_unit": "ns",
      "items_per_second": 5.0261679026885918e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 2.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)2; bool is_training = true]": 8.6489340726076344e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 1.6000000000000000e+01,
      "input[2]": 1.1200000000000000e+02,
      "input[3]": 1.1200000000000000e+02,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 1.6000000000000000e+01,
      "input_height": 1.1200000000000000e+02,
      "input_size": 2.5690112000000000e+07,
      "input_width": 1.1200000000000000e+02,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 1.3700000000000000e+03,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 1.6000000000000000e+01,
      "output_height": 1.1200000000000000e+02,
      "output_size": 2.5690112000000000e+07,
      "output_width": 1.1200000000000000e+02,
      "predicted_flops": 5.0261679026885918e+10,
      "predicted_flops_count": 2.5690112000000000e+07
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_128__10276510862693067751<CUDNN_BATCHNORM_SPATIAL>/input[0]:128/input[1]:96/input[2]:56/input[3]:56/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 1330,
      "real_time": 5.2611955373260868e+05,
      "cpu_time": 5.3619676992481854e+05,
      "time_unit": "ns",
      "items_per_second": 7.3244128119945984e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 1.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)1; bool is_training = false]": 7.0429798546002954e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 9.6000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 9.6000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 3.8535168000000000e+07,
      "input_width": 5.6000000000000000e+01,
      "is_training": 0.0000000000000000e+00,
      "num_iterations": 1.3300000000000000e+03,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 9.6000000000000000e+01,
      "output_height": 5.6000000000000000e+01,
      "output_size": 3.8535168000000000e+07,
      "output_width": 5.6000000000000000e+01,
      "predicted_flops": 7.3244128119945984e+10,
      "predicted_flops_count": 3.8535168000000000e+07
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_128__10276510862693067751<CUDNN_BATCHNORM_SPATIAL_PERSISTENT>/input[0]:128/input[1]:96/input[2]:56/input[3]:56/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/BATCHNORM_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_128__3911997026276211320<CUDNN_BATCHNORM_SPATIAL>/input[0]:128/input[1]:96/input[2]:56/input[3]:56/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 858,
      "real_time": 8.1607067875025712e+05,
      "cpu_time": 8.3164230885769078e+05,
      "time_unit": "ns",
      "items_per_second": 4.7220380542299759e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 1.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)1; bool is_training = true]": 1.2389518253260638e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 9.6000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 9.6000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 3.8535168000000000e+07,
      "input_width": 5.6000000000000000e+01,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 8.5800000000000000e+02,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 9.6000000000000000e+01,
      "output_height": 5.6000000000000000e+01,
      "output_size": 3.8535168000000000e+07,
      "output_width": 5.6000000000000000e+01,
      "predicted_flops": 4.7220380542299759e+10,
      "predicted_flops_count": 3.8535168000000000e+07
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_128__3911997026276211320<CUDNN_BATCHNORM_SPATIAL_PERSISTENT>/input[0]:128/input[1]:96/input[2]:56/input[3]:56/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 962,
      "real_time": 7.2680871760406822e+05,
      "cpu_time": 7.4038972245278920e+05,
      "time_unit": "ns",
      "items_per_second": 5.3019683262786865e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 2.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)2; bool is_training = true]": 8.6489340726076344e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 9.6000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 9.6000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 3.8535168000000000e+07,
      "input_width": 5.6000000000000000e+01,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 9.6200000000000000e+02,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 9.6000000000000000e+01,
      "output_height": 5.6000000000000000e+01,
      "output_size": 3.8535168000000000e+07,
      "output_width": 5.6000000000000000e+01,
      "predicted_flops": 5.3019683262786865e+10,
      "predicted_flops_count": 3.8535168000000000e+07
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_128__1224786440798679422<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:1/input[1]:384/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 100352,
      "real_time": 6.9479372940029607e+03,
      "cpu_time": 1.2807580197514917e+04,
      "time_unit": "ns",
      "items_per_second": 1.0832567539860115e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = false]": 1.4627515035010154e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 3.8400000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 3.8400000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 7.5264000000000000e+04,
      "input_width": 1.4000000000000000e+01,
      "is_training": 0.0000000000000000e+00,
      "num_iterations": 1.0035200000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 3.8400000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 7.5264000000000000e+04,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 1.0832567539860115e+10,
      "predicted_flops_count": 7.5264000000000000e+04
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_128__18435032050711360597<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:1/input[1]:384/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 55400,
      "real_time": 1.2621207327336686e+04,
      "cpu_time": 1.8536943068882410e+04,
      "time_unit": "ns",
      "items_per_second": 5.9632963826672297e+09,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = true]": 9.0033003156525926e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 3.8400000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 3.8400000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 7.5264000000000000e+04,
      "input_width": 1.4000000000000000e+01,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 5.5400000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 3.8400000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 7.5264000000000000e+04,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 5.9632963826672297e+09,
      "predicted_flops_count": 7.5264000000000000e+04
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_128__3418271484845960793<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:1/input[1]:864/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 73639,
      "real_time": 9.5168454075891477e+03,
      "cpu_time": 1.5378180828269984e+04,
      "time_unit": "ns",
      "items_per_second": 1.7794131642083595e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = false]": 1.4627515035010154e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 8.6400000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 8.6400000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 1.6934400000000000e+05,
      "input_width": 1.4000000000000000e+01,
      "is_training": 0.0000000000000000e+00,
      "num_iterations": 7.3639000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 8.6400000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 1.6934400000000000e+05,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 1.7794131642083595e+10,
      "predicted_flops_count": 1.6934400000000000e+05
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_128__13860127966153239410<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:1/input[1]:864/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 32812,
      "real_time": 2.1333783188916284e+04,
      "cpu_time": 2.7522830489083983e+04,
      "time_unit": "ns",
      "items_per_second": 7.9378326150788231e+09,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = true]": 9.0033003156525926e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 8.6400000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 8.6400000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 1.6934400000000000e+05,
      "input_width": 1.4000000000000000e+01,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 3.2812000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 8.6400000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 1.6934400000000000e+05,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 7.9378326150788231e+09,
      "predicted_flops_count": 1.6934400000000000e+05
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_128__15669433027751393051<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:1/input[1]:672/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 87738,
      "real_time": 7.9837595078620379e+03,
      "cpu_time": 1.3771919852440575e+04,
      "time_unit": "ns",
      "items_per_second": 1.6497490921450741e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = false]": 1.4627515035010154e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 6.7200000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 6.7200000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 1.3171200000000000e+05,
      "input_width": 1.4000000000000000e+01,
      "is_training": 0.0000000000000000e+00,
      "num_iterations": 8.7738000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 6.7200000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 1.3171200000000000e+05,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 1.6497490921450741e+10,
      "predicted_flops_count": 1.3171200000000000e+05
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_128__3917060119975129648<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:1/input[1]:672/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 38564,
      "real_time": 1.8209063710467086e+04,
      "cpu_time": 2.4278064282766525e+04,
      "time_unit": "ns",
      "items_per_second": 7.2333208392416258e+09,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = true]": 9.0033003156525926e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 6.7200000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 6.7200000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 1.3171200000000000e+05,
      "input_width": 1.4000000000000000e+01,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 3.8564000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 6.7200000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 1.3171200000000000e+05,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 7.2333208392416258e+09,
      "predicted_flops_count": 1.3171200000000000e+05
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_128__9799513258356179318<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:1/input[1]:384/input[2]:28/input[3]:28/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 36445,
      "real_time": 1.9199106428543073e+04,
      "cpu_time": 2.5273638386636219e+04,
      "time_unit": "ns",
      "items_per_second": 1.5680729783987438e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = false]": 1.4627515035010154e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 3.8400000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 3.8400000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 3.0105600000000000e+05,
      "input_width": 2.8000000000000000e+01,
      "is_training": 0.0000000000000000e+00,
      "num_iterations": 3.6445000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 3.8400000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 3.0105600000000000e+05,
      "output_width": 2.8000000000000000e+01,
      "predicted_flops": 1.5680729783987438e+10,
      "predicted_flops_count": 3.0105600000000000e+05
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_128__7554768987635008605<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:1/input[1]:384/input[2]:28/input[3]:28/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 18380,
      "real_time": 3.8007427850163440e+04,
      "cpu_time": 4.4214314091111861e+04,
      "time_unit": "ns",
      "items_per_second": 7.9209780042693787e+09,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = true]": 9.0033003156525926e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 3.8400000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 3.8400000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 3.0105600000000000e+05,
      "input_width": 2.8000000000000000e+01,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 1.8380000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 3.8400000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 3.0105600000000000e+05,
      "output_width": 2.8000000000000000e+01,
      "predicted_flops": 7.9209780042693787e+09,
      "predicted_flops_count": 3.0105600000000000e+05
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_128__11235266512668642963<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:1/input[1]:832/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 77719,
      "real_time": 9.0066082117495880e+03,
      "cpu_time": 1.4819823029135874e+04,
      "time_unit": "ns",
      "items_per_second": 1.8105816991935333e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = false]": 1.4627515035010154e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 8.3200000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 8.3200000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 1.6307200000000000e+05,
      "input_width": 1.4000000000000000e+01,
      "is_training": 0.0000000000000000e+00,
      "num_iterations": 7.7719000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 8.3200000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 1.6307200000000000e+05,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 1.8105816991935333e+10,
      "predicted_flops_count": 1.6307200000000000e+05
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_128__8413458993106029496<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:1/input[1]:832/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 33611,
      "real_time": 2.0841175936699565e+04,
      "cpu_time": 2.7047719021006837e+04,
      "time_unit": "ns",
      "items_per_second": 7.8245105024445314e+09,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = true]": 9.0033003156525926e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 8.3200000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 8.3200000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 1.6307200000000000e+05,
      "input_width": 1.4000000000000000e+01,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 3.3611000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 8.3200000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 1.6307200000000000e+05,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 7.8245105024445314e+09,
      "predicted_flops_count": 1.6307200000000000e+05
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_128__8817918391201856227<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:1/input[1]:704/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 85867,
      "real_time": 8.1236932883439895e+03,
      "cpu_time": 1.3955713533598615e+04,
      "time_unit": "ns",
      "items_per_second": 1.6985377845072233e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = false]": 1.4627515035010154e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 7.0400000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 7.0400000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 1.3798400000000000e+05,
      "input_width": 1.4000000000000000e+01,
      "is_training": 0.0000000000000000e+00,
      "num_iterations": 8.5867000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 7.0400000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 1.3798400000000000e+05,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 1.6985377845072233e+10,
      "predicted_flops_count": 1.3798400000000000e+05
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_128__10769999190985162696<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:1/input[1]:704/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 37653,
      "real_time": 1.8704354977295814e+04,
      "cpu_time": 2.4814673386334256e+04,
      "time_unit": "ns",
      "items_per_second": 7.3771055012317286e+09,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = true]": 9.0033003156525926e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 7.0400000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 7.0400000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 1.3798400000000000e+05,
      "input_width": 1.4000000000000000e+01,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 3.7653000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 7.0400000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 1.3798400000000000e+05,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 7.3771055012317286e+09,
      "predicted_flops_count": 1.3798400000000000e+05
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_128__15288471399323613850<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:1/input[1]:416/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 98864,
      "real_time": 7.0787801797005714e+03,
      "cpu_time": 1.2859785756083988e+04,
      "time_unit": "ns",
      "items_per_second": 1.1518368692082897e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = false]": 1.4627515035010154e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 4.1600000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 4.1600000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 8.1536000000000000e+04,
      "input_width": 1.4000000000000000e+01,
      "is_training": 0.0000000000000000e+00,
      "num_iterations": 9.8864000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 4.1600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 8.1536000000000000e+04,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 1.1518368692082897e+10,
      "predicted_flops_count": 8.1536000000000000e+04
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_128__4252168260955766705<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:1/input[1]:416/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 54468,
      "real_time": 1.2985727373246536e+04,
      "cpu_time": 1.8816592219216858e+04,
      "time_unit": "ns",
      "items_per_second": 6.2788935618640938e+09,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = true]": 9.0033003156525926e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 4.1600000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 4.1600000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 8.1536000000000000e+04,
      "input_width": 1.4000000000000000e+01,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 5.4468000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 4.1600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 8.1536000000000000e+04,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 6.2788935618640938e+09,
      "predicted_flops_count": 8.1536000000000000e+04
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_128__4276539337276957636<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:1/input[1]:736/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 83822,
      "real_time": 8.3763860292931622e+03,
      "cpu_time": 1.4281789279691264e+04,
      "time_unit": "ns",
      "items_per_second": 1.7221746884100201e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = false]": 1.4627515035010154e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 7.3600000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 7.3600000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 1.4425600000000000e+05,
      "input_width": 1.4000000000000000e+01,
      "is_training": 0.0000000000000000e+00,
      "num_iterations": 8.3822000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 7.3600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 1.4425600000000000e+05,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 1.7221746884100201e+10,
      "predicted_flops_count": 1.4425600000000000e+05
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_128__15307843864798357231<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:1/input[1]:736/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 36048,
      "real_time": 1.9547988362718141e+04,
      "cpu_time": 2.5711782789803550e+04,
      "time_unit": "ns",
      "items_per_second": 7.3795828667017517e+09,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = true]": 9.0033003156525926e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 7.3600000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 7.3600000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 1.4425600000000000e+05,
      "input_width": 1.4000000000000000e+01,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 3.6048000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 7.3600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 1.4425600000000000e+05,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 7.3795828667017517e+09,
      "predicted_flops_count": 1.4425600000000000e+05
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_128__17268586585507208266<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:1/input[1]:416/input[2]:28/input[3]:28/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 34460,
      "real_time": 2.0319049843573452e+04,
      "cpu_time": 2.6401192483946576e+04,
      "time_unit": "ns",
      "items_per_second": 1.6051144246941914e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = false]": 1.4627515035010154e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 4.1600000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 4.1600000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 3.2614400000000000e+05,
      "input_width": 2.8000000000000000e+01,
      "is_training": 0.0000000000000000e+00,
      "num_iterations": 3.4460000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 4.1600000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 3.2614400000000000e+05,
      "output_width": 2.8000000000000000e+01,
      "predicted_flops": 1.6051144246941914e+10,
      "predicted_flops_count": 3.2614400000000000e+05
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_128__40368830570682721<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:1/input[1]:416/input[2]:28/input[3]:28/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 17404,
      "real_time": 4.0273420977447888e+04,
      "cpu_time": 4.6489080958033599e+04,
      "time_unit": "ns",
      "items_per_second": 8.0982442535148058e+09,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = true]": 9.0033003156525926e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 4.1600000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 4.1600000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 3.2614400000000000e+05,
      "input_width": 2.8000000000000000e+01,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 1.7404000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 4.1600000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 3.2614400000000000e+05,
      "output_width": 2.8000000000000000e+01,
      "predicted_flops": 8.0982442535148058e+09,
      "predicted_flops_count": 3.2614400000000000e+05
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_128__2066729369142305911<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:1/input[1]:896/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 70845,
      "real_time": 9.8508491720957754e+03,
      "cpu_time": 1.5704686343230880e+04,
      "time_unit": "ns",
      "items_per_second": 1.7827498617831093e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = false]": 1.4627515035010154e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 8.9600000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 8.9600000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 1.7561600000000000e+05,
      "input_width": 1.4000000000000000e+01,
      "is_training": 0.0000000000000000e+00,
      "num_iterations": 7.0845000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 8.9600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 1.7561600000000000e+05,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 1.7827498617831093e+10,
      "predicted_flops_count": 1.7561600000000000e+05
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_128__17548078397715538268<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:1/input[1]:896/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 31835,
      "real_time": 2.1975587620178012e+04,
      "cpu_time": 2.8157769750245898e+04,
      "time_unit": "ns",
      "items_per_second": 7.9914131551480856e+09,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = true]": 9.0033003156525926e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 8.9600000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 8.9600000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 1.7561600000000000e+05,
      "input_width": 1.4000000000000000e+01,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 3.1835000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 8.9600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 1.7561600000000000e+05,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 7.9914131551480856e+09,
      "predicted_flops_count": 1.7561600000000000e+05
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_128__5932182551825187565<CUDNN_BATCHNORM_SPATIAL>/input[0]:128/input[1]:24/input[2]:56/input[3]:56/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 5115,
      "real_time": 1.3688026782546742e+05,
      "cpu_time": 1.4331223675442403e+05,
      "time_unit": "ns",
      "items_per_second": 7.0381159775956940e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 1.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)1; bool is_training = false]": 7.0429798546002954e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 2.4000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 2.4000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 9.6337920000000000e+06,
      "input_width": 5.6000000000000000e+01,
      "is_training": 0.0000000000000000e+00,
      "num_iterations": 5.1150000000000000e+03,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 2.4000000000000000e+01,
      "output_height": 5.6000000000000000e+01,
      "output_size": 9.6337920000000000e+06,
      "output_width": 5.6000000000000000e+01,
      "predicted_flops": 7.0381159775956940e+10,
      "predicted_flops_count": 9.6337920000000000e+06
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_128__5932182551825187565<CUDNN_BATCHNORM_SPATIAL_PERSISTENT>/input[0]:128/input[1]:24/input[2]:56/input[3]:56/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/BATCHNORM_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_128__16898891353589486450<CUDNN_BATCHNORM_SPATIAL>/input[0]:128/input[1]:24/input[2]:56/input[3]:56/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 2282,
      "real_time": 3.0669976569584419e+05,
      "cpu_time": 3.1418790184122429e+05,
      "time_unit": "ns",
      "items_per_second": 3.1411148874348614e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 1.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)1; bool is_training = true]": 1.2389518253260638e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 2.4000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 2.4000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 9.6337920000000000e+06,
      "input_width": 5.6000000000000000e+01,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 2.2820000000000000e+03,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 2.4000000000000000e+01,
      "output_height": 5.6000000000000000e+01,
      "output_size": 9.6337920000000000e+06,
      "output_width": 5.6000000000000000e+01,
      "predicted_flops": 3.1411148874348614e+10,
      "predicted_flops_count": 9.6337920000000000e+06
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_128__16898891353589486450<CUDNN_BATCHNORM_SPATIAL_PERSISTENT>/input[0]:128/input[1]:24/input[2]:56/input[3]:56/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 3817,
      "real_time": 1.8319369451491028e+05,
      "cpu_time": 1.8980017290997333e+05,
      "time_unit": "ns",
      "items_per_second": 5.2588010878376053e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 2.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)2; bool is_training = true]": 8.6489340726076344e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 2.4000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 2.4000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 9.6337920000000000e+06,
      "input_width": 5.6000000000000000e+01,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 3.8170000000000000e+03,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 2.4000000000000000e+01,
      "output_height": 5.6000000000000000e+01,
      "output_size": 9.6337920000000000e+06,
      "output_width": 5.6000000000000000e+01,
      "predicted_flops": 5.2588010878376053e+10,
      "predicted_flops_count": 9.6337920000000000e+06
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_128__11226853231070190167<CUDNN_BATCHNORM_SPATIAL>/input[0]:128/input[1]:144/input[2]:56/input[3]:56/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 891,
      "real_time": 7.8563661263329547e+05,
      "cpu_time": 8.0054353984147473e+05,
      "time_unit": "ns",
      "items_per_second": 7.3574412228901642e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 1.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)1; bool is_training = false]": 7.0429798546002954e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 1.4400000000000000e+02,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 1.4400000000000000e+02,
      "input_height": 5.6000000000000000e+01,
      "input_size": 5.7802752000000000e+07,
      "input_width": 5.6000000000000000e+01,
      "is_training": 0.0000000000000000e+00,
      "num_iterations": 8.9100000000000000e+02,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 1.4400000000000000e+02,
      "output_height": 5.6000000000000000e+01,
      "output_size": 5.7802752000000000e+07,
      "output_width": 5.6000000000000000e+01,
      "predicted_flops": 7.3574412228901642e+10,
      "predicted_flops_count": 5.7802752000000000e+07
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_128__11226853231070190167<CUDNN_BATCHNORM_SPATIAL_PERSISTENT>/input[0]:128/input[1]:144/input[2]:56/input[3]:56/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/BATCHNORM_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_128__2529474022634294216<CUDNN_BATCHNORM_SPATIAL>/input[0]:128/input[1]:144/input[2]:56/input[3]:56/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 587,
      "real_time": 1.1926475308242124e+06,
      "cpu_time": 1.2189445349250077e+06,
      "time_unit": "ns",
      "items_per_second": 4.8465913445570786e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 1.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)1; bool is_training = true]": 1.2389518253260638e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 1.4400000000000000e+02,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 1.4400000000000000e+02,
      "input_height": 5.6000000000000000e+01,
      "input_size": 5.7802752000000000e+07,
      "input_width": 5.6000000000000000e+01,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 5.8700000000000000e+02,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 1.4400000000000000e+02,
      "output_height": 5.6000000000000000e+01,
      "output_size": 5.7802752000000000e+07,
      "output_width": 5.6000000000000000e+01,
      "predicted_flops": 4.8465913445570786e+10,
      "predicted_flops_count": 5.7802752000000000e+07
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_128__2529474022634294216<CUDNN_BATCHNORM_SPATIAL_PERSISTENT>/input[0]:128/input[1]:144/input[2]:56/input[3]:56/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 660,
      "real_time": 1.0591182016386567e+06,
      "cpu_time": 1.0812357712140828e+06,
      "time_unit": "ns",
      "items_per_second": 5.4576299331432686e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 2.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)2; bool is_training = true]": 8.6489340726076344e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 1.4400000000000000e+02,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 1.4400000000000000e+02,
      "input_height": 5.6000000000000000e+01,
      "input_size": 5.7802752000000000e+07,
      "input_width": 5.6000000000000000e+01,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 6.6000000000000000e+02,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 1.4400000000000000e+02,
      "output_height": 5.6000000000000000e+01,
      "output_size": 5.7802752000000000e+07,
      "output_width": 5.6000000000000000e+01,
      "predicted_flops": 5.4576299331432686e+10,
      "predicted_flops_count": 5.7802752000000000e+07
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_128__13138794921079207493<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:1/input[1]:800/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 80709,
      "real_time": 8.6873866584091047e+03,
      "cpu_time": 1.4553548303067068e+04,
      "time_unit": "ns",
      "items_per_second": 1.8049156341881336e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = false]": 1.4627515035010154e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 8.0000000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 8.0000000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 1.5680000000000000e+05,
      "input_width": 1.4000000000000000e+01,
      "is_training": 0.0000000000000000e+00,
      "num_iterations": 8.0709000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 8.0000000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 1.5680000000000000e+05,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 1.8049156341881336e+10,
      "predicted_flops_count": 1.5680000000000000e+05
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_128__6448964876952122222<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:1/input[1]:800/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 34405,
      "real_time": 2.0354664545516342e+04,
      "cpu_time": 2.6556375352017989e+04,
      "time_unit": "ns",
      "items_per_second": 7.7033939640405130e+09,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = true]": 9.0033003156525926e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 8.0000000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 8.0000000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 1.5680000000000000e+05,
      "input_width": 1.4000000000000000e+01,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 3.4405000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 8.0000000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 1.5680000000000000e+05,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 7.7033939640405130e+09,
      "predicted_flops_count": 1.5680000000000000e+05
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_128__7736438617458458995<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:1/input[1]:448/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 98033,
      "real_time": 7.2353488604861723e+03,
      "cpu_time": 1.3100590943913279e+04,
      "time_unit": "ns",
      "items_per_second": 1.2135973218864229e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = false]": 1.4627515035010154e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 4.4800000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 4.4800000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 8.7808000000000000e+04,
      "input_width": 1.4000000000000000e+01,
      "is_training": 0.0000000000000000e+00,
      "num_iterations": 9.8033000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 4.4800000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 8.7808000000000000e+04,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 1.2135973218864229e+10,
      "predicted_flops_count": 8.7808000000000000e+04
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_128__9544370967328556120<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:1/input[1]:448/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 53574,
      "real_time": 1.3065662137647430e+04,
      "cpu_time": 1.8789855862707929e+04,
      "time_unit": "ns",
      "items_per_second": 6.7205166546431522e+09,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = true]": 9.0033003156525926e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 4.4800000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 4.4800000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 8.7808000000000000e+04,
      "input_width": 1.4000000000000000e+01,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 5.3574000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 4.4800000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 8.7808000000000000e+04,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 6.7205166546431522e+09,
      "predicted_flops_count": 8.7808000000000000e+04
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_128__6193347507491773787<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:1/input[1]:480/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 94814,
      "real_time": 7.3981625293995839e+03,
      "cpu_time": 1.3319694032584339e+04,
      "time_unit": "ns",
      "items_per_second": 1.2716671149915289e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = false]": 1.4627515035010154e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 4.8000000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 4.8000000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 9.4080000000000000e+04,
      "input_width": 1.4000000000000000e+01,
      "is_training": 0.0000000000000000e+00,
      "num_iterations": 9.4814000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 4.8000000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 9.4080000000000000e+04,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 1.2716671149915289e+10,
      "predicted_flops_count": 9.4080000000000000e+04
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_128__13464077901289445488<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:1/input[1]:480/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 49160,
      "real_time": 1.4211692959078700e+04,
      "cpu_time": 2.0162932668736095e+04,
      "time_unit": "ns",
      "items_per_second": 6.6199009696378145e+09,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = true]": 9.0033003156525926e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 4.8000000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 4.8000000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 9.4080000000000000e+04,
      "input_width": 1.4000000000000000e+01,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 4.9160000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 4.8000000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 9.4080000000000000e+04,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 6.6199009696378145e+09,
      "predicted_flops_count": 9.4080000000000000e+04
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_128__12125660515354148524<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:128/input[1]:64/input[2]:400/input[3]:400/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 17,
      "real_time": 4.0975841529229105e+07,
      "cpu_time": 6.5083137647046469e+07,
      "time_unit": "ns",
      "items_per_second": 3.1987628590007851e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = false]": 1.4627515035010154e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 4.0000000000000000e+02,
      "input[3]": 4.0000000000000000e+02,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 4.0000000000000000e+02,
      "input_size": 1.3107200000000000e+09,
      "input_width": 4.0000000000000000e+02,
      "is_training": 0.0000000000000000e+00,
      "num_iterations": 1.7000000000000000e+01,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 4.0000000000000000e+02,
      "output_size": 1.3107200000000000e+09,
      "output_width": 4.0000000000000000e+02,
      "predicted_flops": 3.1987628590007851e+10,
      "predicted_flops_count": 1.3107200000000000e+09
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_128__5147558041171508103<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:128/input[1]:64/input[2]:400/input[3]:400/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 12,
      "real_time": 5.8746792065600552e+07,
      "cpu_time": 1.0770449458336391e+08,
      "time_unit": "ns",
      "items_per_second": 2.2311345929091129e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = true]": 9.0033003156525926e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 4.0000000000000000e+02,
      "input[3]": 4.0000000000000000e+02,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 4.0000000000000000e+02,
      "input_size": 1.3107200000000000e+09,
      "input_width": 4.0000000000000000e+02,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 1.2000000000000000e+01,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 4.0000000000000000e+02,
      "output_size": 1.3107200000000000e+09,
      "output_width": 4.0000000000000000e+02,
      "predicted_flops": 2.2311345929091129e+10,
      "predicted_flops_count": 1.3107200000000000e+09
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_128__16904277444093157933<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:1/input[1]:544/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 115659,
      "real_time": 5.9967312595427138e+03,
      "cpu_time": 1.1821037454962163e+04,
      "time_unit": "ns",
      "items_per_second": 4.4450883066640339e+09,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = false]": 1.4627515035010154e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 5.4400000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 5.4400000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 2.6656000000000000e+04,
      "input_width": 7.0000000000000000e+00,
      "is_training": 0.0000000000000000e+00,
      "num_iterations": 1.1565900000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 5.4400000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 2.6656000000000000e+04,
      "output_width": 7.0000000000000000e+00,
      "predicted_flops": 4.4450883066640339e+09,
      "predicted_flops_count": 2.6656000000000000e+04
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_128__410177179444340486<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:1/input[1]:544/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 67406,
      "real_time": 1.0378281285284214e+04,
      "cpu_time": 1.6191715975015653e+04,
      "time_unit": "ns",
      "items_per_second": 2.5684406952620006e+09,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = true]": 9.0033003156525926e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 5.4400000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 5.4400000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 2.6656000000000000e+04,
      "input_width": 7.0000000000000000e+00,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 6.7406000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 5.4400000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 2.6656000000000000e+04,
      "output_width": 7.0000000000000000e+00,
      "predicted_flops": 2.5684406952620006e+09,
      "predicted_flops_count": 2.6656000000000000e+04
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_128__9821257763164194723<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:128/input[1]:128/input[2]:400/input[3]:400/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD failed to cudnnSetTensor4dDescriptor",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_128__7450412676701831816<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:128/input[1]:128/input[2]:400/input[3]:400/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD failed to cudnnSetTensor4dDescriptor",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_128__5901503973176032831<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:1/input[1]:448/input[2]:28/input[3]:28/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 32596,
      "real_time": 2.1474462095750103e+04,
      "cpu_time": 2.7549975733047751e+04,
      "time_unit": "ns",
      "items_per_second": 1.6355799667248030e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = false]": 1.4627515035010154e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 4.4800000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 4.4800000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 3.5123200000000000e+05,
      "input_width": 2.8000000000000000e+01,
      "is_training": 0.0000000000000000e+00,
      "num_iterations": 3.2596000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 4.4800000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 3.5123200000000000e+05,
      "output_width": 2.8000000000000000e+01,
      "predicted_flops": 1.6355799667248030e+10,
      "predicted_flops_count": 3.5123200000000000e+05
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_128__13749324348628728596<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:1/input[1]:448/input[2]:28/input[3]:28/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 16334,
      "real_time": 4.2778275400498642e+04,
      "cpu_time": 4.8991841863619302e+04,
      "time_unit": "ns",
      "items_per_second": 8.2105226709514771e+09,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = true]": 9.0033003156525926e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 4.4800000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 4.4800000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 3.5123200000000000e+05,
      "input_width": 2.8000000000000000e+01,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 1.6334000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 4.4800000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 3.5123200000000000e+05,
      "output_width": 2.8000000000000000e+01,
      "predicted_flops": 8.2105226709514771e+09,
      "predicted_flops_count": 3.5123200000000000e+05
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_128__17399262348674148785<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:1/input[1]:608/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 115969,
      "real_time": 6.0373149813852342e+03,
      "cpu_time": 1.1843982029716230e+04,
      "time_unit": "ns",
      "items_per_second": 4.9346439753196983e+09,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = false]": 1.4627515035010154e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 6.0800000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 6.0800000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 2.9792000000000000e+04,
      "input_width": 7.0000000000000000e+00,
      "is_training": 0.0000000000000000e+00,
      "num_iterations": 1.1596900000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 6.0800000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 2.9792000000000000e+04,
      "output_width": 7.0000000000000000e+00,
      "predicted_flops": 4.9346439753196983e+09,
      "predicted_flops_count": 2.9792000000000000e+04
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_128__2188656882801929370<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:1/input[1]:608/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 65073,
      "real_time": 1.0733022125492491e+04,
      "cpu_time": 1.6622109353949549e+04,
      "time_unit": "ns",
      "items_per_second": 2.7757326549471712e+09,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = true]": 9.0033003156525926e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 6.0800000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 6.0800000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 2.9792000000000000e+04,
      "input_width": 7.0000000000000000e+00,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 6.5073000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 6.0800000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 2.9792000000000000e+04,
      "output_width": 7.0000000000000000e+00,
      "predicted_flops": 2.7757326549471712e+09,
      "predicted_flops_count": 2.9792000000000000e+04
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_128__8017254434804693755<CUDNN_BATCHNORM_SPATIAL>/input[0]:128/input[1]:192/input[2]:28/input[3]:28/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 2627,
      "real_time": 2.6640605915443803e+05,
      "cpu_time": 2.7357924438447290e+05,
      "time_unit": "ns",
      "items_per_second": 7.2324120784469116e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 1.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)1; bool is_training = false]": 7.0429798546002954e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 1.9200000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 1.9200000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 1.9267584000000000e+07,
      "input_width": 2.8000000000000000e+01,
      "is_training": 0.0000000000000000e+00,
      "num_iterations": 2.6270000000000000e+03,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 1.9200000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 1.9267584000000000e+07,
      "output_width": 2.8000000000000000e+01,
      "predicted_flops": 7.2324120784469116e+10,
      "predicted_flops_count": 1.9267584000000000e+07
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_128__8017254434804693755<CUDNN_BATCHNORM_SPATIAL_PERSISTENT>/input[0]:128/input[1]:192/input[2]:28/input[3]:28/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/BATCHNORM_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_128__15534242024825154404<CUDNN_BATCHNORM_SPATIAL>/input[0]:128/input[1]:192/input[2]:28/input[3]:28/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 1718,
      "real_time": 4.0751446840923594e+05,
      "cpu_time": 4.1598968742759060e+05,
      "time_unit": "ns",
      "items_per_second": 4.7280736007269867e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 1.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)1; bool is_training = true]": 1.2389518253260638e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 1.9200000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 1.9200000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 1.9267584000000000e+07,
      "input_width": 2.8000000000000000e+01,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 1.7180000000000000e+03,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 1.9200000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 1.9267584000000000e+07,
      "output_width": 2.8000000000000000e+01,
      "predicted_flops": 4.7280736007269867e+10,
      "predicted_flops_count": 1.9267584000000000e+07
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_128__15534242024825154404<CUDNN_BATCHNORM_SPATIAL_PERSISTENT>/input[0]:128/input[1]:192/input[2]:28/input[3]:28/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 2035,
      "real_time": 3.4381732665270072e+05,
      "cpu_time": 3.5166320982853550e+05,
      "time_unit": "ns",
      "items_per_second": 5.6040177461628372e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 2.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)2; bool is_training = true]": 8.6489340726076344e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 1.9200000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 1.9200000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 1.9267584000000000e+07,
      "input_width": 2.8000000000000000e+01,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 2.0350000000000000e+03,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 1.9200000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 1.9267584000000000e+07,
      "output_width": 2.8000000000000000e+01,
      "predicted_flops": 5.6040177461628372e+10,
      "predicted_flops_count": 1.9267584000000000e+07
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_128__14576981906394236471<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:1/input[1]:480/input[2]:28/input[3]:28/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 31292,
      "real_time": 2.2511809788055878e+04,
      "cpu_time": 2.8826490828226037e+04,
      "time_unit": "ns",
      "items_per_second": 1.6716559154638229e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = false]": 1.4627515035010154e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 4.8000000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 4.8000000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 3.7632000000000000e+05,
      "input_width": 2.8000000000000000e+01,
      "is_training": 0.0000000000000000e+00,
      "num_iterations": 3.1292000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 4.8000000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 3.7632000000000000e+05,
      "output_width": 2.8000000000000000e+01,
      "predicted_flops": 1.6716559154638229e+10,
      "predicted_flops_count": 3.7632000000000000e+05
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_128__2693967258241106716<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:1/input[1]:480/input[2]:28/input[3]:28/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 15299,
      "real_time": 4.5537577210925287e+04,
      "cpu_time": 5.1613997777656914e+04,
      "time_unit": "ns",
      "items_per_second": 8.2639442642485161e+09,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = true]": 9.0033003156525926e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 4.8000000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 4.8000000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 3.7632000000000000e+05,
      "input_width": 2.8000000000000000e+01,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 1.5299000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 4.8000000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 3.7632000000000000e+05,
      "output_width": 2.8000000000000000e+01,
      "predicted_flops": 8.2639442642485161e+09,
      "predicted_flops_count": 3.7632000000000000e+05
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_128__16621857322922710516<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:1/input[1]:928/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 59785,
      "real_time": 1.1410161641118839e+04,
      "cpu_time": 1.7245033001545224e+04,
      "time_unit": "ns",
      "items_per_second": 1.5940878466132294e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = false]": 1.4627515035010154e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 9.2800000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 9.2800000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 1.8188800000000000e+05,
      "input_width": 1.4000000000000000e+01,
      "is_training": 0.0000000000000000e+00,
      "num_iterations": 5.9785000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 9.2800000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 1.8188800000000000e+05,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 1.5940878466132294e+10,
      "predicted_flops_count": 1.8188800000000000e+05
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_128__686095351364112607<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:1/input[1]:928/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 30971,
      "real_time": 2.2649320235883373e+04,
      "cpu_time": 2.8970744244539754e+04,
      "time_unit": "ns",
      "items_per_second": 8.0306162880700684e+09,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = true]": 9.0033003156525926e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 9.2800000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 9.2800000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 1.8188800000000000e+05,
      "input_width": 1.4000000000000000e+01,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 3.0971000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 9.2800000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 1.8188800000000000e+05,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 8.0306162880700684e+09,
      "predicted_flops_count": 1.8188800000000000e+05
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_128__3683730341301957751<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:1/input[1]:128/input[2]:28/input[3]:28/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 94057,
      "real_time": 7.4363098590505169e+03,
      "cpu_time": 1.3327580393069116e+04,
      "time_unit": "ns",
      "items_per_second": 1.3494865316547358e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = false]": 1.4627515035010154e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 1.2800000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 1.2800000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 1.0035200000000000e+05,
      "input_width": 2.8000000000000000e+01,
      "is_training": 0.0000000000000000e+00,
      "num_iterations": 9.4057000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 1.0035200000000000e+05,
      "output_width": 2.8000000000000000e+01,
      "predicted_flops": 1.3494865316547358e+10,
      "predicted_flops_count": 1.0035200000000000e+05
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_128__15867885760678195548<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:1/input[1]:128/input[2]:28/input[3]:28/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 48984,
      "real_time": 1.4189296972739201e+04,
      "cpu_time": 2.0086958353494829e+04,
      "time_unit": "ns",
      "items_per_second": 7.0723729436911869e+09,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = true]": 9.0033003156525926e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 1.2800000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 1.2800000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 1.0035200000000000e+05,
      "input_width": 2.8000000000000000e+01,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 4.8984000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 1.0035200000000000e+05,
      "output_width": 2.8000000000000000e+01,
      "predicted_flops": 7.0723729436911869e+09,
      "predicted_flops_count": 1.0035200000000000e+05
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_128__9156435283693894329<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:1/input[1]:544/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 91425,
      "real_time": 7.6541136565426514e+03,
      "cpu_time": 1.3447277462738228e+04,
      "time_unit": "ns",
      "items_per_second": 1.3930287004408276e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = false]": 1.4627515035010154e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 5.4400000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 5.4400000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 1.0662400000000000e+05,
      "input_width": 1.4000000000000000e+01,
      "is_training": 0.0000000000000000e+00,
      "num_iterations": 9.1425000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 5.4400000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 1.0662400000000000e+05,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 1.3930287004408276e+10,
      "predicted_flops_count": 1.0662400000000000e+05
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_128__10392903167057543058<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:1/input[1]:544/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 47592,
      "real_time": 1.4776347583650087e+04,
      "cpu_time": 2.0610406412626115e+04,
      "time_unit": "ns",
      "items_per_second": 7.2158562456921768e+09,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = true]": 9.0033003156525926e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 5.4400000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 5.4400000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 1.0662400000000000e+05,
      "input_width": 1.4000000000000000e+01,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 4.7592000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 5.4400000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 1.0662400000000000e+05,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 7.2158562456921768e+09,
      "predicted_flops_count": 1.0662400000000000e+05
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_128__5968685270233129840<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:1/input[1]:512/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 94126,
      "real_time": 7.4347685905649141e+03,
      "cpu_time": 1.3326926088277964e+04,
      "time_unit": "ns",
      "items_per_second": 1.3497662876468222e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = false]": 1.4627515035010154e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 1.0035200000000000e+05,
      "input_width": 1.4000000000000000e+01,
      "is_training": 0.0000000000000000e+00,
      "num_iterations": 9.4126000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 1.0035200000000000e+05,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 1.3497662876468222e+10,
      "predicted_flops_count": 1.0035200000000000e+05
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_128__13689874812997494363<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:1/input[1]:512/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 49349,
      "real_time": 1.4296851126054116e+04,
      "cpu_time": 2.0134922490960340e+04,
      "time_unit": "ns",
      "items_per_second": 7.0191680052624865e+09,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = true]": 9.0033003156525926e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 1.0035200000000000e+05,
      "input_width": 1.4000000000000000e+01,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 4.9349000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 1.0035200000000000e+05,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 7.0191680052624865e+09,
      "predicted_flops_count": 1.0035200000000000e+05
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_128__9828769825327627606<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:1/input[1]:960/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 57768,
      "real_time": 1.2227658321490560e+04,
      "cpu_time": 1.8173595935678368e+04,
      "time_unit": "ns",
      "items_per_second": 1.5388064914220074e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = false]": 1.4627515035010154e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 9.6000000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 9.6000000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 1.8816000000000000e+05,
      "input_width": 1.4000000000000000e+01,
      "is_training": 0.0000000000000000e+00,
      "num_iterations": 5.7768000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 9.6000000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 1.8816000000000000e+05,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 1.5388064914220074e+10,
      "predicted_flops_count": 1.8816000000000000e+05
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_128__7444447064784205949<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:1/input[1]:960/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 29304,
      "real_time": 2.3839411526887874e+04,
      "cpu_time": 3.0137947072244468e+04,
      "time_unit": "ns",
      "items_per_second": 7.8928122780119410e+09,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = true]": 9.0033003156525926e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 9.6000000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 9.6000000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 1.8816000000000000e+05,
      "input_width": 1.4000000000000000e+01,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 2.9304000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 9.6000000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 1.8816000000000000e+05,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 7.8928122780119410e+09,
      "predicted_flops_count": 1.8816000000000000e+05
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_128__847297196735432346<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:1/input[1]:320/input[2]:28/input[3]:28/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 41788,
      "real_time": 1.6747529067387342e+04,
      "cpu_time": 2.2694247463594187e+04,
      "time_unit": "ns",
      "items_per_second": 1.4980120290612993e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = false]": 1.4627515035010154e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 3.2000000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 3.2000000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 2.5088000000000000e+05,
      "input_width": 2.8000000000000000e+01,
      "is_training": 0.0000000000000000e+00,
      "num_iterations": 4.1788000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 3.2000000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 2.5088000000000000e+05,
      "output_width": 2.8000000000000000e+01,
      "predicted_flops": 1.4980120290612993e+10,
      "predicted_flops_count": 2.5088000000000000e+05
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_128__16495286249914614705<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:1/input[1]:320/input[2]:28/input[3]:28/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 22013,
      "real_time": 3.1917532829200387e+04,
      "cpu_time": 3.8181434289023186e+04,
      "time_unit": "ns",
      "items_per_second": 7.8602566602665930e+09,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = true]": 9.0033003156525926e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 3.2000000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 3.2000000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 2.5088000000000000e+05,
      "input_width": 2.8000000000000000e+01,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 2.2013000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 3.2000000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 2.5088000000000000e+05,
      "output_width": 2.8000000000000000e+01,
      "predicted_flops": 7.8602566602665930e+09,
      "predicted_flops_count": 2.5088000000000000e+05
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_128__8405694704743189508<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:1/input[1]:576/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 116636,
      "real_time": 6.0075915226623865e+03,
      "cpu_time": 1.1826288495878343e+04,
      "time_unit": "ns",
      "items_per_second": 4.6980557671956959e+09,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = false]": 1.4627515035010154e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 5.7600000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 5.7600000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 2.8224000000000000e+04,
      "input_width": 7.0000000000000000e+00,
      "is_training": 0.0000000000000000e+00,
      "num_iterations": 1.1663600000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 5.7600000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 2.8224000000000000e+04,
      "output_width": 7.0000000000000000e+00,
      "predicted_flops": 4.6980557671956959e+09,
      "predicted_flops_count": 2.8224000000000000e+04
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_128__11208955831952066863<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:1/input[1]:576/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 66769,
      "real_time": 1.0426665728088943e+04,
      "cpu_time": 1.6266254189798850e+04,
      "time_unit": "ns",
      "items_per_second": 2.7069056145116348e+09,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = true]": 9.0033003156525926e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 5.7600000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 5.7600000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 2.8224000000000000e+04,
      "input_width": 7.0000000000000000e+00,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 6.6769000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 5.7600000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 2.8224000000000000e+04,
      "output_width": 7.0000000000000000e+00,
      "predicted_flops": 2.7069056145116348e+09,
      "predicted_flops_count": 2.8224000000000000e+04
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_128__9114343306464528187<CUDNN_BATCHNORM_SPATIAL>/input[0]:128/input[1]:384/input[2]:28/input[3]:28/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 1328,
      "real_time": 5.2710916865925607e+05,
      "cpu_time": 5.3718443599257653e+05,
      "time_unit": "ns",
      "items_per_second": 7.3106616790630402e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 1.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)1; bool is_training = false]": 7.0429798546002954e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 3.8400000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 3.8400000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 3.8535168000000000e+07,
      "input_width": 2.8000000000000000e+01,
      "is_training": 0.0000000000000000e+00,
      "num_iterations": 1.3280000000000000e+03,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 3.8400000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 3.8535168000000000e+07,
      "output_width": 2.8000000000000000e+01,
      "predicted_flops": 7.3106616790630402e+10,
      "predicted_flops_count": 3.8535168000000000e+07
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_128__9114343306464528187<CUDNN_BATCHNORM_SPATIAL_PERSISTENT>/input[0]:128/input[1]:384/input[2]:28/input[3]:28/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/BATCHNORM_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_128__14315555965436925604<CUDNN_BATCHNORM_SPATIAL>/input[0]:128/input[1]:384/input[2]:28/input[3]:28/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 806,
      "real_time": 8.6829101605567313e+05,
      "cpu_time": 8.8515616005055467e+05,
      "time_unit": "ns",
      "items_per_second": 4.4380475310053421e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 1.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)1; bool is_training = true]": 1.2389518253260638e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 3.8400000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 3.8400000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 3.8535168000000000e+07,
      "input_width": 2.8000000000000000e+01,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 8.0600000000000000e+02,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 3.8400000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 3.8535168000000000e+07,
      "output_width": 2.8000000000000000e+01,
      "predicted_flops": 4.4380475310053421e+10,
      "predicted_flops_count": 3.8535168000000000e+07
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_128__14315555965436925604<CUDNN_BATCHNORM_SPATIAL_PERSISTENT>/input[0]:128/input[1]:384/input[2]:28/input[3]:28/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 1026,
      "real_time": 6.8258785103269829e+05,
      "cpu_time": 6.9528634308084543e+05,
      "time_unit": "ns",
      "items_per_second": 5.6454517820232986e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 2.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)2; bool is_training = true]": 8.6489340726076344e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 3.8400000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 3.8400000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 3.8535168000000000e+07,
      "input_width": 2.8000000000000000e+01,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 1.0260000000000000e+03,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 3.8400000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 3.8535168000000000e+07,
      "output_width": 2.8000000000000000e+01,
      "predicted_flops": 5.6454517820232986e+10,
      "predicted_flops_count": 3.8535168000000000e+07
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_128__14916697881833509299<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:128/input[1]:64/input[2]:199/input[3]:199/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 69,
      "real_time": 1.0152826882034972e+07,
      "cpu_time": 1.1631554347824628e+07,
      "time_unit": "ns",
      "items_per_second": 3.1952814301801323e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = false]": 1.4627515035010154e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 1.9900000000000000e+02,
      "input[3]": 1.9900000000000000e+02,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 1.9900000000000000e+02,
      "input_size": 3.2441139200000000e+08,
      "input_width": 1.9900000000000000e+02,
      "is_training": 0.0000000000000000e+00,
      "num_iterations": 6.9000000000000000e+01,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 1.9900000000000000e+02,
      "output_size": 3.2441139200000000e+08,
      "output_width": 1.9900000000000000e+02,
      "predicted_flops": 3.1952814301801323e+10,
      "predicted_flops_count": 3.2441139200000000e+08
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_128__2318213118344320152<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:128/input[1]:64/input[2]:199/input[3]:199/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 48,
      "real_time": 1.4557866049775233e+07,
      "cpu_time": 1.7598371500004835e+07,
      "time_unit": "ns",
      "items_per_second": 2.2284268236209576e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = true]": 9.0033003156525926e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 1.9900000000000000e+02,
      "input[3]": 1.9900000000000000e+02,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 1.9900000000000000e+02,
      "input_size": 3.2441139200000000e+08,
      "input_width": 1.9900000000000000e+02,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 4.8000000000000000e+01,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 1.9900000000000000e+02,
      "output_size": 3.2441139200000000e+08,
      "output_width": 1.9900000000000000e+02,
      "predicted_flops": 2.2284268236209576e+10,
      "predicted_flops_count": 3.2441139200000000e+08
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_128__7122968153930484572<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:1/input[1]:736/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 111744,
      "real_time": 6.2799651247167094e+03,
      "cpu_time": 1.2132344975888258e+04,
      "time_unit": "ns",
      "items_per_second": 5.7427070507221737e+09,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = false]": 1.4627515035010154e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 7.3600000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 7.3600000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 3.6064000000000000e+04,
      "input_width": 7.0000000000000000e+00,
      "is_training": 0.0000000000000000e+00,
      "num_iterations": 1.1174400000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 7.3600000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 3.6064000000000000e+04,
      "output_width": 7.0000000000000000e+00,
      "predicted_flops": 5.7427070507221737e+09,
      "predicted_flops_count": 3.6064000000000000e+04
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_128__10227937474716372599<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:1/input[1]:736/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 61841,
      "real_time": 1.1096072027164017e+04,
      "cpu_time": 1.7020403939136759e+04,
      "time_unit": "ns",
      "items_per_second": 3.2501591474634109e+09,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = true]": 9.0033003156525926e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 7.3600000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 7.3600000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 3.6064000000000000e+04,
      "input_width": 7.0000000000000000e+00,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 6.1841000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 7.3600000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 3.6064000000000000e+04,
      "output_width": 7.0000000000000000e+00,
      "predicted_flops": 3.2501591474634109e+09,
      "predicted_flops_count": 3.6064000000000000e+04
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_128__4906908824640152787<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:1/input[1]:128/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 113496,
      "real_time": 6.1793555104550187e+03,
      "cpu_time": 1.2011661591780034e+04,
      "time_unit": "ns",
      "items_per_second": 4.0599703249882512e+09,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = false]": 1.4627515035010154e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 1.2800000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 1.2800000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 2.5088000000000000e+04,
      "input_width": 1.4000000000000000e+01,
      "is_training": 0.0000000000000000e+00,
      "num_iterations": 1.1349600000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 2.5088000000000000e+04,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 4.0599703249882512e+09,
      "predicted_flops_count": 2.5088000000000000e+04
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_128__12335892292500300280<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:1/input[1]:128/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 67167,
      "real_time": 1.0616595356501237e+04,
      "cpu_time": 1.6492457486414660e+04,
      "time_unit": "ns",
      "items_per_second": 2.3630927955294986e+09,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = true]": 9.0033003156525926e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 1.2800000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 1.2800000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 2.5088000000000000e+04,
      "input_width": 1.4000000000000000e+01,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 6.7167000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 2.5088000000000000e+04,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 2.3630927955294986e+09,
      "predicted_flops_count": 2.5088000000000000e+04
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_128__14178741234798799958<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:1/input[1]:640/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 114084,
      "real_time": 6.1477171735429274e+03,
      "cpu_time": 1.2023600390832948e+04,
      "time_unit": "ns",
      "items_per_second": 5.1010804685289783e+09,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = false]": 1.4627515035010154e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 6.4000000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 6.4000000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 3.1360000000000000e+04,
      "input_width": 7.0000000000000000e+00,
      "is_training": 0.0000000000000000e+00,
      "num_iterations": 1.1408400000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 6.4000000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 3.1360000000000000e+04,
      "output_width": 7.0000000000000000e+00,
      "predicted_flops": 5.1010804685289783e+09,
      "predicted_flops_count": 3.1360000000000000e+04
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_128__3164958765901408637<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:1/input[1]:640/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 64886,
      "real_time": 1.0812245434020622e+04,
      "cpu_time": 1.6684225904281597e+04,
      "time_unit": "ns",
      "items_per_second": 2.9004151072381392e+09,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = true]": 9.0033003156525926e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 6.4000000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 6.4000000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 3.1360000000000000e+04,
      "input_width": 7.0000000000000000e+00,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 6.4886000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 6.4000000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 3.1360000000000000e+04,
      "output_width": 7.0000000000000000e+00,
      "predicted_flops": 2.9004151072381392e+09,
      "predicted_flops_count": 3.1360000000000000e+04
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_128__10623436706895202255<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:128/input[1]:256/input[2]:199/input[3]:199/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 17,
      "real_time": 4.0608285323661916e+07,
      "cpu_time": 6.4505764882362783e+07,
      "time_unit": "ns",
      "items_per_second": 3.1955192337162754e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = false]": 1.4627515035010154e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 1.9900000000000000e+02,
      "input[3]": 1.9900000000000000e+02,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 1.9900000000000000e+02,
      "input_size": 1.2976455680000000e+09,
      "input_width": 1.9900000000000000e+02,
      "is_training": 0.0000000000000000e+00,
      "num_iterations": 1.7000000000000000e+01,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 1.9900000000000000e+02,
      "output_size": 1.2976455680000000e+09,
      "output_width": 1.9900000000000000e+02,
      "predicted_flops": 3.1955192337162754e+10,
      "predicted_flops_count": 1.2976455680000000e+09
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_128__8955183950373307108<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:128/input[1]:256/input[2]:199/input[3]:199/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 12,
      "real_time": 5.8190420890847839e+07,
      "cpu_time": 1.0668492275000100e+08,
      "time_unit": "ns",
      "items_per_second": 2.2299985945007885e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = true]": 9.0033003156525926e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 1.9900000000000000e+02,
      "input[3]": 1.9900000000000000e+02,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 1.9900000000000000e+02,
      "input_size": 1.2976455680000000e+09,
      "input_width": 1.9900000000000000e+02,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 1.2000000000000000e+01,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 1.9900000000000000e+02,
      "output_size": 1.2976455680000000e+09,
      "output_width": 1.9900000000000000e+02,
      "predicted_flops": 2.2299985945007885e+10,
      "predicted_flops_count": 1.2976455680000000e+09
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_128__16940678669688044217<CUDNN_BATCHNORM_SPATIAL>/input[0]:128/input[1]:576/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 3479,
      "real_time": 2.0058930189685122e+05,
      "cpu_time": 2.0732259442327518e+05,
      "time_unit": "ns",
      "items_per_second": 7.2041170009310669e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 1.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)1; bool is_training = false]": 7.0429798546002954e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 5.7600000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 5.7600000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 1.4450688000000000e+07,
      "input_width": 1.4000000000000000e+01,
      "is_training": 0.0000000000000000e+00,
      "num_iterations": 3.4790000000000000e+03,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 5.7600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 1.4450688000000000e+07,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 7.2041170009310669e+10,
      "predicted_flops_count": 1.4450688000000000e+07
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_128__16940678669688044217<CUDNN_BATCHNORM_SPATIAL_PERSISTENT>/input[0]:128/input[1]:576/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/BATCHNORM_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_128__6038999178143230758<CUDNN_BATCHNORM_SPATIAL>/input[0]:128/input[1]:576/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 2048,
      "real_time": 3.4179271916912060e+05,
      "cpu_time": 3.4957156445292180e+05,
      "time_unit": "ns",
      "items_per_second": 4.2279098381992554e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 1.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)1; bool is_training = true]": 1.2389518253260638e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 5.7600000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 5.7600000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 1.4450688000000000e+07,
      "input_width": 1.4000000000000000e+01,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 2.0480000000000000e+03,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 5.7600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 1.4450688000000000e+07,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 4.2279098381992554e+10,
      "predicted_flops_count": 1.4450688000000000e+07
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_128__6038999178143230758<CUDNN_BATCHNORM_SPATIAL_PERSISTENT>/input[0]:128/input[1]:576/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 2602,
      "real_time": 2.6907307972027693e+05,
      "cpu_time": 2.7625651575829991e+05,
      "time_unit": "ns",
      "items_per_second": 5.3705439485148979e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 2.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)2; bool is_training = true]": 8.6489340726076344e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 5.7600000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 5.7600000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 1.4450688000000000e+07,
      "input_width": 1.4000000000000000e+01,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 2.6020000000000000e+03,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 5.7600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 1.4450688000000000e+07,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 5.3705439485148979e+10,
      "predicted_flops_count": 1.4450688000000000e+07
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_128__529242968985074814<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:1/input[1]:992/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 53162,
      "real_time": 1.3161176628845256e+04,
      "cpu_time": 1.9096703641394928e+04,
      "time_unit": "ns",
      "items_per_second": 1.4773147225595680e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = false]": 1.4627515035010154e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 9.9200000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 9.9200000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 1.9443200000000000e+05,
      "input_width": 1.4000000000000000e+01,
      "is_training": 0.0000000000000000e+00,
      "num_iterations": 5.3162000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 9.9200000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 1.9443200000000000e+05,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 1.4773147225595680e+10,
      "predicted_flops_count": 1.9443200000000000e+05
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_128__16749182303429212501<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:1/input[1]:992/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 28456,
      "real_time": 2.4581075081922125e+04,
      "cpu_time": 3.0768942929014705e+04,
      "time_unit": "ns",
      "items_per_second": 7.9098249100989418e+09,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = true]": 9.0033003156525926e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 9.9200000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 9.9200000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 1.9443200000000000e+05,
      "input_width": 1.4000000000000000e+01,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 2.8456000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 9.9200000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 1.9443200000000000e+05,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 7.9098249100989418e+09,
      "predicted_flops_count": 1.9443200000000000e+05
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_128__18021674889009843961<CUDNN_BATCHNORM_SPATIAL>/input[0]:128/input[1]:576/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 5088,
      "real_time": 1.3761767925775214e+05,
      "cpu_time": 1.4403517511907622e+05,
      "time_unit": "ns",
      "items_per_second": 2.6251510848643337e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 1.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)1; bool is_training = false]": 7.0429798546002954e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 5.7600000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 5.7600000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 3.6126720000000000e+06,
      "input_width": 7.0000000000000000e+00,
      "is_training": 0.0000000000000000e+00,
      "num_iterations": 5.0880000000000000e+03,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 5.7600000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 3.6126720000000000e+06,
      "output_width": 7.0000000000000000e+00,
      "predicted_flops": 2.6251510848643337e+10,
      "predicted_flops_count": 3.6126720000000000e+06
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_128__18021674889009843961<CUDNN_BATCHNORM_SPATIAL_PERSISTENT>/input[0]:128/input[1]:576/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/BATCHNORM_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_128__4813905358400708454<CUDNN_BATCHNORM_SPATIAL>/input[0]:128/input[1]:576/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 10215,
      "real_time": 6.8615359069614948e+04,
      "cpu_time": 7.4885681545985834e+04,
      "time_unit": "ns",
      "items_per_second": 5.2651068929548241e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 1.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)1; bool is_training = true]": 1.2389518253260638e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 5.7600000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 5.7600000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 3.6126720000000000e+06,
      "input_width": 7.0000000000000000e+00,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 1.0215000000000000e+04,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 5.7600000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 3.6126720000000000e+06,
      "output_width": 7.0000000000000000e+00,
      "predicted_flops": 5.2651068929548241e+10,
      "predicted_flops_count": 3.6126720000000000e+06
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_128__4813905358400708454<CUDNN_BATCHNORM_SPATIAL_PERSISTENT>/input[0]:128/input[1]:576/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 10166,
      "real_time": 6.8656585940177305e+04,
      "cpu_time": 7.4935716998189499e+04,
      "time_unit": "ns",
      "items_per_second": 5.2619453043409958e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 2.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)2; bool is_training = true]": 8.6489340726076344e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 5.7600000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 5.7600000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 3.6126720000000000e+06,
      "input_width": 7.0000000000000000e+00,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 1.0166000000000000e+04,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 5.7600000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 3.6126720000000000e+06,
      "output_width": 7.0000000000000000e+00,
      "predicted_flops": 5.2619453043409958e+10,
      "predicted_flops_count": 3.6126720000000000e+06
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_128__17377787318148837475<CUDNN_BATCHNORM_SPATIAL>/input[0]:128/input[1]:384/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 5143,
      "real_time": 1.3615935907893654e+05,
      "cpu_time": 1.4257811394116923e+05,
      "time_unit": "ns",
      "items_per_second": 7.0753799556407578e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 1.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)1; bool is_training = false]": 7.0429798546002954e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 3.8400000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 3.8400000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 9.6337920000000000e+06,
      "input_width": 1.4000000000000000e+01,
      "is_training": 0.0000000000000000e+00,
      "num_iterations": 5.1430000000000000e+03,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 3.8400000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 9.6337920000000000e+06,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 7.0753799556407578e+10,
      "predicted_flops_count": 9.6337920000000000e+06
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_128__17377787318148837475<CUDNN_BATCHNORM_SPATIAL_PERSISTENT>/input[0]:128/input[1]:384/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/BATCHNORM_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_128__5331692143958041084<CUDNN_BATCHNORM_SPATIAL>/input[0]:128/input[1]:384/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 2912,
      "real_time": 2.4063990321047933e+05,
      "cpu_time": 2.4761449931321022e+05,
      "time_unit": "ns",
      "items_per_second": 4.0034058655574089e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 1.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)1; bool is_training = true]": 1.2389518253260638e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 3.8400000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 3.8400000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 9.6337920000000000e+06,
      "input_width": 1.4000000000000000e+01,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 2.9120000000000000e+03,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 3.8400000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 9.6337920000000000e+06,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 4.0034058655574089e+10,
      "predicted_flops_count": 9.6337920000000000e+06
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_128__5331692143958041084<CUDNN_BATCHNORM_SPATIAL_PERSISTENT>/input[0]:128/input[1]:384/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 3762,
      "real_time": 1.8603247573420603e+05,
      "cpu_time": 1.9267789367202122e+05,
      "time_unit": "ns",
      "items_per_second": 5.1785538852712379e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 2.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)2; bool is_training = true]": 8.6489340726076344e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 3.8400000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 3.8400000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 9.6337920000000000e+06,
      "input_width": 1.4000000000000000e+01,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 3.7620000000000000e+03,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 3.8400000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 9.6337920000000000e+06,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 5.1785538852712379e+10,
      "predicted_flops_count": 9.6337920000000000e+06
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_128__15408246865298578512<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:1/input[1]:1024/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 107236,
      "real_time": 6.5223184081796562e+03,
      "cpu_time": 1.2333794248401051e+04,
      "time_unit": "ns",
      "items_per_second": 7.6929700238298931e+09,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = false]": 1.4627515035010154e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 1.0240000000000000e+03,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 1.0240000000000000e+03,
      "input_height": 7.0000000000000000e+00,
      "input_size": 5.0176000000000000e+04,
      "input_width": 7.0000000000000000e+00,
      "is_training": 0.0000000000000000e+00,
      "num_iterations": 1.0723600000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 1.0240000000000000e+03,
      "output_height": 7.0000000000000000e+00,
      "output_size": 5.0176000000000000e+04,
      "output_width": 7.0000000000000000e+00,
      "predicted_flops": 7.6929700238298931e+09,
      "predicted_flops_count": 5.0176000000000000e+04
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_128__4250313784913533307<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:1/input[1]:1024/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 61019,
      "real_time": 1.1496518316177855e+04,
      "cpu_time": 1.7457473770467073e+04,
      "time_unit": "ns",
      "items_per_second": 4.3644517948875475e+09,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = true]": 9.0033003156525926e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 1.0240000000000000e+03,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 1.0240000000000000e+03,
      "input_height": 7.0000000000000000e+00,
      "input_size": 5.0176000000000000e+04,
      "input_width": 7.0000000000000000e+00,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 6.1019000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 1.0240000000000000e+03,
      "output_height": 7.0000000000000000e+00,
      "output_size": 5.0176000000000000e+04,
      "output_width": 7.0000000000000000e+00,
      "predicted_flops": 4.3644517948875475e+09,
      "predicted_flops_count": 5.0176000000000000e+04
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_128__9250940892129420376<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:1/input[1]:928/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 108486,
      "real_time": 6.4546548706654030e+03,
      "cpu_time": 1.2257155734630134e+04,
      "time_unit": "ns",
      "items_per_second": 7.0448383238362579e+09,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = false]": 1.4627515035010154e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 9.2800000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 9.2800000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 4.5472000000000000e+04,
      "input_width": 7.0000000000000000e+00,
      "is_training": 0.0000000000000000e+00,
      "num_iterations": 1.0848600000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 9.2800000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 4.5472000000000000e+04,
      "output_width": 7.0000000000000000e+00,
      "predicted_flops": 7.0448383238362579e+09,
      "predicted_flops_count": 4.5472000000000000e+04
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_128__8018873022373962099<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:1/input[1]:928/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 61207,
      "real_time": 1.1412152516035851e+04,
      "cpu_time": 1.7341589834594051e+04,
      "time_unit": "ns",
      "items_per_second": 3.9845243862719812e+09,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = true]": 9.0033003156525926e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 9.2800000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 9.2800000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 4.5472000000000000e+04,
      "input_width": 7.0000000000000000e+00,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 6.1207000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 9.2800000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 4.5472000000000000e+04,
      "output_width": 7.0000000000000000e+00,
      "predicted_flops": 3.9845243862719812e+09,
      "predicted_flops_count": 4.5472000000000000e+04
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_128__4262545065456962351<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:1/input[1]:672/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 113234,
      "real_time": 6.1845800931936719e+03,
      "cpu_time": 1.2058855909039761e+04,
      "time_unit": "ns",
      "items_per_second": 5.3242094861441469e+09,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = false]": 1.4627515035010154e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 6.7200000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 6.7200000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 3.2928000000000000e+04,
      "input_width": 7.0000000000000000e+00,
      "is_training": 0.0000000000000000e+00,
      "num_iterations": 1.1323400000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 6.7200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 3.2928000000000000e+04,
      "output_width": 7.0000000000000000e+00,
      "predicted_flops": 5.3242094861441469e+09,
      "predicted_flops_count": 3.2928000000000000e+04
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_128__15280336516152970756<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:1/input[1]:672/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 64656,
      "real_time": 1.0804764123636925e+04,
      "cpu_time": 1.6675096263410749e+04,
      "time_unit": "ns",
      "items_per_second": 3.0475445482391801e+09,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = true]": 9.0033003156525926e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 6.7200000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 6.7200000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 3.2928000000000000e+04,
      "input_width": 7.0000000000000000e+00,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 6.4656000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 6.7200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 3.2928000000000000e+04,
      "output_width": 7.0000000000000000e+00,
      "predicted_flops": 3.0475445482391801e+09,
      "predicted_flops_count": 3.2928000000000000e+04
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_128__12512093971862784174<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:1/input[1]:960/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 107888,
      "real_time": 6.5646870209823892e+03,
      "cpu_time": 1.2400000880334619e+04,
      "time_unit": "ns",
      "items_per_second": 7.1656119857120886e+09,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = false]": 1.4627515035010154e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 9.6000000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 9.6000000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 4.7040000000000000e+04,
      "input_width": 7.0000000000000000e+00,
      "is_training": 0.0000000000000000e+00,
      "num_iterations": 1.0788800000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 9.6000000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 4.7040000000000000e+04,
      "output_width": 7.0000000000000000e+00,
      "predicted_flops": 7.1656119857120886e+09,
      "predicted_flops_count": 4.7040000000000000e+04
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_128__4794873527157280133<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:1/input[1]:960/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 55975,
      "real_time": 1.1431242714692649e+04,
      "cpu_time": 1.7363717445311384e+04,
      "time_unit": "ns",
      "items_per_second": 4.1150381611212912e+09,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = true]": 9.0033003156525926e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 9.6000000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 9.6000000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 4.7040000000000000e+04,
      "input_width": 7.0000000000000000e+00,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 5.5975000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 9.6000000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 4.7040000000000000e+04,
      "output_width": 7.0000000000000000e+00,
      "predicted_flops": 4.1150381611212912e+09,
      "predicted_flops_count": 4.7040000000000000e+04
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_128__17954723705592091707<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:1/input[1]:704/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 112448,
      "real_time": 6.2326833260565818e+03,
      "cpu_time": 1.2091037732934601e+04,
      "time_unit": "ns",
      "items_per_second": 5.5346948008387928e+09,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = false]": 1.4627515035010154e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 7.0400000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 7.0400000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 3.4496000000000000e+04,
      "input_width": 7.0000000000000000e+00,
      "is_training": 0.0000000000000000e+00,
      "num_iterations": 1.1244800000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 7.0400000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 3.4496000000000000e+04,
      "output_width": 7.0000000000000000e+00,
      "predicted_flops": 5.5346948008387928e+09,
      "predicted_flops_count": 3.4496000000000000e+04
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_128__1586055592551141648<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:1/input[1]:704/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 64532,
      "real_time": 1.0827780531474264e+04,
      "cpu_time": 1.6696372838248499e+04,
      "time_unit": "ns",
      "items_per_second": 3.1858791282042341e+09,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = true]": 9.0033003156525926e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 7.0400000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 7.0400000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 3.4496000000000000e+04,
      "input_width": 7.0000000000000000e+00,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 6.4532000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 7.0400000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 3.4496000000000000e+04,
      "output_width": 7.0000000000000000e+00,
      "predicted_flops": 3.1858791282042341e+09,
      "predicted_flops_count": 3.4496000000000000e+04
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_128__12753740602899994428<CUDNN_BATCHNORM_SPATIAL>/input[0]:128/input[1]:1280/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 2342,
      "real_time": 2.9887048331799940e+05,
      "cpu_time": 3.0627954440564575e+05,
      "time_unit": "ns",
      "items_per_second": 2.6861669010847103e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 1.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)1; bool is_training = false]": 7.0429798546002954e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 1.2800000000000000e+03,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 1.2800000000000000e+03,
      "input_height": 7.0000000000000000e+00,
      "input_size": 8.0281600000000000e+06,
      "input_width": 7.0000000000000000e+00,
      "is_training": 0.0000000000000000e+00,
      "num_iterations": 2.3420000000000000e+03,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 1.2800000000000000e+03,
      "output_height": 7.0000000000000000e+00,
      "output_size": 8.0281600000000000e+06,
      "output_width": 7.0000000000000000e+00,
      "predicted_flops": 2.6861669010847103e+10,
      "predicted_flops_count": 8.0281600000000000e+06
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_128__12753740602899994428<CUDNN_BATCHNORM_SPATIAL_PERSISTENT>/input[0]:128/input[1]:1280/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/BATCHNORM_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_128__588237890413397667<CUDNN_BATCHNORM_SPATIAL>/input[0]:128/input[1]:1280/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 5173,
      "real_time": 1.3532502245590131e+05,
      "cpu_time": 1.4176369476118911e+05,
      "time_unit": "ns",
      "items_per_second": 5.9325022485151665e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 1.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)1; bool is_training = true]": 1.2389518253260638e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 1.2800000000000000e+03,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 1.2800000000000000e+03,
      "input_height": 7.0000000000000000e+00,
      "input_size": 8.0281600000000000e+06,
      "input_width": 7.0000000000000000e+00,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 5.1730000000000000e+03,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 1.2800000000000000e+03,
      "output_height": 7.0000000000000000e+00,
      "output_size": 8.0281600000000000e+06,
      "output_width": 7.0000000000000000e+00,
      "predicted_flops": 5.9325022485151665e+10,
      "predicted_flops_count": 8.0281600000000000e+06
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_128__588237890413397667<CUDNN_BATCHNORM_SPATIAL_PERSISTENT>/input[0]:128/input[1]:1280/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 5173,
      "real_time": 1.3533071959963298e+05,
      "cpu_time": 1.4181281654691210e+05,
      "time_unit": "ns",
      "items_per_second": 5.9322525024257477e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 2.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)2; bool is_training = true]": 8.6489340726076344e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 1.2800000000000000e+03,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 1.2800000000000000e+03,
      "input_height": 7.0000000000000000e+00,
      "input_size": 8.0281600000000000e+06,
      "input_width": 7.0000000000000000e+00,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 5.1730000000000000e+03,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 1.2800000000000000e+03,
      "output_height": 7.0000000000000000e+00,
      "output_size": 8.0281600000000000e+06,
      "output_width": 7.0000000000000000e+00,
      "predicted_flops": 5.9322525024257477e+10,
      "predicted_flops_count": 8.0281600000000000e+06
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_128__17475387745110757518<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:1/input[1]:992/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 107208,
      "real_time": 6.4944930282447049e+03,
      "cpu_time": 1.2308697998190701e+04,
      "time_unit": "ns",
      "items_per_second": 7.4844949080093937e+09,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = false]": 1.4627515035010154e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 9.9200000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 9.9200000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 4.8608000000000000e+04,
      "input_width": 7.0000000000000000e+00,
      "is_training": 0.0000000000000000e+00,
      "num_iterations": 1.0720800000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 9.9200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 4.8608000000000000e+04,
      "output_width": 7.0000000000000000e+00,
      "predicted_flops": 7.4844949080093937e+09,
      "predicted_flops_count": 4.8608000000000000e+04
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_128__2138153938436281765<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:1/input[1]:992/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 61188,
      "real_time": 1.1424818513785320e+04,
      "cpu_time": 1.7357595999026187e+04,
      "time_unit": "ns",
      "items_per_second": 4.2545971247901239e+09,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = true]": 9.0033003156525926e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 9.9200000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 9.9200000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 4.8608000000000000e+04,
      "input_width": 7.0000000000000000e+00,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 6.1188000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 9.9200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 4.8608000000000000e+04,
      "output_width": 7.0000000000000000e+00,
      "predicted_flops": 4.2545971247901239e+09,
      "predicted_flops_count": 4.8608000000000000e+04
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_128__9315111828153586377<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:128/input[1]:192/input[2]:56/input[3]:56/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 290,
      "real_time": 2.4155074842916480e+06,
      "cpu_time": 2.5052336482739015e+06,
      "time_unit": "ns",
      "items_per_second": 3.1906477831759239e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = false]": 1.4627515035010154e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 1.9200000000000000e+02,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 1.9200000000000000e+02,
      "input_height": 5.6000000000000000e+01,
      "input_size": 7.7070336000000000e+07,
      "input_width": 5.6000000000000000e+01,
      "is_training": 0.0000000000000000e+00,
      "num_iterations": 2.9000000000000000e+02,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 1.9200000000000000e+02,
      "output_height": 5.6000000000000000e+01,
      "output_size": 7.7070336000000000e+07,
      "output_width": 5.6000000000000000e+01,
      "predicted_flops": 3.1906477831759239e+10,
      "predicted_flops_count": 7.7070336000000000e+07
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_128__7956980828447184866<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:128/input[1]:192/input[2]:56/input[3]:56/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 202,
      "real_time": 3.4572737381360172e+06,
      "cpu_time": 3.6348702425700575e+06,
      "time_unit": "ns",
      "items_per_second": 2.2292228454421528e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = true]": 9.0033003156525926e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 1.9200000000000000e+02,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 1.9200000000000000e+02,
      "input_height": 5.6000000000000000e+01,
      "input_size": 7.7070336000000000e+07,
      "input_width": 5.6000000000000000e+01,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 2.0200000000000000e+02,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 1.9200000000000000e+02,
      "output_height": 5.6000000000000000e+01,
      "output_size": 7.7070336000000000e+07,
      "output_width": 5.6000000000000000e+01,
      "predicted_flops": 2.2292228454421528e+10,
      "predicted_flops_count": 7.7070336000000000e+07
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_128__11704208335948976675<CUDNN_BATCHNORM_SPATIAL>/input[0]:128/input[1]:960/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 3103,
      "real_time": 2.2554084848139985e+05,
      "cpu_time": 2.3241604060507016e+05,
      "time_unit": "ns",
      "items_per_second": 2.6696361393251373e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 1.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)1; bool is_training = false]": 7.0429798546002954e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 9.6000000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 9.6000000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 6.0211200000000000e+06,
      "input_width": 7.0000000000000000e+00,
      "is_training": 0.0000000000000000e+00,
      "num_iterations": 3.1030000000000000e+03,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 9.6000000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 6.0211200000000000e+06,
      "output_width": 7.0000000000000000e+00,
      "predicted_flops": 2.6696361393251373e+10,
      "predicted_flops_count": 6.0211200000000000e+06
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_128__11704208335948976675<CUDNN_BATCHNORM_SPATIAL_PERSISTENT>/input[0]:128/input[1]:960/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/BATCHNORM_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_128__1925860343640687548<CUDNN_BATCHNORM_SPATIAL>/input[0]:128/input[1]:960/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 6651,
      "real_time": 1.0528554216812045e+05,
      "cpu_time": 1.1165818688952443e+05,
      "time_unit": "ns",
      "items_per_second": 5.7188478835825798e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 1.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)1; bool is_training = true]": 1.2389518253260638e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 9.6000000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 9.6000000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 6.0211200000000000e+06,
      "input_width": 7.0000000000000000e+00,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 6.6510000000000000e+03,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 9.6000000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 6.0211200000000000e+06,
      "output_width": 7.0000000000000000e+00,
      "predicted_flops": 5.7188478835825798e+10,
      "predicted_flops_count": 6.0211200000000000e+06
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_128__1925860343640687548<CUDNN_BATCHNORM_SPATIAL_PERSISTENT>/input[0]:128/input[1]:960/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 6642,
      "real_time": 1.0530781283543585e+05,
      "cpu_time": 1.1168196431799090e+05,
      "time_unit": "ns",
      "items_per_second": 5.7176384523427368e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 2.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)2; bool is_training = true]": 8.6489340726076344e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 9.6000000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 9.6000000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 6.0211200000000000e+06,
      "input_width": 7.0000000000000000e+00,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 6.6420000000000000e+03,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 9.6000000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 6.0211200000000000e+06,
      "output_width": 7.0000000000000000e+00,
      "predicted_flops": 5.7176384523427368e+10,
      "predicted_flops_count": 6.0211200000000000e+06
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_128__2997144610040967143<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:1/input[1]:128/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 126253,
      "real_time": 5.5333166293163467e+03,
      "cpu_time": 1.1397772401441074e+04,
      "time_unit": "ns",
      "items_per_second": 1.1334973977035758e+09,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = false]": 1.4627515035010154e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 1.2800000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 1.2800000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 6.2720000000000000e+03,
      "input_width": 7.0000000000000000e+00,
      "is_training": 0.0000000000000000e+00,
      "num_iterations": 1.2625300000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 6.2720000000000000e+03,
      "output_width": 7.0000000000000000e+00,
      "predicted_flops": 1.1334973977035758e+09,
      "predicted_flops_count": 6.2720000000000000e+03
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_128__14321108276352494284<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:1/input[1]:128/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 72729,
      "real_time": 9.5524424528577347e+03,
      "cpu_time": 1.5410965130568688e+04,
      "time_unit": "ns",
      "items_per_second": 6.5658600205685103e+08,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = true]": 9.0033003156525926e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 1.2800000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 1.2800000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 6.2720000000000000e+03,
      "input_width": 7.0000000000000000e+00,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 7.2729000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 6.2720000000000000e+03,
      "output_width": 7.0000000000000000e+00,
      "predicted_flops": 6.5658600205685103e+08,
      "predicted_flops_count": 6.2720000000000000e+03
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_128__13047406773353044781<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:1/input[1]:800/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 111356,
      "real_time": 6.2895662119600156e+03,
      "cpu_time": 1.2141670156722141e+04,
      "time_unit": "ns",
      "items_per_second": 6.2325442930322714e+09,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = false]": 1.4627515035010154e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 8.0000000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 8.0000000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 3.9200000000000000e+04,
      "input_width": 7.0000000000000000e+00,
      "is_training": 0.0000000000000000e+00,
      "num_iterations": 1.1135600000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 8.0000000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 3.9200000000000000e+04,
      "output_width": 7.0000000000000000e+00,
      "predicted_flops": 6.2325442930322714e+09,
      "predicted_flops_count": 3.9200000000000000e+04
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_128__6501087248181206534<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:1/input[1]:800/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 64026,
      "real_time": 1.0940853750883560e+04,
      "cpu_time": 1.6856716630904786e+04,
      "time_unit": "ns",
      "items_per_second": 3.5829013797789130e+09,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = true]": 9.0033003156525926e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 8.0000000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 8.0000000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 3.9200000000000000e+04,
      "input_width": 7.0000000000000000e+00,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 6.4026000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 8.0000000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 3.9200000000000000e+04,
      "output_width": 7.0000000000000000e+00,
      "predicted_flops": 3.5829013797789130e+09,
      "predicted_flops_count": 3.9200000000000000e+04
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_128__10360143998073788507<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:1/input[1]:832/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 110764,
      "real_time": 6.3291715661053104e+03,
      "cpu_time": 1.2171025522769287e+04,
      "time_unit": "ns",
      "items_per_second": 6.4412853363503952e+09,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = false]": 1.4627515035010154e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 8.3200000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 8.3200000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 4.0768000000000000e+04,
      "input_width": 7.0000000000000000e+00,
      "is_training": 0.0000000000000000e+00,
      "num_iterations": 1.1076400000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 8.3200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 4.0768000000000000e+04,
      "output_width": 7.0000000000000000e+00,
      "predicted_flops": 6.4412853363503952e+09,
      "predicted_flops_count": 4.0768000000000000e+04
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_128__6984963373239049584<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:1/input[1]:832/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 63417,
      "real_time": 1.1218651412435636e+04,
      "cpu_time": 1.7150828720834408e+04,
      "time_unit": "ns",
      "items_per_second": 3.6339483687682405e+09,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = true]": 9.0033003156525926e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 8.3200000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 8.3200000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 4.0768000000000000e+04,
      "input_width": 7.0000000000000000e+00,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 6.3417000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 8.3200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 4.0768000000000000e+04,
      "output_width": 7.0000000000000000e+00,
      "predicted_flops": 3.6339483687682405e+09,
      "predicted_flops_count": 4.0768000000000000e+04
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_128__12668583987080541220<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:1/input[1]:512/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 117028,
      "real_time": 5.9758701565158972e+03,
      "cpu_time": 1.1775231406199075e+04,
      "time_unit": "ns",
      "items_per_second": 4.1982170534018126e+09,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = false]": 1.4627515035010154e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 2.5088000000000000e+04,
      "input_width": 7.0000000000000000e+00,
      "is_training": 0.0000000000000000e+00,
      "num_iterations": 1.1702800000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 2.5088000000000000e+04,
      "output_width": 7.0000000000000000e+00,
      "predicted_flops": 4.1982170534018126e+09,
      "predicted_flops_count": 2.5088000000000000e+04
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_128__4676681718138237199<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:1/input[1]:512/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 67673,
      "real_time": 1.0360130095843653e+04,
      "cpu_time": 1.6167043429296895e+04,
      "time_unit": "ns",
      "items_per_second": 2.4215912124563932e+09,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = true]": 9.0033003156525926e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 2.5088000000000000e+04,
      "input_width": 7.0000000000000000e+00,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 6.7673000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 2.5088000000000000e+04,
      "output_width": 7.0000000000000000e+00,
      "predicted_flops": 2.4215912124563932e+09,
      "predicted_flops_count": 2.5088000000000000e+04
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_128__12384897384250453501<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:128/input[1]:128/input[2]:100/input[3]:100/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 136,
      "real_time": 5.1315349170609433e+06,
      "cpu_time": 5.5157346397093683e+06,
      "time_unit": "ns",
      "items_per_second": 3.1928068823087811e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = false]": 1.4627515035010154e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 1.2800000000000000e+02,
      "input[2]": 1.0000000000000000e+02,
      "input[3]": 1.0000000000000000e+02,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 1.2800000000000000e+02,
      "input_height": 1.0000000000000000e+02,
      "input_size": 1.6384000000000000e+08,
      "input_width": 1.0000000000000000e+02,
      "is_training": 0.0000000000000000e+00,
      "num_iterations": 1.3600000000000000e+02,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 1.0000000000000000e+02,
      "output_size": 1.6384000000000000e+08,
      "output_width": 1.0000000000000000e+02,
      "predicted_flops": 3.1928068823087811e+10,
      "predicted_flops_count": 1.6384000000000000e+08
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_128__4969385398741231830<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:128/input[1]:128/input[2]:100/input[3]:100/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 95,
      "real_time": 7.3534946055396609e+06,
      "cpu_time": 8.1346542631631801e+06,
      "time_unit": "ns",
      "items_per_second": 2.2280563023269676e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = true]": 9.0033003156525926e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 1.2800000000000000e+02,
      "input[2]": 1.0000000000000000e+02,
      "input[3]": 1.0000000000000000e+02,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 1.2800000000000000e+02,
      "input_height": 1.0000000000000000e+02,
      "input_size": 1.6384000000000000e+08,
      "input_width": 1.0000000000000000e+02,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 9.5000000000000000e+01,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 1.0000000000000000e+02,
      "output_size": 1.6384000000000000e+08,
      "output_width": 1.0000000000000000e+02,
      "predicted_flops": 2.2280563023269676e+10,
      "predicted_flops_count": 1.6384000000000000e+08
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_128__11734954346342802385<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:128/input[1]:96/input[2]:28/input[3]:28/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 3304,
      "real_time": 2.1184192676960825e+05,
      "cpu_time": 2.1864294975957472e+05,
      "time_unit": "ns",
      "items_per_second": 4.5476323534752251e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = false]": 1.4627515035010154e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 9.6000000000000000e+01,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 9.6000000000000000e+01,
      "input_height": 2.8000000000000000e+01,
      "input_size": 9.6337920000000000e+06,
      "input_width": 2.8000000000000000e+01,
      "is_training": 0.0000000000000000e+00,
      "num_iterations": 3.3040000000000000e+03,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 9.6000000000000000e+01,
      "output_height": 2.8000000000000000e+01,
      "output_size": 9.6337920000000000e+06,
      "output_width": 2.8000000000000000e+01,
      "predicted_flops": 4.5476323534752251e+10,
      "predicted_flops_count": 9.6337920000000000e+06
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_128__5617077186497488634<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:128/input[1]:96/input[2]:28/input[3]:28/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 1990,
      "real_time": 3.5184351961367094e+05,
      "cpu_time": 3.5975498291596276e+05,
      "time_unit": "ns",
      "items_per_second": 2.7380899357129093e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = true]": 9.0033003156525926e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 9.6000000000000000e+01,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 9.6000000000000000e+01,
      "input_height": 2.8000000000000000e+01,
      "input_size": 9.6337920000000000e+06,
      "input_width": 2.8000000000000000e+01,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 1.9900000000000000e+03,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 9.6000000000000000e+01,
      "output_height": 2.8000000000000000e+01,
      "output_size": 9.6337920000000000e+06,
      "output_width": 2.8000000000000000e+01,
      "predicted_flops": 2.7380899357129093e+10,
      "predicted_flops_count": 9.6337920000000000e+06
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_128__11782951207299271753<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:1/input[1]:864/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 110009,
      "real_time": 6.3659842343424889e+03,
      "cpu_time": 1.2186185675877494e+04,
      "time_unit": "ns",
      "items_per_second": 6.6503463473268681e+09,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = false]": 1.4627515035010154e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 8.6400000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 8.6400000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 4.2336000000000000e+04,
      "input_width": 7.0000000000000000e+00,
      "is_training": 0.0000000000000000e+00,
      "num_iterations": 1.1000900000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 8.6400000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 4.2336000000000000e+04,
      "output_width": 7.0000000000000000e+00,
      "predicted_flops": 6.6503463473268681e+09,
      "predicted_flops_count": 4.2336000000000000e+04
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_128__5524861816150624610<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:1/input[1]:864/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 61682,
      "real_time": 1.1529842522128547e+04,
      "cpu_time": 1.7513933238221540e+04,
      "time_unit": "ns",
      "items_per_second": 3.6718628132818818e+09,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = true]": 9.0033003156525926e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 8.6400000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 8.6400000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 4.2336000000000000e+04,
      "input_width": 7.0000000000000000e+00,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 6.1682000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 8.6400000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 4.2336000000000000e+04,
      "output_width": 7.0000000000000000e+00,
      "predicted_flops": 3.6718628132818818e+09,
      "predicted_flops_count": 4.2336000000000000e+04
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_128__5187831624680532546<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:128/input[1]:32/input[2]:28/input[3]:28/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 10992,
      "real_time": 6.3701210334141528e+04,
      "cpu_time": 6.9912607169185751e+04,
      "time_unit": "ns",
      "items_per_second": 5.0411349849641388e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = false]": 1.4627515035010154e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 3.2000000000000000e+01,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 3.2000000000000000e+01,
      "input_height": 2.8000000000000000e+01,
      "input_size": 3.2112640000000000e+06,
      "input_width": 2.8000000000000000e+01,
      "is_training": 0.0000000000000000e+00,
      "num_iterations": 1.0992000000000000e+04,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 3.2000000000000000e+01,
      "output_height": 2.8000000000000000e+01,
      "output_size": 3.2112640000000000e+06,
      "output_width": 2.8000000000000000e+01,
      "predicted_flops": 5.0411349849641388e+10,
      "predicted_flops_count": 3.2112640000000000e+06
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_128__12166424215969116009<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:128/input[1]:32/input[2]:28/input[3]:28/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 6385,
      "real_time": 1.0964270983485341e+05,
      "cpu_time": 1.1597263727478152e+05,
      "time_unit": "ns",
      "items_per_second": 2.9288440652706287e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = true]": 9.0033003156525926e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 3.2000000000000000e+01,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 3.2000000000000000e+01,
      "input_height": 2.8000000000000000e+01,
      "input_size": 3.2112640000000000e+06,
      "input_width": 2.8000000000000000e+01,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 6.3850000000000000e+03,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 3.2000000000000000e+01,
      "output_height": 2.8000000000000000e+01,
      "output_size": 3.2112640000000000e+06,
      "output_width": 2.8000000000000000e+01,
      "predicted_flops": 2.9288440652706287e+10,
      "predicted_flops_count": 3.2112640000000000e+06
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_128__11942918449905572021<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:128/input[1]:160/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 8835,
      "real_time": 7.9061862728063032e+04,
      "cpu_time": 8.5311928126817947e+04,
      "time_unit": "ns",
      "items_per_second": 5.0771381567451996e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = false]": 1.4627515035010154e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 1.6000000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 1.6000000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 4.0140800000000000e+06,
      "input_width": 1.4000000000000000e+01,
      "is_training": 0.0000000000000000e+00,
      "num_iterations": 8.8350000000000000e+03,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 1.6000000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 4.0140800000000000e+06,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 5.0771381567451996e+10,
      "predicted_flops_count": 4.0140800000000000e+06
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_128__5374190944331947422<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:128/input[1]:160/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 5114,
      "real_time": 1.3690872837357386e+05,
      "cpu_time": 1.4333619436836377e+05,
      "time_unit": "ns",
      "items_per_second": 2.9319387066740139e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = true]": 9.0033003156525926e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 1.6000000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 1.6000000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 4.0140800000000000e+06,
      "input_width": 1.4000000000000000e+01,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 5.1140000000000000e+03,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 1.6000000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 4.0140800000000000e+06,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 2.9319387066740139e+10,
      "predicted_flops_count": 4.0140800000000000e+06
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_128__15427634327624673709<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:128/input[1]:224/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 6221,
      "real_time": 1.1248349318513759e+05,
      "cpu_time": 1.1882125365688368e+05,
      "time_unit": "ns",
      "items_per_second": 4.9960326096474136e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = false]": 1.4627515035010154e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 2.2400000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 2.2400000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 5.6197120000000000e+06,
      "input_width": 1.4000000000000000e+01,
      "is_training": 0.0000000000000000e+00,
      "num_iterations": 6.2210000000000000e+03,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 2.2400000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 5.6197120000000000e+06,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 4.9960326096474136e+10,
      "predicted_flops_count": 5.6197120000000000e+06
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_128__4121009798753987718<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:128/input[1]:224/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 3628,
      "real_time": 1.9295293780075424e+05,
      "cpu_time": 1.9964452397998350e+05,
      "time_unit": "ns",
      "items_per_second": 2.9124780705868233e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = true]": 9.0033003156525926e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 2.2400000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 2.2400000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 5.6197120000000000e+06,
      "input_width": 1.4000000000000000e+01,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 3.6280000000000000e+03,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 2.2400000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 5.6197120000000000e+06,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 2.9124780705868233e+10,
      "predicted_flops_count": 5.6197120000000000e+06
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_128__10412202008746128787<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:1/input[1]:896/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 109299,
      "real_time": 6.4626550686368109e+03,
      "cpu_time": 1.2328348465964080e+04,
      "time_unit": "ns",
      "items_per_second": 6.7934926951409798e+09,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = false]": 1.4627515035010154e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 8.9600000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 8.9600000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 4.3904000000000000e+04,
      "input_width": 7.0000000000000000e+00,
      "is_training": 0.0000000000000000e+00,
      "num_iterations": 1.0929900000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 8.9600000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 4.3904000000000000e+04,
      "output_width": 7.0000000000000000e+00,
      "predicted_flops": 6.7934926951409798e+09,
      "predicted_flops_count": 4.3904000000000000e+04
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_128__9175699080733110456<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:1/input[1]:896/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 61450,
      "real_time": 1.1377559163206573e+04,
      "cpu_time": 1.7294438779323722e+04,
      "time_unit": "ns",
      "items_per_second": 3.8588241441081109e+09,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = true]": 9.0033003156525926e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 8.9600000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 8.9600000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 4.3904000000000000e+04,
      "input_width": 7.0000000000000000e+00,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 6.1450000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 8.9600000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 4.3904000000000000e+04,
      "output_width": 7.0000000000000000e+00,
      "predicted_flops": 3.8588241441081109e+09,
      "predicted_flops_count": 4.3904000000000000e+04
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_128__10608086617193583488<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:128/input[1]:128/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 10981,
      "real_time": 6.3695997802270576e+04,
      "cpu_time": 6.9927344139439592e+04,
      "time_unit": "ns",
      "items_per_second": 5.0415475238626808e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = false]": 1.4627515035010154e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 1.2800000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 1.2800000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 3.2112640000000000e+06,
      "input_width": 1.4000000000000000e+01,
      "is_training": 0.0000000000000000e+00,
      "num_iterations": 1.0981000000000000e+04,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 3.2112640000000000e+06,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 5.0415475238626808e+10,
      "predicted_flops_count": 3.2112640000000000e+06
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_128__8943671321744922283<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:128/input[1]:128/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 6383,
      "real_time": 1.0964369083021976e+05,
      "cpu_time": 1.1597706720954737e+05,
      "time_unit": "ns",
      "items_per_second": 2.9288178605484509e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = true]": 9.0033003156525926e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 1.2800000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 1.2800000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 3.2112640000000000e+06,
      "input_width": 1.4000000000000000e+01,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 6.3830000000000000e+03,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 3.2112640000000000e+06,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 2.9288178605484509e+10,
      "predicted_flops_count": 3.2112640000000000e+06
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_128__8808396215514917642<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:128/input[1]:256/input[2]:100/input[3]:100/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 68,
      "real_time": 1.0258250486324815e+07,
      "cpu_time": 1.1774499397056522e+07,
      "time_unit": "ns",
      "items_per_second": 3.1943068697418468e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = false]": 1.4627515035010154e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 1.0000000000000000e+02,
      "input[3]": 1.0000000000000000e+02,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 1.0000000000000000e+02,
      "input_size": 3.2768000000000000e+08,
      "input_width": 1.0000000000000000e+02,
      "is_training": 0.0000000000000000e+00,
      "num_iterations": 6.8000000000000000e+01,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 1.0000000000000000e+02,
      "output_size": 3.2768000000000000e+08,
      "output_width": 1.0000000000000000e+02,
      "predicted_flops": 3.1943068697418468e+10,
      "predicted_flops_count": 3.2768000000000000e+08
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_128__10742358951715352097<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:128/input[1]:256/input[2]:100/input[3]:100/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 48,
      "real_time": 1.4710250135976821e+07,
      "cpu_time": 1.7781799687497824e+07,
      "time_unit": "ns",
      "items_per_second": 2.2275623933721825e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = true]": 9.0033003156525926e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 1.0000000000000000e+02,
      "input[3]": 1.0000000000000000e+02,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 1.0000000000000000e+02,
      "input_size": 3.2768000000000000e+08,
      "input_width": 1.0000000000000000e+02,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 4.8000000000000000e+01,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 1.0000000000000000e+02,
      "output_size": 3.2768000000000000e+08,
      "output_width": 1.0000000000000000e+02,
      "predicted_flops": 2.2275623933721825e+10,
      "predicted_flops_count": 3.2768000000000000e+08
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_128__17490820606047731802<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:128/input[1]:1024/input[2]:100/input[3]:100/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 17,
      "real_time": 4.0974519051173151e+07,
      "cpu_time": 6.5084681352947667e+07,
      "time_unit": "ns",
      "items_per_second": 3.1988661010591469e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = false]": 1.4627515035010154e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 1.0240000000000000e+03,
      "input[2]": 1.0000000000000000e+02,
      "input[3]": 1.0000000000000000e+02,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 1.0240000000000000e+03,
      "input_height": 1.0000000000000000e+02,
      "input_size": 1.3107200000000000e+09,
      "input_width": 1.0000000000000000e+02,
      "is_training": 0.0000000000000000e+00,
      "num_iterations": 1.7000000000000000e+01,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 1.0240000000000000e+03,
      "output_height": 1.0000000000000000e+02,
      "output_size": 1.3107200000000000e+09,
      "output_width": 1.0000000000000000e+02,
      "predicted_flops": 3.1988661010591469e+10,
      "predicted_flops_count": 1.3107200000000000e+09
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_128__2130998218146481521<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:128/input[1]:1024/input[2]:100/input[3]:100/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 12,
      "real_time": 5.8751741424202919e+07,
      "cpu_time": 1.0771090975001131e+08,
      "time_unit": "ns",
      "items_per_second": 2.2309466378813511e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = true]": 9.0033003156525926e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 1.0240000000000000e+03,
      "input[2]": 1.0000000000000000e+02,
      "input[3]": 1.0000000000000000e+02,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 1.0240000000000000e+03,
      "input_height": 1.0000000000000000e+02,
      "input_size": 1.3107200000000000e+09,
      "input_width": 1.0000000000000000e+02,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 1.2000000000000000e+01,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 1.0240000000000000e+03,
      "output_height": 1.0000000000000000e+02,
      "output_size": 1.3107200000000000e+09,
      "output_width": 1.0000000000000000e+02,
      "predicted_flops": 2.2309466378813511e+10,
      "predicted_flops_count": 1.3107200000000000e+09
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_128__1700967414942911679<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:128/input[1]:64/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 19633,
      "real_time": 3.4490855254089103e+04,
      "cpu_time": 4.0685015229164521e+04,
      "time_unit": "ns",
      "items_per_second": 4.6552397386830307e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = false]": 1.4627515035010154e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 1.4000000000000000e+01,
      "input_size": 1.6056320000000000e+06,
      "input_width": 1.4000000000000000e+01,
      "is_training": 0.0000000000000000e+00,
      "num_iterations": 1.9633000000000000e+04,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 1.4000000000000000e+01,
      "output_size": 1.6056320000000000e+06,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 4.6552397386830307e+10,
      "predicted_flops_count": 1.6056320000000000e+06
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_128__17920456130547255700<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:128/input[1]:64/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 12439,
      "real_time": 5.6098053900357765e+04,
      "cpu_time": 6.2325422220643035e+04,
      "time_unit": "ns",
      "items_per_second": 2.8621884153984173e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = true]": 9.0033003156525926e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 1.4000000000000000e+01,
      "input_size": 1.6056320000000000e+06,
      "input_width": 1.4000000000000000e+01,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 1.2439000000000000e+04,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 1.4000000000000000e+01,
      "output_size": 1.6056320000000000e+06,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 2.8621884153984173e+10,
      "predicted_flops_count": 1.6056320000000000e+06
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_128__8685481160810607313<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:128/input[1]:96/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 14201,
      "real_time": 4.9298418606905507e+04,
      "cpu_time": 5.5499704739072338e+04,
      "time_unit": "ns",
      "items_per_second": 4.8854467710301666e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = false]": 1.4627515035010154e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 9.6000000000000000e+01,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 9.6000000000000000e+01,
      "input_height": 1.4000000000000000e+01,
      "input_size": 2.4084480000000000e+06,
      "input_width": 1.4000000000000000e+01,
      "is_training": 0.0000000000000000e+00,
      "num_iterations": 1.4201000000000000e+04,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 9.6000000000000000e+01,
      "output_height": 1.4000000000000000e+01,
      "output_size": 2.4084480000000000e+06,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 4.8854467710301666e+10,
      "predicted_flops_count": 2.4084480000000000e+06
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_128__10925790026858297338<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:128/input[1]:96/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 8504,
      "real_time": 8.2310398704831649e+04,
      "cpu_time": 8.8572831374154732e+04,
      "time_unit": "ns",
      "items_per_second": 2.9260555627203190e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = true]": 9.0033003156525926e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 9.6000000000000000e+01,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 9.6000000000000000e+01,
      "input_height": 1.4000000000000000e+01,
      "input_size": 2.4084480000000000e+06,
      "input_width": 1.4000000000000000e+01,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 8.5040000000000000e+03,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 9.6000000000000000e+01,
      "output_height": 1.4000000000000000e+01,
      "output_size": 2.4084480000000000e+06,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 2.9260555627203190e+10,
      "predicted_flops_count": 2.4084480000000000e+06
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_128__10131216821502558429<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:128/input[1]:192/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 7422,
      "real_time": 9.4279219334989248e+04,
      "cpu_time": 1.0058285542997978e+05,
      "time_unit": "ns",
      "items_per_second": 5.1091810411420494e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = false]": 1.4627515035010154e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 1.9200000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 1.9200000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 4.8168960000000000e+06,
      "input_width": 1.4000000000000000e+01,
      "is_training": 0.0000000000000000e+00,
      "num_iterations": 7.4220000000000000e+03,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 1.9200000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 4.8168960000000000e+06,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 5.1091810411420494e+10,
      "predicted_flops_count": 4.8168960000000000e+06
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_128__7183350501852644854<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:128/input[1]:192/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 4269,
      "real_time": 1.6387182187491233e+05,
      "cpu_time": 1.7042574560497809e+05,
      "time_unit": "ns",
      "items_per_second": 2.9394290884718811e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = true]": 9.0033003156525926e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 1.9200000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 1.9200000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 4.8168960000000000e+06,
      "input_width": 1.4000000000000000e+01,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 4.2690000000000000e+03,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 1.9200000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 4.8168960000000000e+06,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 2.9394290884718811e+10,
      "predicted_flops_count": 4.8168960000000000e+06
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_128__526845759088817605<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:128/input[1]:160/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 29534,
      "real_time": 2.3698283103570790e+04,
      "cpu_time": 2.9871737962917334e+04,
      "time_unit": "ns",
      "items_per_second": 4.2345683677345909e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = false]": 1.4627515035010154e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 1.6000000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 1.6000000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 1.0035200000000000e+06,
      "input_width": 7.0000000000000000e+00,
      "is_training": 0.0000000000000000e+00,
      "num_iterations": 2.9534000000000000e+04,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 1.6000000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 1.0035200000000000e+06,
      "output_width": 7.0000000000000000e+00,
      "predicted_flops": 4.2345683677345909e+10,
      "predicted_flops_count": 1.0035200000000000e+06
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_128__16746222142910804206<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:128/input[1]:160/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 18095,
      "real_time": 3.8710194624059142e+04,
      "cpu_time": 4.4908133240536350e+04,
      "time_unit": "ns",
      "items_per_second": 2.5923920294017139e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = true]": 9.0033003156525926e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 1.6000000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 1.6000000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 1.0035200000000000e+06,
      "input_width": 7.0000000000000000e+00,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 1.8095000000000000e+04,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 1.6000000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 1.0035200000000000e+06,
      "output_width": 7.0000000000000000e+00,
      "predicted_flops": 2.5923920294017139e+10,
      "predicted_flops_count": 1.0035200000000000e+06
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_128__7394299333228314911<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:128/input[1]:256/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 20293,
      "real_time": 3.4494644691954003e+04,
      "cpu_time": 4.0683486572076894e+04,
      "time_unit": "ns",
      "items_per_second": 4.6547283334520599e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = false]": 1.4627515035010154e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 1.6056320000000000e+06,
      "input_width": 7.0000000000000000e+00,
      "is_training": 0.0000000000000000e+00,
      "num_iterations": 2.0293000000000000e+04,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 1.6056320000000000e+06,
      "output_width": 7.0000000000000000e+00,
      "predicted_flops": 4.6547283334520599e+10,
      "predicted_flops_count": 1.6056320000000000e+06
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_128__9922810056844837940<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:128/input[1]:256/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 12461,
      "real_time": 5.6092012876392633e+04,
      "cpu_time": 6.2331206163712472e+04,
      "time_unit": "ns",
      "items_per_second": 2.8624966687115627e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = true]": 9.0033003156525926e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 1.6056320000000000e+06,
      "input_width": 7.0000000000000000e+00,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 1.2461000000000000e+04,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 1.6056320000000000e+06,
      "output_width": 7.0000000000000000e+00,
      "predicted_flops": 2.8624966687115627e+10,
      "predicted_flops_count": 1.6056320000000000e+06
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_128__5195681524022659666<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:128/input[1]:512/input[2]:100/input[3]:100/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 34,
      "real_time": 2.0528035950573053e+07,
      "cpu_time": 2.6573717764710423e+07,
      "time_unit": "ns",
      "items_per_second": 3.1925119459940601e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = false]": 1.4627515035010154e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 1.0000000000000000e+02,
      "input[3]": 1.0000000000000000e+02,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 1.0000000000000000e+02,
      "input_size": 6.5536000000000000e+08,
      "input_width": 1.0000000000000000e+02,
      "is_training": 0.0000000000000000e+00,
      "num_iterations": 3.4000000000000000e+01,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 1.0000000000000000e+02,
      "output_size": 6.5536000000000000e+08,
      "output_width": 1.0000000000000000e+02,
      "predicted_flops": 3.1925119459940601e+10,
      "predicted_flops_count": 6.5536000000000000e+08
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_128__12048246021289676665<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:128/input[1]:512/input[2]:100/input[3]:100/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 24,
      "real_time": 2.9419605387374759e+07,
      "cpu_time": 4.1683816583329760e+07,
      "time_unit": "ns",
      "items_per_second": 2.2276301512910290e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = true]": 9.0033003156525926e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 1.0000000000000000e+02,
      "input[3]": 1.0000000000000000e+02,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 1.0000000000000000e+02,
      "input_size": 6.5536000000000000e+08,
      "input_width": 1.0000000000000000e+02,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 2.4000000000000000e+01,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 1.0000000000000000e+02,
      "output_size": 6.5536000000000000e+08,
      "output_width": 1.0000000000000000e+02,
      "predicted_flops": 2.2276301512910290e+10,
      "predicted_flops_count": 6.5536000000000000e+08
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_128__7577871760015364520<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:128/input[1]:128/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 34020,
      "real_time": 2.0162731363554300e+04,
      "cpu_time": 2.6350445120355314e+04,
      "time_unit": "ns",
      "items_per_second": 3.9816827667066589e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = false]": 1.4627515035010154e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 1.2800000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 1.2800000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 8.0281600000000000e+05,
      "input_width": 7.0000000000000000e+00,
      "is_training": 0.0000000000000000e+00,
      "num_iterations": 3.4020000000000000e+04,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 8.0281600000000000e+05,
      "output_width": 7.0000000000000000e+00,
      "predicted_flops": 3.9816827667066589e+10,
      "predicted_flops_count": 8.0281600000000000e+05
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_128__9656615945388184707<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:128/input[1]:128/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 21186,
      "real_time": 3.3057225568561451e+04,
      "cpu_time": 3.9251899603252823e+04,
      "time_unit": "ns",
      "items_per_second": 2.4285643643473377e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = true]": 9.0033003156525926e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 1.2800000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 1.2800000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 8.0281600000000000e+05,
      "input_width": 7.0000000000000000e+00,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 2.1186000000000000e+04,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 8.0281600000000000e+05,
      "output_width": 7.0000000000000000e+00,
      "predicted_flops": 2.4285643643473377e+10,
      "predicted_flops_count": 8.0281600000000000e+05
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_128__4496119707191152535<CUDNN_BATCHNORM_SPATIAL>/input[0]:128/input[1]:16/input[2]:416/input[3]:416/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 135,
      "real_time": 5.1883436877418449e+06,
      "cpu_time": 5.5783412074038936e+06,
      "time_unit": "ns",
      "items_per_second": 6.8310564860489388e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 1.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)1; bool is_training = false]": 7.0429798546002954e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 1.6000000000000000e+01,
      "input[2]": 4.1600000000000000e+02,
      "input[3]": 4.1600000000000000e+02,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 1.6000000000000000e+01,
      "input_height": 4.1600000000000000e+02,
      "input_size": 3.5441868800000000e+08,
      "input_width": 4.1600000000000000e+02,
      "is_training": 0.0000000000000000e+00,
      "num_iterations": 1.3500000000000000e+02,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 1.6000000000000000e+01,
      "output_height": 4.1600000000000000e+02,
      "output_size": 3.5441868800000000e+08,
      "output_width": 4.1600000000000000e+02,
      "predicted_flops": 6.8310564860489388e+10,
      "predicted_flops_count": 3.5441868800000000e+08
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_128__4496119707191152535<CUDNN_BATCHNORM_SPATIAL_PERSISTENT>/input[0]:128/input[1]:16/input[2]:416/input[3]:416/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/BATCHNORM_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_128__9706059507243916808<CUDNN_BATCHNORM_SPATIAL>/input[0]:128/input[1]:16/input[2]:416/input[3]:416/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 47,
      "real_time": 1.4811876229941845e+07,
      "cpu_time": 1.7968084255316887e+07,
      "time_unit": "ns",
      "items_per_second": 2.3928007667492611e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 1.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)1; bool is_training = true]": 1.2389518253260638e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 1.6000000000000000e+01,
      "input[2]": 4.1600000000000000e+02,
      "input[3]": 4.1600000000000000e+02,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 1.6000000000000000e+01,
      "input_height": 4.1600000000000000e+02,
      "input_size": 3.5441868800000000e+08,
      "input_width": 4.1600000000000000e+02,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 4.7000000000000000e+01,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 1.6000000000000000e+01,
      "output_height": 4.1600000000000000e+02,
      "output_size": 3.5441868800000000e+08,
      "output_width": 4.1600000000000000e+02,
      "predicted_flops": 2.3928007667492611e+10,
      "predicted_flops_count": 3.5441868800000000e+08
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_128__9706059507243916808<CUDNN_BATCHNORM_SPATIAL_PERSISTENT>/input[0]:128/input[1]:16/input[2]:416/input[3]:416/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 47,
      "real_time": 1.4817627226101590e+07,
      "cpu_time": 1.7974249468086280e+07,
      "time_unit": "ns",
      "items_per_second": 2.3918720763583748e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 2.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)2; bool is_training = true]": 8.6489340726076344e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 1.6000000000000000e+01,
      "input[2]": 4.1600000000000000e+02,
      "input[3]": 4.1600000000000000e+02,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 1.6000000000000000e+01,
      "input_height": 4.1600000000000000e+02,
      "input_size": 3.5441868800000000e+08,
      "input_width": 4.1600000000000000e+02,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 4.7000000000000000e+01,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 1.6000000000000000e+01,
      "output_height": 4.1600000000000000e+02,
      "output_size": 3.5441868800000000e+08,
      "output_width": 4.1600000000000000e+02,
      "predicted_flops": 2.3918720763583748e+10,
      "predicted_flops_count": 3.5441868800000000e+08
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_128__4097505820209792395<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:128/input[1]:64/input[2]:28/input[3]:28/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 5417,
      "real_time": 1.2918783714585604e+05,
      "cpu_time": 1.3561359719233937e+05,
      "time_unit": "ns",
      "items_per_second": 4.9714649164292595e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = false]": 1.4627515035010154e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 2.8000000000000000e+01,
      "input_size": 6.4225280000000000e+06,
      "input_width": 2.8000000000000000e+01,
      "is_training": 0.0000000000000000e+00,
      "num_iterations": 5.4170000000000000e+03,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 2.8000000000000000e+01,
      "output_size": 6.4225280000000000e+06,
      "output_width": 2.8000000000000000e+01,
      "predicted_flops": 4.9714649164292595e+10,
      "predicted_flops_count": 6.4225280000000000e+06
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_128__15561186754250735776<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:128/input[1]:64/input[2]:28/input[3]:28/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 3195,
      "real_time": 2.1909568491588594e+05,
      "cpu_time": 2.2596129765581439e+05,
      "time_unit": "ns",
      "items_per_second": 2.9313804160340733e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = true]": 9.0033003156525926e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 2.8000000000000000e+01,
      "input_size": 6.4225280000000000e+06,
      "input_width": 2.8000000000000000e+01,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 3.1950000000000000e+03,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 2.8000000000000000e+01,
      "output_size": 6.4225280000000000e+06,
      "output_width": 2.8000000000000000e+01,
      "predicted_flops": 2.9313804160340733e+10,
      "predicted_flops_count": 6.4225280000000000e+06
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_128__309343917831893305<CUDNN_BATCHNORM_SPATIAL>/input[0]:128/input[1]:512/input[2]:13/input[3]:13/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 4501,
      "real_time": 1.5555571606443767e+05,
      "cpu_time": 1.6205692357176330e+05,
      "time_unit": "ns",
      "items_per_second": 7.1200109389821655e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 1.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)1; bool is_training = false]": 7.0429798546002954e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 1.3000000000000000e+01,
      "input[3]": 1.3000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 1.3000000000000000e+01,
      "input_size": 1.1075584000000000e+07,
      "input_width": 1.3000000000000000e+01,
      "is_training": 0.0000000000000000e+00,
      "num_iterations": 4.5010000000000000e+03,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 1.3000000000000000e+01,
      "output_size": 1.1075584000000000e+07,
      "output_width": 1.3000000000000000e+01,
      "predicted_flops": 7.1200109389821655e+10,
      "predicted_flops_count": 1.1075584000000000e+07
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_128__309343917831893305<CUDNN_BATCHNORM_SPATIAL_PERSISTENT>/input[0]:128/input[1]:512/input[2]:13/input[3]:13/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/BATCHNORM_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_128__13590937990952951974<CUDNN_BATCHNORM_SPATIAL>/input[0]:128/input[1]:512/input[2]:13/input[3]:13/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 2644,
      "real_time": 2.6451639898696210e+05,
      "cpu_time": 2.7164123940758308e+05,
      "time_unit": "ns",
      "items_per_second": 4.1871067511946243e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 1.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)1; bool is_training = true]": 1.2389518253260638e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 1.3000000000000000e+01,
      "input[3]": 1.3000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 1.3000000000000000e+01,
      "input_size": 1.1075584000000000e+07,
      "input_width": 1.3000000000000000e+01,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 2.6440000000000000e+03,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 1.3000000000000000e+01,
      "output_size": 1.1075584000000000e+07,
      "output_width": 1.3000000000000000e+01,
      "predicted_flops": 4.1871067511946243e+10,
      "predicted_flops_count": 1.1075584000000000e+07
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_128__13590937990952951974<CUDNN_BATCHNORM_SPATIAL_PERSISTENT>/input[0]:128/input[1]:512/input[2]:13/input[3]:13/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 3287,
      "real_time": 2.1271922724308170e+05,
      "cpu_time": 2.1950898265688200e+05,
      "time_unit": "ns",
      "items_per_second": 5.2066680306917175e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 2.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)2; bool is_training = true]": 8.6489340726076344e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 1.3000000000000000e+01,
      "input[3]": 1.3000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 1.3000000000000000e+01,
      "input_size": 1.1075584000000000e+07,
      "input_width": 1.3000000000000000e+01,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 3.2870000000000000e+03,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 1.3000000000000000e+01,
      "output_size": 1.1075584000000000e+07,
      "output_width": 1.3000000000000000e+01,
      "predicted_flops": 5.2066680306917175e+10,
      "predicted_flops_count": 1.1075584000000000e+07
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_128__7006336951657907319<CUDNN_BATCHNORM_SPATIAL>/input[0]:128/input[1]:32/input[2]:208/input[3]:208/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 279,
      "real_time": 2.5129939769945480e+06,
      "cpu_time": 2.6088968709645146e+06,
      "time_unit": "ns",
      "items_per_second": 7.0517217956859619e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 1.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)1; bool is_training = false]": 7.0429798546002954e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 3.2000000000000000e+01,
      "input[2]": 2.0800000000000000e+02,
      "input[3]": 2.0800000000000000e+02,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 3.2000000000000000e+01,
      "input_height": 2.0800000000000000e+02,
      "input_size": 1.7720934400000000e+08,
      "input_width": 2.0800000000000000e+02,
      "is_training": 0.0000000000000000e+00,
      "num_iterations": 2.7900000000000000e+02,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 3.2000000000000000e+01,
      "output_height": 2.0800000000000000e+02,
      "output_size": 1.7720934400000000e+08,
      "output_width": 2.0800000000000000e+02,
      "predicted_flops": 7.0517217956859619e+10,
      "predicted_flops_count": 1.7720934400000000e+08
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_128__7006336951657907319<CUDNN_BATCHNORM_SPATIAL_PERSISTENT>/input[0]:128/input[1]:32/input[2]:208/input[3]:208/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/BATCHNORM_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_128__15702986375770133992<CUDNN_BATCHNORM_SPATIAL>/input[0]:128/input[1]:32/input[2]:208/input[3]:208/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 156,
      "real_time": 4.4821462868593438e+06,
      "cpu_time": 4.7747741474349592e+06,
      "time_unit": "ns",
      "items_per_second": 3.9536715818387802e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 1.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)1; bool is_training = true]": 1.2389518253260638e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 3.2000000000000000e+01,
      "input[2]": 2.0800000000000000e+02,
      "input[3]": 2.0800000000000000e+02,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 3.2000000000000000e+01,
      "input_height": 2.0800000000000000e+02,
      "input_size": 1.7720934400000000e+08,
      "input_width": 2.0800000000000000e+02,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 1.5600000000000000e+02,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 3.2000000000000000e+01,
      "output_height": 2.0800000000000000e+02,
      "output_size": 1.7720934400000000e+08,
      "output_width": 2.0800000000000000e+02,
      "predicted_flops": 3.9536715818387802e+10,
      "predicted_flops_count": 1.7720934400000000e+08
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_128__15702986375770133992<CUDNN_BATCHNORM_SPATIAL_PERSISTENT>/input[0]:128/input[1]:32/input[2]:208/input[3]:208/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 156,
      "real_time": 4.4820933238579296e+06,
      "cpu_time": 4.7747857628220841e+06,
      "time_unit": "ns",
      "items_per_second": 3.9537183007039291e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 2.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)2; bool is_training = true]": 8.6489340726076344e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 3.2000000000000000e+01,
      "input[2]": 2.0800000000000000e+02,
      "input[3]": 2.0800000000000000e+02,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 3.2000000000000000e+01,
      "input_height": 2.0800000000000000e+02,
      "input_size": 1.7720934400000000e+08,
      "input_width": 2.0800000000000000e+02,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 1.5600000000000000e+02,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 3.2000000000000000e+01,
      "output_height": 2.0800000000000000e+02,
      "output_size": 1.7720934400000000e+08,
      "output_width": 2.0800000000000000e+02,
      "predicted_flops": 3.9537183007039291e+10,
      "predicted_flops_count": 1.7720934400000000e+08
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_128__2272772328970393420<CUDNN_BATCHNORM_SPATIAL>/input[0]:128/input[1]:128/input[2]:52/input[3]:52/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 1157,
      "real_time": 6.0489764030581678e+05,
      "cpu_time": 6.1622848832900869e+05,
      "time_unit": "ns",
      "items_per_second": 7.3239392994824982e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 1.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)1; bool is_training = false]": 7.0429798546002954e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 1.2800000000000000e+02,
      "input[2]": 5.2000000000000000e+01,
      "input[3]": 5.2000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 1.2800000000000000e+02,
      "input_height": 5.2000000000000000e+01,
      "input_size": 4.4302336000000000e+07,
      "input_width": 5.2000000000000000e+01,
      "is_training": 0.0000000000000000e+00,
      "num_iterations": 1.1570000000000000e+03,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 5.2000000000000000e+01,
      "output_size": 4.4302336000000000e+07,
      "output_width": 5.2000000000000000e+01,
      "predicted_flops": 7.3239392994824982e+10,
      "predicted_flops_count": 4.4302336000000000e+07
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_128__2272772328970393420<CUDNN_BATCHNORM_SPATIAL_PERSISTENT>/input[0]:128/input[1]:128/input[2]:52/input[3]:52/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/BATCHNORM_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_128__12059855691650598611<CUDNN_BATCHNORM_SPATIAL>/input[0]:128/input[1]:128/input[2]:52/input[3]:52/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 740,
      "real_time": 9.4665236679862288e+05,
      "cpu_time": 9.6552347567123093e+05,
      "time_unit": "ns",
      "items_per_second": 4.6798949174786400e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 1.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)1; bool is_training = true]": 1.2389518253260638e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 1.2800000000000000e+02,
      "input[2]": 5.2000000000000000e+01,
      "input[3]": 5.2000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 1.2800000000000000e+02,
      "input_height": 5.2000000000000000e+01,
      "input_size": 4.4302336000000000e+07,
      "input_width": 5.2000000000000000e+01,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 7.4000000000000000e+02,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 5.2000000000000000e+01,
      "output_size": 4.4302336000000000e+07,
      "output_width": 5.2000000000000000e+01,
      "predicted_flops": 4.6798949174786400e+10,
      "predicted_flops_count": 4.4302336000000000e+07
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_128__12059855691650598611<CUDNN_BATCHNORM_SPATIAL_PERSISTENT>/input[0]:128/input[1]:128/input[2]:52/input[3]:52/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 879,
      "real_time": 7.9781158583024691e+05,
      "cpu_time": 8.1288769055482827e+05,
      "time_unit": "ns",
      "items_per_second": 5.5529822813862167e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 2.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)2; bool is_training = true]": 8.6489340726076344e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 1.2800000000000000e+02,
      "input[2]": 5.2000000000000000e+01,
      "input[3]": 5.2000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 1.2800000000000000e+02,
      "input_height": 5.2000000000000000e+01,
      "input_size": 4.4302336000000000e+07,
      "input_width": 5.2000000000000000e+01,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 8.7900000000000000e+02,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 5.2000000000000000e+01,
      "output_size": 4.4302336000000000e+07,
      "output_width": 5.2000000000000000e+01,
      "predicted_flops": 5.5529822813862167e+10,
      "predicted_flops_count": 4.4302336000000000e+07
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_128__17743665713052587241<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:128/input[1]:2048/input[2]:100/input[3]:100/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD failed to cudnnSetTensor4dDescriptor",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_128__1807943229288829378<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:128/input[1]:2048/input[2]:100/input[3]:100/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD failed to cudnnSetTensor4dDescriptor",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_128__5722518830201903470<CUDNN_BATCHNORM_SPATIAL>/input[0]:128/input[1]:256/input[2]:26/input[3]:26/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 2284,
      "real_time": 3.0640654069952172e+05,
      "cpu_time": 3.1388780648114893e+05,
      "time_unit": "ns",
      "items_per_second": 7.2293391483841049e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 1.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)1; bool is_training = false]": 7.0429798546002954e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 2.6000000000000000e+01,
      "input[3]": 2.6000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 2.6000000000000000e+01,
      "input_size": 2.2151168000000000e+07,
      "input_width": 2.6000000000000000e+01,
      "is_training": 0.0000000000000000e+00,
      "num_iterations": 2.2840000000000000e+03,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 2.6000000000000000e+01,
      "output_size": 2.2151168000000000e+07,
      "output_width": 2.6000000000000000e+01,
      "predicted_flops": 7.2293391483841049e+10,
      "predicted_flops_count": 2.2151168000000000e+07
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_128__5722518830201903470<CUDNN_BATCHNORM_SPATIAL_PERSISTENT>/input[0]:128/input[1]:256/input[2]:26/input[3]:26/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/BATCHNORM_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_128__17851649011920636145<CUDNN_BATCHNORM_SPATIAL>/input[0]:128/input[1]:256/input[2]:26/input[3]:26/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 1351,
      "real_time": 5.1809541977939231e+05,
      "cpu_time": 5.2801548408859561e+05,
      "time_unit": "ns",
      "items_per_second": 4.2754996771506065e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 1.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)1; bool is_training = true]": 1.2389518253260638e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 2.6000000000000000e+01,
      "input[3]": 2.6000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 2.6000000000000000e+01,
      "input_size": 2.2151168000000000e+07,
      "input_width": 2.6000000000000000e+01,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 1.3510000000000000e+03,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 2.6000000000000000e+01,
      "output_size": 2.2151168000000000e+07,
      "output_width": 2.6000000000000000e+01,
      "predicted_flops": 4.2754996771506065e+10,
      "predicted_flops_count": 2.2151168000000000e+07
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_128__17851649011920636145<CUDNN_BATCHNORM_SPATIAL_PERSISTENT>/input[0]:128/input[1]:256/input[2]:26/input[3]:26/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 1784,
      "real_time": 3.9275519347816473e+05,
      "cpu_time": 4.0107071356640663e+05,
      "time_unit": "ns",
      "items_per_second": 5.6399427347690811e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 2.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)2; bool is_training = true]": 8.6489340726076344e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 2.6000000000000000e+01,
      "input[3]": 2.6000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 2.6000000000000000e+01,
      "input_size": 2.2151168000000000e+07,
      "input_width": 2.6000000000000000e+01,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 1.7840000000000000e+03,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 2.6000000000000000e+01,
      "output_size": 2.2151168000000000e+07,
      "output_width": 2.6000000000000000e+01,
      "predicted_flops": 5.6399427347690811e+10,
      "predicted_flops_count": 2.2151168000000000e+07
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_128__10920519682909109743<CUDNN_BATCHNORM_SPATIAL>/input[0]:128/input[1]:1024/input[2]:12/input[3]:12/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 2702,
      "real_time": 2.5908166203916012e+05,
      "cpu_time": 2.6617399111812934e+05,
      "time_unit": "ns",
      "items_per_second": 7.2851037975613815e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 1.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)1; bool is_training = false]": 7.0429798546002954e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 1.0240000000000000e+03,
      "input[2]": 1.2000000000000000e+01,
      "input[3]": 1.2000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 1.0240000000000000e+03,
      "input_height": 1.2000000000000000e+01,
      "input_size": 1.8874368000000000e+07,
      "input_width": 1.2000000000000000e+01,
      "is_training": 0.0000000000000000e+00,
      "num_iterations": 2.7020000000000000e+03,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 1.0240000000000000e+03,
      "output_height": 1.2000000000000000e+01,
      "output_size": 1.8874368000000000e+07,
      "output_width": 1.2000000000000000e+01,
      "predicted_flops": 7.2851037975613815e+10,
      "predicted_flops_count": 1.8874368000000000e+07
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_128__10920519682909109743<CUDNN_BATCHNORM_SPATIAL_PERSISTENT>/input[0]:128/input[1]:1024/input[2]:12/input[3]:12/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/BATCHNORM_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_128__3412266673798245488<CUDNN_BATCHNORM_SPATIAL>/input[0]:128/input[1]:1024/input[2]:12/input[3]:12/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 1607,
      "real_time": 4.3549479144235916e+05,
      "cpu_time": 4.4432420846152882e+05,
      "time_unit": "ns",
      "items_per_second": 4.3340054510154015e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 1.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)1; bool is_training = true]": 1.2389518253260638e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 1.0240000000000000e+03,
      "input[2]": 1.2000000000000000e+01,
      "input[3]": 1.2000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 1.0240000000000000e+03,
      "input_height": 1.2000000000000000e+01,
      "input_size": 1.8874368000000000e+07,
      "input_width": 1.2000000000000000e+01,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 1.6070000000000000e+03,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 1.0240000000000000e+03,
      "output_height": 1.2000000000000000e+01,
      "output_size": 1.8874368000000000e+07,
      "output_width": 1.2000000000000000e+01,
      "predicted_flops": 4.3340054510154015e+10,
      "predicted_flops_count": 1.8874368000000000e+07
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_128__3412266673798245488<CUDNN_BATCHNORM_SPATIAL_PERSISTENT>/input[0]:128/input[1]:1024/input[2]:12/input[3]:12/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 1849,
      "real_time": 3.7898025605142547e+05,
      "cpu_time": 3.8711497350180545e+05,
      "time_unit": "ns",
      "items_per_second": 4.9803037753604912e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 2.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)2; bool is_training = true]": 8.6489340726076344e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 1.0240000000000000e+03,
      "input[2]": 1.2000000000000000e+01,
      "input[3]": 1.2000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 1.0240000000000000e+03,
      "input_height": 1.2000000000000000e+01,
      "input_size": 1.8874368000000000e+07,
      "input_width": 1.2000000000000000e+01,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 1.8490000000000000e+03,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 1.0240000000000000e+03,
      "output_height": 1.2000000000000000e+01,
      "output_size": 1.8874368000000000e+07,
      "output_width": 1.2000000000000000e+01,
      "predicted_flops": 4.9803037753604912e+10,
      "predicted_flops_count": 1.8874368000000000e+07
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_128__17742941907917574867<CUDNN_BATCHNORM_SPATIAL>/input[0]:128/input[1]:144/input[2]:28/input[3]:28/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 3473,
      "real_time": 2.0158449431146949e+05,
      "cpu_time": 2.0832918974947120e+05,
      "time_unit": "ns",
      "items_per_second": 7.1685513557764755e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 1.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)1; bool is_training = false]": 7.0429798546002954e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 1.4400000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 1.4400000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 1.4450688000000000e+07,
      "input_width": 2.8000000000000000e+01,
      "is_training": 0.0000000000000000e+00,
      "num_iterations": 3.4730000000000000e+03,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 1.4400000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 1.4450688000000000e+07,
      "output_width": 2.8000000000000000e+01,
      "predicted_flops": 7.1685513557764755e+10,
      "predicted_flops_count": 1.4450688000000000e+07
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_128__17742941907917574867<CUDNN_BATCHNORM_SPATIAL_PERSISTENT>/input[0]:128/input[1]:144/input[2]:28/input[3]:28/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/BATCHNORM_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_128__5686959013552522060<CUDNN_BATCHNORM_SPATIAL>/input[0]:128/input[1]:144/input[2]:28/input[3]:28/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 2309,
      "real_time": 3.0307037114377884e+05,
      "cpu_time": 3.1055136985451839e+05,
      "time_unit": "ns",
      "items_per_second": 4.7680965795051231e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 1.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)1; bool is_training = true]": 1.2389518253260638e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 1.4400000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 1.4400000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 1.4450688000000000e+07,
      "input_width": 2.8000000000000000e+01,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 2.3090000000000000e+03,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 1.4400000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 1.4450688000000000e+07,
      "output_width": 2.8000000000000000e+01,
      "predicted_flops": 4.7680965795051231e+10,
      "predicted_flops_count": 1.4450688000000000e+07
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_128__5686959013552522060<CUDNN_BATCHNORM_SPATIAL_PERSISTENT>/input[0]:128/input[1]:144/input[2]:28/input[3]:28/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 2686,
      "real_time": 2.6077148068972953e+05,
      "cpu_time": 2.6787732315733796e+05,
      "time_unit": "ns",
      "items_per_second": 5.5415139576530922e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 2.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)2; bool is_training = true]": 8.6489340726076344e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 1.4400000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 1.4400000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 1.4450688000000000e+07,
      "input_width": 2.8000000000000000e+01,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 2.6860000000000000e+03,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 1.4400000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 1.4450688000000000e+07,
      "output_width": 2.8000000000000000e+01,
      "predicted_flops": 5.5415139576530922e+10,
      "predicted_flops_count": 1.4450688000000000e+07
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_128__2594067515868035456<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:1/input[1]:1024/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 50496,
      "real_time": 1.3879261926322606e+04,
      "cpu_time": 1.9804376624114982e+04,
      "time_unit": "ns",
      "items_per_second": 1.4460711316309723e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = false]": 1.4627515035010154e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 1.0240000000000000e+03,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 1.0240000000000000e+03,
      "input_height": 1.4000000000000000e+01,
      "input_size": 2.0070400000000000e+05,
      "input_width": 1.4000000000000000e+01,
      "is_training": 0.0000000000000000e+00,
      "num_iterations": 5.0496000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 1.0240000000000000e+03,
      "output_height": 1.4000000000000000e+01,
      "output_size": 2.0070400000000000e+05,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 1.4460711316309723e+10,
      "predicted_flops_count": 2.0070400000000000e+05
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_128__14760206466692676779<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:1/input[1]:1024/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 27391,
      "real_time": 2.5590843248244815e+04,
      "cpu_time": 3.1759811506922284e+04,
      "time_unit": "ns",
      "items_per_second": 7.8428052586256838e+09,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = true]": 9.0033003156525926e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 1.0240000000000000e+03,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 1.0240000000000000e+03,
      "input_height": 1.4000000000000000e+01,
      "input_size": 2.0070400000000000e+05,
      "input_width": 1.4000000000000000e+01,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 2.7391000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 1.0240000000000000e+03,
      "output_height": 1.4000000000000000e+01,
      "output_size": 2.0070400000000000e+05,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 7.8428052586256838e+09,
      "predicted_flops_count": 2.0070400000000000e+05
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_128__1791419340914813916<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:1/input[1]:768/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 111303,
      "real_time": 6.2872265350766329e+03,
      "cpu_time": 1.2138574414172024e+04,
      "time_unit": "ns",
      "items_per_second": 5.9854690760782833e+09,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = false]": 1.4627515035010154e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 7.6800000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 7.6800000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 3.7632000000000000e+04,
      "input_width": 7.0000000000000000e+00,
      "is_training": 0.0000000000000000e+00,
      "num_iterations": 1.1130300000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 7.6800000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 3.7632000000000000e+04,
      "output_width": 7.0000000000000000e+00,
      "predicted_flops": 5.9854690760782833e+09,
      "predicted_flops_count": 3.7632000000000000e+04
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_128__17867280947317026551<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:1/input[1]:768/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 64278,
      "real_time": 1.0900363510251496e+04,
      "cpu_time": 1.6779907884787252e+04,
      "time_unit": "ns",
      "items_per_second": 3.4523619294538317e+09,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = true]": 9.0033003156525926e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 7.6800000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 7.6800000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 3.7632000000000000e+04,
      "input_width": 7.0000000000000000e+00,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 6.4278000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 7.6800000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 3.7632000000000000e+04,
      "output_width": 7.0000000000000000e+00,
      "predicted_flops": 3.4523619294538317e+09,
      "predicted_flops_count": 3.7632000000000000e+04
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_128__2713734424672025849<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:128/input[1]:224/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 22674,
      "real_time": 3.0879433087724839e+04,
      "cpu_time": 3.7069882728992823e+04,
      "time_unit": "ns",
      "items_per_second": 4.5497208320138672e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = false]": 1.4627515035010154e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 2.2400000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 2.2400000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 1.4049280000000000e+06,
      "input_width": 7.0000000000000000e+00,
      "is_training": 0.0000000000000000e+00,
      "num_iterations": 2.2674000000000000e+04,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 2.2400000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 1.4049280000000000e+06,
      "output_width": 7.0000000000000000e+00,
      "predicted_flops": 4.5497208320138672e+10,
      "predicted_flops_count": 1.4049280000000000e+06
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_128__14591711350259546578<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:128/input[1]:224/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 13661,
      "real_time": 5.1102348582146624e+04,
      "cpu_time": 5.7296913548001059e+04,
      "time_unit": "ns",
      "items_per_second": 2.7492435063754250e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = true]": 9.0033003156525926e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 2.2400000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 2.2400000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 1.4049280000000000e+06,
      "input_width": 7.0000000000000000e+00,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 1.3661000000000000e+04,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 2.2400000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 1.4049280000000000e+06,
      "output_width": 7.0000000000000000e+00,
      "predicted_flops": 2.7492435063754250e+10,
      "predicted_flops_count": 1.4049280000000000e+06
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_128__16797863604158727113<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:128/input[1]:320/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 16776,
      "real_time": 4.1727370341921662e+04,
      "cpu_time": 4.7940794944867957e+04,
      "time_unit": "ns",
      "items_per_second": 4.8098885301277054e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = false]": 1.4627515035010154e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 3.2000000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 3.2000000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 2.0070400000000000e+06,
      "input_width": 7.0000000000000000e+00,
      "is_training": 0.0000000000000000e+00,
      "num_iterations": 1.6776000000000000e+04,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 3.2000000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 2.0070400000000000e+06,
      "output_width": 7.0000000000000000e+00,
      "predicted_flops": 4.8098885301277054e+10,
      "predicted_flops_count": 2.0070400000000000e+06
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_128__447207454783719138<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:128/input[1]:320/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 10127,
      "real_time": 6.9226273008525852e+04,
      "cpu_time": 7.5484514663806724e+04,
      "time_unit": "ns",
      "items_per_second": 2.8992460705674774e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = true]": 9.0033003156525926e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 3.2000000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 3.2000000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 2.0070400000000000e+06,
      "input_width": 7.0000000000000000e+00,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 1.0127000000000000e+04,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 3.2000000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 2.0070400000000000e+06,
      "output_width": 7.0000000000000000e+00,
      "predicted_flops": 2.8992460705674774e+10,
      "predicted_flops_count": 2.0070400000000000e+06
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_128__10732765357663032777<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:128/input[1]:192/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 25689,
      "real_time": 2.7253395990841513e+04,
      "cpu_time": 3.3434912724389724e+04,
      "time_unit": "ns",
      "items_per_second": 4.4186199782393311e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = false]": 1.4627515035010154e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 1.9200000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 1.9200000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 1.2042240000000000e+06,
      "input_width": 7.0000000000000000e+00,
      "is_training": 0.0000000000000000e+00,
      "num_iterations": 2.5689000000000000e+04,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 1.9200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 1.2042240000000000e+06,
      "output_width": 7.0000000000000000e+00,
      "predicted_flops": 4.4186199782393311e+10,
      "predicted_flops_count": 1.2042240000000000e+06
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_128__8924799684750201058<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:128/input[1]:192/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 15921,
      "real_time": 4.3940908230708912e+04,
      "cpu_time": 5.0140971421719601e+04,
      "time_unit": "ns",
      "items_per_second": 2.7405532759525574e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = true]": 9.0033003156525926e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 1.9200000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 1.9200000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 1.2042240000000000e+06,
      "input_width": 7.0000000000000000e+00,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 1.5921000000000000e+04,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 1.9200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 1.2042240000000000e+06,
      "output_width": 7.0000000000000000e+00,
      "predicted_flops": 2.7405532759525574e+10,
      "predicted_flops_count": 1.2042240000000000e+06
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_128__16838400792959797723<CUDNN_BATCHNORM_SPATIAL>/input[0]:128/input[1]:64/input[2]:104/input[3]:104/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 568,
      "real_time": 1.2322744140631035e+06,
      "cpu_time": 1.2600032024589786e+06,
      "time_unit": "ns",
      "items_per_second": 7.1903360963122818e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 1.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)1; bool is_training = false]": 7.0429798546002954e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 1.0400000000000000e+02,
      "input[3]": 1.0400000000000000e+02,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 1.0400000000000000e+02,
      "input_size": 8.8604672000000000e+07,
      "input_width": 1.0400000000000000e+02,
      "is_training": 0.0000000000000000e+00,
      "num_iterations": 5.6800000000000000e+02,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 1.0400000000000000e+02,
      "output_size": 8.8604672000000000e+07,
      "output_width": 1.0400000000000000e+02,
      "predicted_flops": 7.1903360963122818e+10,
      "predicted_flops_count": 8.8604672000000000e+07
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_128__16838400792959797723<CUDNN_BATCHNORM_SPATIAL_PERSISTENT>/input[0]:128/input[1]:64/input[2]:104/input[3]:104/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/BATCHNORM_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_128__5870918140784203844<CUDNN_BATCHNORM_SPATIAL>/input[0]:128/input[1]:64/input[2]:104/input[3]:104/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 365,
      "real_time": 1.9196130989170440e+06,
      "cpu_time": 1.9780004411032142e+06,
      "time_unit": "ns",
      "items_per_second": 4.6157567923445930e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 1.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)1; bool is_training = true]": 1.2389518253260638e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 1.0400000000000000e+02,
      "input[3]": 1.0400000000000000e+02,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 1.0400000000000000e+02,
      "input_size": 8.8604672000000000e+07,
      "input_width": 1.0400000000000000e+02,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 3.6500000000000000e+02,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 1.0400000000000000e+02,
      "output_size": 8.8604672000000000e+07,
      "output_width": 1.0400000000000000e+02,
      "predicted_flops": 4.6157567923445930e+10,
      "predicted_flops_count": 8.8604672000000000e+07
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_128__5870918140784203844<CUDNN_BATCHNORM_SPATIAL_PERSISTENT>/input[0]:128/input[1]:64/input[2]:104/input[3]:104/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 397,
      "real_time": 1.7641351525425462e+06,
      "cpu_time": 1.8145007707818178e+06,
      "time_unit": "ns",
      "items_per_second": 5.0225557759732414e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 2.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)2; bool is_training = true]": 8.6489340726076344e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 1.0400000000000000e+02,
      "input[3]": 1.0400000000000000e+02,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 1.0400000000000000e+02,
      "input_size": 8.8604672000000000e+07,
      "input_width": 1.0400000000000000e+02,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 3.9700000000000000e+02,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 1.0400000000000000e+02,
      "output_size": 8.8604672000000000e+07,
      "output_width": 1.0400000000000000e+02,
      "predicted_flops": 5.0225557759732414e+10,
      "predicted_flops_count": 8.8604672000000000e+07
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_128__4461149277244782514<CUDNN_BATCHNORM_SPATIAL>/input[0]:128/input[1]:2048/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 1474,
      "real_time": 4.7476795997048559e+05,
      "cpu_time": 4.8410149050177413e+05,
      "time_unit": "ns",
      "items_per_second": 2.7055439884356407e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 1.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)1; bool is_training = false]": 7.0429798546002954e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 2.0480000000000000e+03,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 2.0480000000000000e+03,
      "input_height": 7.0000000000000000e+00,
      "input_size": 1.2845056000000000e+07,
      "input_width": 7.0000000000000000e+00,
      "is_training": 0.0000000000000000e+00,
      "num_iterations": 1.4740000000000000e+03,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 2.0480000000000000e+03,
      "output_height": 7.0000000000000000e+00,
      "output_size": 1.2845056000000000e+07,
      "output_width": 7.0000000000000000e+00,
      "predicted_flops": 2.7055439884356407e+10,
      "predicted_flops_count": 1.2845056000000000e+07
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_128__4461149277244782514<CUDNN_BATCHNORM_SPATIAL_PERSISTENT>/input[0]:128/input[1]:2048/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/BATCHNORM_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_128__9601282011385488941<CUDNN_BATCHNORM_SPATIAL>/input[0]:128/input[1]:2048/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 3210,
      "real_time": 2.1787045512735014e+05,
      "cpu_time": 2.2474989158974006e+05,
      "time_unit": "ns",
      "items_per_second": 5.8957310170815857e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 1.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)1; bool is_training = true]": 1.2389518253260638e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 2.0480000000000000e+03,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 2.0480000000000000e+03,
      "input_height": 7.0000000000000000e+00,
      "input_size": 1.2845056000000000e+07,
      "input_width": 7.0000000000000000e+00,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 3.2100000000000000e+03,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 2.0480000000000000e+03,
      "output_height": 7.0000000000000000e+00,
      "output_size": 1.2845056000000000e+07,
      "output_width": 7.0000000000000000e+00,
      "predicted_flops": 5.8957310170815857e+10,
      "predicted_flops_count": 1.2845056000000000e+07
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_128__9601282011385488941<CUDNN_BATCHNORM_SPATIAL_PERSISTENT>/input[0]:128/input[1]:2048/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 3214,
      "real_time": 2.1783044209781173e+05,
      "cpu_time": 2.2468270317310566e+05,
      "time_unit": "ns",
      "items_per_second": 5.8968139972980568e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 2.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)2; bool is_training = true]": 8.6489340726076344e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 2.0480000000000000e+03,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 2.0480000000000000e+03,
      "input_height": 7.0000000000000000e+00,
      "input_size": 1.2845056000000000e+07,
      "input_width": 7.0000000000000000e+00,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 3.2140000000000000e+03,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 2.0480000000000000e+03,
      "output_height": 7.0000000000000000e+00,
      "output_size": 1.2845056000000000e+07,
      "output_width": 7.0000000000000000e+00,
      "predicted_flops": 5.8968139972980568e+10,
      "predicted_flops_count": 1.2845056000000000e+07
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_128__14227782098438994395<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:128/input[1]:352/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 15278,
      "real_time": 4.5815008397536112e+04,
      "cpu_time": 5.2013247283837874e+04,
      "time_unit": "ns",
      "items_per_second": 4.8188226461587433e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = false]": 1.4627515035010154e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 3.5200000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 3.5200000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 2.2077440000000000e+06,
      "input_width": 7.0000000000000000e+00,
      "is_training": 0.0000000000000000e+00,
      "num_iterations": 1.5278000000000000e+04,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 3.5200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 2.2077440000000000e+06,
      "output_width": 7.0000000000000000e+00,
      "predicted_flops": 4.8188226461587433e+10,
      "predicted_flops_count": 2.2077440000000000e+06
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_128__3051768545631042800<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:128/input[1]:352/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 9181,
      "real_time": 7.6156132130808779e+04,
      "cpu_time": 8.2392528482377966e+04,
      "time_unit": "ns",
      "items_per_second": 2.8989707568234848e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = true]": 9.0033003156525926e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 3.5200000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 3.5200000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 2.2077440000000000e+06,
      "input_width": 7.0000000000000000e+00,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 9.1810000000000000e+03,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 3.5200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 2.2077440000000000e+06,
      "output_width": 7.0000000000000000e+00,
      "predicted_flops": 2.8989707568234848e+10,
      "predicted_flops_count": 2.2077440000000000e+06
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_128__7019092671655129238<CUDNN_BATCHNORM_SPATIAL>/input[0]:128/input[1]:128/input[2]:28/input[3]:28/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 3892,
      "real_time": 1.7983518064788752e+05,
      "cpu_time": 1.8647157888044848e+05,
      "time_unit": "ns",
      "items_per_second": 7.1426825128005814e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 1.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)1; bool is_training = false]": 7.0429798546002954e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 1.2800000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 1.2800000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 1.2845056000000000e+07,
      "input_width": 2.8000000000000000e+01,
      "is_training": 0.0000000000000000e+00,
      "num_iterations": 3.8920000000000000e+03,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 1.2845056000000000e+07,
      "output_width": 2.8000000000000000e+01,
      "predicted_flops": 7.1426825128005814e+10,
      "predicted_flops_count": 1.2845056000000000e+07
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_128__7019092671655129238<CUDNN_BATCHNORM_SPATIAL_PERSISTENT>/input[0]:128/input[1]:128/input[2]:28/input[3]:28/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/BATCHNORM_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_128__15690373046925631753<CUDNN_BATCHNORM_SPATIAL>/input[0]:128/input[1]:128/input[2]:28/input[3]:28/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 2587,
      "real_time": 2.7047338822869502e+05,
      "cpu_time": 2.7764905412161112e+05,
      "time_unit": "ns",
      "items_per_second": 4.7491015970632347e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 1.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)1; bool is_training = true]": 1.2389518253260638e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 1.2800000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 1.2800000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 1.2845056000000000e+07,
      "input_width": 2.8000000000000000e+01,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 2.5870000000000000e+03,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 1.2845056000000000e+07,
      "output_width": 2.8000000000000000e+01,
      "predicted_flops": 4.7491015970632347e+10,
      "predicted_flops_count": 1.2845056000000000e+07
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_128__15690373046925631753<CUDNN_BATCHNORM_SPATIAL_PERSISTENT>/input[0]:128/input[1]:128/input[2]:28/input[3]:28/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 2946,
      "real_time": 2.3765193522675120e+05,
      "cpu_time": 2.4460314731908473e+05,
      "time_unit": "ns",
      "items_per_second": 5.4049869140531624e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 2.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)2; bool is_training = true]": 8.6489340726076344e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 1.2800000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 1.2800000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 1.2845056000000000e+07,
      "input_width": 2.8000000000000000e+01,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 2.9460000000000000e+03,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 1.2845056000000000e+07,
      "output_width": 2.8000000000000000e+01,
      "predicted_flops": 5.4049869140531624e+10,
      "predicted_flops_count": 1.2845056000000000e+07
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_128__16272328137972800345<CUDNN_BATCHNORM_SPATIAL>/input[0]:128/input[1]:512/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 5692,
      "real_time": 1.2295595390532112e+05,
      "cpu_time": 1.2929778794819485e+05,
      "time_unit": "ns",
      "items_per_second": 2.6117189920487679e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 1.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)1; bool is_training = false]": 7.0429798546002954e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 3.2112640000000000e+06,
      "input_width": 7.0000000000000000e+00,
      "is_training": 0.0000000000000000e+00,
      "num_iterations": 5.6920000000000000e+03,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 3.2112640000000000e+06,
      "output_width": 7.0000000000000000e+00,
      "predicted_flops": 2.6117189920487679e+10,
      "predicted_flops_count": 3.2112640000000000e+06
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_128__16272328137972800345<CUDNN_BATCHNORM_SPATIAL_PERSISTENT>/input[0]:128/input[1]:512/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/BATCHNORM_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_128__6414630573195053766<CUDNN_BATCHNORM_SPATIAL>/input[0]:128/input[1]:512/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 10992,
      "real_time": 6.3752814696809743e+04,
      "cpu_time": 7.0015896197941925e+04,
      "time_unit": "ns",
      "items_per_second": 5.0370544661782516e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 1.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)1; bool is_training = true]": 1.2389518253260638e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 3.2112640000000000e+06,
      "input_width": 7.0000000000000000e+00,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 1.0992000000000000e+04,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 3.2112640000000000e+06,
      "output_width": 7.0000000000000000e+00,
      "predicted_flops": 5.0370544661782516e+10,
      "predicted_flops_count": 3.2112640000000000e+06
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_128__6414630573195053766<CUDNN_BATCHNORM_SPATIAL_PERSISTENT>/input[0]:128/input[1]:512/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 10971,
      "real_time": 6.3728607728938623e+04,
      "cpu_time": 7.0003704950612562e+04,
      "time_unit": "ns",
      "items_per_second": 5.0389677641455704e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 2.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)2; bool is_training = true]": 8.6489340726076344e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 3.2112640000000000e+06,
      "input_width": 7.0000000000000000e+00,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 1.0971000000000000e+04,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 3.2112640000000000e+06,
      "output_width": 7.0000000000000000e+00,
      "predicted_flops": 5.0389677641455704e+10,
      "predicted_flops_count": 3.2112640000000000e+06
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_128__7463260461156666753<CUDNN_BATCHNORM_SPATIAL>/input[0]:128/input[1]:1024/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 1999,
      "real_time": 3.5014015194629622e+05,
      "cpu_time": 3.5802371335778682e+05,
      "time_unit": "ns",
      "items_per_second": 7.3370939771398453e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 1.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)1; bool is_training = false]": 7.0429798546002954e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 1.0240000000000000e+03,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 1.0240000000000000e+03,
      "input_height": 1.4000000000000000e+01,
      "input_size": 2.5690112000000000e+07,
      "input_width": 1.4000000000000000e+01,
      "is_training": 0.0000000000000000e+00,
      "num_iterations": 1.9990000000000000e+03,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 1.0240000000000000e+03,
      "output_height": 1.4000000000000000e+01,
      "output_size": 2.5690112000000000e+07,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 7.3370939771398453e+10,
      "predicted_flops_count": 2.5690112000000000e+07
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_128__7463260461156666753<CUDNN_BATCHNORM_SPATIAL_PERSISTENT>/input[0]:128/input[1]:1024/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/BATCHNORM_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_128__16088378939581832222<CUDNN_BATCHNORM_SPATIAL>/input[0]:128/input[1]:1024/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 1183,
      "real_time": 5.9196854449906212e+05,
      "cpu_time": 6.0306507185142708e+05,
      "time_unit": "ns",
      "items_per_second": 4.3397765369002136e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 1.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)1; bool is_training = true]": 1.2389518253260638e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 1.0240000000000000e+03,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 1.0240000000000000e+03,
      "input_height": 1.4000000000000000e+01,
      "input_size": 2.5690112000000000e+07,
      "input_width": 1.4000000000000000e+01,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 1.1830000000000000e+03,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 1.0240000000000000e+03,
      "output_height": 1.4000000000000000e+01,
      "output_size": 2.5690112000000000e+07,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 4.3397765369002136e+10,
      "predicted_flops_count": 2.5690112000000000e+07
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_128__16088378939581832222<CUDNN_BATCHNORM_SPATIAL_PERSISTENT>/input[0]:128/input[1]:1024/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 1475,
      "real_time": 4.7413421690195671e+05,
      "cpu_time": 4.8342164067774214e+05,
      "time_unit": "ns",
      "items_per_second": 5.4183206113791824e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 2.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)2; bool is_training = true]": 8.6489340726076344e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 1.0240000000000000e+03,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 1.0240000000000000e+03,
      "input_height": 1.4000000000000000e+01,
      "input_size": 2.5690112000000000e+07,
      "input_width": 1.4000000000000000e+01,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 1.4750000000000000e+03,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 1.0240000000000000e+03,
      "output_height": 1.4000000000000000e+01,
      "output_size": 2.5690112000000000e+07,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 5.4183206113791824e+10,
      "predicted_flops_count": 2.5690112000000000e+07
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_128__198034484080130553<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:128/input[1]:64/input[2]:224/input[3]:224/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 54,
      "real_time": 1.2886168348982379e+07,
      "cpu_time": 1.5279656759267474e+07,
      "time_unit": "ns",
      "items_per_second": 3.1897906411602951e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = false]": 1.4627515035010154e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 2.2400000000000000e+02,
      "input[3]": 2.2400000000000000e+02,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 2.2400000000000000e+02,
      "input_size": 4.1104179200000000e+08,
      "input_width": 2.2400000000000000e+02,
      "is_training": 0.0000000000000000e+00,
      "num_iterations": 5.4000000000000000e+01,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 2.2400000000000000e+02,
      "output_size": 4.1104179200000000e+08,
      "output_width": 2.2400000000000000e+02,
      "predicted_flops": 3.1897906411602951e+10,
      "predicted_flops_count": 4.1104179200000000e+08
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_128__17120078210249129170<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:128/input[1]:64/input[2]:224/input[3]:224/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 38,
      "real_time": 1.8444046182067771e+07,
      "cpu_time": 2.3304487500001270e+07,
      "time_unit": "ns",
      "items_per_second": 2.2285879570158283e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = true]": 9.0033003156525926e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 2.2400000000000000e+02,
      "input[3]": 2.2400000000000000e+02,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 2.2400000000000000e+02,
      "input_size": 4.1104179200000000e+08,
      "input_width": 2.2400000000000000e+02,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 3.8000000000000000e+01,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 2.2400000000000000e+02,
      "output_size": 4.1104179200000000e+08,
      "output_width": 2.2400000000000000e+02,
      "predicted_flops": 2.2285879570158283e+10,
      "predicted_flops_count": 4.1104179200000000e+08
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_128__5572927234915852209<CUDNN_BATCHNORM_SPATIAL>/input[0]:128/input[1]:256/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 7523,
      "real_time": 9.3073217573449525e+04,
      "cpu_time": 9.9360238601105346e+04,
      "time_unit": "ns",
      "items_per_second": 6.9005114118157639e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 1.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)1; bool is_training = false]": 7.0429798546002954e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 6.4225280000000000e+06,
      "input_width": 1.4000000000000000e+01,
      "is_training": 0.0000000000000000e+00,
      "num_iterations": 7.5230000000000000e+03,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 6.4225280000000000e+06,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 6.9005114118157639e+10,
      "predicted_flops_count": 6.4225280000000000e+06
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_128__5572927234915852209<CUDNN_BATCHNORM_SPATIAL_PERSISTENT>/input[0]:128/input[1]:256/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/BATCHNORM_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_128__17690341045433454126<CUDNN_BATCHNORM_SPATIAL>/input[0]:128/input[1]:256/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 4739,
      "real_time": 1.4777994858704138e+05,
      "cpu_time": 1.5424710255423354e+05,
      "time_unit": "ns",
      "items_per_second": 4.3460077374551086e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 1.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)1; bool is_training = true]": 1.2389518253260638e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 6.4225280000000000e+06,
      "input_width": 1.4000000000000000e+01,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 4.7390000000000000e+03,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 6.4225280000000000e+06,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 4.3460077374551086e+10,
      "predicted_flops_count": 6.4225280000000000e+06
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_128__17690341045433454126<CUDNN_BATCHNORM_SPATIAL_PERSISTENT>/input[0]:128/input[1]:256/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 5550,
      "real_time": 1.2616253947484650e+05,
      "cpu_time": 1.3260216378323815e+05,
      "time_unit": "ns",
      "items_per_second": 5.0906774916975121e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 2.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)2; bool is_training = true]": 8.6489340726076344e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 6.4225280000000000e+06,
      "input_width": 1.4000000000000000e+01,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 5.5500000000000000e+03,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 6.4225280000000000e+06,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 5.0906774916975121e+10,
      "predicted_flops_count": 6.4225280000000000e+06
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_128__2213003517432460084<CUDNN_BATCHNORM_SPATIAL>/input[0]:128/input[1]:3/input[2]:224/input[3]:224/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 2260,
      "real_time": 3.0973834922873060e+05,
      "cpu_time": 3.1725714645906002e+05,
      "time_unit": "ns",
      "items_per_second": 6.2206000800280571e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 1.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)1; bool is_training = false]": 7.0429798546002954e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 3.0000000000000000e+00,
      "input[2]": 2.2400000000000000e+02,
      "input[3]": 2.2400000000000000e+02,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 3.0000000000000000e+00,
      "input_height": 2.2400000000000000e+02,
      "input_size": 1.9267584000000000e+07,
      "input_width": 2.2400000000000000e+02,
      "is_training": 0.0000000000000000e+00,
      "num_iterations": 2.2600000000000000e+03,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 3.0000000000000000e+00,
      "output_height": 2.2400000000000000e+02,
      "output_size": 1.9267584000000000e+07,
      "output_width": 2.2400000000000000e+02,
      "predicted_flops": 6.2206000800280571e+10,
      "predicted_flops_count": 1.9267584000000000e+07
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_128__2213003517432460084<CUDNN_BATCHNORM_SPATIAL_PERSISTENT>/input[0]:128/input[1]:3/input[2]:224/input[3]:224/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/BATCHNORM_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_128__11989037708326527659<CUDNN_BATCHNORM_SPATIAL>/input[0]:128/input[1]:3/input[2]:224/input[3]:224/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 191,
      "real_time": 3.6607090205792827e+06,
      "cpu_time": 3.8581848377054762e+06,
      "time_unit": "ns",
      "items_per_second": 5.2633475896838789e+09,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 1.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)1; bool is_training = true]": 1.2389518253260638e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 3.0000000000000000e+00,
      "input[2]": 2.2400000000000000e+02,
      "input[3]": 2.2400000000000000e+02,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 3.0000000000000000e+00,
      "input_height": 2.2400000000000000e+02,
      "input_size": 1.9267584000000000e+07,
      "input_width": 2.2400000000000000e+02,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 1.9100000000000000e+02,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 3.0000000000000000e+00,
      "output_height": 2.2400000000000000e+02,
      "output_size": 1.9267584000000000e+07,
      "output_width": 2.2400000000000000e+02,
      "predicted_flops": 5.2633475896838789e+09,
      "predicted_flops_count": 1.9267584000000000e+07
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_128__11989037708326527659<CUDNN_BATCHNORM_SPATIAL_PERSISTENT>/input[0]:128/input[1]:3/input[2]:224/input[3]:224/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 191,
      "real_time": 3.6599368212929885e+06,
      "cpu_time": 3.8569864554886343e+06,
      "time_unit": "ns",
      "items_per_second": 5.2644580878839102e+09,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 2.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)2; bool is_training = true]": 8.6489340726076344e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 3.0000000000000000e+00,
      "input[2]": 2.2400000000000000e+02,
      "input[3]": 2.2400000000000000e+02,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 3.0000000000000000e+00,
      "input_height": 2.2400000000000000e+02,
      "input_size": 1.9267584000000000e+07,
      "input_width": 2.2400000000000000e+02,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 1.9100000000000000e+02,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 3.0000000000000000e+00,
      "output_height": 2.2400000000000000e+02,
      "output_size": 1.9267584000000000e+07,
      "output_width": 2.2400000000000000e+02,
      "predicted_flops": 5.2644580878839102e+09,
      "predicted_flops_count": 1.9267584000000000e+07
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_128__15237176484055752321<CUDNN_BATCHNORM_SPATIAL>/input[0]:128/input[1]:256/input[2]:28/input[3]:28/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 1981,
      "real_time": 3.5332992453958344e+05,
      "cpu_time": 3.6125292630045977e+05,
      "time_unit": "ns",
      "items_per_second": 7.2708565608973618e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 1.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)1; bool is_training = false]": 7.0429798546002954e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 2.5690112000000000e+07,
      "input_width": 2.8000000000000000e+01,
      "is_training": 0.0000000000000000e+00,
      "num_iterations": 1.9810000000000000e+03,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 2.5690112000000000e+07,
      "output_width": 2.8000000000000000e+01,
      "predicted_flops": 7.2708565608973618e+10,
      "predicted_flops_count": 2.5690112000000000e+07
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_128__15237176484055752321<CUDNN_BATCHNORM_SPATIAL_PERSISTENT>/input[0]:128/input[1]:256/input[2]:28/input[3]:28/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/BATCHNORM_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_128__7756016558287392542<CUDNN_BATCHNORM_SPATIAL>/input[0]:128/input[1]:256/input[2]:28/input[3]:28/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 1275,
      "real_time": 5.4956368535903154e+05,
      "cpu_time": 5.5996260941195511e+05,
      "time_unit": "ns",
      "items_per_second": 4.6746378416937386e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 1.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)1; bool is_training = true]": 1.2389518253260638e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 2.5690112000000000e+07,
      "input_width": 2.8000000000000000e+01,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 1.2750000000000000e+03,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 2.5690112000000000e+07,
      "output_width": 2.8000000000000000e+01,
      "predicted_flops": 4.6746378416937386e+10,
      "predicted_flops_count": 2.5690112000000000e+07
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_128__7756016558287392542<CUDNN_BATCHNORM_SPATIAL_PERSISTENT>/input[0]:128/input[1]:256/input[2]:28/input[3]:28/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 1502,
      "real_time": 4.6603768720516638e+05,
      "cpu_time": 4.7526401198297058e+05,
      "time_unit": "ns",
      "items_per_second": 5.5124537575628082e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 2.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)2; bool is_training = true]": 8.6489340726076344e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 2.5690112000000000e+07,
      "input_width": 2.8000000000000000e+01,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 1.5020000000000000e+03,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 2.5690112000000000e+07,
      "output_width": 2.8000000000000000e+01,
      "predicted_flops": 5.5124537575628082e+10,
      "predicted_flops_count": 2.5690112000000000e+07
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_128__13532161854996290001<CUDNN_BATCHNORM_SPATIAL>/input[0]:128/input[1]:64/input[2]:112/input[3]:112/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 482,
      "real_time": 1.4529522267823336e+06,
      "cpu_time": 1.4891233817421093e+06,
      "time_unit": "ns",
      "items_per_second": 7.0725276513440735e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 1.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)1; bool is_training = false]": 7.0429798546002954e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 1.1200000000000000e+02,
      "input[3]": 1.1200000000000000e+02,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 1.1200000000000000e+02,
      "input_size": 1.0276044800000000e+08,
      "input_width": 1.1200000000000000e+02,
      "is_training": 0.0000000000000000e+00,
      "num_iterations": 4.8200000000000000e+02,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 1.1200000000000000e+02,
      "output_size": 1.0276044800000000e+08,
      "output_width": 1.1200000000000000e+02,
      "predicted_flops": 7.0725276513440735e+10,
      "predicted_flops_count": 1.0276044800000000e+08
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_128__13532161854996290001<CUDNN_BATCHNORM_SPATIAL_PERSISTENT>/input[0]:128/input[1]:64/input[2]:112/input[3]:112/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/BATCHNORM_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_128__224143406294992974<CUDNN_BATCHNORM_SPATIAL>/input[0]:128/input[1]:64/input[2]:112/input[3]:112/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 320,
      "real_time": 2.1900865860516205e+06,
      "cpu_time": 2.2644164499936895e+06,
      "time_unit": "ns",
      "items_per_second": 4.6920723890310120e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 1.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)1; bool is_training = true]": 1.2389518253260638e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 1.1200000000000000e+02,
      "input[3]": 1.1200000000000000e+02,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 1.1200000000000000e+02,
      "input_size": 1.0276044800000000e+08,
      "input_width": 1.1200000000000000e+02,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 3.2000000000000000e+02,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 1.1200000000000000e+02,
      "output_size": 1.0276044800000000e+08,
      "output_width": 1.1200000000000000e+02,
      "predicted_flops": 4.6920723890310120e+10,
      "predicted_flops_count": 1.0276044800000000e+08
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_128__224143406294992974<CUDNN_BATCHNORM_SPATIAL_PERSISTENT>/input[0]:128/input[1]:64/input[2]:112/input[3]:112/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 346,
      "real_time": 2.0268094918362238e+06,
      "cpu_time": 2.0912394711006584e+06,
      "time_unit": "ns",
      "items_per_second": 5.0700595400755882e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 2.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)2; bool is_training = true]": 8.6489340726076344e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 1.1200000000000000e+02,
      "input[3]": 1.1200000000000000e+02,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 1.1200000000000000e+02,
      "input_size": 1.0276044800000000e+08,
      "input_width": 1.1200000000000000e+02,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 3.4600000000000000e+02,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 1.1200000000000000e+02,
      "output_size": 1.0276044800000000e+08,
      "output_width": 1.1200000000000000e+02,
      "predicted_flops": 5.0700595400755882e+10,
      "predicted_flops_count": 1.0276044800000000e+08
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_128__17303674499206576512<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:128/input[1]:128/input[2]:112/input[3]:112/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 108,
      "real_time": 6.4587847812584154e+06,
      "cpu_time": 7.0631891944496296e+06,
      "time_unit": "ns",
      "items_per_second": 3.1820366053435329e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = false]": 1.4627515035010154e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 1.2800000000000000e+02,
      "input[2]": 1.1200000000000000e+02,
      "input[3]": 1.1200000000000000e+02,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 1.2800000000000000e+02,
      "input_height": 1.1200000000000000e+02,
      "input_size": 2.0552089600000000e+08,
      "input_width": 1.1200000000000000e+02,
      "is_training": 0.0000000000000000e+00,
      "num_iterations": 1.0800000000000000e+02,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 1.1200000000000000e+02,
      "output_size": 2.0552089600000000e+08,
      "output_width": 1.1200000000000000e+02,
      "predicted_flops": 3.1820366053435329e+10,
      "predicted_flops_count": 2.0552089600000000e+08
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_128__2236656765198613675<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:128/input[1]:128/input[2]:112/input[3]:112/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 76,
      "real_time": 9.2295401631609388e+06,
      "cpu_time": 1.0450089828934420e+07,
      "time_unit": "ns",
      "items_per_second": 2.2267728658933868e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = true]": 9.0033003156525926e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 1.2800000000000000e+02,
      "input[2]": 1.1200000000000000e+02,
      "input[3]": 1.1200000000000000e+02,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 1.2800000000000000e+02,
      "input_height": 1.1200000000000000e+02,
      "input_size": 2.0552089600000000e+08,
      "input_width": 1.1200000000000000e+02,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 7.6000000000000000e+01,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 1.1200000000000000e+02,
      "output_size": 2.0552089600000000e+08,
      "output_width": 1.1200000000000000e+02,
      "predicted_flops": 2.2267728658933868e+10,
      "predicted_flops_count": 2.0552089600000000e+08
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_128__13794862331259056757<CUDNN_BATCHNORM_SPATIAL>/input[0]:128/input[1]:64/input[2]:56/input[3]:56/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 1982,
      "real_time": 3.5308513664497173e+05,
      "cpu_time": 3.6099084712673537e+05,
      "time_unit": "ns",
      "items_per_second": 7.2758973215662415e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 1.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)1; bool is_training = false]": 7.0429798546002954e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 2.5690112000000000e+07,
      "input_width": 5.6000000000000000e+01,
      "is_training": 0.0000000000000000e+00,
      "num_iterations": 1.9820000000000000e+03,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 5.6000000000000000e+01,
      "output_size": 2.5690112000000000e+07,
      "output_width": 5.6000000000000000e+01,
      "predicted_flops": 7.2758973215662415e+10,
      "predicted_flops_count": 2.5690112000000000e+07
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_128__13794862331259056757<CUDNN_BATCHNORM_SPATIAL_PERSISTENT>/input[0]:128/input[1]:64/input[2]:56/input[3]:56/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/BATCHNORM_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_128__551275942413886442<CUDNN_BATCHNORM_SPATIAL>/input[0]:128/input[1]:64/input[2]:56/input[3]:56/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 1261,
      "real_time": 5.5499309596356703e+05,
      "cpu_time": 5.6548937906314572e+05,
      "time_unit": "ns",
      "items_per_second": 4.6289065912427940e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 1.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)1; bool is_training = true]": 1.2389518253260638e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 2.5690112000000000e+07,
      "input_width": 5.6000000000000000e+01,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 1.2610000000000000e+03,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 5.6000000000000000e+01,
      "output_size": 2.5690112000000000e+07,
      "output_width": 5.6000000000000000e+01,
      "predicted_flops": 4.6289065912427940e+10,
      "predicted_flops_count": 2.5690112000000000e+07
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_128__551275942413886442<CUDNN_BATCHNORM_SPATIAL_PERSISTENT>/input[0]:128/input[1]:64/input[2]:56/input[3]:56/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 1435,
      "real_time": 4.8789822318808595e+05,
      "cpu_time": 4.9739984181222174e+05,
      "time_unit": "ns",
      "items_per_second": 5.2654653735224609e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 2.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)2; bool is_training = true]": 8.6489340726076344e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 2.5690112000000000e+07,
      "input_width": 5.6000000000000000e+01,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 1.4350000000000000e+03,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 5.6000000000000000e+01,
      "output_size": 2.5690112000000000e+07,
      "output_width": 5.6000000000000000e+01,
      "predicted_flops": 5.2654653735224609e+10,
      "predicted_flops_count": 2.5690112000000000e+07
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_128__3151323325098886682<CUDNN_BATCHNORM_SPATIAL>/input[0]:128/input[1]:128/input[2]:56/input[3]:56/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 1001,
      "real_time": 6.9918974260143656e+05,
      "cpu_time": 7.1225256942716578e+05,
      "time_unit": "ns",
      "items_per_second": 7.3485380104165207e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 1.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)1; bool is_training = false]": 7.0429798546002954e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 1.2800000000000000e+02,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 1.2800000000000000e+02,
      "input_height": 5.6000000000000000e+01,
      "input_size": 5.1380224000000000e+07,
      "input_width": 5.6000000000000000e+01,
      "is_training": 0.0000000000000000e+00,
      "num_iterations": 1.0010000000000000e+03,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 5.6000000000000000e+01,
      "output_size": 5.1380224000000000e+07,
      "output_width": 5.6000000000000000e+01,
      "predicted_flops": 7.3485380104165207e+10,
      "predicted_flops_count": 5.1380224000000000e+07
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_128__3151323325098886682<CUDNN_BATCHNORM_SPATIAL_PERSISTENT>/input[0]:128/input[1]:128/input[2]:56/input[3]:56/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/BATCHNORM_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_128__10622878132572297093<CUDNN_BATCHNORM_SPATIAL>/input[0]:128/input[1]:128/input[2]:56/input[3]:56/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 659,
      "real_time": 1.0626134460888046e+06,
      "cpu_time": 1.0847803323230683e+06,
      "time_unit": "ns",
      "items_per_second": 4.8352695130215828e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 1.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)1; bool is_training = true]": 1.2389518253260638e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 1.2800000000000000e+02,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 1.2800000000000000e+02,
      "input_height": 5.6000000000000000e+01,
      "input_size": 5.1380224000000000e+07,
      "input_width": 5.6000000000000000e+01,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 6.5900000000000000e+02,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 5.6000000000000000e+01,
      "output_size": 5.1380224000000000e+07,
      "output_width": 5.6000000000000000e+01,
      "predicted_flops": 4.8352695130215828e+10,
      "predicted_flops_count": 5.1380224000000000e+07
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_128__10622878132572297093<CUDNN_BATCHNORM_SPATIAL_PERSISTENT>/input[0]:128/input[1]:128/input[2]:56/input[3]:56/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 726,
      "real_time": 9.6414853892797104e+05,
      "cpu_time": 9.8340162947962014e+05,
      "time_unit": "ns",
      "items_per_second": 5.3290776188002380e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 2.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)2; bool is_training = true]": 8.6489340726076344e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 1.2800000000000000e+02,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 1.2800000000000000e+02,
      "input_height": 5.6000000000000000e+01,
      "input_size": 5.1380224000000000e+07,
      "input_width": 5.6000000000000000e+01,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 7.2600000000000000e+02,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 5.6000000000000000e+01,
      "output_size": 5.1380224000000000e+07,
      "output_width": 5.6000000000000000e+01,
      "predicted_flops": 5.3290776188002380e+10,
      "predicted_flops_count": 5.1380224000000000e+07
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_128__17019452842774484627<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:128/input[1]:512/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 2129,
      "real_time": 3.2873997731235350e+05,
      "cpu_time": 3.3646926162213553e+05,
      "time_unit": "ns",
      "items_per_second": 3.9073604935475266e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = false]": 1.4627515035010154e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 1.2845056000000000e+07,
      "input_width": 1.4000000000000000e+01,
      "is_training": 0.0000000000000000e+00,
      "num_iterations": 2.1290000000000000e+03,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 1.2845056000000000e+07,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 3.9073604935475266e+10,
      "predicted_flops_count": 1.2845056000000000e+07
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_128__222942533071115192<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:128/input[1]:512/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 1393,
      "real_time": 5.0216790297712496e+05,
      "cpu_time": 5.1192598994445341e+05,
      "time_unit": "ns",
      "items_per_second": 2.5579205528365135e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = true]": 9.0033003156525926e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 1.2845056000000000e+07,
      "input_width": 1.4000000000000000e+01,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 1.3930000000000000e+03,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 1.2845056000000000e+07,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 2.5579205528365135e+10,
      "predicted_flops_count": 1.2845056000000000e+07
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_128__12927673252549650035<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:128/input[1]:512/input[2]:28/input[3]:28/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 435,
      "real_time": 1.6103821758437774e+06,
      "cpu_time": 1.6537873632204402e+06,
      "time_unit": "ns",
      "items_per_second": 3.1905608973272926e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = false]": 1.4627515035010154e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 5.1380224000000000e+07,
      "input_width": 2.8000000000000000e+01,
      "is_training": 0.0000000000000000e+00,
      "num_iterations": 4.3500000000000000e+02,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 5.1380224000000000e+07,
      "output_width": 2.8000000000000000e+01,
      "predicted_flops": 3.1905608973272926e+10,
      "predicted_flops_count": 5.1380224000000000e+07
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_128__6647701629289636696<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:128/input[1]:512/input[2]:28/input[3]:28/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 303,
      "real_time": 2.3139017071611811e+06,
      "cpu_time": 2.3967277095800499e+06,
      "time_unit": "ns",
      "items_per_second": 2.2205015814192047e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = true]": 9.0033003156525926e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 5.1380224000000000e+07,
      "input_width": 2.8000000000000000e+01,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 3.0300000000000000e+02,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 5.1380224000000000e+07,
      "output_width": 2.8000000000000000e+01,
      "predicted_flops": 2.2205015814192047e+10,
      "predicted_flops_count": 5.1380224000000000e+07
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_128__7342692363450781667<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:128/input[1]:256/input[2]:56/input[3]:56/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 218,
      "real_time": 3.2137056285036951e+06,
      "cpu_time": 3.3674792110077925e+06,
      "time_unit": "ns",
      "items_per_second": 3.1975687844143143e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = false]": 1.4627515035010154e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 5.6000000000000000e+01,
      "input_size": 1.0276044800000000e+08,
      "input_width": 5.6000000000000000e+01,
      "is_training": 0.0000000000000000e+00,
      "num_iterations": 2.1800000000000000e+02,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 5.6000000000000000e+01,
      "output_size": 1.0276044800000000e+08,
      "output_width": 5.6000000000000000e+01,
      "predicted_flops": 3.1975687844143143e+10,
      "predicted_flops_count": 1.0276044800000000e+08
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_128__10002293494626339528<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:128/input[1]:256/input[2]:56/input[3]:56/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 152,
      "real_time": 4.6061946746991258e+06,
      "cpu_time": 4.9157411052721944e+06,
      "time_unit": "ns",
      "items_per_second": 2.2309184751665375e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = true]": 9.0033003156525926e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 5.6000000000000000e+01,
      "input_size": 1.0276044800000000e+08,
      "input_width": 5.6000000000000000e+01,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 1.5200000000000000e+02,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 5.6000000000000000e+01,
      "output_size": 1.0276044800000000e+08,
      "output_width": 5.6000000000000000e+01,
      "predicted_flops": 2.2309184751665375e+10,
      "predicted_flops_count": 1.0276044800000000e+08
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__9607949287547158492<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:1/input[1]:544/input[2]:7/input[3]:7/filter_count:544/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:4/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__9607949287547158492<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:1/input[1]:544/input[2]:7/input[3]:7/filter_count:544/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:4/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__9607949287547158492<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:1/input[1]:544/input[2]:7/input[3]:7/filter_count:544/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:4/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__9607949287547158492<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:1/input[1]:544/input[2]:7/input[3]:7/filter_count:544/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:4/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__9607949287547158492<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:1/input[1]:544/input[2]:7/input[3]:7/filter_count:544/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:4/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__9607949287547158492<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:1/input[1]:544/input[2]:7/input[3]:7/filter_count:544/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:4/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__9607949287547158492<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:1/input[1]:544/input[2]:7/input[3]:7/filter_count:544/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:4/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__9607949287547158492<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:1/input[1]:544/input[2]:7/input[3]:7/filter_count:544/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:4/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__10859654046309683015<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:256/input[2]:27/input[3]:27/filter_count:32/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 2710,
      "real_time": 2.5836781178071848e+05,
      "cpu_time": 2.6548310036961047e+05,
      "time_unit": "ns",
      "items_per_second": 2.9586189499827109e+12,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 3.0105599761009216e-01,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4730153338016043e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 3.2000000000000000e+01,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 2.7000000000000000e+01,
      "input[3]": 2.7000000000000000e+01,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 2.7000000000000000e+01,
      "input_size": 2.3887872000000000e+07,
      "input_width": 2.7000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 3.2000000000000000e+01,
      "num_iterations": 2.7100000000000000e+03,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 3.2000000000000000e+01,
      "output_height": 2.7000000000000000e+01,
      "output_size": 2.9859840000000000e+06,
      "output_width": 2.7000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 2.9586189499827109e+12,
      "predicted_advised_flops_count": 7.6441190400000000e+08,
      "predicted_flops": 2.9586189499827109e+12,
      "predicted_flops_count": 7.6441190400000000e+08,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__10859654046309683015<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:256/input[2]:27/input[3]:27/filter_count:32/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 2541,
      "real_time": 2.7380074169677350e+05,
      "cpu_time": 2.8100910704319086e+05,
      "time_unit": "ns",
      "items_per_second": 2.7918547600085186e+12,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 4.3800000000000000e+03,
      "advised_time": 2.5907200574874878e-01,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.2419525699096977e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 3.2000000000000000e+01,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 2.7000000000000000e+01,
      "input[3]": 2.7000000000000000e+01,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 2.7000000000000000e+01,
      "input_size": 2.3887872000000000e+07,
      "input_width": 2.7000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 3.2000000000000000e+01,
      "num_iterations": 2.5410000000000000e+03,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 3.2000000000000000e+01,
      "output_height": 2.7000000000000000e+01,
      "output_size": 2.9859840000000000e+06,
      "output_width": 2.7000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 2.7918547600085186e+12,
      "predicted_advised_flops_count": 7.6441190400000000e+08,
      "predicted_flops": 2.7918547600085186e+12,
      "predicted_flops_count": 7.6441190400000000e+08,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 4.3800000000000000e+03,
      "workspace_megabytes": 4.1770935058593750e-03
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__10859654046309683015<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:256/input[2]:27/input[3]:27/filter_count:32/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 1064,
      "real_time": 6.5818164985376596e+05,
      "cpu_time": 6.7043043514800083e+05,
      "time_unit": "ns",
      "items_per_second": 1.1613995986819690e+12,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 9.5551488000000000e+07,
      "advised_time": 6.5433597564697266e-01,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)2; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4280899851402570e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 2.0000000000000000e+00,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 3.2000000000000000e+01,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 2.7000000000000000e+01,
      "input[3]": 2.7000000000000000e+01,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 2.7000000000000000e+01,
      "input_size": 2.3887872000000000e+07,
      "input_width": 2.7000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 3.2000000000000000e+01,
      "num_iterations": 1.0640000000000000e+03,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 3.2000000000000000e+01,
      "output_height": 2.7000000000000000e+01,
      "output_size": 2.9859840000000000e+06,
      "output_width": 2.7000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 1.1613995986819690e+12,
      "predicted_advised_flops_count": 7.6441190400000000e+08,
      "predicted_flops": 1.1613995986819690e+12,
      "predicted_flops_count": 7.6441190400000000e+08,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 9.5551488000000000e+07,
      "workspace_megabytes": 9.1125000000000000e+01
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__10859654046309683015<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:256/input[2]:27/input[3]:27/filter_count:32/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__10859654046309683015<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:256/input[2]:27/input[3]:27/filter_count:32/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 494,
      "real_time": 1.4179585921495159e+06,
      "cpu_time": 1.4524360060808589e+06,
      "time_unit": "ns",
      "items_per_second": 5.3909324872541626e+11,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 3.5654860800000000e+08,
      "advised_time": 1.4735360145568848e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)4; cudnnMathType_t math_type = (cudnnMathType_t)0]": 2.3237108083472476e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 4.0000000000000000e+00,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 3.2000000000000000e+01,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 2.7000000000000000e+01,
      "input[3]": 2.7000000000000000e+01,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 2.7000000000000000e+01,
      "input_size": 2.3887872000000000e+07,
      "input_width": 2.7000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 3.2000000000000000e+01,
      "num_iterations": 4.9400000000000000e+02,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 3.2000000000000000e+01,
      "output_height": 2.7000000000000000e+01,
      "output_size": 2.9859840000000000e+06,
      "output_width": 2.7000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 5.3909324872541626e+11,
      "predicted_advised_flops_count": 7.6441190400000000e+08,
      "predicted_flops": 7.5937922731539294e+11,
      "predicted_flops_count": 1.0767683000717218e+09,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 3.5654860800000000e+08,
      "workspace_megabytes": 3.4003125000000000e+02
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__10859654046309683015<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:256/input[2]:27/input[3]:27/filter_count:32/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 809,
      "real_time": 8.6477883636424202e+05,
      "cpu_time": 8.8151749938649428e+05,
      "time_unit": "ns",
      "items_per_second": 8.8393918983238416e+11,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.3647913600000000e+08,
      "advised_time": 9.3798398971557617e-01,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)5; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.6667819325789325e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 5.0000000000000000e+00,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 3.2000000000000000e+01,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 2.7000000000000000e+01,
      "input[3]": 2.7000000000000000e+01,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 2.7000000000000000e+01,
      "input_size": 2.3887872000000000e+07,
      "input_width": 2.7000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 3.2000000000000000e+01,
      "num_iterations": 8.0900000000000000e+02,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 3.2000000000000000e+01,
      "output_height": 2.7000000000000000e+01,
      "output_size": 2.9859840000000000e+06,
      "output_width": 2.7000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 8.8393918983238416e+11,
      "predicted_advised_flops_count": 7.6441190400000000e+08,
      "predicted_flops": 1.2451372013204434e+12,
      "predicted_flops_count": 1.0767683000717218e+09,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 1.3647913600000000e+08,
      "workspace_megabytes": 1.3015664672851562e+02
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__10859654046309683015<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:256/input[2]:27/input[3]:27/filter_count:32/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__10859654046309683015<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:256/input[2]:27/input[3]:27/filter_count:32/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__14936272760149814657<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:1/input[1]:136/input[2]:28/input[3]:28/filter_count:136/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:136/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__14936272760149814657<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:1/input[1]:136/input[2]:28/input[3]:28/filter_count:136/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:136/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__14936272760149814657<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:1/input[1]:136/input[2]:28/input[3]:28/filter_count:136/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:136/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__14936272760149814657<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:1/input[1]:136/input[2]:28/input[3]:28/filter_count:136/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:136/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__14936272760149814657<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:1/input[1]:136/input[2]:28/input[3]:28/filter_count:136/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:136/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__14936272760149814657<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:1/input[1]:136/input[2]:28/input[3]:28/filter_count:136/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:136/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__14936272760149814657<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:1/input[1]:136/input[2]:28/input[3]:28/filter_count:136/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:136/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__14936272760149814657<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:1/input[1]:136/input[2]:28/input[3]:28/filter_count:136/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:136/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__8883220012763298277<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:1/input[1]:192/input[2]:6/input[3]:6/filter_count:384/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 5817,
      "real_time": 1.1598548765136111e+05,
      "cpu_time": 1.2209825236376541e+05,
      "time_unit": "ns",
      "items_per_second": 2.2883966380158184e+10,
      "advised_convolution_algorithm": 6.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 1.1673600226640701e-01,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4730153338016043e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 3.8400000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 1.9200000000000000e+02,
      "input[2]": 6.0000000000000000e+00,
      "input[3]": 6.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 1.9200000000000000e+02,
      "input_height": 6.0000000000000000e+00,
      "input_size": 6.9120000000000000e+03,
      "input_width": 6.0000000000000000e+00,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 3.8400000000000000e+02,
      "num_iterations": 5.8170000000000000e+03,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 3.8400000000000000e+02,
      "output_height": 6.0000000000000000e+00,
      "output_size": 1.3824000000000000e+04,
      "output_width": 6.0000000000000000e+00,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "predicted_advised_flops": -8.6217682940290233e+03,
      "predicted_advised_flops_count": -1.0000000000000000e+00,
      "predicted_flops": 2.0595569742142365e+11,
      "predicted_flops_count": 2.3887872000000000e+07,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__8883220012763298277<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:1/input[1]:192/input[2]:6/input[3]:6/filter_count:384/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 3101,
      "real_time": 2.2634206937016486e+05,
      "cpu_time": 2.3218945952951425e+05,
      "time_unit": "ns",
      "items_per_second": 1.1726534123266539e+10,
      "advised_convolution_algorithm": 6.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 2.2400000000000000e+02,
      "advised_time": 2.2835199534893036e-01,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.2419525699096977e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 3.8400000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 1.9200000000000000e+02,
      "input[2]": 6.0000000000000000e+00,
      "input[3]": 6.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 1.9200000000000000e+02,
      "input_height": 6.0000000000000000e+00,
      "input_size": 6.9120000000000000e+03,
      "input_width": 6.0000000000000000e+00,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 3.8400000000000000e+02,
      "num_iterations": 3.1010000000000000e+03,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 3.8400000000000000e+02,
      "output_height": 6.0000000000000000e+00,
      "output_size": 1.3824000000000000e+04,
      "output_width": 6.0000000000000000e+00,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "predicted_advised_flops": -4.4180916202748758e+03,
      "predicted_advised_flops_count": -1.0000000000000000e+00,
      "predicted_flops": 1.0553880710939885e+11,
      "predicted_flops_count": 2.3887872000000000e+07,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 2.2400000000000000e+02,
      "workspace_megabytes": 2.1362304687500000e-04
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__8883220012763298277<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:1/input[1]:192/input[2]:6/input[3]:6/filter_count:384/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 5473,
      "real_time": 1.2709713707224185e+05,
      "cpu_time": 1.3326028485353402e+05,
      "time_unit": "ns",
      "items_per_second": 2.0883302811859180e+10,
      "advised_convolution_algorithm": 6.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 2.4883200000000000e+05,
      "advised_time": 1.2800000607967377e-01,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)2; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4280899851402570e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 2.0000000000000000e+00,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 3.8400000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 1.9200000000000000e+02,
      "input[2]": 6.0000000000000000e+00,
      "input[3]": 6.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 1.9200000000000000e+02,
      "input_height": 6.0000000000000000e+00,
      "input_size": 6.9120000000000000e+03,
      "input_width": 6.0000000000000000e+00,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 3.8400000000000000e+02,
      "num_iterations": 5.4730000000000000e+03,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 3.8400000000000000e+02,
      "output_height": 6.0000000000000000e+00,
      "output_size": 1.3824000000000000e+04,
      "output_width": 6.0000000000000000e+00,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "predicted_advised_flops": -7.8679978403573423e+03,
      "predicted_advised_flops_count": -1.0000000000000000e+00,
      "predicted_flops": 1.8794972530673264e+11,
      "predicted_flops_count": 2.3887872000000000e+07,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 2.4883200000000000e+05,
      "workspace_megabytes": 2.3730468750000000e-01
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__8883220012763298277<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:1/input[1]:192/input[2]:6/input[3]:6/filter_count:384/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__8883220012763298277<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:1/input[1]:192/input[2]:6/input[3]:6/filter_count:384/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 1843,
      "real_time": 3.8033732500738843e+05,
      "cpu_time": 3.8840049538934324e+05,
      "time_unit": "ns",
      "items_per_second": 6.9785630425529222e+09,
      "advised_convolution_algorithm": 6.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.7296588800000000e+08,
      "advised_time": 3.8192000985145569e-01,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)4; cudnnMathType_t math_type = (cudnnMathType_t)0]": 2.3237108083472476e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 4.0000000000000000e+00,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 3.8400000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 1.9200000000000000e+02,
      "input[2]": 6.0000000000000000e+00,
      "input[3]": 6.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 1.9200000000000000e+02,
      "input_height": 6.0000000000000000e+00,
      "input_size": 6.9120000000000000e+03,
      "input_width": 6.0000000000000000e+00,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 3.8400000000000000e+02,
      "num_iterations": 1.8430000000000000e+03,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 3.8400000000000000e+02,
      "output_height": 6.0000000000000000e+00,
      "output_size": 1.3824000000000000e+04,
      "output_width": 6.0000000000000000e+00,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "predicted_advised_flops": -2.6292449734734137e+03,
      "predicted_advised_flops_count": -1.0000000000000000e+00,
      "predicted_flops": 4.3339075024356071e+10,
      "predicted_flops_count": 1.6483467863058105e+07,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 1.7296588800000000e+08,
      "workspace_megabytes": 1.6495312500000000e+02
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__8883220012763298277<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:1/input[1]:192/input[2]:6/input[3]:6/filter_count:384/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 475,
      "real_time": 1.4770953555738453e+06,
      "cpu_time": 1.5166071178899936e+06,
      "time_unit": "ns",
      "items_per_second": 1.7969103957874479e+09,
      "advised_convolution_algorithm": 6.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 3.2339558400000000e+08,
      "advised_time": 1.5943679809570312e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)5; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.6667819325789325e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 5.0000000000000000e+00,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 3.8400000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 1.9200000000000000e+02,
      "input[2]": 6.0000000000000000e+00,
      "input[3]": 6.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 1.9200000000000000e+02,
      "input_height": 6.0000000000000000e+00,
      "input_size": 6.9120000000000000e+03,
      "input_width": 6.0000000000000000e+00,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 3.8400000000000000e+02,
      "num_iterations": 4.7500000000000000e+02,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 3.8400000000000000e+02,
      "output_height": 6.0000000000000000e+00,
      "output_size": 1.3824000000000000e+04,
      "output_width": 6.0000000000000000e+00,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "predicted_advised_flops": -6.7700436280331007e+02,
      "predicted_advised_flops_count": -1.0000000000000000e+00,
      "predicted_flops": 1.1159379657418491e+10,
      "predicted_flops_count": 1.6483467863058105e+07,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 3.2339558400000000e+08,
      "workspace_megabytes": 3.0841406250000000e+02
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__8883220012763298277<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:1/input[1]:192/input[2]:6/input[3]:6/filter_count:384/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 9824,
      "real_time": 7.0950890112696856e+04,
      "cpu_time": 7.7218060160513152e+04,
      "time_unit": "ns",
      "items_per_second": 3.7409086704678596e+10,
      "advised_convolution_algorithm": 6.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 7.3743360000000000e+06,
      "advised_time": 1.0444799810647964e-01,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)6; cudnnMathType_t math_type = (cudnnMathType_t)0]": 5.7500739770702787e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 6.0000000000000000e+00,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 3.8400000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 1.9200000000000000e+02,
      "input[2]": 6.0000000000000000e+00,
      "input[3]": 6.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 1.9200000000000000e+02,
      "input_height": 6.0000000000000000e+00,
      "input_size": 6.9120000000000000e+03,
      "input_width": 6.0000000000000000e+00,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 3.8400000000000000e+02,
      "num_iterations": 9.8240000000000000e+03,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 3.8400000000000000e+02,
      "output_height": 6.0000000000000000e+00,
      "output_size": 1.3824000000000000e+04,
      "output_width": 6.0000000000000000e+00,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "predicted_advised_flops": -1.4094255877715159e+04,
      "predicted_advised_flops_count": -1.0000000000000000e+00,
      "predicted_flops": -1.4094255877715159e+04,
      "predicted_flops_count": -1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 7.3743360000000000e+06,
      "workspace_megabytes": 7.0327148437500000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__8883220012763298277<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:1/input[1]:192/input[2]:6/input[3]:6/filter_count:384/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 6127,
      "real_time": 1.1448367996392233e+05,
      "cpu_time": 1.2094765366413495e+05,
      "time_unit": "ns",
      "items_per_second": 2.3184160404665802e+10,
      "advised_convolution_algorithm": 6.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.5925248000000000e+07,
      "advised_time": 1.4028799533843994e-01,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)7; cudnnMathType_t math_type = (cudnnMathType_t)0]": 8.2538945752816425e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 7.0000000000000000e+00,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 3.8400000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 1.9200000000000000e+02,
      "input[2]": 6.0000000000000000e+00,
      "input[3]": 6.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 1.9200000000000000e+02,
      "input_height": 6.0000000000000000e+00,
      "input_size": 6.9120000000000000e+03,
      "input_width": 6.0000000000000000e+00,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 3.8400000000000000e+02,
      "num_iterations": 6.1270000000000000e+03,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 3.8400000000000000e+02,
      "output_height": 6.0000000000000000e+00,
      "output_size": 1.3824000000000000e+04,
      "output_width": 6.0000000000000000e+00,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "predicted_advised_flops": -8.7348694618755599e+03,
      "predicted_advised_flops_count": -1.0000000000000000e+00,
      "predicted_flops": -8.7348694618755599e+03,
      "predicted_flops_count": -1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 1.5925248000000000e+07,
      "workspace_megabytes": 1.5187500000000000e+01
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__14633515634938261890<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:1/input[1]:832/input[2]:6/input[3]:6/filter_count:192/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 11534,
      "real_time": 6.0619012645071765e+04,
      "cpu_time": 6.6695744755418316e+04,
      "time_unit": "ns",
      "items_per_second": 9.4867661960632904e+10,
      "advised_convolution_algorithm": 0.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 6.1439998447895050e-02,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4730153338016043e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.9200000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 8.3200000000000000e+02,
      "input[2]": 6.0000000000000000e+00,
      "input[3]": 6.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 8.3200000000000000e+02,
      "input_height": 6.0000000000000000e+00,
      "input_size": 2.9952000000000000e+04,
      "input_width": 6.0000000000000000e+00,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.9200000000000000e+02,
      "num_iterations": 1.1534000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 1.9200000000000000e+02,
      "output_height": 6.0000000000000000e+00,
      "output_size": 6.9120000000000000e+03,
      "output_width": 6.0000000000000000e+00,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 9.4867661960632904e+10,
      "predicted_advised_flops_count": 5.7507840000000000e+06,
      "predicted_flops": 9.4867661960632904e+10,
      "predicted_flops_count": 5.7507840000000000e+06,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__14633515634938261890<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:1/input[1]:832/input[2]:6/input[3]:6/filter_count:192/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 6078,
      "real_time": 1.1486033698644921e+05,
      "cpu_time": 1.2111337347537342e+05,
      "time_unit": "ns",
      "items_per_second": 5.0067622565642090e+10,
      "advised_convolution_algorithm": 0.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 2.2400000000000000e+02,
      "advised_time": 1.1776000261306763e-01,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.2419525699096977e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.9200000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 8.3200000000000000e+02,
      "input[2]": 6.0000000000000000e+00,
      "input[3]": 6.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 8.3200000000000000e+02,
      "input_height": 6.0000000000000000e+00,
      "input_size": 2.9952000000000000e+04,
      "input_width": 6.0000000000000000e+00,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.9200000000000000e+02,
      "num_iterations": 6.0780000000000000e+03,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 1.9200000000000000e+02,
      "output_height": 6.0000000000000000e+00,
      "output_size": 6.9120000000000000e+03,
      "output_width": 6.0000000000000000e+00,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 5.0067622565642090e+10,
      "predicted_advised_flops_count": 5.7507840000000000e+06,
      "predicted_flops": 5.0067622565642090e+10,
      "predicted_flops_count": 5.7507840000000000e+06,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 2.2400000000000000e+02,
      "workspace_megabytes": 2.1362304687500000e-04
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__14633515634938261890<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:1/input[1]:832/input[2]:6/input[3]:6/filter_count:192/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 4932,
      "real_time": 1.4025788748182132e+05,
      "cpu_time": 1.4675224715831835e+05,
      "time_unit": "ns",
      "items_per_second": 4.1001501614270020e+10,
      "advised_convolution_algorithm": 0.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.1980800000000000e+05,
      "advised_time": 1.4233599603176117e-01,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)2; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4280899851402570e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 2.0000000000000000e+00,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.9200000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 8.3200000000000000e+02,
      "input[2]": 6.0000000000000000e+00,
      "input[3]": 6.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 8.3200000000000000e+02,
      "input_height": 6.0000000000000000e+00,
      "input_size": 2.9952000000000000e+04,
      "input_width": 6.0000000000000000e+00,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.9200000000000000e+02,
      "num_iterations": 4.9320000000000000e+03,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 1.9200000000000000e+02,
      "output_height": 6.0000000000000000e+00,
      "output_size": 6.9120000000000000e+03,
      "output_width": 6.0000000000000000e+00,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 4.1001501614270020e+10,
      "predicted_advised_flops_count": 5.7507840000000000e+06,
      "predicted_flops": 4.1001501614270020e+10,
      "predicted_flops_count": 5.7507840000000000e+06,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 1.1980800000000000e+05,
      "workspace_megabytes": 1.1425781250000000e-01
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__14633515634938261890<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:1/input[1]:832/input[2]:6/input[3]:6/filter_count:192/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__14633515634938261890<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:1/input[1]:832/input[2]:6/input[3]:6/filter_count:192/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 1015,
      "real_time": 6.6373137145858316e+05,
      "cpu_time": 6.7799115271232324e+05,
      "time_unit": "ns",
      "items_per_second": 8.6643245253909912e+09,
      "advised_convolution_algorithm": 0.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 3.7060608000000000e+08,
      "advised_time": 6.5945601463317871e-01,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)4; cudnnMathType_t math_type = (cudnnMathType_t)0]": 2.3237108083472476e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 4.0000000000000000e+00,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.9200000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 8.3200000000000000e+02,
      "input[2]": 6.0000000000000000e+00,
      "input[3]": 6.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 8.3200000000000000e+02,
      "input_height": 6.0000000000000000e+00,
      "input_size": 2.9952000000000000e+04,
      "input_width": 6.0000000000000000e+00,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.9200000000000000e+02,
      "num_iterations": 1.0150000000000000e+03,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 1.9200000000000000e+02,
      "output_height": 6.0000000000000000e+00,
      "output_size": 6.9120000000000000e+03,
      "output_width": 6.0000000000000000e+00,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 8.6643245253909912e+09,
      "predicted_advised_flops_count": 5.7507840000000000e+06,
      "predicted_flops": 5.3745372945617294e+10,
      "predicted_flops_count": 3.5672490094747595e+07,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 3.7060608000000000e+08,
      "workspace_megabytes": 3.5343750000000000e+02
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__14633515634938261890<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:1/input[1]:832/input[2]:6/input[3]:6/filter_count:192/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 3008,
      "real_time": 2.3187691375185634e+05,
      "cpu_time": 2.3904530485484269e+05,
      "time_unit": "ns",
      "items_per_second": 2.4801020105667854e+10,
      "advised_convolution_algorithm": 0.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 2.2561184000000000e+07,
      "advised_time": 2.5600001215934753e-01,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)5; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.6667819325789325e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 5.0000000000000000e+00,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.9200000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 8.3200000000000000e+02,
      "input[2]": 6.0000000000000000e+00,
      "input[3]": 6.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 8.3200000000000000e+02,
      "input_height": 6.0000000000000000e+00,
      "input_size": 2.9952000000000000e+04,
      "input_width": 6.0000000000000000e+00,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.9200000000000000e+02,
      "num_iterations": 3.0080000000000000e+03,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 1.9200000000000000e+02,
      "output_height": 6.0000000000000000e+00,
      "output_size": 6.9120000000000000e+03,
      "output_width": 6.0000000000000000e+00,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 2.4801020105667854e+10,
      "predicted_advised_flops_count": 5.7507840000000000e+06,
      "predicted_flops": 1.5384235333114102e+11,
      "predicted_flops_count": 3.5672490094747595e+07,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 2.2561184000000000e+07,
      "workspace_megabytes": 2.1516021728515625e+01
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__14633515634938261890<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:1/input[1]:832/input[2]:6/input[3]:6/filter_count:192/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__14633515634938261890<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:1/input[1]:832/input[2]:6/input[3]:6/filter_count:192/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__6011671299275867608<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:1/input[1]:224/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 22590,
      "real_time": 3.0994612499016624e+04,
      "cpu_time": 3.6933645773385564e+04,
      "time_unit": "ns",
      "items_per_second": 7.2525017051634998e+11,
      "advised_convolution_algorithm": 0.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 3.1743999570608139e-02,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4730153338016043e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 2.2400000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 2.2400000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 1.7561600000000000e+05,
      "input_width": 2.8000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 2.2590000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 1.0035200000000000e+05,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 7.2525017051634998e+11,
      "predicted_advised_flops_count": 2.2478848000000000e+07,
      "predicted_flops": 7.2525017051634998e+11,
      "predicted_flops_count": 2.2478848000000000e+07,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__6011671299275867608<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:1/input[1]:224/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 15888,
      "real_time": 4.4000453175620401e+04,
      "cpu_time": 4.9991375503871190e+04,
      "time_unit": "ns",
      "items_per_second": 5.1087764733420953e+11,
      "advised_convolution_algorithm": 0.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 4.7120000000000000e+03,
      "advised_time": 4.6048000454902649e-02,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.2419525699096977e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 2.2400000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 2.2400000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 1.7561600000000000e+05,
      "input_width": 2.8000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 1.5888000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 1.0035200000000000e+05,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 5.1087764733420953e+11,
      "predicted_advised_flops_count": 2.2478848000000000e+07,
      "predicted_flops": 5.1087764733420953e+11,
      "predicted_flops_count": 2.2478848000000000e+07,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 4.7120000000000000e+03,
      "workspace_megabytes": 4.4937133789062500e-03
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__6011671299275867608<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:1/input[1]:224/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 6303,
      "real_time": 1.1002822486436895e+05,
      "cpu_time": 1.1617724797767343e+05,
      "time_unit": "ns",
      "items_per_second": 2.0430074217510574e+11,
      "advised_convolution_algorithm": 0.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 7.0246400000000000e+05,
      "advised_time": 1.1264000087976456e-01,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)2; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4280899851402570e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 2.0000000000000000e+00,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 2.2400000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 2.2400000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 1.7561600000000000e+05,
      "input_width": 2.8000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 6.3030000000000000e+03,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 1.0035200000000000e+05,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 2.0430074217510574e+11,
      "predicted_advised_flops_count": 2.2478848000000000e+07,
      "predicted_flops": 2.0430074217510574e+11,
      "predicted_flops_count": 2.2478848000000000e+07,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 7.0246400000000000e+05,
      "workspace_megabytes": 6.6992187500000000e-01
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__6011671299275867608<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:1/input[1]:224/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__6011671299275867608<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:1/input[1]:224/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 1360,
      "real_time": 4.8629807037393813e+05,
      "cpu_time": 4.9704762646623584e+05,
      "time_unit": "ns",
      "items_per_second": 4.6224423598298317e+10,
      "advised_convolution_algorithm": 0.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 2.5162547200000000e+08,
      "advised_time": 4.8227199912071228e-01,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)4; cudnnMathType_t math_type = (cudnnMathType_t)0]": 2.3237108083472476e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 4.0000000000000000e+00,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 2.2400000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 2.2400000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 1.7561600000000000e+05,
      "input_width": 2.8000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 1.3600000000000000e+03,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 1.0035200000000000e+05,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 4.6224423598298317e+10,
      "predicted_advised_flops_count": 2.2478848000000000e+07,
      "predicted_flops": 4.9611507035327924e+11,
      "predicted_flops_count": 2.4125980139623022e+08,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 2.5162547200000000e+08,
      "workspace_megabytes": 2.3996875000000000e+02
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__6011671299275867608<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:1/input[1]:224/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 10406,
      "real_time": 6.7350439463346978e+04,
      "cpu_time": 7.3705618585222401e+04,
      "time_unit": "ns",
      "items_per_second": 3.3375948515129279e+11,
      "advised_convolution_algorithm": 0.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 5.2402240000000000e+06,
      "advised_time": 9.2160001397132874e-02,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)5; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.6667819325789325e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 5.0000000000000000e+00,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 2.2400000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 2.2400000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 1.7561600000000000e+05,
      "input_width": 2.8000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 1.0406000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 1.0035200000000000e+05,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 3.3375948515129279e+11,
      "predicted_advised_flops_count": 2.2478848000000000e+07,
      "predicted_flops": 3.5821563054169390e+12,
      "predicted_flops_count": 2.4125980139623022e+08,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 5.2402240000000000e+06,
      "workspace_megabytes": 4.9974670410156250e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__6011671299275867608<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:1/input[1]:224/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__6011671299275867608<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:1/input[1]:224/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__14256040405851014902<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:1/input[1]:512/input[2]:13/input[3]:13/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 17294,
      "real_time": 4.0495803576105209e+04,
      "cpu_time": 4.6464375101892416e+04,
      "time_unit": "ns",
      "items_per_second": 1.3674977432149556e+11,
      "advised_convolution_algorithm": 0.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 4.2975999414920807e-02,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4730153338016043e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 1.3000000000000000e+01,
      "input[3]": 1.3000000000000000e+01,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 1.3000000000000000e+01,
      "input_size": 8.6528000000000000e+04,
      "input_width": 1.3000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 1.7294000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 1.3000000000000000e+01,
      "output_size": 1.0816000000000000e+04,
      "output_width": 1.3000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 1.3674977432149556e+11,
      "predicted_advised_flops_count": 5.5377920000000000e+06,
      "predicted_flops": 1.3674977432149556e+11,
      "predicted_flops_count": 5.5377920000000000e+06,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__14256040405851014902<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:1/input[1]:512/input[2]:13/input[3]:13/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 9005,
      "real_time": 7.7504835276464219e+04,
      "cpu_time": 8.3535235536878230e+04,
      "time_unit": "ns",
      "items_per_second": 7.1450922774642075e+10,
      "advised_convolution_algorithm": 0.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.0200000000000000e+03,
      "advised_time": 7.9871997237205505e-02,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.2419525699096977e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 1.3000000000000000e+01,
      "input[3]": 1.3000000000000000e+01,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 1.3000000000000000e+01,
      "input_size": 8.6528000000000000e+04,
      "input_width": 1.3000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 9.0050000000000000e+03,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 1.3000000000000000e+01,
      "output_size": 1.0816000000000000e+04,
      "output_width": 1.3000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 7.1450922774642075e+10,
      "predicted_advised_flops_count": 5.5377920000000000e+06,
      "predicted_flops": 7.1450922774642075e+10,
      "predicted_flops_count": 5.5377920000000000e+06,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 1.0200000000000000e+03,
      "workspace_megabytes": 9.7274780273437500e-04
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__14256040405851014902<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:1/input[1]:512/input[2]:13/input[3]:13/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 5597,
      "real_time": 1.2489322977332234e+05,
      "cpu_time": 1.3111152313743447e+05,
      "time_unit": "ns",
      "items_per_second": 4.4340209713936729e+10,
      "advised_convolution_algorithm": 0.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 3.4611200000000000e+05,
      "advised_time": 1.2697599828243256e-01,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)2; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4280899851402570e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 2.0000000000000000e+00,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 1.3000000000000000e+01,
      "input[3]": 1.3000000000000000e+01,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 1.3000000000000000e+01,
      "input_size": 8.6528000000000000e+04,
      "input_width": 1.3000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 5.5970000000000000e+03,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 1.3000000000000000e+01,
      "output_size": 1.0816000000000000e+04,
      "output_width": 1.3000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 4.4340209713936729e+10,
      "predicted_advised_flops_count": 5.5377920000000000e+06,
      "predicted_flops": 4.4340209713936729e+10,
      "predicted_flops_count": 5.5377920000000000e+06,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 3.4611200000000000e+05,
      "workspace_megabytes": 3.3007812500000000e-01
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__14256040405851014902<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:1/input[1]:512/input[2]:13/input[3]:13/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__14256040405851014902<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:1/input[1]:512/input[2]:13/input[3]:13/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 4480,
      "real_time": 1.5656291237259470e+05,
      "cpu_time": 1.6333510781057569e+05,
      "time_unit": "ns",
      "items_per_second": 3.5371033382548096e+10,
      "advised_convolution_algorithm": 0.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 7.6808192000000000e+07,
      "advised_time": 1.6179199516773224e-01,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)4; cudnnMathType_t math_type = (cudnnMathType_t)0]": 2.3237108083472476e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 4.0000000000000000e+00,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 1.3000000000000000e+01,
      "input[3]": 1.3000000000000000e+01,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 1.3000000000000000e+01,
      "input_size": 8.6528000000000000e+04,
      "input_width": 1.3000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 4.4800000000000000e+03,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 1.3000000000000000e+01,
      "output_size": 1.0816000000000000e+04,
      "output_width": 1.3000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 3.5371033382548096e+10,
      "predicted_advised_flops_count": 5.5377920000000000e+06,
      "predicted_flops": 3.0174933148039069e+11,
      "predicted_flops_count": 4.7242754143053442e+07,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 7.6808192000000000e+07,
      "workspace_megabytes": 7.3250000000000000e+01
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__14256040405851014902<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:1/input[1]:512/input[2]:13/input[3]:13/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 7351,
      "real_time": 9.5251047422007439e+04,
      "cpu_time": 1.0142008488727572e+05,
      "time_unit": "ns",
      "items_per_second": 5.8138909228629768e+10,
      "advised_convolution_algorithm": 0.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 5.4752320000000000e+06,
      "advised_time": 1.1571200191974640e-01,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)5; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.6667819325789325e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 5.0000000000000000e+00,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 1.3000000000000000e+01,
      "input[3]": 1.3000000000000000e+01,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 1.3000000000000000e+01,
      "input_size": 8.6528000000000000e+04,
      "input_width": 1.3000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 7.3510000000000000e+03,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 1.3000000000000000e+01,
      "output_size": 1.0816000000000000e+04,
      "output_width": 1.3000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 5.8138909228629768e+10,
      "predicted_advised_flops_count": 5.5377920000000000e+06,
      "predicted_flops": 4.9598146604882550e+11,
      "predicted_flops_count": 4.7242754143053442e+07,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 5.4752320000000000e+06,
      "workspace_megabytes": 5.2215881347656250e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__14256040405851014902<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:1/input[1]:512/input[2]:13/input[3]:13/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__14256040405851014902<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:1/input[1]:512/input[2]:13/input[3]:13/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__16209620136994831937<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:1/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:7/filter_width:7/pad_height:3/pad_width:3/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 13871,
      "real_time": 5.0136303915655044e+04,
      "cpu_time": 5.6073786604866196e+04,
      "time_unit": "ns",
      "items_per_second": 1.9215201854941388e+11,
      "advised_convolution_algorithm": 0.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 5.1199998706579208e-02,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4730153338016043e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 7.0000000000000000e+00,
      "filter_width": 7.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 3.0000000000000000e+00,
      "input[2]": 2.2400000000000000e+02,
      "input[3]": 2.2400000000000000e+02,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 3.0000000000000000e+00,
      "input_height": 2.2400000000000000e+02,
      "input_size": 1.5052800000000000e+05,
      "input_width": 2.2400000000000000e+02,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 1.3871000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 1.1200000000000000e+02,
      "output_size": 8.0281600000000000e+05,
      "output_width": 1.1200000000000000e+02,
      "pad_height": 3.0000000000000000e+00,
      "pad_width": 3.0000000000000000e+00,
      "predicted_advised_flops": 2.3538622272303203e+12,
      "predicted_advised_flops_count": 1.1801395200000000e+08,
      "predicted_flops": 2.3538622272303203e+12,
      "predicted_flops_count": 1.1801395200000000e+08,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__16209620136994831937<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:1/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:7/filter_width:7/pad_height:3/pad_width:3/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 11228,
      "real_time": 6.1103449340754691e+04,
      "cpu_time": 6.7070377449816180e+04,
      "time_unit": "ns",
      "items_per_second": 1.5766363607847040e+11,
      "advised_convolution_algorithm": 0.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 7.5272000000000000e+04,
      "advised_time": 6.4511999487876892e-02,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.2419525699096977e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 7.0000000000000000e+00,
      "filter_width": 7.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 3.0000000000000000e+00,
      "input[2]": 2.2400000000000000e+02,
      "input[3]": 2.2400000000000000e+02,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 3.0000000000000000e+00,
      "input_height": 2.2400000000000000e+02,
      "input_size": 1.5052800000000000e+05,
      "input_width": 2.2400000000000000e+02,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 1.1228000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 1.1200000000000000e+02,
      "output_size": 8.0281600000000000e+05,
      "output_width": 1.1200000000000000e+02,
      "pad_height": 3.0000000000000000e+00,
      "pad_width": 3.0000000000000000e+00,
      "predicted_advised_flops": 1.9313795419612625e+12,
      "predicted_advised_flops_count": 1.1801395200000000e+08,
      "predicted_flops": 1.9313795419612625e+12,
      "predicted_flops_count": 1.1801395200000000e+08,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "workspace_bytes": 7.5272000000000000e+04,
      "workspace_megabytes": 7.1784973144531250e-02
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__16209620136994831937<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:1/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:7/filter_width:7/pad_height:3/pad_width:3/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 8757,
      "real_time": 7.9767541892235400e+04,
      "cpu_time": 8.6055103801579069e+04,
      "time_unit": "ns",
      "items_per_second": 1.2077333425937946e+11,
      "advised_convolution_algorithm": 0.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 7.3758720000000000e+06,
      "advised_time": 7.9871997237205505e-02,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)2; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4280899851402570e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 2.0000000000000000e+00,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 7.0000000000000000e+00,
      "filter_width": 7.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 3.0000000000000000e+00,
      "input[2]": 2.2400000000000000e+02,
      "input[3]": 2.2400000000000000e+02,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 3.0000000000000000e+00,
      "input_height": 2.2400000000000000e+02,
      "input_size": 1.5052800000000000e+05,
      "input_width": 2.2400000000000000e+02,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 8.7570000000000000e+03,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 1.1200000000000000e+02,
      "output_size": 8.0281600000000000e+05,
      "output_width": 1.1200000000000000e+02,
      "pad_height": 3.0000000000000000e+00,
      "pad_width": 3.0000000000000000e+00,
      "predicted_advised_flops": 1.4794733446773984e+12,
      "predicted_advised_flops_count": 1.1801395200000000e+08,
      "predicted_flops": 1.4794733446773984e+12,
      "predicted_flops_count": 1.1801395200000000e+08,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "workspace_bytes": 7.3758720000000000e+06,
      "workspace_megabytes": 7.0341796875000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__16209620136994831937<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:1/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:7/filter_width:7/pad_height:3/pad_width:3/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__16209620136994831937<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:1/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:7/filter_width:7/pad_height:3/pad_width:3/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__16209620136994831937<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:1/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:7/filter_width:7/pad_height:3/pad_width:3/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 384,
      "real_time": 1.8312046692396204e+06,
      "cpu_time": 1.8753619166620439e+06,
      "time_unit": "ns",
      "items_per_second": 5.2609040168078451e+09,
      "advised_convolution_algorithm": 0.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.4679040000000000e+06,
      "advised_time": 1.8145279884338379e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)5; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.6667819325789325e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 5.0000000000000000e+00,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 7.0000000000000000e+00,
      "filter_width": 7.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 3.0000000000000000e+00,
      "input[2]": 2.2400000000000000e+02,
      "input[3]": 2.2400000000000000e+02,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 3.0000000000000000e+00,
      "input_height": 2.2400000000000000e+02,
      "input_size": 1.5052800000000000e+05,
      "input_width": 2.2400000000000000e+02,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 3.8400000000000000e+02,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 1.1200000000000000e+02,
      "output_size": 8.0281600000000000e+05,
      "output_width": 1.1200000000000000e+02,
      "pad_height": 3.0000000000000000e+00,
      "pad_width": 3.0000000000000000e+00,
      "predicted_advised_flops": 6.4446074205896103e+10,
      "predicted_advised_flops_count": 1.1801395200000000e+08,
      "predicted_flops": 1.1607444486425798e+11,
      "predicted_flops_count": 2.1255606541482610e+08,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "workspace_bytes": 1.4679040000000000e+06,
      "workspace_megabytes": 1.3999023437500000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__16209620136994831937<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:1/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:7/filter_width:7/pad_height:3/pad_width:3/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__16209620136994831937<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:1/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:7/filter_width:7/pad_height:3/pad_width:3/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__3955321705791342273<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:1/input[1]:192/input[2]:27/input[3]:27/filter_count:96/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 33180,
      "real_time": 2.1064975927079071e+04,
      "cpu_time": 2.7040473237071397e+04,
      "time_unit": "ns",
      "items_per_second": 6.3788005486048523e+11,
      "advised_convolution_algorithm": 0.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 2.2528000175952911e-02,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4730153338016043e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 9.6000000000000000e+01,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 1.9200000000000000e+02,
      "input[2]": 2.7000000000000000e+01,
      "input[3]": 2.7000000000000000e+01,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 1.9200000000000000e+02,
      "input_height": 2.7000000000000000e+01,
      "input_size": 1.3996800000000000e+05,
      "input_width": 2.7000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 9.6000000000000000e+01,
      "num_iterations": 3.3180000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 9.6000000000000000e+01,
      "output_height": 2.7000000000000000e+01,
      "output_size": 6.9984000000000000e+04,
      "output_width": 2.7000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 6.3788005486048523e+11,
      "predicted_advised_flops_count": 1.3436928000000000e+07,
      "predicted_flops": 6.3788005486048523e+11,
      "predicted_flops_count": 1.3436928000000000e+07,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__3955321705791342273<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:1/input[1]:192/input[2]:27/input[3]:27/filter_count:96/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 17443,
      "real_time": 4.0209293959009454e+04,
      "cpu_time": 4.6235432092320378e+04,
      "time_unit": "ns",
      "items_per_second": 3.3417468144797577e+11,
      "advised_convolution_algorithm": 0.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 4.3800000000000000e+03,
      "advised_time": 4.3007999658584595e-02,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.2419525699096977e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 9.6000000000000000e+01,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 1.9200000000000000e+02,
      "input[2]": 2.7000000000000000e+01,
      "input[3]": 2.7000000000000000e+01,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 1.9200000000000000e+02,
      "input_height": 2.7000000000000000e+01,
      "input_size": 1.3996800000000000e+05,
      "input_width": 2.7000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 9.6000000000000000e+01,
      "num_iterations": 1.7443000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 9.6000000000000000e+01,
      "output_height": 2.7000000000000000e+01,
      "output_size": 6.9984000000000000e+04,
      "output_width": 2.7000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 3.3417468144797577e+11,
      "predicted_advised_flops_count": 1.3436928000000000e+07,
      "predicted_flops": 3.3417468144797577e+11,
      "predicted_flops_count": 1.3436928000000000e+07,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 4.3800000000000000e+03,
      "workspace_megabytes": 4.1770935058593750e-03
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__3955321705791342273<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:1/input[1]:192/input[2]:27/input[3]:27/filter_count:96/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 7695,
      "real_time": 9.0688176585981331e+04,
      "cpu_time": 9.6931011565788562e+04,
      "time_unit": "ns",
      "items_per_second": 1.4816626054070529e+11,
      "advised_convolution_algorithm": 0.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 5.5987200000000000e+05,
      "advised_time": 9.1136001050472260e-02,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)2; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4280899851402570e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 2.0000000000000000e+00,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 9.6000000000000000e+01,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 1.9200000000000000e+02,
      "input[2]": 2.7000000000000000e+01,
      "input[3]": 2.7000000000000000e+01,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 1.9200000000000000e+02,
      "input_height": 2.7000000000000000e+01,
      "input_size": 1.3996800000000000e+05,
      "input_width": 2.7000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 9.6000000000000000e+01,
      "num_iterations": 7.6950000000000000e+03,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 9.6000000000000000e+01,
      "output_height": 2.7000000000000000e+01,
      "output_size": 6.9984000000000000e+04,
      "output_width": 2.7000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 1.4816626054070529e+11,
      "predicted_advised_flops_count": 1.3436928000000000e+07,
      "predicted_flops": 1.4816626054070529e+11,
      "predicted_flops_count": 1.3436928000000000e+07,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 5.5987200000000000e+05,
      "workspace_megabytes": 5.3393554687500000e-01
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__3955321705791342273<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:1/input[1]:192/input[2]:27/input[3]:27/filter_count:96/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__3955321705791342273<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:1/input[1]:192/input[2]:27/input[3]:27/filter_count:96/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 2141,
      "real_time": 3.2664512624809257e+05,
      "cpu_time": 3.3487446146899217e+05,
      "time_unit": "ns",
      "items_per_second": 4.1136165582321968e+10,
      "advised_convolution_algorithm": 0.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.6217702400000000e+08,
      "advised_time": 3.3177599310874939e-01,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)4; cudnnMathType_t math_type = (cudnnMathType_t)0]": 2.3237108083472476e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 4.0000000000000000e+00,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 9.6000000000000000e+01,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 1.9200000000000000e+02,
      "input[2]": 2.7000000000000000e+01,
      "input[3]": 2.7000000000000000e+01,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 1.9200000000000000e+02,
      "input_height": 2.7000000000000000e+01,
      "input_size": 1.3996800000000000e+05,
      "input_width": 2.7000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 9.6000000000000000e+01,
      "num_iterations": 2.1410000000000000e+03,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 9.6000000000000000e+01,
      "output_height": 2.7000000000000000e+01,
      "output_size": 6.9984000000000000e+04,
      "output_width": 2.7000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 4.1136165582321968e+10,
      "predicted_advised_flops_count": 1.3436928000000000e+07,
      "predicted_flops": 4.3844427729888849e+11,
      "predicted_flops_count": 1.4321568631104916e+08,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 1.6217702400000000e+08,
      "workspace_megabytes": 1.5466406250000000e+02
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__3955321705791342273<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:1/input[1]:192/input[2]:27/input[3]:27/filter_count:96/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 12672,
      "real_time": 5.5044601918261185e+04,
      "cpu_time": 6.1095704780606837e+04,
      "time_unit": "ns",
      "items_per_second": 2.4410982243005856e+11,
      "advised_convolution_algorithm": 0.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 3.5647040000000000e+06,
      "advised_time": 8.2943998277187347e-02,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)5; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.6667819325789325e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 5.0000000000000000e+00,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 9.6000000000000000e+01,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 1.9200000000000000e+02,
      "input[2]": 2.7000000000000000e+01,
      "input[3]": 2.7000000000000000e+01,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 1.9200000000000000e+02,
      "input_height": 2.7000000000000000e+01,
      "input_size": 1.3996800000000000e+05,
      "input_width": 2.7000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 9.6000000000000000e+01,
      "num_iterations": 1.2672000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 9.6000000000000000e+01,
      "output_height": 2.7000000000000000e+01,
      "output_size": 6.9984000000000000e+04,
      "output_width": 2.7000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 2.4410982243005856e+11,
      "predicted_advised_flops_count": 1.3436928000000000e+07,
      "predicted_flops": 2.6018116458307422e+12,
      "predicted_flops_count": 1.4321568631104916e+08,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 3.5647040000000000e+06,
      "workspace_megabytes": 3.3995666503906250e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__3955321705791342273<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:1/input[1]:192/input[2]:27/input[3]:27/filter_count:96/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__3955321705791342273<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:1/input[1]:192/input[2]:27/input[3]:27/filter_count:96/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__6709418483479307307<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:384/input[2]:13/input[3]:13/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:2/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__6709418483479307307<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:384/input[2]:13/input[3]:13/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:2/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__6709418483479307307<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:384/input[2]:13/input[3]:13/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:2/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__6709418483479307307<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:384/input[2]:13/input[3]:13/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:2/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__6709418483479307307<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:384/input[2]:13/input[3]:13/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:2/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__6709418483479307307<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:384/input[2]:13/input[3]:13/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:2/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__6709418483479307307<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:384/input[2]:13/input[3]:13/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:2/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__6709418483479307307<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:384/input[2]:13/input[3]:13/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:2/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__2821109436439167584<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:1/input[1]:64/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 32538,
      "real_time": 2.1606559680172184e+04,
      "cpu_time": 2.7501860532167975e+04,
      "time_unit": "ns",
      "items_per_second": 1.1889959521679517e+12,
      "advised_convolution_algorithm": 0.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 2.2528000175952911e-02,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4730153338016043e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 2.0070400000000000e+05,
      "input_width": 5.6000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 3.2538000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 5.6000000000000000e+01,
      "output_size": 4.0140800000000000e+05,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 1.1889959521679517e+12,
      "predicted_advised_flops_count": 2.5690112000000000e+07,
      "predicted_flops": 1.1889959521679517e+12,
      "predicted_flops_count": 2.5690112000000000e+07,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__2821109436439167584<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:1/input[1]:64/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 27444,
      "real_time": 2.5541516468414753e+04,
      "cpu_time": 3.1439046384240082e+04,
      "time_unit": "ns",
      "items_per_second": 1.0058178038006866e+12,
      "advised_convolution_algorithm": 0.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.8824000000000000e+04,
      "advised_time": 2.7648000046610832e-02,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.2419525699096977e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 2.0070400000000000e+05,
      "input_width": 5.6000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 2.7444000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 5.6000000000000000e+01,
      "output_size": 4.0140800000000000e+05,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 1.0058178038006866e+12,
      "predicted_advised_flops_count": 2.5690112000000000e+07,
      "predicted_flops": 1.0058178038006866e+12,
      "predicted_flops_count": 2.5690112000000000e+07,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 1.8824000000000000e+04,
      "workspace_megabytes": 1.7951965332031250e-02
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__2821109436439167584<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:1/input[1]:64/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 14706,
      "real_time": 4.7552106906976624e+04,
      "cpu_time": 5.3515322384845778e+04,
      "time_unit": "ns",
      "items_per_second": 5.4025181366318945e+11,
      "advised_convolution_algorithm": 0.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 8.0281600000000000e+05,
      "advised_time": 4.9152001738548279e-02,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)2; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4280899851402570e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 2.0000000000000000e+00,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 2.0070400000000000e+05,
      "input_width": 5.6000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 1.4706000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 5.6000000000000000e+01,
      "output_size": 4.0140800000000000e+05,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 5.4025181366318945e+11,
      "predicted_advised_flops_count": 2.5690112000000000e+07,
      "predicted_flops": 5.4025181366318945e+11,
      "predicted_flops_count": 2.5690112000000000e+07,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 8.0281600000000000e+05,
      "workspace_megabytes": 7.6562500000000000e-01
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__2821109436439167584<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:1/input[1]:64/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__2821109436439167584<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:1/input[1]:64/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 700,
      "real_time": 9.9142541244093864e+05,
      "cpu_time": 1.0123151128521255e+06,
      "time_unit": "ns",
      "items_per_second": 2.5912299279024601e+10,
      "advised_convolution_algorithm": 0.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 2.7908505600000000e+08,
      "advised_time": 1.0188800096511841e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)4; cudnnMathType_t math_type = (cudnnMathType_t)0]": 2.3237108083472476e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 4.0000000000000000e+00,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 2.0070400000000000e+05,
      "input_width": 5.6000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 7.0000000000000000e+02,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 5.6000000000000000e+01,
      "output_size": 4.0140800000000000e+05,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 2.5912299279024601e+10,
      "predicted_advised_flops_count": 2.5690112000000000e+07,
      "predicted_flops": 3.3392997674064008e+11,
      "predicted_flops_count": 3.3106666491648209e+08,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 2.7908505600000000e+08,
      "workspace_megabytes": 2.6615625000000000e+02
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__2821109436439167584<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:1/input[1]:64/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 10759,
      "real_time": 6.4208283908339377e+04,
      "cpu_time": 7.0431135514589158e+04,
      "time_unit": "ns",
      "items_per_second": 4.0010588098996625e+11,
      "advised_convolution_algorithm": 0.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 4.0394880000000000e+06,
      "advised_time": 8.0895997583866119e-02,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)5; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.6667819325789325e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 5.0000000000000000e+00,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 2.0070400000000000e+05,
      "input_width": 5.6000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 1.0759000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 5.6000000000000000e+01,
      "output_size": 4.0140800000000000e+05,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 4.0010588098996625e+11,
      "predicted_advised_flops_count": 2.5690112000000000e+07,
      "predicted_flops": 5.1561363232989795e+12,
      "predicted_flops_count": 3.3106666491648209e+08,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 4.0394880000000000e+06,
      "workspace_megabytes": 3.8523559570312500e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__2821109436439167584<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:1/input[1]:64/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__2821109436439167584<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:1/input[1]:64/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__2255578786481836553<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:1/input[1]:96/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 27378,
      "real_time": 2.5512907680162116e+04,
      "cpu_time": 3.1443074658343572e+04,
      "time_unit": "ns",
      "items_per_second": 1.5104185098417266e+12,
      "advised_convolution_algorithm": 0.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 2.5599999353289604e-02,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4730153338016043e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 9.6000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 9.6000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 3.0105600000000000e+05,
      "input_width": 5.6000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 2.7378000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 5.6000000000000000e+01,
      "output_size": 4.0140800000000000e+05,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 1.5104185098417266e+12,
      "predicted_advised_flops_count": 3.8535168000000000e+07,
      "predicted_flops": 1.5104185098417266e+12,
      "predicted_flops_count": 3.8535168000000000e+07,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__2255578786481836553<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:1/input[1]:96/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 23806,
      "real_time": 2.9235734737324452e+04,
      "cpu_time": 3.5180523398529745e+04,
      "time_unit": "ns",
      "items_per_second": 1.3180844725206519e+12,
      "advised_convolution_algorithm": 0.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.8824000000000000e+04,
      "advised_time": 3.0719999223947525e-02,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.2419525699096977e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 9.6000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 9.6000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 3.0105600000000000e+05,
      "input_width": 5.6000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 2.3806000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 5.6000000000000000e+01,
      "output_size": 4.0140800000000000e+05,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 1.3180844725206519e+12,
      "predicted_advised_flops_count": 3.8535168000000000e+07,
      "predicted_flops": 1.3180844725206519e+12,
      "predicted_flops_count": 3.8535168000000000e+07,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 1.8824000000000000e+04,
      "workspace_megabytes": 1.7951965332031250e-02
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__2255578786481836553<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:1/input[1]:96/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 10708,
      "real_time": 6.4687976493327922e+04,
      "cpu_time": 7.0680974318708846e+04,
      "time_unit": "ns",
      "items_per_second": 5.9570835399333618e+11,
      "advised_convolution_algorithm": 0.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.2042240000000000e+06,
      "advised_time": 6.5503999590873718e-02,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)2; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4280899851402570e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 2.0000000000000000e+00,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 9.6000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 9.6000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 3.0105600000000000e+05,
      "input_width": 5.6000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 1.0708000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 5.6000000000000000e+01,
      "output_size": 4.0140800000000000e+05,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 5.9570835399333618e+11,
      "predicted_advised_flops_count": 3.8535168000000000e+07,
      "predicted_flops": 5.9570835399333618e+11,
      "predicted_flops_count": 3.8535168000000000e+07,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 1.2042240000000000e+06,
      "workspace_megabytes": 1.1484375000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__2255578786481836553<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:1/input[1]:96/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__2255578786481836553<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:1/input[1]:96/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 480,
      "real_time": 1.4562561945543468e+06,
      "cpu_time": 1.4943150270819196e+06,
      "time_unit": "ns",
      "items_per_second": 2.6461805377447876e+10,
      "advised_convolution_algorithm": 0.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 4.1857843200000000e+08,
      "advised_time": 1.4786560535430908e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)4; cudnnMathType_t math_type = (cudnnMathType_t)0]": 2.3237108083472476e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 4.0000000000000000e+00,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 9.6000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 9.6000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 3.0105600000000000e+05,
      "input_width": 5.6000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 4.8000000000000000e+02,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 5.6000000000000000e+01,
      "output_size": 4.0140800000000000e+05,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 2.6461805377447876e+10,
      "predicted_advised_flops_count": 3.8535168000000000e+07,
      "predicted_flops": 3.3941066173553979e+11,
      "predicted_flops_count": 4.9426887865016985e+08,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 4.1857843200000000e+08,
      "workspace_megabytes": 3.9918750000000000e+02
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__2255578786481836553<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:1/input[1]:96/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 9552,
      "real_time": 7.2466606628861744e+04,
      "cpu_time": 7.8687656720316460e+04,
      "time_unit": "ns",
      "items_per_second": 5.3176448839888617e+11,
      "advised_convolution_algorithm": 0.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 5.0839680000000000e+06,
      "advised_time": 9.2160001397132874e-02,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)5; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.6667819325789325e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 5.0000000000000000e+00,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 9.6000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 9.6000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 3.0105600000000000e+05,
      "input_width": 5.6000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 9.5520000000000000e+03,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 5.6000000000000000e+01,
      "output_size": 4.0140800000000000e+05,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 5.3176448839888617e+11,
      "predicted_advised_flops_count": 3.8535168000000000e+07,
      "predicted_flops": 6.8206433506893955e+12,
      "predicted_flops_count": 4.9426887865016985e+08,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 5.0839680000000000e+06,
      "workspace_megabytes": 4.8484497070312500e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__2255578786481836553<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:1/input[1]:96/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__2255578786481836553<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:1/input[1]:96/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__15656687763263169433<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:1/input[1]:192/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 18584,
      "real_time": 3.7545509412505911e+04,
      "cpu_time": 4.3541700926050646e+04,
      "time_unit": "ns",
      "items_per_second": 2.0527178138200701e+12,
      "advised_convolution_algorithm": 0.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 3.8911998271942139e-02,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4730153338016043e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 1.9200000000000000e+02,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 1.9200000000000000e+02,
      "input_height": 5.6000000000000000e+01,
      "input_size": 6.0211200000000000e+05,
      "input_width": 5.6000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 1.8584000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 5.6000000000000000e+01,
      "output_size": 4.0140800000000000e+05,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 2.0527178138200701e+12,
      "predicted_advised_flops_count": 7.7070336000000000e+07,
      "predicted_flops": 2.0527178138200701e+12,
      "predicted_flops_count": 7.7070336000000000e+07,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__15656687763263169433<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:1/input[1]:192/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 17288,
      "real_time": 4.0605010366316266e+04,
      "cpu_time": 4.6682678389513683e+04,
      "time_unit": "ns",
      "items_per_second": 1.8980499033176802e+12,
      "advised_convolution_algorithm": 0.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.8824000000000000e+04,
      "advised_time": 4.3007999658584595e-02,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.2419525699096977e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 1.9200000000000000e+02,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 1.9200000000000000e+02,
      "input_height": 5.6000000000000000e+01,
      "input_size": 6.0211200000000000e+05,
      "input_width": 5.6000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 1.7288000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 5.6000000000000000e+01,
      "output_size": 4.0140800000000000e+05,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 1.8980499033176802e+12,
      "predicted_advised_flops_count": 7.7070336000000000e+07,
      "predicted_flops": 1.8980499033176802e+12,
      "predicted_flops_count": 7.7070336000000000e+07,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 1.8824000000000000e+04,
      "workspace_megabytes": 1.7951965332031250e-02
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__15656687763263169433<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:1/input[1]:192/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 4657,
      "real_time": 1.4947654458635964e+05,
      "cpu_time": 1.5624335731149101e+05,
      "time_unit": "ns",
      "items_per_second": 5.1560153610236041e+11,
      "advised_convolution_algorithm": 0.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 2.4084480000000000e+06,
      "advised_time": 1.4131200313568115e-01,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)2; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4280899851402570e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 2.0000000000000000e+00,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 1.9200000000000000e+02,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 1.9200000000000000e+02,
      "input_height": 5.6000000000000000e+01,
      "input_size": 6.0211200000000000e+05,
      "input_width": 5.6000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 4.6570000000000000e+03,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 5.6000000000000000e+01,
      "output_size": 4.0140800000000000e+05,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 5.1560153610236041e+11,
      "predicted_advised_flops_count": 7.7070336000000000e+07,
      "predicted_flops": 5.1560153610236041e+11,
      "predicted_flops_count": 7.7070336000000000e+07,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 2.4084480000000000e+06,
      "workspace_megabytes": 2.2968750000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__15656687763263169433<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:1/input[1]:192/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__15656687763263169433<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:1/input[1]:192/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 245,
      "real_time": 2.8468073364727353e+06,
      "cpu_time": 2.9792461632691161e+06,
      "time_unit": "ns",
      "items_per_second": 2.7072550717637272e+10,
      "advised_convolution_algorithm": 0.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 8.3705856000000000e+08,
      "advised_time": 2.8764159679412842e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)4; cudnnMathType_t math_type = (cudnnMathType_t)0]": 2.3237108083472476e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 4.0000000000000000e+00,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 1.9200000000000000e+02,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 1.9200000000000000e+02,
      "input_height": 5.6000000000000000e+01,
      "input_size": 6.0211200000000000e+05,
      "input_width": 5.6000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 2.4500000000000000e+02,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 5.6000000000000000e+01,
      "output_size": 4.0140800000000000e+05,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 2.7072550717637272e+10,
      "predicted_advised_flops_count": 7.7070336000000000e+07,
      "predicted_flops": 3.4560664054992896e+11,
      "predicted_flops_count": 9.8387551985123312e+08,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 8.3705856000000000e+08,
      "workspace_megabytes": 7.9828125000000000e+02
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__15656687763263169433<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:1/input[1]:192/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 6694,
      "real_time": 1.0324100649203022e+05,
      "cpu_time": 1.0969038407499081e+05,
      "time_unit": "ns",
      "items_per_second": 7.4650895626389990e+11,
      "advised_convolution_algorithm": 0.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 8.2174080000000000e+06,
      "advised_time": 1.2185599654912949e-01,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)5; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.6667819325789325e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 5.0000000000000000e+00,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 1.9200000000000000e+02,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 1.9200000000000000e+02,
      "input_height": 5.6000000000000000e+01,
      "input_size": 6.0211200000000000e+05,
      "input_width": 5.6000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 6.6940000000000000e+03,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 5.6000000000000000e+01,
      "output_size": 4.0140800000000000e+05,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 7.4650895626389990e+11,
      "predicted_advised_flops_count": 7.7070336000000000e+07,
      "predicted_flops": 9.5298908184044512e+12,
      "predicted_flops_count": 9.8387551985123312e+08,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 8.2174080000000000e+06,
      "workspace_megabytes": 7.8367309570312500e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__15656687763263169433<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:1/input[1]:192/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__15656687763263169433<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:1/input[1]:192/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__17605375797884481413<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:1/input[1]:128/input[2]:27/input[3]:27/filter_count:192/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 6007,
      "real_time": 1.1461036751185615e+05,
      "cpu_time": 1.2029829698525666e+05,
      "time_unit": "ns",
      "items_per_second": 1.5632009903595020e+11,
      "advised_convolution_algorithm": 6.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 1.1673600226640701e-01,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4730153338016043e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.9200000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 1.2800000000000000e+02,
      "input[2]": 2.7000000000000000e+01,
      "input[3]": 2.7000000000000000e+01,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 1.2800000000000000e+02,
      "input_height": 2.7000000000000000e+01,
      "input_size": 9.3312000000000000e+04,
      "input_width": 2.7000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.9200000000000000e+02,
      "num_iterations": 6.0070000000000000e+03,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 1.9200000000000000e+02,
      "output_height": 2.7000000000000000e+01,
      "output_size": 1.3996800000000000e+05,
      "output_width": 2.7000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "predicted_advised_flops": -8.7252141469361632e+03,
      "predicted_advised_flops_count": -1.0000000000000000e+00,
      "predicted_flops": 1.4068808913235515e+12,
      "predicted_flops_count": 1.6124313600000000e+08,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__17605375797884481413<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:1/input[1]:128/input[2]:27/input[3]:27/filter_count:192/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 4456,
      "real_time": 1.5669671098895089e+05,
      "cpu_time": 1.6298298272098671e+05,
      "time_unit": "ns",
      "items_per_second": 1.1433490777775992e+11,
      "advised_convolution_algorithm": 6.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 4.3800000000000000e+03,
      "advised_time": 1.5974399447441101e-01,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.2419525699096977e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.9200000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 1.2800000000000000e+02,
      "input[2]": 2.7000000000000000e+01,
      "input[3]": 2.7000000000000000e+01,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 1.2800000000000000e+02,
      "input_height": 2.7000000000000000e+01,
      "input_size": 9.3312000000000000e+04,
      "input_width": 2.7000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.9200000000000000e+02,
      "num_iterations": 4.4560000000000000e+03,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 1.9200000000000000e+02,
      "output_height": 2.7000000000000000e+01,
      "output_size": 1.3996800000000000e+05,
      "output_width": 2.7000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "predicted_advised_flops": -6.3817548797850177e+03,
      "predicted_advised_flops_count": -1.0000000000000000e+00,
      "predicted_flops": 1.0290141699998394e+12,
      "predicted_flops_count": 1.6124313600000000e+08,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 4.3800000000000000e+03,
      "workspace_megabytes": 4.1770935058593750e-03
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__17605375797884481413<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:1/input[1]:128/input[2]:27/input[3]:27/filter_count:192/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 4596,
      "real_time": 1.5149466807372344e+05,
      "cpu_time": 1.5804836379287951e+05,
      "time_unit": "ns",
      "items_per_second": 1.1826095418276634e+11,
      "advised_convolution_algorithm": 6.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 3.3592320000000000e+06,
      "advised_time": 1.4537599682807922e-01,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)2; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4280899851402570e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 2.0000000000000000e+00,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.9200000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 1.2800000000000000e+02,
      "input[2]": 2.7000000000000000e+01,
      "input[3]": 2.7000000000000000e+01,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 1.2800000000000000e+02,
      "input_height": 2.7000000000000000e+01,
      "input_size": 9.3312000000000000e+04,
      "input_width": 2.7000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.9200000000000000e+02,
      "num_iterations": 4.5960000000000000e+03,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 1.9200000000000000e+02,
      "output_height": 2.7000000000000000e+01,
      "output_size": 1.3996800000000000e+05,
      "output_width": 2.7000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "predicted_advised_flops": -6.6008923793500089e+03,
      "predicted_advised_flops_count": -1.0000000000000000e+00,
      "predicted_flops": 1.0643485876448971e+12,
      "predicted_flops_count": 1.6124313600000000e+08,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 3.3592320000000000e+06,
      "workspace_megabytes": 3.2036132812500000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__17605375797884481413<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:1/input[1]:128/input[2]:27/input[3]:27/filter_count:192/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__17605375797884481413<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:1/input[1]:128/input[2]:27/input[3]:27/filter_count:192/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 1365,
      "real_time": 4.9796139803500130e+05,
      "cpu_time": 5.0800573992271710e+05,
      "time_unit": "ns",
      "items_per_second": 3.5978499680291893e+10,
      "advised_convolution_algorithm": 6.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 2.1590835200000000e+08,
      "advised_time": 5.0585597753524780e-01,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)4; cudnnMathType_t math_type = (cudnnMathType_t)0]": 2.3237108083472476e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 4.0000000000000000e+00,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.9200000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 1.2800000000000000e+02,
      "input[2]": 2.7000000000000000e+01,
      "input[3]": 2.7000000000000000e+01,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 1.2800000000000000e+02,
      "input_height": 2.7000000000000000e+01,
      "input_size": 9.3312000000000000e+04,
      "input_width": 2.7000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.9200000000000000e+02,
      "num_iterations": 1.3650000000000000e+03,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 1.9200000000000000e+02,
      "output_height": 2.7000000000000000e+01,
      "output_size": 1.3996800000000000e+05,
      "output_width": 2.7000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "predicted_advised_flops": -2.0081877911542670e+03,
      "predicted_advised_flops_count": -1.0000000000000000e+00,
      "predicted_flops": 3.8258098138510632e+11,
      "predicted_flops_count": 1.9051056035213035e+08,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 2.1590835200000000e+08,
      "workspace_megabytes": 2.0590625000000000e+02
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__17605375797884481413<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:1/input[1]:128/input[2]:27/input[3]:27/filter_count:192/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 1351,
      "real_time": 5.1272417775229126e+05,
      "cpu_time": 5.1622093338529539e+05,
      "time_unit": "ns",
      "items_per_second": 3.4942576881279007e+10,
      "advised_convolution_algorithm": 6.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.0837196800000000e+08,
      "advised_time": 5.5808001756668091e-01,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)5; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.6667819325789325e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 5.0000000000000000e+00,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.9200000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 1.2800000000000000e+02,
      "input[2]": 2.7000000000000000e+01,
      "input[3]": 2.7000000000000000e+01,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 1.2800000000000000e+02,
      "input_height": 2.7000000000000000e+01,
      "input_size": 9.3312000000000000e+04,
      "input_width": 2.7000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.9200000000000000e+02,
      "num_iterations": 1.3510000000000000e+03,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 1.9200000000000000e+02,
      "output_height": 2.7000000000000000e+01,
      "output_size": 1.3996800000000000e+05,
      "output_width": 2.7000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "predicted_advised_flops": -1.9503663829231841e+03,
      "predicted_advised_flops_count": -1.0000000000000000e+00,
      "predicted_flops": 3.7156539250265344e+11,
      "predicted_flops_count": 1.9051056035213035e+08,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 1.0837196800000000e+08,
      "workspace_megabytes": 1.0335156250000000e+02
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__17605375797884481413<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:1/input[1]:128/input[2]:27/input[3]:27/filter_count:192/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 14534,
      "real_time": 4.7093597052273988e+04,
      "cpu_time": 5.3074680885976610e+04,
      "time_unit": "ns",
      "items_per_second": 3.8043184469670709e+11,
      "advised_convolution_algorithm": 6.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 2.4583680000000000e+06,
      "advised_time": 6.9632001221179962e-02,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)6; cudnnMathType_t math_type = (cudnnMathType_t)0]": 5.7500739770702787e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 6.0000000000000000e+00,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.9200000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 1.2800000000000000e+02,
      "input[2]": 2.7000000000000000e+01,
      "input[3]": 2.7000000000000000e+01,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 1.2800000000000000e+02,
      "input_height": 2.7000000000000000e+01,
      "input_size": 9.3312000000000000e+04,
      "input_width": 2.7000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.9200000000000000e+02,
      "num_iterations": 1.4534000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 1.9200000000000000e+02,
      "output_height": 2.7000000000000000e+01,
      "output_size": 1.3996800000000000e+05,
      "output_width": 2.7000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "predicted_advised_flops": -2.1234309175618884e+04,
      "predicted_advised_flops_count": -1.0000000000000000e+00,
      "predicted_flops": -2.1234309175618884e+04,
      "predicted_flops_count": -1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 2.4583680000000000e+06,
      "workspace_megabytes": 2.3444824218750000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__17605375797884481413<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:1/input[1]:128/input[2]:27/input[3]:27/filter_count:192/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 2974,
      "real_time": 2.3552678313794301e+05,
      "cpu_time": 2.4255438836385965e+05,
      "time_unit": "ns",
      "items_per_second": 7.6067374424704132e+10,
      "advised_convolution_algorithm": 6.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 3.9665664000000000e+07,
      "advised_time": 2.5292798876762390e-01,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)7; cudnnMathType_t math_type = (cudnnMathType_t)0]": 8.2538945752816425e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 7.0000000000000000e+00,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.9200000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 1.2800000000000000e+02,
      "input[2]": 2.7000000000000000e+01,
      "input[3]": 2.7000000000000000e+01,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 1.2800000000000000e+02,
      "input_height": 2.7000000000000000e+01,
      "input_size": 9.3312000000000000e+04,
      "input_width": 2.7000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.9200000000000000e+02,
      "num_iterations": 2.9740000000000000e+03,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 1.9200000000000000e+02,
      "output_height": 2.7000000000000000e+01,
      "output_size": 1.3996800000000000e+05,
      "output_width": 2.7000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "predicted_advised_flops": -4.2458016310371013e+03,
      "predicted_advised_flops_count": -1.0000000000000000e+00,
      "predicted_flops": -4.2458016310371013e+03,
      "predicted_flops_count": -1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 3.9665664000000000e+07,
      "workspace_megabytes": 3.7828125000000000e+01
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__6065165212417003451<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:1/input[1]:160/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 28349,
      "real_time": 2.4677847104800097e+04,
      "cpu_time": 3.0698514021028252e+04,
      "time_unit": "ns",
      "items_per_second": 6.5063698351858569e+11,
      "advised_convolution_algorithm": 0.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 2.5599999353289604e-02,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4730153338016043e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 1.6000000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 1.6000000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 1.2544000000000000e+05,
      "input_width": 2.8000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 2.8349000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 1.0035200000000000e+05,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 6.5063698351858569e+11,
      "predicted_advised_flops_count": 1.6056320000000000e+07,
      "predicted_flops": 6.5063698351858569e+11,
      "predicted_flops_count": 1.6056320000000000e+07,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__6065165212417003451<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:1/input[1]:160/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 19222,
      "real_time": 3.6450478490117966e+04,
      "cpu_time": 4.2386715273903923e+04,
      "time_unit": "ns",
      "items_per_second": 4.4049682377566064e+11,
      "advised_convolution_algorithm": 0.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 4.7120000000000000e+03,
      "advised_time": 3.8911998271942139e-02,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.2419525699096977e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 1.6000000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 1.6000000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 1.2544000000000000e+05,
      "input_width": 2.8000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 1.9222000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 1.0035200000000000e+05,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 4.4049682377566064e+11,
      "predicted_advised_flops_count": 1.6056320000000000e+07,
      "predicted_flops": 4.4049682377566064e+11,
      "predicted_flops_count": 1.6056320000000000e+07,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 4.7120000000000000e+03,
      "workspace_megabytes": 4.4937133789062500e-03
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__6065165212417003451<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:1/input[1]:160/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 8509,
      "real_time": 8.1964472838342714e+04,
      "cpu_time": 8.8097280525255657e+04,
      "time_unit": "ns",
      "items_per_second": 1.9589365299362857e+11,
      "advised_convolution_algorithm": 0.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 5.0176000000000000e+05,
      "advised_time": 8.2943998277187347e-02,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)2; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4280899851402570e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 2.0000000000000000e+00,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 1.6000000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 1.6000000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 1.2544000000000000e+05,
      "input_width": 2.8000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 8.5090000000000000e+03,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 1.0035200000000000e+05,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 1.9589365299362857e+11,
      "predicted_advised_flops_count": 1.6056320000000000e+07,
      "predicted_flops": 1.9589365299362857e+11,
      "predicted_flops_count": 1.6056320000000000e+07,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 5.0176000000000000e+05,
      "workspace_megabytes": 4.7851562500000000e-01
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__6065165212417003451<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:1/input[1]:160/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__6065165212417003451<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:1/input[1]:160/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 1994,
      "real_time": 3.4795138708067313e+05,
      "cpu_time": 3.5647284202537301e+05,
      "time_unit": "ns",
      "items_per_second": 4.6145296717202957e+10,
      "advised_convolution_algorithm": 0.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.7973248000000000e+08,
      "advised_time": 3.5225600004196167e-01,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)4; cudnnMathType_t math_type = (cudnnMathType_t)0]": 2.3237108083472476e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 4.0000000000000000e+00,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 1.6000000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 1.6000000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 1.2544000000000000e+05,
      "input_width": 2.8000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 1.9940000000000000e+03,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 1.0035200000000000e+05,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 4.6145296717202957e+10,
      "predicted_advised_flops_count": 1.6056320000000000e+07,
      "predicted_flops": 4.9605809586661536e+11,
      "predicted_flops_count": 1.7260410252938634e+08,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 1.7973248000000000e+08,
      "workspace_megabytes": 1.7140625000000000e+02
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__6065165212417003451<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:1/input[1]:160/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 12758,
      "real_time": 5.4834948057725400e+04,
      "cpu_time": 6.1142204342426885e+04,
      "time_unit": "ns",
      "items_per_second": 2.9281180285057117e+11,
      "advised_convolution_algorithm": 0.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 3.8824000000000000e+06,
      "advised_time": 8.0895997583866119e-02,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)5; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.6667819325789325e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 5.0000000000000000e+00,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 1.6000000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 1.6000000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 1.2544000000000000e+05,
      "input_width": 2.8000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 1.2758000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 1.0035200000000000e+05,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 2.9281180285057117e+11,
      "predicted_advised_flops_count": 1.6056320000000000e+07,
      "predicted_flops": 3.1477024898005552e+12,
      "predicted_flops_count": 1.7260410252938634e+08,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 3.8824000000000000e+06,
      "workspace_megabytes": 3.7025451660156250e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__6065165212417003451<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:1/input[1]:160/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__6065165212417003451<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:1/input[1]:160/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__12513461715419514171<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:1/input[1]:320/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 17382,
      "real_time": 4.0247264218243676e+04,
      "cpu_time": 4.6265292313906080e+04,
      "time_unit": "ns",
      "items_per_second": 7.9788379716611072e+11,
      "advised_convolution_algorithm": 0.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 4.1983999311923981e-02,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4730153338016043e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 3.2000000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 3.2000000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 2.5088000000000000e+05,
      "input_width": 2.8000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 1.7382000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 1.0035200000000000e+05,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 7.9788379716611072e+11,
      "predicted_advised_flops_count": 3.2112640000000000e+07,
      "predicted_flops": 7.9788379716611072e+11,
      "predicted_flops_count": 3.2112640000000000e+07,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__12513461715419514171<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:1/input[1]:320/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 12529,
      "real_time": 5.5246405913701637e+04,
      "cpu_time": 6.1259011574080701e+04,
      "time_unit": "ns",
      "items_per_second": 5.8126206526741235e+11,
      "advised_convolution_algorithm": 0.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 4.7120000000000000e+03,
      "advised_time": 5.8368001133203506e-02,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.2419525699096977e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 3.2000000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 3.2000000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 2.5088000000000000e+05,
      "input_width": 2.8000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 1.2529000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 1.0035200000000000e+05,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 5.8126206526741235e+11,
      "predicted_advised_flops_count": 3.2112640000000000e+07,
      "predicted_flops": 5.8126206526741235e+11,
      "predicted_flops_count": 3.2112640000000000e+07,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 4.7120000000000000e+03,
      "workspace_megabytes": 4.4937133789062500e-03
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__12513461715419514171<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:1/input[1]:320/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 5353,
      "real_time": 1.2929528858423473e+05,
      "cpu_time": 1.3574298169442284e+05,
      "time_unit": "ns",
      "items_per_second": 2.4836666789353964e+11,
      "advised_convolution_algorithm": 0.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.0035200000000000e+06,
      "advised_time": 1.3107199966907501e-01,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)2; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4280899851402570e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 2.0000000000000000e+00,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 3.2000000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 3.2000000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 2.5088000000000000e+05,
      "input_width": 2.8000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 5.3530000000000000e+03,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 1.0035200000000000e+05,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 2.4836666789353964e+11,
      "predicted_advised_flops_count": 3.2112640000000000e+07,
      "predicted_flops": 2.4836666789353964e+11,
      "predicted_flops_count": 3.2112640000000000e+07,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 1.0035200000000000e+06,
      "workspace_megabytes": 9.5703125000000000e-01
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__12513461715419514171<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:1/input[1]:320/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__12513461715419514171<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:1/input[1]:320/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 1037,
      "real_time": 6.5561426206686778e+05,
      "cpu_time": 6.6941641079966980e+05,
      "time_unit": "ns",
      "items_per_second": 4.8980996689673523e+10,
      "advised_convolution_algorithm": 0.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 3.5946496000000000e+08,
      "advised_time": 6.6150397062301636e-01,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)4; cudnnMathType_t math_type = (cudnnMathType_t)0]": 2.3237108083472476e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 4.0000000000000000e+00,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 3.2000000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 3.2000000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 2.5088000000000000e+05,
      "input_width": 2.8000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 1.0370000000000000e+03,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 1.0035200000000000e+05,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 4.8980996689673523e+10,
      "predicted_advised_flops_count": 3.2112640000000000e+07,
      "predicted_flops": 5.2506995288852612e+11,
      "predicted_flops_count": 3.4424334969649607e+08,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 3.5946496000000000e+08,
      "workspace_megabytes": 3.4281250000000000e+02
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__12513461715419514171<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:1/input[1]:320/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 8322,
      "real_time": 8.3483010603738468e+04,
      "cpu_time": 8.9910645519881233e+04,
      "time_unit": "ns",
      "items_per_second": 3.8466078029248688e+11,
      "advised_convolution_algorithm": 0.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 7.2769600000000000e+06,
      "advised_time": 1.1059200018644333e-01,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)5; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.6667819325789325e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 5.0000000000000000e+00,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 3.2000000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 3.2000000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 2.5088000000000000e+05,
      "input_width": 2.8000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 8.3220000000000000e+03,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 1.0035200000000000e+05,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 3.8466078029248688e+11,
      "predicted_advised_flops_count": 3.2112640000000000e+07,
      "predicted_flops": 4.1235138408039204e+12,
      "predicted_flops_count": 3.4424334969649607e+08,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 7.2769600000000000e+06,
      "workspace_megabytes": 6.9398498535156250e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__12513461715419514171<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:1/input[1]:320/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__12513461715419514171<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:1/input[1]:320/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__1930434020982545224<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:1/input[1]:544/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 16462,
      "real_time": 4.2489155509202923e+04,
      "cpu_time": 4.8472103753219009e+04,
      "time_unit": "ns",
      "items_per_second": 3.2120836096739893e+11,
      "advised_convolution_algorithm": 0.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 4.3007999658584595e-02,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4730153338016043e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 5.4400000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 5.4400000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 1.0662400000000000e+05,
      "input_width": 1.4000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 1.6462000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 2.5088000000000000e+04,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 3.2120836096739893e+11,
      "predicted_advised_flops_count": 1.3647872000000000e+07,
      "predicted_flops": 3.2120836096739893e+11,
      "predicted_flops_count": 1.3647872000000000e+07,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__1930434020982545224<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:1/input[1]:544/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 8581,
      "real_time": 8.1426684441767327e+04,
      "cpu_time": 8.7540914346483420e+04,
      "time_unit": "ns",
      "items_per_second": 1.6760932971255069e+11,
      "advised_convolution_algorithm": 0.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.1840000000000000e+03,
      "advised_time": 8.3967998623847961e-02,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.2419525699096977e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 5.4400000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 5.4400000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 1.0662400000000000e+05,
      "input_width": 1.4000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 8.5810000000000000e+03,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 2.5088000000000000e+04,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 1.6760932971255069e+11,
      "predicted_advised_flops_count": 1.3647872000000000e+07,
      "predicted_flops": 1.6760932971255069e+11,
      "predicted_flops_count": 1.3647872000000000e+07,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 1.1840000000000000e+03,
      "workspace_megabytes": 1.1291503906250000e-03
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__1930434020982545224<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:1/input[1]:544/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 5523,
      "real_time": 1.2682397717823483e+05,
      "cpu_time": 1.3322158736129923e+05,
      "time_unit": "ns",
      "items_per_second": 1.0761271096883887e+11,
      "advised_convolution_algorithm": 0.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 4.2649600000000000e+05,
      "advised_time": 1.2800000607967377e-01,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)2; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4280899851402570e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 2.0000000000000000e+00,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 5.4400000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 5.4400000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 1.0662400000000000e+05,
      "input_width": 1.4000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 5.5230000000000000e+03,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 2.5088000000000000e+04,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 1.0761271096883887e+11,
      "predicted_advised_flops_count": 1.3647872000000000e+07,
      "predicted_flops": 1.0761271096883887e+11,
      "predicted_flops_count": 1.3647872000000000e+07,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 4.2649600000000000e+05,
      "workspace_megabytes": 4.0673828125000000e-01
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__1930434020982545224<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:1/input[1]:544/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__1930434020982545224<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:1/input[1]:544/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 2330,
      "real_time": 3.0037334182323655e+05,
      "cpu_time": 3.0839565278873226e+05,
      "time_unit": "ns",
      "items_per_second": 4.5436362352127396e+10,
      "advised_convolution_algorithm": 0.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.6196403200000000e+08,
      "advised_time": 3.0617600679397583e-01,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)4; cudnnMathType_t math_type = (cudnnMathType_t)0]": 2.3237108083472476e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 4.0000000000000000e+00,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 5.4400000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 5.4400000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 1.0662400000000000e+05,
      "input_width": 1.4000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 2.3300000000000000e+03,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 2.5088000000000000e+04,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 4.5436362352127396e+10,
      "predicted_advised_flops_count": 1.3647872000000000e+07,
      "predicted_flops": 3.9476008494252985e+11,
      "predicted_flops_count": 1.1857540593261242e+08,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 1.6196403200000000e+08,
      "workspace_megabytes": 1.5446093750000000e+02
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__1930434020982545224<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:1/input[1]:544/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 5754,
      "real_time": 1.2100568279144648e+05,
      "cpu_time": 1.2747684393462873e+05,
      "time_unit": "ns",
      "items_per_second": 1.1278703351083217e+11,
      "advised_convolution_algorithm": 0.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.0749856000000000e+07,
      "advised_time": 1.3926400244235992e-01,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)5; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.6667819325789325e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 5.0000000000000000e+00,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 5.4400000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 5.4400000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 1.0662400000000000e+05,
      "input_width": 1.4000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 5.7540000000000000e+03,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 2.5088000000000000e+04,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 1.1278703351083217e+11,
      "predicted_advised_flops_count": 1.3647872000000000e+07,
      "predicted_flops": 9.7991601053131824e+11,
      "predicted_flops_count": 1.1857540593261242e+08,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 1.0749856000000000e+07,
      "workspace_megabytes": 1.0251861572265625e+01
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__1930434020982545224<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:1/input[1]:544/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__1930434020982545224<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:1/input[1]:544/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__7032941452476097680<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:8/input[2]:14/input[3]:14/filter_count:16/filter_height:5/filter_width:5/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 18616,
      "real_time": 3.7627170814928730e+04,
      "cpu_time": 4.3545000482897216e+04,
      "time_unit": "ns",
      "items_per_second": 8.5344285271799332e+10,
      "advised_convolution_algorithm": 4.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 3.8911998271942139e-02,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4730153338016043e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.6000000000000000e+01,
      "filter_height": 5.0000000000000000e+00,
      "filter_width": 5.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 8.0000000000000000e+00,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 8.0000000000000000e+00,
      "input_height": 1.4000000000000000e+01,
      "input_size": 2.0070400000000000e+05,
      "input_width": 1.4000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.6000000000000000e+01,
      "num_iterations": 1.8616000000000000e+04,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 1.6000000000000000e+01,
      "output_height": 1.0000000000000000e+01,
      "output_size": 2.0480000000000000e+05,
      "output_width": 1.0000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 2.1227240425581241e+11,
      "predicted_advised_flops_count": 7.9872100142290583e+06,
      "predicted_flops": 1.0885750672423385e+12,
      "predicted_flops_count": 4.0960000000000000e+07,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__7032941452476097680<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:8/input[2]:14/input[3]:14/filter_count:16/filter_height:5/filter_width:5/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 11183,
      "real_time": 6.1537335017167250e+04,
      "cpu_time": 6.7500548332811843e+04,
      "time_unit": "ns",
      "items_per_second": 5.2183995278705910e+10,
      "advised_convolution_algorithm": 4.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 6.0800000000000000e+02,
      "advised_time": 6.3487999141216278e-02,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.2419525699096977e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.6000000000000000e+01,
      "filter_height": 5.0000000000000000e+00,
      "filter_width": 5.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 8.0000000000000000e+00,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 8.0000000000000000e+00,
      "input_height": 1.4000000000000000e+01,
      "input_size": 2.0070400000000000e+05,
      "input_width": 1.4000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.6000000000000000e+01,
      "num_iterations": 1.1183000000000000e+04,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 1.6000000000000000e+01,
      "output_height": 1.0000000000000000e+01,
      "output_size": 2.0480000000000000e+05,
      "output_width": 1.0000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 1.2979453874628862e+11,
      "predicted_advised_flops_count": 7.9872100142290583e+06,
      "predicted_flops": 6.6561218467737134e+11,
      "predicted_flops_count": 4.0960000000000000e+07,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 6.0800000000000000e+02,
      "workspace_megabytes": 5.7983398437500000e-04
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__7032941452476097680<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:8/input[2]:14/input[3]:14/filter_count:16/filter_height:5/filter_width:5/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 7980,
      "real_time": 8.7920773467774052e+04,
      "cpu_time": 9.4219951879574844e+04,
      "time_unit": "ns",
      "items_per_second": 3.6524519443371796e+10,
      "advised_convolution_algorithm": 4.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.0240000000000000e+07,
      "advised_time": 8.6015999317169189e-02,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)2; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4280899851402570e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 2.0000000000000000e+00,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.6000000000000000e+01,
      "filter_height": 5.0000000000000000e+00,
      "filter_width": 5.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 8.0000000000000000e+00,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 8.0000000000000000e+00,
      "input_height": 1.4000000000000000e+01,
      "input_size": 2.0070400000000000e+05,
      "input_width": 1.4000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.6000000000000000e+01,
      "num_iterations": 7.9800000000000000e+03,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 1.6000000000000000e+01,
      "output_height": 1.0000000000000000e+01,
      "output_size": 2.0480000000000000e+05,
      "output_width": 1.0000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 9.0845538536539856e+10,
      "predicted_advised_flops_count": 7.9872100142290583e+06,
      "predicted_flops": 4.6587397249198718e+11,
      "predicted_flops_count": 4.0960000000000000e+07,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 1.0240000000000000e+07,
      "workspace_megabytes": 9.7656250000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__7032941452476097680<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:8/input[2]:14/input[3]:14/filter_count:16/filter_height:5/filter_width:5/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__7032941452476097680<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:8/input[2]:14/input[3]:14/filter_count:16/filter_height:5/filter_width:5/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 15541,
      "real_time": 4.5108811107671056e+04,
      "cpu_time": 5.1335109387979013e+04,
      "time_unit": "ns",
      "items_per_second": 7.1189284779307846e+10,
      "advised_convolution_algorithm": 4.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 4.7313920000000000e+06,
      "advised_time": 4.9152001738548279e-02,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)4; cudnnMathType_t math_type = (cudnnMathType_t)0]": 2.3237108083472476e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 4.0000000000000000e+00,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.6000000000000000e+01,
      "filter_height": 5.0000000000000000e+00,
      "filter_width": 5.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 8.0000000000000000e+00,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 8.0000000000000000e+00,
      "input_height": 1.4000000000000000e+01,
      "input_size": 2.0070400000000000e+05,
      "input_width": 1.4000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.6000000000000000e+01,
      "num_iterations": 1.5541000000000000e+04,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 1.6000000000000000e+01,
      "output_height": 1.0000000000000000e+01,
      "output_size": 2.0480000000000000e+05,
      "output_width": 1.0000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 1.7706540735831494e+11,
      "predicted_advised_flops_count": 7.9872100142290583e+06,
      "predicted_flops": 1.7706540735831494e+11,
      "predicted_flops_count": 7.9872100142290583e+06,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 4.7313920000000000e+06,
      "workspace_megabytes": 4.5122070312500000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__7032941452476097680<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:8/input[2]:14/input[3]:14/filter_count:16/filter_height:5/filter_width:5/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 6792,
      "real_time": 1.0289580829646920e+05,
      "cpu_time": 1.0924487176124907e+05,
      "time_unit": "ns",
      "items_per_second": 3.1208890363614475e+10,
      "advised_convolution_algorithm": 4.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.3950976000000000e+07,
      "advised_time": 1.2492799758911133e-01,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)5; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.6667819325789325e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 5.0000000000000000e+00,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.6000000000000000e+01,
      "filter_height": 5.0000000000000000e+00,
      "filter_width": 5.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 8.0000000000000000e+00,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 8.0000000000000000e+00,
      "input_height": 1.4000000000000000e+01,
      "input_size": 2.0070400000000000e+05,
      "input_width": 1.4000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.6000000000000000e+01,
      "num_iterations": 6.7920000000000000e+03,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 1.6000000000000000e+01,
      "output_height": 1.0000000000000000e+01,
      "output_size": 2.0480000000000000e+05,
      "output_width": 1.0000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 7.7624250651842484e+10,
      "predicted_advised_flops_count": 7.9872100142290583e+06,
      "predicted_flops": 7.7624250651842484e+10,
      "predicted_flops_count": 7.9872100142290583e+06,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 1.3950976000000000e+07,
      "workspace_megabytes": 1.3304687500000000e+01
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__7032941452476097680<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:8/input[2]:14/input[3]:14/filter_count:16/filter_height:5/filter_width:5/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__7032941452476097680<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:8/input[2]:14/input[3]:14/filter_count:16/filter_height:5/filter_width:5/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 8923,
      "real_time": 7.8193194172024945e+04,
      "cpu_time": 8.4505709626432668e+04,
      "time_unit": "ns",
      "items_per_second": 4.1068331253167931e+10,
      "advised_convolution_algorithm": 4.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 8.3932160000000000e+06,
      "advised_time": 8.4959998726844788e-02,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)7; cudnnMathType_t math_type = (cudnnMathType_t)0]": 8.2538945752816425e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 7.0000000000000000e+00,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.6000000000000000e+01,
      "filter_height": 5.0000000000000000e+00,
      "filter_width": 5.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 8.0000000000000000e+00,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 8.0000000000000000e+00,
      "input_height": 1.4000000000000000e+01,
      "input_size": 2.0070400000000000e+05,
      "input_width": 1.4000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.6000000000000000e+01,
      "num_iterations": 8.9230000000000000e+03,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 1.6000000000000000e+01,
      "output_height": 1.0000000000000000e+01,
      "output_size": 2.0480000000000000e+05,
      "output_width": 1.0000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 1.0214712544748082e+11,
      "predicted_advised_flops_count": 7.9872100142290583e+06,
      "predicted_flops": -1.2788836811040117e+04,
      "predicted_flops_count": -1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 8.3932160000000000e+06,
      "workspace_megabytes": 8.0043945312500000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__12881974682802933222<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:1/input[1]:96/input[2]:13/input[3]:13/filter_count:208/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 11141,
      "real_time": 6.2471879439051401e+04,
      "cpu_time": 6.8386979087091429e+04,
      "time_unit": "ns",
      "items_per_second": 5.4017776162670242e+10,
      "advised_convolution_algorithm": 6.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 6.3487999141216278e-02,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4730153338016043e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.0800000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 9.6000000000000000e+01,
      "input[2]": 1.3000000000000000e+01,
      "input[3]": 1.3000000000000000e+01,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 9.6000000000000000e+01,
      "input_height": 1.3000000000000000e+01,
      "input_size": 1.6224000000000000e+04,
      "input_width": 1.3000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 2.0800000000000000e+02,
      "num_iterations": 1.1141000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 2.0800000000000000e+02,
      "output_height": 1.3000000000000000e+01,
      "output_size": 3.5152000000000000e+04,
      "output_width": 1.3000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "predicted_advised_flops": -1.6007202104038131e+04,
      "predicted_advised_flops_count": -1.0000000000000000e+00,
      "predicted_flops": 4.8615998546403223e+11,
      "predicted_flops_count": 3.0371328000000000e+07,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__12881974682802933222<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:1/input[1]:96/input[2]:13/input[3]:13/filter_count:208/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 5735,
      "real_time": 1.2197042884277309e+05,
      "cpu_time": 1.2815569747268999e+05,
      "time_unit": "ns",
      "items_per_second": 2.7667296344018299e+10,
      "advised_convolution_algorithm": 6.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.0200000000000000e+03,
      "advised_time": 1.2390399724245071e-01,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.2419525699096977e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.0800000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 9.6000000000000000e+01,
      "input[2]": 1.3000000000000000e+01,
      "input[3]": 1.3000000000000000e+01,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 9.6000000000000000e+01,
      "input_height": 1.3000000000000000e+01,
      "input_size": 1.6224000000000000e+04,
      "input_width": 1.3000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 2.0800000000000000e+02,
      "num_iterations": 5.7350000000000000e+03,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 2.0800000000000000e+02,
      "output_height": 1.3000000000000000e+01,
      "output_size": 3.5152000000000000e+04,
      "output_width": 1.3000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "predicted_advised_flops": -8.1987085680337932e+03,
      "predicted_advised_flops_count": -1.0000000000000000e+00,
      "predicted_flops": 2.4900566709616467e+11,
      "predicted_flops_count": 3.0371328000000000e+07,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 1.0200000000000000e+03,
      "workspace_megabytes": 9.7274780273437500e-04
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__12881974682802933222<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:1/input[1]:96/input[2]:13/input[3]:13/filter_count:208/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 7813,
      "real_time": 8.9767156815114970e+04,
      "cpu_time": 9.5890787406693547e+04,
      "time_unit": "ns",
      "items_per_second": 3.7592724552369766e+10,
      "advised_convolution_algorithm": 6.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 5.8406400000000000e+05,
      "advised_time": 9.1136001050472260e-02,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)2; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4280899851402570e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 2.0000000000000000e+00,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.0800000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 9.6000000000000000e+01,
      "input[2]": 1.3000000000000000e+01,
      "input[3]": 1.3000000000000000e+01,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 9.6000000000000000e+01,
      "input_height": 1.3000000000000000e+01,
      "input_size": 1.6224000000000000e+04,
      "input_width": 1.3000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 2.0800000000000000e+02,
      "num_iterations": 7.8130000000000000e+03,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 2.0800000000000000e+02,
      "output_height": 1.3000000000000000e+01,
      "output_size": 3.5152000000000000e+04,
      "output_width": 1.3000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "predicted_advised_flops": -1.1139931746525141e+04,
      "predicted_advised_flops_count": -1.0000000000000000e+00,
      "predicted_flops": 3.3833452097132794e+11,
      "predicted_flops_count": 3.0371328000000000e+07,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 5.8406400000000000e+05,
      "workspace_megabytes": 5.5700683593750000e-01
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__12881974682802933222<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:1/input[1]:96/input[2]:13/input[3]:13/filter_count:208/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__12881974682802933222<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:1/input[1]:96/input[2]:13/input[3]:13/filter_count:208/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 6459,
      "real_time": 1.0798153990493696e+05,
      "cpu_time": 1.1450787583126414e+05,
      "time_unit": "ns",
      "items_per_second": 3.1251563952235439e+10,
      "advised_convolution_algorithm": 6.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 4.6946304000000000e+07,
      "advised_time": 1.1059200018644333e-01,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)4; cudnnMathType_t math_type = (cudnnMathType_t)0]": 2.3237108083472476e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 4.0000000000000000e+00,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.0800000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 9.6000000000000000e+01,
      "input[2]": 1.3000000000000000e+01,
      "input[3]": 1.3000000000000000e+01,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 9.6000000000000000e+01,
      "input_height": 1.3000000000000000e+01,
      "input_size": 1.6224000000000000e+04,
      "input_width": 1.3000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 2.0800000000000000e+02,
      "num_iterations": 6.4590000000000000e+03,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 2.0800000000000000e+02,
      "output_height": 1.3000000000000000e+01,
      "output_size": 3.5152000000000000e+04,
      "output_width": 1.3000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "predicted_advised_flops": -9.2608421854361768e+03,
      "predicted_advised_flops_count": -1.0000000000000000e+00,
      "predicted_flops": 2.6606184858868887e+11,
      "predicted_flops_count": 2.8729768120560803e+07,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 4.6946304000000000e+07,
      "workspace_megabytes": 4.4771484375000000e+01
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__12881974682802933222<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:1/input[1]:96/input[2]:13/input[3]:13/filter_count:208/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 2024,
      "real_time": 3.4859278959428280e+05,
      "cpu_time": 3.5692428260886692e+05,
      "time_unit": "ns",
      "items_per_second": 9.6806133136821079e+09,
      "advised_convolution_algorithm": 6.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 8.8248320000000000e+07,
      "advised_time": 3.8809600472450256e-01,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)5; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.6667819325789325e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 5.0000000000000000e+00,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.0800000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 9.6000000000000000e+01,
      "input[2]": 1.3000000000000000e+01,
      "input[3]": 1.3000000000000000e+01,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 9.6000000000000000e+01,
      "input_height": 1.3000000000000000e+01,
      "input_size": 1.6224000000000000e+04,
      "input_width": 1.3000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 2.0800000000000000e+02,
      "num_iterations": 2.0240000000000000e+03,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 2.0800000000000000e+02,
      "output_height": 1.3000000000000000e+01,
      "output_size": 3.5152000000000000e+04,
      "output_width": 1.3000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "predicted_advised_flops": -2.8686766618548577e+03,
      "predicted_advised_flops_count": -1.0000000000000000e+00,
      "predicted_flops": 8.2416415307954483e+10,
      "predicted_flops_count": 2.8729768120560803e+07,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 8.8248320000000000e+07,
      "workspace_megabytes": 8.4160156250000000e+01
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__12881974682802933222<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:1/input[1]:96/input[2]:13/input[3]:13/filter_count:208/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 18330,
      "real_time": 3.8283108453948364e+04,
      "cpu_time": 4.4202386252694567e+04,
      "time_unit": "ns",
      "items_per_second": 8.8148327977582458e+10,
      "advised_convolution_algorithm": 6.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 2.0959360000000000e+06,
      "advised_time": 6.2463998794555664e-02,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)6; cudnnMathType_t math_type = (cudnnMathType_t)0]": 5.7500739770702787e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 6.0000000000000000e+00,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.0800000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 9.6000000000000000e+01,
      "input[2]": 1.3000000000000000e+01,
      "input[3]": 1.3000000000000000e+01,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 9.6000000000000000e+01,
      "input_height": 1.3000000000000000e+01,
      "input_size": 1.6224000000000000e+04,
      "input_width": 1.3000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 2.0800000000000000e+02,
      "num_iterations": 1.8330000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 2.0800000000000000e+02,
      "output_height": 1.3000000000000000e+01,
      "output_size": 3.5152000000000000e+04,
      "output_width": 1.3000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "predicted_advised_flops": -2.6121180865000111e+04,
      "predicted_advised_flops_count": -1.0000000000000000e+00,
      "predicted_flops": -2.6121180865000111e+04,
      "predicted_flops_count": -1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 2.0959360000000000e+06,
      "workspace_megabytes": 1.9988403320312500e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__12881974682802933222<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:1/input[1]:96/input[2]:13/input[3]:13/filter_count:208/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 7916,
      "real_time": 8.8530293165450741e+04,
      "cpu_time": 9.4928331605251442e+04,
      "time_unit": "ns",
      "items_per_second": 3.8117935447173538e+10,
      "advised_convolution_algorithm": 6.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.4082048000000000e+07,
      "advised_time": 1.0342399775981903e-01,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)7; cudnnMathType_t math_type = (cudnnMathType_t)0]": 8.2538945752816425e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 7.0000000000000000e+00,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.0800000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 9.6000000000000000e+01,
      "input[2]": 1.3000000000000000e+01,
      "input[3]": 1.3000000000000000e+01,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 9.6000000000000000e+01,
      "input_height": 1.3000000000000000e+01,
      "input_size": 1.6224000000000000e+04,
      "input_width": 1.3000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 2.0800000000000000e+02,
      "num_iterations": 7.9160000000000000e+03,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 2.0800000000000000e+02,
      "output_height": 1.3000000000000000e+01,
      "output_size": 3.5152000000000000e+04,
      "output_width": 1.3000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "predicted_advised_flops": -1.1295568604196756e+04,
      "predicted_advised_flops_count": -1.0000000000000000e+00,
      "predicted_flops": -1.1295568604196756e+04,
      "predicted_flops_count": -1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 1.4082048000000000e+07,
      "workspace_megabytes": 1.3429687500000000e+01
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__736502095446915514<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:1/input[1]:608/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 15074,
      "real_time": 4.6487515133881214e+04,
      "cpu_time": 5.2478042258294241e+04,
      "time_unit": "ns",
      "items_per_second": 3.2812044171582062e+11,
      "advised_convolution_algorithm": 0.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 4.7104001045227051e-02,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4730153338016043e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 6.0800000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 6.0800000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 1.1916800000000000e+05,
      "input_width": 1.4000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 1.5074000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 2.5088000000000000e+04,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 3.2812044171582062e+11,
      "predicted_advised_flops_count": 1.5253504000000000e+07,
      "predicted_flops": 3.2812044171582062e+11,
      "predicted_flops_count": 1.5253504000000000e+07,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__736502095446915514<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:1/input[1]:608/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 7868,
      "real_time": 8.8837858798930407e+04,
      "cpu_time": 9.4968237672523421e+04,
      "time_unit": "ns",
      "items_per_second": 1.7170049127955402e+11,
      "advised_convolution_algorithm": 0.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.1840000000000000e+03,
      "advised_time": 9.1168001294136047e-02,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.2419525699096977e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 6.0800000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 6.0800000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 1.1916800000000000e+05,
      "input_width": 1.4000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 7.8680000000000000e+03,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 2.5088000000000000e+04,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 1.7170049127955402e+11,
      "predicted_advised_flops_count": 1.5253504000000000e+07,
      "predicted_flops": 1.7170049127955402e+11,
      "predicted_flops_count": 1.5253504000000000e+07,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 1.1840000000000000e+03,
      "workspace_megabytes": 1.1291503906250000e-03
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__736502095446915514<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:1/input[1]:608/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 5377,
      "real_time": 1.2969497517980610e+05,
      "cpu_time": 1.3616523042421538e+05,
      "time_unit": "ns",
      "items_per_second": 1.1761060117288966e+11,
      "advised_convolution_algorithm": 0.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 4.7667200000000000e+05,
      "advised_time": 1.3107199966907501e-01,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)2; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4280899851402570e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 2.0000000000000000e+00,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 6.0800000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 6.0800000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 1.1916800000000000e+05,
      "input_width": 1.4000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 5.3770000000000000e+03,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 2.5088000000000000e+04,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 1.1761060117288966e+11,
      "predicted_advised_flops_count": 1.5253504000000000e+07,
      "predicted_flops": 1.1761060117288966e+11,
      "predicted_flops_count": 1.5253504000000000e+07,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 4.7667200000000000e+05,
      "workspace_megabytes": 4.5458984375000000e-01
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__736502095446915514<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:1/input[1]:608/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__736502095446915514<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:1/input[1]:608/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 2126,
      "real_time": 3.3152291433995648e+05,
      "cpu_time": 3.3989213029248547e+05,
      "time_unit": "ns",
      "items_per_second": 4.6010406340596008e+10,
      "advised_convolution_algorithm": 0.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.8101862400000000e+08,
      "advised_time": 3.3894398808479309e-01,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)4; cudnnMathType_t math_type = (cudnnMathType_t)0]": 2.3237108083472476e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 4.0000000000000000e+00,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 6.0800000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 6.0800000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 1.1916800000000000e+05,
      "input_width": 1.4000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 2.1260000000000000e+03,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 2.5088000000000000e+04,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 4.6010406340596008e+10,
      "predicted_advised_flops_count": 1.5253504000000000e+07,
      "predicted_flops": 3.9967969910354279e+11,
      "predicted_flops_count": 1.3250297864932339e+08,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 1.8101862400000000e+08,
      "workspace_megabytes": 1.7263281250000000e+02
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__736502095446915514<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:1/input[1]:608/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 5395,
      "real_time": 1.2951613270556356e+05,
      "cpu_time": 1.3601280092655940e+05,
      "time_unit": "ns",
      "items_per_second": 1.1777300388266429e+11,
      "advised_convolution_algorithm": 0.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.1985824000000000e+07,
      "advised_time": 1.5257599949836731e-01,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)5; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.6667819325789325e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 5.0000000000000000e+00,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 6.0800000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 6.0800000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 1.1916800000000000e+05,
      "input_width": 1.4000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 5.3950000000000000e+03,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 2.5088000000000000e+04,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 1.1777300388266429e+11,
      "predicted_advised_flops_count": 1.5253504000000000e+07,
      "predicted_flops": 1.0230615745032321e+12,
      "predicted_flops_count": 1.3250297864932339e+08,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 1.1985824000000000e+07,
      "workspace_megabytes": 1.1430572509765625e+01
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__736502095446915514<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:1/input[1]:608/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__736502095446915514<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:1/input[1]:608/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__16728485132556763852<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:32/input[2]:112/input[3]:112/filter_count:32/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 769,
      "real_time": 9.1087547945638606e+05,
      "cpu_time": 9.2916148244001507e+05,
      "time_unit": "ns",
      "items_per_second": 1.8050405407567290e+12,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 9.2262399196624756e-01,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4730153338016043e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 3.2000000000000000e+01,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 3.2000000000000000e+01,
      "input[2]": 1.1200000000000000e+02,
      "input[3]": 1.1200000000000000e+02,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 3.2000000000000000e+01,
      "input_height": 1.1200000000000000e+02,
      "input_size": 5.1380224000000000e+07,
      "input_width": 1.1200000000000000e+02,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 3.2000000000000000e+01,
      "num_iterations": 7.6900000000000000e+02,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 3.2000000000000000e+01,
      "output_height": 1.1200000000000000e+02,
      "output_size": 5.1380224000000000e+07,
      "output_width": 1.1200000000000000e+02,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 1.8050405407567290e+12,
      "predicted_advised_flops_count": 1.6441671680000000e+09,
      "predicted_flops": 1.8050405407567290e+12,
      "predicted_flops_count": 1.6441671680000000e+09,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__16728485132556763852<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:32/input[2]:112/input[3]:112/filter_count:32/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 972,
      "real_time": 7.1963864206643042e+05,
      "cpu_time": 7.3340279835265549e+05,
      "time_unit": "ns",
      "items_per_second": 2.2847121762094390e+12,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 7.5272000000000000e+04,
      "advised_time": 7.4035197496414185e-01,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.2419525699096977e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 3.2000000000000000e+01,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 3.2000000000000000e+01,
      "input[2]": 1.1200000000000000e+02,
      "input[3]": 1.1200000000000000e+02,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 3.2000000000000000e+01,
      "input_height": 1.1200000000000000e+02,
      "input_size": 5.1380224000000000e+07,
      "input_width": 1.1200000000000000e+02,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 3.2000000000000000e+01,
      "num_iterations": 9.7200000000000000e+02,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 3.2000000000000000e+01,
      "output_height": 1.1200000000000000e+02,
      "output_size": 5.1380224000000000e+07,
      "output_width": 1.1200000000000000e+02,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 2.2847121762094390e+12,
      "predicted_advised_flops_count": 1.6441671680000000e+09,
      "predicted_flops": 2.2847121762094390e+12,
      "predicted_flops_count": 1.6441671680000000e+09,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 7.5272000000000000e+04,
      "workspace_megabytes": 7.1784973144531250e-02
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__16728485132556763852<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:32/input[2]:112/input[3]:112/filter_count:32/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 402,
      "real_time": 1.7417626367390750e+06,
      "cpu_time": 1.7917058532291106e+06,
      "time_unit": "ns",
      "items_per_second": 9.4396741170094629e+11,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 2.0552089600000000e+08,
      "advised_time": 1.7459199428558350e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)2; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4280899851402570e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 2.0000000000000000e+00,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 3.2000000000000000e+01,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 3.2000000000000000e+01,
      "input[2]": 1.1200000000000000e+02,
      "input[3]": 1.1200000000000000e+02,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 3.2000000000000000e+01,
      "input_height": 1.1200000000000000e+02,
      "input_size": 5.1380224000000000e+07,
      "input_width": 1.1200000000000000e+02,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 3.2000000000000000e+01,
      "num_iterations": 4.0200000000000000e+02,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 3.2000000000000000e+01,
      "output_height": 1.1200000000000000e+02,
      "output_size": 5.1380224000000000e+07,
      "output_width": 1.1200000000000000e+02,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 9.4396741170094629e+11,
      "predicted_advised_flops_count": 1.6441671680000000e+09,
      "predicted_flops": 9.4396741170094629e+11,
      "predicted_flops_count": 1.6441671680000000e+09,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 2.0552089600000000e+08,
      "workspace_megabytes": 1.9600000000000000e+02
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__16728485132556763852<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:32/input[2]:112/input[3]:112/filter_count:32/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__16728485132556763852<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:32/input[2]:112/input[3]:112/filter_count:32/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 91,
      "real_time": 7.6562560337421661e+06,
      "cpu_time": 8.5055261098769624e+06,
      "time_unit": "ns",
      "items_per_second": 2.1474819556111118e+11,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 6.8196761600000000e+08,
      "advised_time": 7.8981118202209473e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)4; cudnnMathType_t math_type = (cudnnMathType_t)0]": 2.3237108083472476e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 4.0000000000000000e+00,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 3.2000000000000000e+01,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 3.2000000000000000e+01,
      "input[2]": 1.1200000000000000e+02,
      "input[3]": 1.1200000000000000e+02,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 3.2000000000000000e+01,
      "input_height": 1.1200000000000000e+02,
      "input_size": 5.1380224000000000e+07,
      "input_width": 1.1200000000000000e+02,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 3.2000000000000000e+01,
      "num_iterations": 9.1000000000000000e+01,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 3.2000000000000000e+01,
      "output_height": 1.1200000000000000e+02,
      "output_size": 5.1380224000000000e+07,
      "output_width": 1.1200000000000000e+02,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 2.1474819556111118e+11,
      "predicted_advised_flops_count": 1.6441671680000000e+09,
      "predicted_flops": 4.2032326860022479e+11,
      "predicted_flops_count": 3.2181025613427000e+09,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 6.8196761600000000e+08,
      "workspace_megabytes": 6.5037500000000000e+02
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__16728485132556763852<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:32/input[2]:112/input[3]:112/filter_count:32/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 227,
      "real_time": 3.0888979495523521e+06,
      "cpu_time": 3.2302127577153970e+06,
      "time_unit": "ns",
      "items_per_second": 5.3228277361454279e+11,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 2.4970118400000000e+08,
      "advised_time": 3.2665600776672363e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)5; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.6667819325789325e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 5.0000000000000000e+00,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 3.2000000000000000e+01,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 3.2000000000000000e+01,
      "input[2]": 1.1200000000000000e+02,
      "input[3]": 1.1200000000000000e+02,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 3.2000000000000000e+01,
      "input_height": 1.1200000000000000e+02,
      "input_size": 5.1380224000000000e+07,
      "input_width": 1.1200000000000000e+02,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 3.2000000000000000e+01,
      "num_iterations": 2.2700000000000000e+02,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 3.2000000000000000e+01,
      "output_height": 1.1200000000000000e+02,
      "output_size": 5.1380224000000000e+07,
      "output_width": 1.1200000000000000e+02,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 5.3228277361454279e+11,
      "predicted_advised_flops_count": 1.6441671680000000e+09,
      "predicted_flops": 1.0418287084586501e+12,
      "predicted_flops_count": 3.2181025613427000e+09,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 2.4970118400000000e+08,
      "workspace_megabytes": 2.3813360595703125e+02
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__16728485132556763852<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:32/input[2]:112/input[3]:112/filter_count:32/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__16728485132556763852<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:32/input[2]:112/input[3]:112/filter_count:32/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__5841195909144926381<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:1/input[1]:16/input[2]:13/input[3]:13/filter_count:48/filter_height:5/filter_width:5/pad_height:2/pad_width:2/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 20652,
      "real_time": 3.3944116952221586e+04,
      "cpu_time": 3.9828510314114195e+04,
      "time_unit": "ns",
      "items_per_second": 3.8236964650661011e+09,
      "advised_convolution_algorithm": 4.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 3.4816000610589981e-02,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4730153338016043e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 4.8000000000000000e+01,
      "filter_height": 5.0000000000000000e+00,
      "filter_width": 5.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 1.6000000000000000e+01,
      "input[2]": 1.3000000000000000e+01,
      "input[3]": 1.3000000000000000e+01,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 1.6000000000000000e+01,
      "input_height": 1.3000000000000000e+01,
      "input_size": 2.7040000000000000e+03,
      "input_width": 1.3000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 4.8000000000000000e+01,
      "num_iterations": 2.0652000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 4.8000000000000000e+01,
      "output_height": 1.3000000000000000e+01,
      "output_size": 8.1120000000000000e+03,
      "output_width": 1.3000000000000000e+01,
      "pad_height": 2.0000000000000000e+00,
      "pad_width": 2.0000000000000000e+00,
      "predicted_advised_flops": 3.4480639382199738e+10,
      "predicted_advised_flops_count": 1.1704148557767654e+06,
      "predicted_flops": 9.5592411626652527e+10,
      "predicted_flops_count": 3.2448000000000000e+06,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__5841195909144926381<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:1/input[1]:16/input[2]:13/input[3]:13/filter_count:48/filter_height:5/filter_width:5/pad_height:2/pad_width:2/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 10321,
      "real_time": 6.7394641077044595e+04,
      "cpu_time": 7.3386548105438007e+04,
      "time_unit": "ns",
      "items_per_second": 1.9258504522877958e+09,
      "advised_convolution_algorithm": 4.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.0200000000000000e+03,
      "advised_time": 6.7584000527858734e-02,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.2419525699096977e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 4.8000000000000000e+01,
      "filter_height": 5.0000000000000000e+00,
      "filter_width": 5.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 1.6000000000000000e+01,
      "input[2]": 1.3000000000000000e+01,
      "input[3]": 1.3000000000000000e+01,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 1.6000000000000000e+01,
      "input_height": 1.3000000000000000e+01,
      "input_size": 2.7040000000000000e+03,
      "input_width": 1.3000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 4.8000000000000000e+01,
      "num_iterations": 1.0321000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 4.8000000000000000e+01,
      "output_height": 1.3000000000000000e+01,
      "output_size": 8.1120000000000000e+03,
      "output_width": 1.3000000000000000e+01,
      "pad_height": 2.0000000000000000e+00,
      "pad_width": 2.0000000000000000e+00,
      "predicted_advised_flops": 1.7366586379453579e+10,
      "predicted_advised_flops_count": 1.1704148557767654e+06,
      "predicted_flops": 4.8146261307194893e+10,
      "predicted_flops_count": 3.2448000000000000e+06,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 1.0200000000000000e+03,
      "workspace_megabytes": 9.7274780273437500e-04
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__5841195909144926381<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:1/input[1]:16/input[2]:13/input[3]:13/filter_count:48/filter_height:5/filter_width:5/pad_height:2/pad_width:2/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 11652,
      "real_time": 5.9947423177304074e+04,
      "cpu_time": 6.5912291280919191e+04,
      "time_unit": "ns",
      "items_per_second": 2.1650972322216330e+09,
      "advised_convolution_algorithm": 4.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 2.7040000000000000e+05,
      "advised_time": 6.1439998447895050e-02,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)2; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4280899851402570e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 2.0000000000000000e+00,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 4.8000000000000000e+01,
      "filter_height": 5.0000000000000000e+00,
      "filter_width": 5.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 1.6000000000000000e+01,
      "input[2]": 1.3000000000000000e+01,
      "input[3]": 1.3000000000000000e+01,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 1.6000000000000000e+01,
      "input_height": 1.3000000000000000e+01,
      "input_size": 2.7040000000000000e+03,
      "input_width": 1.3000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 4.8000000000000000e+01,
      "num_iterations": 1.1652000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 4.8000000000000000e+01,
      "output_height": 1.3000000000000000e+01,
      "output_size": 8.1120000000000000e+03,
      "output_width": 1.3000000000000000e+01,
      "pad_height": 2.0000000000000000e+00,
      "pad_width": 2.0000000000000000e+00,
      "predicted_advised_flops": 1.9524022781013901e+10,
      "predicted_advised_flops_count": 1.1704148557767654e+06,
      "predicted_flops": 5.4127430805540817e+10,
      "predicted_flops_count": 3.2448000000000000e+06,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 2.7040000000000000e+05,
      "workspace_megabytes": 2.5787353515625000e-01
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__5841195909144926381<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:1/input[1]:16/input[2]:13/input[3]:13/filter_count:48/filter_height:5/filter_width:5/pad_height:2/pad_width:2/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__5841195909144926381<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:1/input[1]:16/input[2]:13/input[3]:13/filter_count:48/filter_height:5/filter_width:5/pad_height:2/pad_width:2/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 16056,
      "real_time": 4.2710678520441434e+04,
      "cpu_time": 4.8615787244775078e+04,
      "time_unit": "ns",
      "items_per_second": 3.0388653258664861e+09,
      "advised_convolution_algorithm": 4.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 6.9007360000000000e+06,
      "advised_time": 4.6080000698566437e-02,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)4; cudnnMathType_t math_type = (cudnnMathType_t)0]": 2.3237108083472476e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 4.0000000000000000e+00,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 4.8000000000000000e+01,
      "filter_height": 5.0000000000000000e+00,
      "filter_width": 5.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 1.6000000000000000e+01,
      "input[2]": 1.3000000000000000e+01,
      "input[3]": 1.3000000000000000e+01,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 1.6000000000000000e+01,
      "input_height": 1.3000000000000000e+01,
      "input_size": 2.7040000000000000e+03,
      "input_width": 1.3000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 4.8000000000000000e+01,
      "num_iterations": 1.6056000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 4.8000000000000000e+01,
      "output_height": 1.3000000000000000e+01,
      "output_size": 8.1120000000000000e+03,
      "output_width": 1.3000000000000000e+01,
      "pad_height": 2.0000000000000000e+00,
      "pad_width": 2.0000000000000000e+00,
      "predicted_advised_flops": 2.7403330884022411e+10,
      "predicted_advised_flops_count": 1.1704148557767654e+06,
      "predicted_flops": 2.7403330884022411e+10,
      "predicted_flops_count": 1.1704148557767654e+06,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 6.9007360000000000e+06,
      "workspace_megabytes": 6.5810546875000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__5841195909144926381<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:1/input[1]:16/input[2]:13/input[3]:13/filter_count:48/filter_height:5/filter_width:5/pad_height:2/pad_width:2/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 17466,
      "real_time": 4.0010186347875795e+04,
      "cpu_time": 4.5901649090249390e+04,
      "time_unit": "ns",
      "items_per_second": 3.2439738938354349e+09,
      "advised_convolution_algorithm": 4.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 3.6454400000000000e+06,
      "advised_time": 4.7104001045227051e-02,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)5; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.6667819325789325e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 5.0000000000000000e+00,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 4.8000000000000000e+01,
      "filter_height": 5.0000000000000000e+00,
      "filter_width": 5.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 1.6000000000000000e+01,
      "input[2]": 1.3000000000000000e+01,
      "input[3]": 1.3000000000000000e+01,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 1.6000000000000000e+01,
      "input_height": 1.3000000000000000e+01,
      "input_size": 2.7040000000000000e+03,
      "input_width": 1.3000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 4.8000000000000000e+01,
      "num_iterations": 1.7466000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 4.8000000000000000e+01,
      "output_height": 1.3000000000000000e+01,
      "output_size": 8.1120000000000000e+03,
      "output_width": 1.3000000000000000e+01,
      "pad_height": 2.0000000000000000e+00,
      "pad_width": 2.0000000000000000e+00,
      "predicted_advised_flops": 2.9252921883451927e+10,
      "predicted_advised_flops_count": 1.1704148557767654e+06,
      "predicted_flops": 2.9252921883451927e+10,
      "predicted_flops_count": 1.1704148557767654e+06,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 3.6454400000000000e+06,
      "workspace_megabytes": 3.4765625000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__5841195909144926381<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:1/input[1]:16/input[2]:13/input[3]:13/filter_count:48/filter_height:5/filter_width:5/pad_height:2/pad_width:2/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__5841195909144926381<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:1/input[1]:16/input[2]:13/input[3]:13/filter_count:48/filter_height:5/filter_width:5/pad_height:2/pad_width:2/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 17429,
      "real_time": 4.0177937603889426e+04,
      "cpu_time": 4.6114551953639406e+04,
      "time_unit": "ns",
      "items_per_second": 3.2304296273145556e+09,
      "advised_convolution_algorithm": 4.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 3.2880640000000000e+06,
      "advised_time": 4.7104001045227051e-02,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)7; cudnnMathType_t math_type = (cudnnMathType_t)0]": 8.2538945752816425e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 7.0000000000000000e+00,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 4.8000000000000000e+01,
      "filter_height": 5.0000000000000000e+00,
      "filter_width": 5.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 1.6000000000000000e+01,
      "input[2]": 1.3000000000000000e+01,
      "input[3]": 1.3000000000000000e+01,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 1.6000000000000000e+01,
      "input_height": 1.3000000000000000e+01,
      "input_size": 2.7040000000000000e+03,
      "input_width": 1.3000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 4.8000000000000000e+01,
      "num_iterations": 1.7429000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 4.8000000000000000e+01,
      "output_height": 1.3000000000000000e+01,
      "output_size": 8.1120000000000000e+03,
      "output_width": 1.3000000000000000e+01,
      "pad_height": 2.0000000000000000e+00,
      "pad_width": 2.0000000000000000e+00,
      "predicted_advised_flops": 2.9130784843059322e+10,
      "predicted_advised_flops_count": 1.1704148557767654e+06,
      "predicted_flops": -2.4889281522085766e+04,
      "predicted_flops_count": -1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 3.2880640000000000e+06,
      "workspace_megabytes": 3.1357421875000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__1569287348367311653<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:1/input[1]:352/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 22778,
      "real_time": 3.0735184252346698e+04,
      "cpu_time": 3.6710611159870175e+04,
      "time_unit": "ns",
      "items_per_second": 2.8732464811320386e+11,
      "advised_convolution_algorithm": 0.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 3.1743999570608139e-02,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4730153338016043e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 3.5200000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 3.5200000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 6.8992000000000000e+04,
      "input_width": 1.4000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 2.2778000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 2.5088000000000000e+04,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 2.8732464811320386e+11,
      "predicted_advised_flops_count": 8.8309760000000000e+06,
      "predicted_flops": 2.8732464811320386e+11,
      "predicted_flops_count": 8.8309760000000000e+06,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__1569287348367311653<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:1/input[1]:352/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 11788,
      "real_time": 5.8845954392198510e+04,
      "cpu_time": 6.4882157533368489e+04,
      "time_unit": "ns",
      "items_per_second": 1.5006938184982120e+11,
      "advised_convolution_algorithm": 0.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.1840000000000000e+03,
      "advised_time": 6.0416001826524734e-02,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.2419525699096977e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 3.5200000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 3.5200000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 6.8992000000000000e+04,
      "input_width": 1.4000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 1.1788000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 2.5088000000000000e+04,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 1.5006938184982120e+11,
      "predicted_advised_flops_count": 8.8309760000000000e+06,
      "predicted_flops": 1.5006938184982120e+11,
      "predicted_flops_count": 8.8309760000000000e+06,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 1.1840000000000000e+03,
      "workspace_megabytes": 1.1291503906250000e-03
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__1569287348367311653<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:1/input[1]:352/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 6069,
      "real_time": 1.1530953530841717e+05,
      "cpu_time": 1.2161278595962959e+05,
      "time_unit": "ns",
      "items_per_second": 7.6584958705972443e+10,
      "advised_convolution_algorithm": 0.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 2.7596800000000000e+05,
      "advised_time": 1.1571200191974640e-01,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)2; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4280899851402570e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 2.0000000000000000e+00,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 3.5200000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 3.5200000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 6.8992000000000000e+04,
      "input_width": 1.4000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 6.0690000000000000e+03,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 2.5088000000000000e+04,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 7.6584958705972443e+10,
      "predicted_advised_flops_count": 8.8309760000000000e+06,
      "predicted_flops": 7.6584958705972443e+10,
      "predicted_flops_count": 8.8309760000000000e+06,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 2.7596800000000000e+05,
      "workspace_megabytes": 2.6318359375000000e-01
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__1569287348367311653<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:1/input[1]:352/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__1569287348367311653<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:1/input[1]:352/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 3439,
      "real_time": 2.0371355934744372e+05,
      "cpu_time": 2.1069221866684617e+05,
      "time_unit": "ns",
      "items_per_second": 4.3349966631029831e+10,
      "advised_convolution_algorithm": 0.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.0480025600000000e+08,
      "advised_time": 2.1094399690628052e-01,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)4; cudnnMathType_t math_type = (cudnnMathType_t)0]": 2.3237108083472476e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 4.0000000000000000e+00,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 3.5200000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 3.5200000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 6.8992000000000000e+04,
      "input_width": 1.4000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 3.4390000000000000e+03,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 2.5088000000000000e+04,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 4.3349966631029831e+10,
      "predicted_advised_flops_count": 8.8309760000000000e+06,
      "predicted_flops": 3.7696404710844855e+11,
      "predicted_flops_count": 7.6792687782479510e+07,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 1.0480025600000000e+08,
      "workspace_megabytes": 9.9945312500000000e+01
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__1569287348367311653<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:1/input[1]:352/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 8137,
      "real_time": 8.6124606254097744e+04,
      "cpu_time": 9.2372845275066938e+04,
      "time_unit": "ns",
      "items_per_second": 1.0253720027404861e+11,
      "advised_convolution_algorithm": 0.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 7.0419520000000000e+06,
      "advised_time": 1.0243199765682220e-01,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)5; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.6667819325789325e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 5.0000000000000000e+00,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 3.5200000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 3.5200000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 6.8992000000000000e+04,
      "input_width": 1.4000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 8.1370000000000000e+03,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 2.5088000000000000e+04,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 1.0253720027404861e+11,
      "predicted_advised_flops_count": 8.8309760000000000e+06,
      "predicted_flops": 8.9164631482800854e+11,
      "predicted_flops_count": 7.6792687782479510e+07,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 7.0419520000000000e+06,
      "workspace_megabytes": 6.7157287597656250e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__1569287348367311653<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:1/input[1]:352/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__1569287348367311653<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:1/input[1]:352/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__2162950824770925913<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:1/input[1]:352/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 16118,
      "real_time": 4.3429610578930602e+04,
      "cpu_time": 4.9394915125040890e+04,
      "time_unit": "ns",
      "items_per_second": 8.1335990650436548e+11,
      "advised_convolution_algorithm": 0.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 4.5024000108242035e-02,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4730153338016043e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 3.5200000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 3.5200000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 2.7596800000000000e+05,
      "input_width": 2.8000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 1.6118000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 1.0035200000000000e+05,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 8.1335990650436548e+11,
      "predicted_advised_flops_count": 3.5323904000000000e+07,
      "predicted_flops": 8.1335990650436548e+11,
      "predicted_flops_count": 3.5323904000000000e+07,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__2162950824770925913<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:1/input[1]:352/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 11729,
      "real_time": 5.9063955513514971e+04,
      "cpu_time": 6.5089781224697668e+04,
      "time_unit": "ns",
      "items_per_second": 5.9806194307316943e+11,
      "advised_convolution_algorithm": 0.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 4.7120000000000000e+03,
      "advised_time": 6.1439998447895050e-02,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.2419525699096977e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 3.5200000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 3.5200000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 2.7596800000000000e+05,
      "input_width": 2.8000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 1.1729000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 1.0035200000000000e+05,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 5.9806194307316943e+11,
      "predicted_advised_flops_count": 3.5323904000000000e+07,
      "predicted_flops": 5.9806194307316943e+11,
      "predicted_flops_count": 3.5323904000000000e+07,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 4.7120000000000000e+03,
      "workspace_megabytes": 4.4937133789062500e-03
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__2162950824770925913<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:1/input[1]:352/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 5248,
      "real_time": 1.3182818930744828e+05,
      "cpu_time": 1.3830031288143390e+05,
      "time_unit": "ns",
      "items_per_second": 2.6795410136156824e+11,
      "advised_convolution_algorithm": 0.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.1038720000000000e+06,
      "advised_time": 1.3312000036239624e-01,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)2; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4280899851402570e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 2.0000000000000000e+00,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 3.5200000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 3.5200000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 2.7596800000000000e+05,
      "input_width": 2.8000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 5.2480000000000000e+03,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 1.0035200000000000e+05,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 2.6795410136156824e+11,
      "predicted_advised_flops_count": 3.5323904000000000e+07,
      "predicted_flops": 2.6795410136156824e+11,
      "predicted_flops_count": 3.5323904000000000e+07,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 1.1038720000000000e+06,
      "workspace_megabytes": 1.0527343750000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__2162950824770925913<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:1/input[1]:352/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__2162950824770925913<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:1/input[1]:352/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 943,
      "real_time": 7.1589626576297171e+05,
      "cpu_time": 7.3117239554947673e+05,
      "time_unit": "ns",
      "items_per_second": 4.9342210162743752e+10,
      "advised_convolution_algorithm": 0.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 3.9541145600000000e+08,
      "advised_time": 7.2908800840377808e-01,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)4; cudnnMathType_t math_type = (cudnnMathType_t)0]": 2.3237108083472476e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 4.0000000000000000e+00,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 3.5200000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 3.5200000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 2.7596800000000000e+05,
      "input_width": 2.8000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 9.4300000000000000e+02,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 1.0035200000000000e+05,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 4.9342210162743752e+10,
      "predicted_advised_flops_count": 3.5323904000000000e+07,
      "predicted_flops": 5.2880733876499963e+11,
      "predicted_flops_count": 3.7857119912991798e+08,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 3.9541145600000000e+08,
      "workspace_megabytes": 3.7709375000000000e+02
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__2162950824770925913<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:1/input[1]:352/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 7841,
      "real_time": 8.8821965590224296e+04,
      "cpu_time": 9.5284819794299590e+04,
      "time_unit": "ns",
      "items_per_second": 3.9769333818804535e+11,
      "advised_convolution_algorithm": 0.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 7.9558720000000000e+06,
      "advised_time": 1.1571200191974640e-01,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)5; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.6667819325789325e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 5.0000000000000000e+00,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 3.5200000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 3.5200000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 2.7596800000000000e+05,
      "input_width": 2.8000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 7.8410000000000000e+03,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 1.0035200000000000e+05,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 3.9769333818804535e+11,
      "predicted_advised_flops_count": 3.5323904000000000e+07,
      "predicted_flops": 4.2621348966362363e+12,
      "predicted_flops_count": 3.7857119912991798e+08,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 7.9558720000000000e+06,
      "workspace_megabytes": 7.5873107910156250e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__2162950824770925913<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:1/input[1]:352/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__2162950824770925913<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:1/input[1]:352/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__7106924633654065131<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:1/input[1]:512/input[2]:13/input[3]:13/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 17276,
      "real_time": 4.0506974475858442e+04,
      "cpu_time": 4.6573997568734558e+04,
      "time_unit": "ns",
      "items_per_second": 2.7342412370494086e+11,
      "advised_convolution_algorithm": 0.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 4.0959998965263367e-02,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4730153338016043e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 1.3000000000000000e+01,
      "input[3]": 1.3000000000000000e+01,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 1.3000000000000000e+01,
      "input_size": 8.6528000000000000e+04,
      "input_width": 1.3000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 1.7276000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 1.3000000000000000e+01,
      "output_size": 2.1632000000000000e+04,
      "output_width": 1.3000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 2.7342412370494086e+11,
      "predicted_advised_flops_count": 1.1075584000000000e+07,
      "predicted_flops": 2.7342412370494086e+11,
      "predicted_flops_count": 1.1075584000000000e+07,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__7106924633654065131<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:1/input[1]:512/input[2]:13/input[3]:13/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 8985,
      "real_time": 7.7618081549881666e+04,
      "cpu_time": 8.3724296160333601e+04,
      "time_unit": "ns",
      "items_per_second": 1.4269334900891898e+11,
      "advised_convolution_algorithm": 0.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.0200000000000000e+03,
      "advised_time": 7.9871997237205505e-02,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.2419525699096977e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 1.3000000000000000e+01,
      "input[3]": 1.3000000000000000e+01,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 1.3000000000000000e+01,
      "input_size": 8.6528000000000000e+04,
      "input_width": 1.3000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 8.9850000000000000e+03,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 1.3000000000000000e+01,
      "output_size": 2.1632000000000000e+04,
      "output_width": 1.3000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 1.4269334900891898e+11,
      "predicted_advised_flops_count": 1.1075584000000000e+07,
      "predicted_flops": 1.4269334900891898e+11,
      "predicted_flops_count": 1.1075584000000000e+07,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 1.0200000000000000e+03,
      "workspace_megabytes": 9.7274780273437500e-04
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__7106924633654065131<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:1/input[1]:512/input[2]:13/input[3]:13/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 5594,
      "real_time": 1.2503892189984083e+05,
      "cpu_time": 1.3145343367894361e+05,
      "time_unit": "ns",
      "items_per_second": 8.8577091290596756e+10,
      "advised_convolution_algorithm": 0.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 3.4611200000000000e+05,
      "advised_time": 1.2697599828243256e-01,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)2; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4280899851402570e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 2.0000000000000000e+00,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 1.3000000000000000e+01,
      "input[3]": 1.3000000000000000e+01,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 1.3000000000000000e+01,
      "input_size": 8.6528000000000000e+04,
      "input_width": 1.3000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 5.5940000000000000e+03,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 1.3000000000000000e+01,
      "output_size": 2.1632000000000000e+04,
      "output_width": 1.3000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 8.8577091290596756e+10,
      "predicted_advised_flops_count": 1.1075584000000000e+07,
      "predicted_flops": 8.8577091290596756e+10,
      "predicted_flops_count": 1.1075584000000000e+07,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 3.4611200000000000e+05,
      "workspace_megabytes": 3.3007812500000000e-01
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__7106924633654065131<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:1/input[1]:512/input[2]:13/input[3]:13/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__7106924633654065131<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:1/input[1]:512/input[2]:13/input[3]:13/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 2439,
      "real_time": 2.8181077517525537e+05,
      "cpu_time": 2.8966146289704123e+05,
      "time_unit": "ns",
      "items_per_second": 3.9301492262360100e+10,
      "advised_convolution_algorithm": 0.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.5243673600000000e+08,
      "advised_time": 2.8979200124740601e-01,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)4; cudnnMathType_t math_type = (cudnnMathType_t)0]": 2.3237108083472476e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 4.0000000000000000e+00,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 1.3000000000000000e+01,
      "input[3]": 1.3000000000000000e+01,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 1.3000000000000000e+01,
      "input_size": 8.6528000000000000e+04,
      "input_width": 1.3000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 2.4390000000000000e+03,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 1.3000000000000000e+01,
      "output_size": 2.1632000000000000e+04,
      "output_width": 1.3000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 3.9301492262360100e+10,
      "predicted_advised_flops_count": 1.1075584000000000e+07,
      "predicted_flops": 3.3300758259467865e+11,
      "predicted_flops_count": 9.3845124990244254e+07,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 1.5243673600000000e+08,
      "workspace_megabytes": 1.4537500000000000e+02
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__7106924633654065131<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:1/input[1]:512/input[2]:13/input[3]:13/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 6028,
      "real_time": 1.1688126596890535e+05,
      "cpu_time": 1.2346287873473842e+05,
      "time_unit": "ns",
      "items_per_second": 9.4759274792133987e+10,
      "advised_convolution_algorithm": 0.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.0044832000000000e+07,
      "advised_time": 1.3414399325847626e-01,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)5; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.6667819325789325e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 5.0000000000000000e+00,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 1.3000000000000000e+01,
      "input[3]": 1.3000000000000000e+01,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 1.3000000000000000e+01,
      "input_size": 8.6528000000000000e+04,
      "input_width": 1.3000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 6.0280000000000000e+03,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 1.3000000000000000e+01,
      "output_size": 2.1632000000000000e+04,
      "output_width": 1.3000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 9.4759274792133987e+10,
      "predicted_advised_flops_count": 1.1075584000000000e+07,
      "predicted_flops": 8.0290989503151392e+11,
      "predicted_flops_count": 9.3845124990244254e+07,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 1.0044832000000000e+07,
      "workspace_megabytes": 9.5794982910156250e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__7106924633654065131<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:1/input[1]:512/input[2]:13/input[3]:13/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__7106924633654065131<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:1/input[1]:512/input[2]:13/input[3]:13/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__1731047546501595228<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:1/input[1]:24/input[2]:13/input[3]:13/filter_count:64/filter_height:5/filter_width:5/pad_height:2/pad_width:2/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 15122,
      "real_time": 4.6396246200656657e+04,
      "cpu_time": 5.2363235881208151e+04,
      "time_unit": "ns",
      "items_per_second": 5.5949353936380749e+09,
      "advised_convolution_algorithm": 4.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 4.7104001045227051e-02,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4730153338016043e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 5.0000000000000000e+00,
      "filter_width": 5.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 2.4000000000000000e+01,
      "input[2]": 1.3000000000000000e+01,
      "input[3]": 1.3000000000000000e+01,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 2.4000000000000000e+01,
      "input_height": 1.3000000000000000e+01,
      "input_size": 4.0560000000000000e+03,
      "input_width": 1.3000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 1.5122000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 1.3000000000000000e+01,
      "output_size": 1.0816000000000000e+04,
      "output_width": 1.3000000000000000e+01,
      "pad_height": 2.0000000000000000e+00,
      "pad_width": 2.0000000000000000e+00,
      "predicted_advised_flops": 4.9374679077632812e+10,
      "predicted_advised_flops_count": 2.2907997665642630e+06,
      "predicted_flops": 1.3987338484095187e+11,
      "predicted_flops_count": 6.4896000000000000e+06,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__1731047546501595228<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:1/input[1]:24/input[2]:13/input[3]:13/filter_count:64/filter_height:5/filter_width:5/pad_height:2/pad_width:2/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 7649,
      "real_time": 9.1158995871634674e+04,
      "cpu_time": 9.7148037519327787e+04,
      "time_unit": "ns",
      "items_per_second": 2.8475960876700816e+09,
      "advised_convolution_algorithm": 4.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.0200000000000000e+03,
      "advised_time": 9.3152001500129700e-02,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.2419525699096977e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 5.0000000000000000e+00,
      "filter_width": 5.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 2.4000000000000000e+01,
      "input[2]": 1.3000000000000000e+01,
      "input[3]": 1.3000000000000000e+01,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 2.4000000000000000e+01,
      "input_height": 1.3000000000000000e+01,
      "input_size": 4.0560000000000000e+03,
      "input_width": 1.3000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 7.6490000000000000e+03,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 1.3000000000000000e+01,
      "output_size": 1.0816000000000000e+04,
      "output_width": 1.3000000000000000e+01,
      "pad_height": 2.0000000000000000e+00,
      "pad_width": 2.0000000000000000e+00,
      "predicted_advised_flops": 2.5129716981416153e+10,
      "predicted_advised_flops_count": 2.2907997665642630e+06,
      "predicted_flops": 7.1189902191752045e+10,
      "predicted_flops_count": 6.4896000000000000e+06,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 1.0200000000000000e+03,
      "workspace_megabytes": 9.7274780273437500e-04
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__1731047546501595228<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:1/input[1]:24/input[2]:13/input[3]:13/filter_count:64/filter_height:5/filter_width:5/pad_height:2/pad_width:2/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 9890,
      "real_time": 7.0494600278946891e+04,
      "cpu_time": 7.6464336804583611e+04,
      "time_unit": "ns",
      "items_per_second": 3.6823245890157123e+09,
      "advised_convolution_algorithm": 4.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 4.0560000000000000e+05,
      "advised_time": 7.1680001914501190e-02,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)2; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4280899851402570e+19,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 2.0000000000000000e+00,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 5.0000000000000000e+00,
      "filter_width": 5.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 2.4000000000000000e+01,
      "input[2]": 1.3000000000000000e+01,
      "input[3]": 1.3000000000000000e+01,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 2.4000000000000000e+01,
      "input_height": 1.3000000000000000e+01,
      "input_size": 4.0560000000000000e+03,
      "input_width": 1.3000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 9.8900000000000000e+03,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 1.3000000000000000e+01,
      "output_size": 1.0816000000000000e+04,
      "output_width": 1.3000000000000000e+01,
      "pad_height": 2.0000000000000000e+00,
      "pad_width": 2.0000000000000000e+00,
      "predicted_advised_flops": 3.2496102644735573e+10,
      "predicted_advised_flops_count": 2.2907997665642630e+06,
      "predicted_flops": 9.2058114725392807e+10,
      "predicted_flops_count": 6.4896000000000000e+06,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 4.0560000000000000e+05,
      "workspace_megabytes": 3.8681030273437500e-01
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__1731047546501595228<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:1/input[1]:24/input[2]:13/input[3]:13/filter_count:64/filter_height:5/filter_width:5/pad_height:2/pad_width:2/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__1731047546501595228<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:1/input[1]:24/input[2]:13/input[3]:13/filter_count:64/filter_height:5/filter_width:5/pad_height:2/pad_width:2/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 11011,
      "real_time": 6.3257111836881122e+04,
      "cpu_time": 6.9550294433454750e+04,
      "time_unit": "ns",
      "items_per_second": 4.1036334486686664e+09,
      "advised_convolution_algorithm": 4.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.3731840000000000e+07,
      "advised_time": 6.7584000527858734e-02,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)4; cudnnMathType_t math_type = (cudnnMathType_t)0]": 2.3237108083472476e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 4.0000000000000000e+00,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 5.0000000000000000e+00,
      "filter_width": 5.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 2.4000000000000000e+01,
      "input[2]": 1.3000000000000000e+01,
      "input[3]": 1.3000000000000000e+01,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 2.4000000000000000e+01,
      "input_height": 1.3000000000000000e+01,
      "input_size": 4.0560000000000000e+03,
      "input_width": 1.3000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 1.1011000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 1.3000000000000000e+01,
      "output_size": 1.0816000000000000e+04,
      "output_width": 1.3000000000000000e+01,
      "pad_height": 2.0000000000000000e+00,
      "pad_width": 2.0000000000000000e+00,
      "predicted_advised_flops": 3.6214106209456215e+10,
      "predicted_advised_flops_count": 2.2907997665642630e+06,
      "predicted_flops": 3.6214106209456215e+10,
      "predicted_flops_count": 2.2907997665642630e+06,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 1.3731840000000000e+07,
      "workspace_megabytes": 1.3095703125000000e+01
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__1731047546501595228<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:1/input[1]:24/input[2]:13/input[3]:13/filter_count:64/filter_height:5/filter_width:5/pad_height:2/pad_width:2/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 12052,
      "real_time": 5.7479130223794324e+04,
      "cpu_time": 6.3700739295897634e+04,
      "time_unit": "ns",
      "items_per_second": 4.5161434939831676e+09,
      "advised_convolution_algorithm": 4.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 7.0922240000000000e+06,
      "advised_time": 6.1439998447895050e-02,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)5; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.6667819325789325e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 5.0000000000000000e+00,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 5.0000000000000000e+00,
      "filter_width": 5.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 2.4000000000000000e+01,
      "input[2]": 1.3000000000000000e+01,
      "input[3]": 1.3000000000000000e+01,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 2.4000000000000000e+01,
      "input_height": 1.3000000000000000e+01,
      "input_size": 4.0560000000000000e+03,
      "input_width": 1.3000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 1.2052000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 1.3000000000000000e+01,
      "output_size": 1.0816000000000000e+04,
      "output_width": 1.3000000000000000e+01,
      "pad_height": 2.0000000000000000e+00,
      "pad_width": 2.0000000000000000e+00,
      "predicted_advised_flops": 3.9854461221752327e+10,
      "predicted_advised_flops_count": 2.2907997665642630e+06,
      "predicted_flops": 3.9854461221752327e+10,
      "predicted_flops_count": 2.2907997665642630e+06,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 7.0922240000000000e+06,
      "workspace_megabytes": 6.7636718750000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__1731047546501595228<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:1/input[1]:24/input[2]:13/input[3]:13/filter_count:64/filter_height:5/filter_width:5/pad_height:2/pad_width:2/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__1731047546501595228<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:1/input[1]:24/input[2]:13/input[3]:13/filter_count:64/filter_height:5/filter_width:5/pad_height:2/pad_width:2/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 15041,
      "real_time": 4.6498423449550966e+04,
      "cpu_time": 5.2718360281554182e+04,
      "time_unit": "ns",
      "items_per_second": 5.5826408884946146e+09,
      "advised_convolution_algorithm": 4.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 4.8455680000000000e+06,
      "advised_time": 5.4271999746561050e-02,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)7; cudnnMathType_t math_type = (cudnnMathType_t)0]": 8.2538945752816425e+18,
      "compute_capability:7.0": 3.8315573330875090e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 7.0000000000000000e+00,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 5.0000000000000000e+00,
      "filter_width": 5.0000000000000000e+00,
      "gpu_name:TITAN V": 9.5859631360347648e+18,
      "group": 1.0000000000000000e+00,
      "host_name:adkv": 1.4538947273850499e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 2.4000000000000000e+01,
      "input[2]": 1.3000000000000000e+01,
      "input[3]": 1.3000000000000000e+01,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 2.4000000000000000e+01,
      "input_height": 1.3000000000000000e+01,
      "input_size": 4.0560000000000000e+03,
      "input_width": 1.3000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 1.5041000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 1.3000000000000000e+01,
      "output_size": 1.0816000000000000e+04,
      "output_width": 1.3000000000000000e+01,
      "pad_height": 2.0000000000000000e+00,
      "pad_width": 2.0000000000000000e+00,
      "predicted_advised_flops": 4.9266181444833168e+10,
      "predicted_advised_flops_count": 2.2907997665642630e+06,
      "predicted_flops": -2.1506105493769315e+04,
      "predicted_flops_count": -1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 4.8455680000000000e+06,
      "workspace_megabytes": 4.6210937500000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__13797260650345318816<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:64/input[2]:400/input[3]:400/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to synchronize kernel because of an illegal memory access was encountered",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__13797260650345318816<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:64/input[2]:400/input[3]:400/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__13797260650345318816<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:64/input[2]:400/input[3]:400/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__13797260650345318816<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:64/input[2]:400/input[3]:400/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__13797260650345318816<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:64/input[2]:400/input[3]:400/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__13797260650345318816<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:64/input[2]:400/input[3]:400/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__13797260650345318816<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:64/input[2]:400/input[3]:400/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__13797260650345318816<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:64/input[2]:400/input[3]:400/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__7091747671013340097<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:528/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__7091747671013340097<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:528/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__7091747671013340097<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:528/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__7091747671013340097<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:528/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__7091747671013340097<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:528/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__7091747671013340097<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:528/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__7091747671013340097<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:528/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__7091747671013340097<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:528/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__1768020777244711864<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:1/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__1768020777244711864<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:1/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__1768020777244711864<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:1/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__1768020777244711864<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:1/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__1768020777244711864<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:1/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__1768020777244711864<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:1/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__1768020777244711864<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:1/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__1768020777244711864<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:1/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__9409420012661581938<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:1/input[1]:576/input[2]:7/input[3]:7/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__9409420012661581938<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:1/input[1]:576/input[2]:7/input[3]:7/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__9409420012661581938<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:1/input[1]:576/input[2]:7/input[3]:7/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__9409420012661581938<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:1/input[1]:576/input[2]:7/input[3]:7/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__9409420012661581938<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:1/input[1]:576/input[2]:7/input[3]:7/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__9409420012661581938<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:1/input[1]:576/input[2]:7/input[3]:7/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__9409420012661581938<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:1/input[1]:576/input[2]:7/input[3]:7/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__9409420012661581938<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:1/input[1]:576/input[2]:7/input[3]:7/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__14680996522150098724<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:1/input[1]:144/input[2]:13/input[3]:13/filter_count:288/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__14680996522150098724<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:1/input[1]:144/input[2]:13/input[3]:13/filter_count:288/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__14680996522150098724<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:1/input[1]:144/input[2]:13/input[3]:13/filter_count:288/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__14680996522150098724<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:1/input[1]:144/input[2]:13/input[3]:13/filter_count:288/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__14680996522150098724<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:1/input[1]:144/input[2]:13/input[3]:13/filter_count:288/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__14680996522150098724<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:1/input[1]:144/input[2]:13/input[3]:13/filter_count:288/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__14680996522150098724<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:1/input[1]:144/input[2]:13/input[3]:13/filter_count:288/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__14680996522150098724<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:1/input[1]:144/input[2]:13/input[3]:13/filter_count:288/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__12193271206321775474<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:1/input[1]:448/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__12193271206321775474<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:1/input[1]:448/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__12193271206321775474<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:1/input[1]:448/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__12193271206321775474<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:1/input[1]:448/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__12193271206321775474<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:1/input[1]:448/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__12193271206321775474<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:1/input[1]:448/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__12193271206321775474<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:1/input[1]:448/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__12193271206321775474<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:1/input[1]:448/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__5930736360517590879<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:1/input[1]:32/input[2]:13/input[3]:13/filter_count:64/filter_height:5/filter_width:5/pad_height:2/pad_width:2/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__5930736360517590879<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:1/input[1]:32/input[2]:13/input[3]:13/filter_count:64/filter_height:5/filter_width:5/pad_height:2/pad_width:2/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__5930736360517590879<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:1/input[1]:32/input[2]:13/input[3]:13/filter_count:64/filter_height:5/filter_width:5/pad_height:2/pad_width:2/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__5930736360517590879<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:1/input[1]:32/input[2]:13/input[3]:13/filter_count:64/filter_height:5/filter_width:5/pad_height:2/pad_width:2/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__5930736360517590879<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:1/input[1]:32/input[2]:13/input[3]:13/filter_count:64/filter_height:5/filter_width:5/pad_height:2/pad_width:2/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__5930736360517590879<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:1/input[1]:32/input[2]:13/input[3]:13/filter_count:64/filter_height:5/filter_width:5/pad_height:2/pad_width:2/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__5930736360517590879<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:1/input[1]:32/input[2]:13/input[3]:13/filter_count:64/filter_height:5/filter_width:5/pad_height:2/pad_width:2/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__5930736360517590879<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:1/input[1]:32/input[2]:13/input[3]:13/filter_count:64/filter_height:5/filter_width:5/pad_height:2/pad_width:2/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__17796363000139811937<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:128/input[2]:199/input[3]:199/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__17796363000139811937<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:128/input[2]:199/input[3]:199/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__17796363000139811937<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:128/input[2]:199/input[3]:199/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__17796363000139811937<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:128/input[2]:199/input[3]:199/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__17796363000139811937<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:128/input[2]:199/input[3]:199/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__17796363000139811937<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:128/input[2]:199/input[3]:199/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__17796363000139811937<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:128/input[2]:199/input[3]:199/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__17796363000139811937<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:128/input[2]:199/input[3]:199/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__12125566219013605913<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:384/input[2]:28/input[3]:28/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__12125566219013605913<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:384/input[2]:28/input[3]:28/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__12125566219013605913<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:384/input[2]:28/input[3]:28/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__12125566219013605913<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:384/input[2]:28/input[3]:28/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__12125566219013605913<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:384/input[2]:28/input[3]:28/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__12125566219013605913<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:384/input[2]:28/input[3]:28/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__12125566219013605913<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:384/input[2]:28/input[3]:28/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__12125566219013605913<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:384/input[2]:28/input[3]:28/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__12640678818964938623<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:1/input[1]:704/input[2]:7/input[3]:7/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__12640678818964938623<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:1/input[1]:704/input[2]:7/input[3]:7/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__12640678818964938623<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:1/input[1]:704/input[2]:7/input[3]:7/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__12640678818964938623<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:1/input[1]:704/input[2]:7/input[3]:7/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__12640678818964938623<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:1/input[1]:704/input[2]:7/input[3]:7/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__12640678818964938623<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:1/input[1]:704/input[2]:7/input[3]:7/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__12640678818964938623<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:1/input[1]:704/input[2]:7/input[3]:7/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__12640678818964938623<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:1/input[1]:704/input[2]:7/input[3]:7/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__13485303612506040645<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:64/input[2]:199/input[3]:199/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__13485303612506040645<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:64/input[2]:199/input[3]:199/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__13485303612506040645<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:64/input[2]:199/input[3]:199/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__13485303612506040645<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:64/input[2]:199/input[3]:199/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__13485303612506040645<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:64/input[2]:199/input[3]:199/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__13485303612506040645<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:64/input[2]:199/input[3]:199/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__13485303612506040645<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:64/input[2]:199/input[3]:199/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__13485303612506040645<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:64/input[2]:199/input[3]:199/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__9085028110051225048<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:256/input[2]:199/input[3]:199/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__9085028110051225048<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:256/input[2]:199/input[3]:199/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__9085028110051225048<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:256/input[2]:199/input[3]:199/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__9085028110051225048<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:256/input[2]:199/input[3]:199/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__9085028110051225048<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:256/input[2]:199/input[3]:199/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__9085028110051225048<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:256/input[2]:199/input[3]:199/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__9085028110051225048<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:256/input[2]:199/input[3]:199/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__9085028110051225048<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:256/input[2]:199/input[3]:199/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__11997250825768733865<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:1/input[1]:992/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__11997250825768733865<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:1/input[1]:992/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__11997250825768733865<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:1/input[1]:992/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__11997250825768733865<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:1/input[1]:992/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__11997250825768733865<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:1/input[1]:992/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__11997250825768733865<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:1/input[1]:992/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__11997250825768733865<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:1/input[1]:992/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__11997250825768733865<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:1/input[1]:992/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__9507450290912991006<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:1/input[1]:640/input[2]:7/input[3]:7/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__9507450290912991006<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:1/input[1]:640/input[2]:7/input[3]:7/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__9507450290912991006<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:1/input[1]:640/input[2]:7/input[3]:7/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__9507450290912991006<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:1/input[1]:640/input[2]:7/input[3]:7/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__9507450290912991006<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:1/input[1]:640/input[2]:7/input[3]:7/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__9507450290912991006<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:1/input[1]:640/input[2]:7/input[3]:7/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__9507450290912991006<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:1/input[1]:640/input[2]:7/input[3]:7/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__9507450290912991006<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:1/input[1]:640/input[2]:7/input[3]:7/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__850383584850063067<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:96/input[2]:14/input[3]:14/filter_count:576/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__850383584850063067<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:96/input[2]:14/input[3]:14/filter_count:576/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__850383584850063067<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:96/input[2]:14/input[3]:14/filter_count:576/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__850383584850063067<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:96/input[2]:14/input[3]:14/filter_count:576/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__850383584850063067<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:96/input[2]:14/input[3]:14/filter_count:576/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__850383584850063067<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:96/input[2]:14/input[3]:14/filter_count:576/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__850383584850063067<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:96/input[2]:14/input[3]:14/filter_count:576/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__850383584850063067<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:96/input[2]:14/input[3]:14/filter_count:576/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__17163396260421646650<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:832/input[2]:7/input[3]:7/filter_count:48/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__17163396260421646650<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:832/input[2]:7/input[3]:7/filter_count:48/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__17163396260421646650<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:832/input[2]:7/input[3]:7/filter_count:48/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__17163396260421646650<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:832/input[2]:7/input[3]:7/filter_count:48/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__17163396260421646650<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:832/input[2]:7/input[3]:7/filter_count:48/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__17163396260421646650<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:832/input[2]:7/input[3]:7/filter_count:48/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__17163396260421646650<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:832/input[2]:7/input[3]:7/filter_count:48/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__17163396260421646650<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:832/input[2]:7/input[3]:7/filter_count:48/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__11433205015984938990<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:1/input[1]:128/input[2]:7/input[3]:7/filter_count:32/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__11433205015984938990<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:1/input[1]:128/input[2]:7/input[3]:7/filter_count:32/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__11433205015984938990<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:1/input[1]:128/input[2]:7/input[3]:7/filter_count:32/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__11433205015984938990<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:1/input[1]:128/input[2]:7/input[3]:7/filter_count:32/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__11433205015984938990<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:1/input[1]:128/input[2]:7/input[3]:7/filter_count:32/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__11433205015984938990<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:1/input[1]:128/input[2]:7/input[3]:7/filter_count:32/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__11433205015984938990<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:1/input[1]:128/input[2]:7/input[3]:7/filter_count:32/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__11433205015984938990<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:1/input[1]:128/input[2]:7/input[3]:7/filter_count:32/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__691194427455094244<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:256/input[2]:100/input[3]:100/filter_count:256/filter_height:3/filter_width:3/pad_height:9/pad_width:9/stride_height:1/stride_width:1/dilation_height:9/dilation_width:9/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__691194427455094244<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:256/input[2]:100/input[3]:100/filter_count:256/filter_height:3/filter_width:3/pad_height:9/pad_width:9/stride_height:1/stride_width:1/dilation_height:9/dilation_width:9/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__691194427455094244<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:256/input[2]:100/input[3]:100/filter_count:256/filter_height:3/filter_width:3/pad_height:9/pad_width:9/stride_height:1/stride_width:1/dilation_height:9/dilation_width:9/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__691194427455094244<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:256/input[2]:100/input[3]:100/filter_count:256/filter_height:3/filter_width:3/pad_height:9/pad_width:9/stride_height:1/stride_width:1/dilation_height:9/dilation_width:9/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__691194427455094244<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:256/input[2]:100/input[3]:100/filter_count:256/filter_height:3/filter_width:3/pad_height:9/pad_width:9/stride_height:1/stride_width:1/dilation_height:9/dilation_width:9/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__691194427455094244<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:256/input[2]:100/input[3]:100/filter_count:256/filter_height:3/filter_width:3/pad_height:9/pad_width:9/stride_height:1/stride_width:1/dilation_height:9/dilation_width:9/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__691194427455094244<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:256/input[2]:100/input[3]:100/filter_count:256/filter_height:3/filter_width:3/pad_height:9/pad_width:9/stride_height:1/stride_width:1/dilation_height:9/dilation_width:9/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__691194427455094244<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:256/input[2]:100/input[3]:100/filter_count:256/filter_height:3/filter_width:3/pad_height:9/pad_width:9/stride_height:1/stride_width:1/dilation_height:9/dilation_width:9/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__912020504027219009<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:1/input[1]:960/input[2]:7/input[3]:7/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__912020504027219009<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:1/input[1]:960/input[2]:7/input[3]:7/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__912020504027219009<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:1/input[1]:960/input[2]:7/input[3]:7/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__912020504027219009<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:1/input[1]:960/input[2]:7/input[3]:7/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__912020504027219009<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:1/input[1]:960/input[2]:7/input[3]:7/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__912020504027219009<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:1/input[1]:960/input[2]:7/input[3]:7/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__912020504027219009<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:1/input[1]:960/input[2]:7/input[3]:7/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__912020504027219009<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:1/input[1]:960/input[2]:7/input[3]:7/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__5477693792388512456<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:96/input[2]:14/input[3]:14/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__5477693792388512456<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:96/input[2]:14/input[3]:14/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__5477693792388512456<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:96/input[2]:14/input[3]:14/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__5477693792388512456<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:96/input[2]:14/input[3]:14/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__5477693792388512456<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:96/input[2]:14/input[3]:14/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__5477693792388512456<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:96/input[2]:14/input[3]:14/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__5477693792388512456<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:96/input[2]:14/input[3]:14/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__5477693792388512456<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:96/input[2]:14/input[3]:14/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__6997417940924550871<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:192/input[2]:28/input[3]:28/filter_count:32/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__6997417940924550871<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:192/input[2]:28/input[3]:28/filter_count:32/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__6997417940924550871<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:192/input[2]:28/input[3]:28/filter_count:32/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__6997417940924550871<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:192/input[2]:28/input[3]:28/filter_count:32/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__6997417940924550871<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:192/input[2]:28/input[3]:28/filter_count:32/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__6997417940924550871<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:192/input[2]:28/input[3]:28/filter_count:32/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__6997417940924550871<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:192/input[2]:28/input[3]:28/filter_count:32/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__6997417940924550871<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:192/input[2]:28/input[3]:28/filter_count:32/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__2513762024360639810<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:128/input[2]:100/input[3]:100/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__2513762024360639810<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:128/input[2]:100/input[3]:100/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__2513762024360639810<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:128/input[2]:100/input[3]:100/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__2513762024360639810<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:128/input[2]:100/input[3]:100/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__2513762024360639810<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:128/input[2]:100/input[3]:100/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__2513762024360639810<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:128/input[2]:100/input[3]:100/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__2513762024360639810<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:128/input[2]:100/input[3]:100/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__2513762024360639810<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:128/input[2]:100/input[3]:100/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__1242877044803516064<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:128/input[2]:14/input[3]:14/filter_count:192/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__1242877044803516064<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:128/input[2]:14/input[3]:14/filter_count:192/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__1242877044803516064<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:128/input[2]:14/input[3]:14/filter_count:192/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__1242877044803516064<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:128/input[2]:14/input[3]:14/filter_count:192/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__1242877044803516064<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:128/input[2]:14/input[3]:14/filter_count:192/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__1242877044803516064<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:128/input[2]:14/input[3]:14/filter_count:192/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__1242877044803516064<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:128/input[2]:14/input[3]:14/filter_count:192/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__1242877044803516064<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:128/input[2]:14/input[3]:14/filter_count:192/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__5678575516939244325<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:1/input[1]:160/input[2]:6/input[3]:6/filter_count:320/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__5678575516939244325<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:1/input[1]:160/input[2]:6/input[3]:6/filter_count:320/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__5678575516939244325<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:1/input[1]:160/input[2]:6/input[3]:6/filter_count:320/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__5678575516939244325<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:1/input[1]:160/input[2]:6/input[3]:6/filter_count:320/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__5678575516939244325<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:1/input[1]:160/input[2]:6/input[3]:6/filter_count:320/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__5678575516939244325<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:1/input[1]:160/input[2]:6/input[3]:6/filter_count:320/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__5678575516939244325<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:1/input[1]:160/input[2]:6/input[3]:6/filter_count:320/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__5678575516939244325<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:1/input[1]:160/input[2]:6/input[3]:6/filter_count:320/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__11078936420021101015<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:1/input[1]:864/input[2]:7/input[3]:7/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__11078936420021101015<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:1/input[1]:864/input[2]:7/input[3]:7/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__11078936420021101015<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:1/input[1]:864/input[2]:7/input[3]:7/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__11078936420021101015<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:1/input[1]:864/input[2]:7/input[3]:7/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__11078936420021101015<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:1/input[1]:864/input[2]:7/input[3]:7/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__11078936420021101015<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:1/input[1]:864/input[2]:7/input[3]:7/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__11078936420021101015<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:1/input[1]:864/input[2]:7/input[3]:7/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__11078936420021101015<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:1/input[1]:864/input[2]:7/input[3]:7/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__12750890609632099864<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:192/input[2]:14/input[3]:14/filter_count:192/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__12750890609632099864<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:192/input[2]:14/input[3]:14/filter_count:192/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__12750890609632099864<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:192/input[2]:14/input[3]:14/filter_count:192/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__12750890609632099864<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:192/input[2]:14/input[3]:14/filter_count:192/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__12750890609632099864<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:192/input[2]:14/input[3]:14/filter_count:192/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__12750890609632099864<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:192/input[2]:14/input[3]:14/filter_count:192/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__12750890609632099864<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:192/input[2]:14/input[3]:14/filter_count:192/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__12750890609632099864<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:192/input[2]:14/input[3]:14/filter_count:192/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__10093872770875139570<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:576/input[2]:14/input[3]:14/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__10093872770875139570<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:576/input[2]:14/input[3]:14/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__10093872770875139570<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:576/input[2]:14/input[3]:14/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__10093872770875139570<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:576/input[2]:14/input[3]:14/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__10093872770875139570<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:576/input[2]:14/input[3]:14/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__10093872770875139570<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:576/input[2]:14/input[3]:14/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__10093872770875139570<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:576/input[2]:14/input[3]:14/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__10093872770875139570<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:576/input[2]:14/input[3]:14/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__3126585237483672815<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:576/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__3126585237483672815<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:576/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__3126585237483672815<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:576/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__3126585237483672815<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:576/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__3126585237483672815<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:576/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__3126585237483672815<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:576/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__3126585237483672815<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:576/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__3126585237483672815<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:576/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__1268296387196985775<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:576/input[2]:14/input[3]:14/filter_count:192/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__1268296387196985775<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:576/input[2]:14/input[3]:14/filter_count:192/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__1268296387196985775<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:576/input[2]:14/input[3]:14/filter_count:192/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__1268296387196985775<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:576/input[2]:14/input[3]:14/filter_count:192/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__1268296387196985775<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:576/input[2]:14/input[3]:14/filter_count:192/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__1268296387196985775<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:576/input[2]:14/input[3]:14/filter_count:192/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__1268296387196985775<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:576/input[2]:14/input[3]:14/filter_count:192/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__1268296387196985775<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:576/input[2]:14/input[3]:14/filter_count:192/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__18276339072188303294<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:2048/input[2]:100/input[3]:100/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD failed to cudnnSetTensor4dDescriptor",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__18276339072188303294<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:2048/input[2]:100/input[3]:100/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD failed to cudnnSetTensor4dDescriptor",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__18276339072188303294<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:2048/input[2]:100/input[3]:100/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD failed to cudnnSetTensor4dDescriptor",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__18276339072188303294<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:2048/input[2]:100/input[3]:100/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD failed to cudnnSetTensor4dDescriptor",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__18276339072188303294<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:2048/input[2]:100/input[3]:100/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD failed to cudnnSetTensor4dDescriptor",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__18276339072188303294<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:2048/input[2]:100/input[3]:100/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD failed to cudnnSetTensor4dDescriptor",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__18276339072188303294<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:2048/input[2]:100/input[3]:100/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD failed to cudnnSetTensor4dDescriptor",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__18276339072188303294<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:2048/input[2]:100/input[3]:100/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD failed to cudnnSetTensor4dDescriptor",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__10736650755504955266<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:256/input[2]:56/input[3]:56/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__10736650755504955266<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:256/input[2]:56/input[3]:56/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__10736650755504955266<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:256/input[2]:56/input[3]:56/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__10736650755504955266<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:256/input[2]:56/input[3]:56/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__10736650755504955266<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:256/input[2]:56/input[3]:56/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__10736650755504955266<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:256/input[2]:56/input[3]:56/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__10736650755504955266<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:256/input[2]:56/input[3]:56/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__10736650755504955266<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:256/input[2]:56/input[3]:56/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__3646521398858508652<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:512/input[2]:14/input[3]:14/filter_count:160/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__3646521398858508652<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:512/input[2]:14/input[3]:14/filter_count:160/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__3646521398858508652<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:512/input[2]:14/input[3]:14/filter_count:160/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__3646521398858508652<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:512/input[2]:14/input[3]:14/filter_count:160/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__3646521398858508652<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:512/input[2]:14/input[3]:14/filter_count:160/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__3646521398858508652<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:512/input[2]:14/input[3]:14/filter_count:160/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__3646521398858508652<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:512/input[2]:14/input[3]:14/filter_count:160/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__3646521398858508652<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:512/input[2]:14/input[3]:14/filter_count:160/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__9592262995097671660<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:1/input[1]:112/input[2]:56/input[3]:56/filter_count:112/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:112/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__9592262995097671660<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:1/input[1]:112/input[2]:56/input[3]:56/filter_count:112/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:112/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__9592262995097671660<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:1/input[1]:112/input[2]:56/input[3]:56/filter_count:112/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:112/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__9592262995097671660<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:1/input[1]:112/input[2]:56/input[3]:56/filter_count:112/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:112/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__9592262995097671660<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:1/input[1]:112/input[2]:56/input[3]:56/filter_count:112/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:112/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__9592262995097671660<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:1/input[1]:112/input[2]:56/input[3]:56/filter_count:112/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:112/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__9592262995097671660<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:1/input[1]:112/input[2]:56/input[3]:56/filter_count:112/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:112/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__9592262995097671660<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:1/input[1]:112/input[2]:56/input[3]:56/filter_count:112/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:112/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__10781708914388989157<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:3/input[2]:224/input[3]:224/filter_count:96/filter_height:7/filter_width:7/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__10781708914388989157<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:3/input[2]:224/input[3]:224/filter_count:96/filter_height:7/filter_width:7/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__10781708914388989157<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:3/input[2]:224/input[3]:224/filter_count:96/filter_height:7/filter_width:7/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__10781708914388989157<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:3/input[2]:224/input[3]:224/filter_count:96/filter_height:7/filter_width:7/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__10781708914388989157<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:3/input[2]:224/input[3]:224/filter_count:96/filter_height:7/filter_width:7/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__10781708914388989157<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:3/input[2]:224/input[3]:224/filter_count:96/filter_height:7/filter_width:7/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__10781708914388989157<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:3/input[2]:224/input[3]:224/filter_count:96/filter_height:7/filter_width:7/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__10781708914388989157<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:3/input[2]:224/input[3]:224/filter_count:96/filter_height:7/filter_width:7/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__17876446781505989659<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:2048/input[2]:100/input[3]:100/filter_count:304/filter_height:3/filter_width:3/pad_height:18/pad_width:18/stride_height:1/stride_width:1/dilation_height:18/dilation_width:18/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD failed to cudnnSetTensor4dDescriptor",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__17876446781505989659<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:2048/input[2]:100/input[3]:100/filter_count:304/filter_height:3/filter_width:3/pad_height:18/pad_width:18/stride_height:1/stride_width:1/dilation_height:18/dilation_width:18/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD failed to cudnnSetTensor4dDescriptor",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__17876446781505989659<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:2048/input[2]:100/input[3]:100/filter_count:304/filter_height:3/filter_width:3/pad_height:18/pad_width:18/stride_height:1/stride_width:1/dilation_height:18/dilation_width:18/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD failed to cudnnSetTensor4dDescriptor",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__17876446781505989659<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:2048/input[2]:100/input[3]:100/filter_count:304/filter_height:3/filter_width:3/pad_height:18/pad_width:18/stride_height:1/stride_width:1/dilation_height:18/dilation_width:18/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD failed to cudnnSetTensor4dDescriptor",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__17876446781505989659<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:2048/input[2]:100/input[3]:100/filter_count:304/filter_height:3/filter_width:3/pad_height:18/pad_width:18/stride_height:1/stride_width:1/dilation_height:18/dilation_width:18/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD failed to cudnnSetTensor4dDescriptor",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__17876446781505989659<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:2048/input[2]:100/input[3]:100/filter_count:304/filter_height:3/filter_width:3/pad_height:18/pad_width:18/stride_height:1/stride_width:1/dilation_height:18/dilation_width:18/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD failed to cudnnSetTensor4dDescriptor",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__17876446781505989659<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:2048/input[2]:100/input[3]:100/filter_count:304/filter_height:3/filter_width:3/pad_height:18/pad_width:18/stride_height:1/stride_width:1/dilation_height:18/dilation_width:18/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD failed to cudnnSetTensor4dDescriptor",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__17876446781505989659<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:2048/input[2]:100/input[3]:100/filter_count:304/filter_height:3/filter_width:3/pad_height:18/pad_width:18/stride_height:1/stride_width:1/dilation_height:18/dilation_width:18/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD failed to cudnnSetTensor4dDescriptor",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__2002090538345329140<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__2002090538345329140<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__2002090538345329140<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__2002090538345329140<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__2002090538345329140<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__2002090538345329140<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__2002090538345329140<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__2002090538345329140<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__2307756902124189084<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:128/input[2]:28/input[3]:28/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__2307756902124189084<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:128/input[2]:28/input[3]:28/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__2307756902124189084<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:128/input[2]:28/input[3]:28/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__2307756902124189084<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:128/input[2]:28/input[3]:28/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__2307756902124189084<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:128/input[2]:28/input[3]:28/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__2307756902124189084<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:128/input[2]:28/input[3]:28/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__2307756902124189084<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:128/input[2]:28/input[3]:28/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__2307756902124189084<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:128/input[2]:28/input[3]:28/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__13695261584197046314<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:32/input[2]:104/input[3]:104/filter_count:64/filter_height:3/filter_width:3/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__13695261584197046314<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:32/input[2]:104/input[3]:104/filter_count:64/filter_height:3/filter_width:3/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__13695261584197046314<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:32/input[2]:104/input[3]:104/filter_count:64/filter_height:3/filter_width:3/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__13695261584197046314<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:32/input[2]:104/input[3]:104/filter_count:64/filter_height:3/filter_width:3/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__13695261584197046314<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:32/input[2]:104/input[3]:104/filter_count:64/filter_height:3/filter_width:3/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__13695261584197046314<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:32/input[2]:104/input[3]:104/filter_count:64/filter_height:3/filter_width:3/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__13695261584197046314<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:32/input[2]:104/input[3]:104/filter_count:64/filter_height:3/filter_width:3/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__13695261584197046314<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:32/input[2]:104/input[3]:104/filter_count:64/filter_height:3/filter_width:3/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__12715654751713490101<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:64/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__12715654751713490101<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:64/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__12715654751713490101<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:64/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__12715654751713490101<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:64/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__12715654751713490101<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:64/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__12715654751713490101<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:64/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__12715654751713490101<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:64/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__12715654751713490101<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:64/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__13208991728305251644<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:64/input[2]:224/input[3]:224/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__13208991728305251644<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:64/input[2]:224/input[3]:224/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__13208991728305251644<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:64/input[2]:224/input[3]:224/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__13208991728305251644<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:64/input[2]:224/input[3]:224/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__13208991728305251644<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:64/input[2]:224/input[3]:224/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__13208991728305251644<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:64/input[2]:224/input[3]:224/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__13208991728305251644<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:64/input[2]:224/input[3]:224/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__13208991728305251644<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:64/input[2]:224/input[3]:224/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__10391216152337922405<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:512/input[2]:100/input[3]:100/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__10391216152337922405<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:512/input[2]:100/input[3]:100/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__10391216152337922405<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:512/input[2]:100/input[3]:100/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__10391216152337922405<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:512/input[2]:100/input[3]:100/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__10391216152337922405<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:512/input[2]:100/input[3]:100/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__10391216152337922405<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:512/input[2]:100/input[3]:100/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__10391216152337922405<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:512/input[2]:100/input[3]:100/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__10391216152337922405<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:512/input[2]:100/input[3]:100/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__12266371639433535290<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__12266371639433535290<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__12266371639433535290<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__12266371639433535290<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__12266371639433535290<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__12266371639433535290<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__12266371639433535290<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__12266371639433535290<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__13071701914491934609<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:64/input[2]:56/input[3]:56/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__13071701914491934609<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:64/input[2]:56/input[3]:56/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__13071701914491934609<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:64/input[2]:56/input[3]:56/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__13071701914491934609<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:64/input[2]:56/input[3]:56/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__13071701914491934609<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:64/input[2]:56/input[3]:56/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__13071701914491934609<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:64/input[2]:56/input[3]:56/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__13071701914491934609<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:64/input[2]:56/input[3]:56/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__13071701914491934609<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:64/input[2]:56/input[3]:56/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__9874246820725629768<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:256/input[2]:56/input[3]:56/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__9874246820725629768<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:256/input[2]:56/input[3]:56/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__9874246820725629768<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:256/input[2]:56/input[3]:56/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__9874246820725629768<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:256/input[2]:56/input[3]:56/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__9874246820725629768<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:256/input[2]:56/input[3]:56/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__9874246820725629768<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:256/input[2]:56/input[3]:56/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__9874246820725629768<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:256/input[2]:56/input[3]:56/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__9874246820725629768<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:256/input[2]:56/input[3]:56/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__14618399664044940892<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:64/input[2]:112/input[3]:112/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__14618399664044940892<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:64/input[2]:112/input[3]:112/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__14618399664044940892<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:64/input[2]:112/input[3]:112/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__14618399664044940892<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:64/input[2]:112/input[3]:112/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__14618399664044940892<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:64/input[2]:112/input[3]:112/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__14618399664044940892<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:64/input[2]:112/input[3]:112/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__14618399664044940892<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:64/input[2]:112/input[3]:112/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__14618399664044940892<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:64/input[2]:112/input[3]:112/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__11927182451544443047<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:3/input[2]:224/input[3]:224/filter_count:24/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__11927182451544443047<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:3/input[2]:224/input[3]:224/filter_count:24/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__11927182451544443047<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:3/input[2]:224/input[3]:224/filter_count:24/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__11927182451544443047<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:3/input[2]:224/input[3]:224/filter_count:24/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__11927182451544443047<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:3/input[2]:224/input[3]:224/filter_count:24/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__11927182451544443047<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:3/input[2]:224/input[3]:224/filter_count:24/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__11927182451544443047<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:3/input[2]:224/input[3]:224/filter_count:24/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__11927182451544443047<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:3/input[2]:224/input[3]:224/filter_count:24/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__5952850647978343049<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:480/input[2]:14/input[3]:14/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__5952850647978343049<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:480/input[2]:14/input[3]:14/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__5952850647978343049<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:480/input[2]:14/input[3]:14/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__5952850647978343049<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:480/input[2]:14/input[3]:14/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__5952850647978343049<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:480/input[2]:14/input[3]:14/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__5952850647978343049<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:480/input[2]:14/input[3]:14/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__5952850647978343049<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:480/input[2]:14/input[3]:14/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__5952850647978343049<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:480/input[2]:14/input[3]:14/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__14827840326238670748<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:1/input[1]:32/input[2]:6/input[3]:6/filter_count:128/filter_height:5/filter_width:5/pad_height:2/pad_width:2/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__14827840326238670748<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:1/input[1]:32/input[2]:6/input[3]:6/filter_count:128/filter_height:5/filter_width:5/pad_height:2/pad_width:2/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__14827840326238670748<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:1/input[1]:32/input[2]:6/input[3]:6/filter_count:128/filter_height:5/filter_width:5/pad_height:2/pad_width:2/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__14827840326238670748<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:1/input[1]:32/input[2]:6/input[3]:6/filter_count:128/filter_height:5/filter_width:5/pad_height:2/pad_width:2/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__14827840326238670748<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:1/input[1]:32/input[2]:6/input[3]:6/filter_count:128/filter_height:5/filter_width:5/pad_height:2/pad_width:2/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__14827840326238670748<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:1/input[1]:32/input[2]:6/input[3]:6/filter_count:128/filter_height:5/filter_width:5/pad_height:2/pad_width:2/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__14827840326238670748<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:1/input[1]:32/input[2]:6/input[3]:6/filter_count:128/filter_height:5/filter_width:5/pad_height:2/pad_width:2/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__14827840326238670748<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:1/input[1]:32/input[2]:6/input[3]:6/filter_count:128/filter_height:5/filter_width:5/pad_height:2/pad_width:2/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__17087991756524041832<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:512/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__17087991756524041832<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:512/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__17087991756524041832<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:512/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__17087991756524041832<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:512/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__17087991756524041832<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:512/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__17087991756524041832<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:512/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__17087991756524041832<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:512/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__17087991756524041832<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:512/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__7393018973176244761<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:32/input[2]:27/input[3]:27/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__7393018973176244761<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:32/input[2]:27/input[3]:27/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__7393018973176244761<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:32/input[2]:27/input[3]:27/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__7393018973176244761<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:32/input[2]:27/input[3]:27/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__7393018973176244761<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:32/input[2]:27/input[3]:27/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__7393018973176244761<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:32/input[2]:27/input[3]:27/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__7393018973176244761<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:32/input[2]:27/input[3]:27/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__7393018973176244761<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:32/input[2]:27/input[3]:27/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__11157633841959188857<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:32/input[2]:27/input[3]:27/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__11157633841959188857<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:32/input[2]:27/input[3]:27/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__11157633841959188857<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:32/input[2]:27/input[3]:27/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__11157633841959188857<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:32/input[2]:27/input[3]:27/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__11157633841959188857<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:32/input[2]:27/input[3]:27/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__11157633841959188857<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:32/input[2]:27/input[3]:27/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__11157633841959188857<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:32/input[2]:27/input[3]:27/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__11157633841959188857<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:32/input[2]:27/input[3]:27/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__1324504187228283026<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:1/input[1]:64/input[2]:55/input[3]:55/filter_count:192/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__1324504187228283026<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:1/input[1]:64/input[2]:55/input[3]:55/filter_count:192/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__1324504187228283026<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:1/input[1]:64/input[2]:55/input[3]:55/filter_count:192/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__1324504187228283026<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:1/input[1]:64/input[2]:55/input[3]:55/filter_count:192/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__1324504187228283026<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:1/input[1]:64/input[2]:55/input[3]:55/filter_count:192/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__1324504187228283026<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:1/input[1]:64/input[2]:55/input[3]:55/filter_count:192/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__1324504187228283026<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:1/input[1]:64/input[2]:55/input[3]:55/filter_count:192/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__1324504187228283026<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:1/input[1]:64/input[2]:55/input[3]:55/filter_count:192/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__5815648101690016187<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:1/input[1]:96/input[2]:27/input[3]:27/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__5815648101690016187<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:1/input[1]:96/input[2]:27/input[3]:27/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__5815648101690016187<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:1/input[1]:96/input[2]:27/input[3]:27/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__5815648101690016187<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:1/input[1]:96/input[2]:27/input[3]:27/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__5815648101690016187<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:1/input[1]:96/input[2]:27/input[3]:27/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__5815648101690016187<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:1/input[1]:96/input[2]:27/input[3]:27/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__5815648101690016187<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:1/input[1]:96/input[2]:27/input[3]:27/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__5815648101690016187<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:1/input[1]:96/input[2]:27/input[3]:27/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__8532430157110871000<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:1/input[1]:192/input[2]:27/input[3]:27/filter_count:32/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__8532430157110871000<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:1/input[1]:192/input[2]:27/input[3]:27/filter_count:32/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__8532430157110871000<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:1/input[1]:192/input[2]:27/input[3]:27/filter_count:32/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__8532430157110871000<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:1/input[1]:192/input[2]:27/input[3]:27/filter_count:32/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__8532430157110871000<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:1/input[1]:192/input[2]:27/input[3]:27/filter_count:32/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__8532430157110871000<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:1/input[1]:192/input[2]:27/input[3]:27/filter_count:32/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__8532430157110871000<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:1/input[1]:192/input[2]:27/input[3]:27/filter_count:32/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__8532430157110871000<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:1/input[1]:192/input[2]:27/input[3]:27/filter_count:32/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__14505120118170555514<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:1/input[1]:272/input[2]:7/input[3]:7/filter_count:272/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:4/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__14505120118170555514<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:1/input[1]:272/input[2]:7/input[3]:7/filter_count:272/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:4/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__14505120118170555514<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:1/input[1]:272/input[2]:7/input[3]:7/filter_count:272/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:4/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__14505120118170555514<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:1/input[1]:272/input[2]:7/input[3]:7/filter_count:272/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:4/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__14505120118170555514<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:1/input[1]:272/input[2]:7/input[3]:7/filter_count:272/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:4/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__14505120118170555514<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:1/input[1]:272/input[2]:7/input[3]:7/filter_count:272/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:4/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__14505120118170555514<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:1/input[1]:272/input[2]:7/input[3]:7/filter_count:272/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:4/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__14505120118170555514<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:1/input[1]:272/input[2]:7/input[3]:7/filter_count:272/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:4/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__6312907282717829527<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:1/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__6312907282717829527<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:1/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__6312907282717829527<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:1/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__6312907282717829527<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:1/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__6312907282717829527<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:1/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__6312907282717829527<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:1/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__6312907282717829527<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:1/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__6312907282717829527<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:1/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__16738348338854482257<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:96/input[2]:27/input[3]:27/filter_count:256/filter_height:5/filter_width:5/pad_height:2/pad_width:2/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:2/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__16738348338854482257<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:96/input[2]:27/input[3]:27/filter_count:256/filter_height:5/filter_width:5/pad_height:2/pad_width:2/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:2/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__16738348338854482257<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:96/input[2]:27/input[3]:27/filter_count:256/filter_height:5/filter_width:5/pad_height:2/pad_width:2/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:2/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__16738348338854482257<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:96/input[2]:27/input[3]:27/filter_count:256/filter_height:5/filter_width:5/pad_height:2/pad_width:2/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:2/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__16738348338854482257<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:96/input[2]:27/input[3]:27/filter_count:256/filter_height:5/filter_width:5/pad_height:2/pad_width:2/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:2/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__16738348338854482257<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:96/input[2]:27/input[3]:27/filter_count:256/filter_height:5/filter_width:5/pad_height:2/pad_width:2/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:2/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__16738348338854482257<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:96/input[2]:27/input[3]:27/filter_count:256/filter_height:5/filter_width:5/pad_height:2/pad_width:2/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:2/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__16738348338854482257<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:96/input[2]:27/input[3]:27/filter_count:256/filter_height:5/filter_width:5/pad_height:2/pad_width:2/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:2/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__7428856221268368590<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:128/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__7428856221268368590<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:128/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__7428856221268368590<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:128/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__7428856221268368590<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:128/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__7428856221268368590<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:128/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__7428856221268368590<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:128/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__7428856221268368590<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:128/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__7428856221268368590<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:128/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__4460365411425090557<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:1/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__4460365411425090557<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:1/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__4460365411425090557<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:1/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__4460365411425090557<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:1/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__4460365411425090557<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:1/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__4460365411425090557<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:1/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__4460365411425090557<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:1/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__4460365411425090557<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:1/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__2956120337198267246<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:1/input[2]:28/input[3]:28/filter_count:8/filter_height:5/filter_width:5/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__2956120337198267246<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:1/input[2]:28/input[3]:28/filter_count:8/filter_height:5/filter_width:5/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__2956120337198267246<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:1/input[2]:28/input[3]:28/filter_count:8/filter_height:5/filter_width:5/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__2956120337198267246<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:1/input[2]:28/input[3]:28/filter_count:8/filter_height:5/filter_width:5/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__2956120337198267246<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:1/input[2]:28/input[3]:28/filter_count:8/filter_height:5/filter_width:5/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__2956120337198267246<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:1/input[2]:28/input[3]:28/filter_count:8/filter_height:5/filter_width:5/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__2956120337198267246<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:1/input[2]:28/input[3]:28/filter_count:8/filter_height:5/filter_width:5/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__2956120337198267246<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:1/input[2]:28/input[3]:28/filter_count:8/filter_height:5/filter_width:5/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__7768986256863016776<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:512/input[2]:14/input[3]:14/filter_count:112/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__7768986256863016776<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:512/input[2]:14/input[3]:14/filter_count:112/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__7768986256863016776<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:512/input[2]:14/input[3]:14/filter_count:112/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__7768986256863016776<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:512/input[2]:14/input[3]:14/filter_count:112/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__7768986256863016776<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:512/input[2]:14/input[3]:14/filter_count:112/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__7768986256863016776<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:512/input[2]:14/input[3]:14/filter_count:112/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__7768986256863016776<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:512/input[2]:14/input[3]:14/filter_count:112/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__7768986256863016776<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:512/input[2]:14/input[3]:14/filter_count:112/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__11577289863291515496<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:3/input[2]:224/input[3]:224/filter_count:32/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__11577289863291515496<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:3/input[2]:224/input[3]:224/filter_count:32/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__11577289863291515496<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:3/input[2]:224/input[3]:224/filter_count:32/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__11577289863291515496<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:3/input[2]:224/input[3]:224/filter_count:32/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__11577289863291515496<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:3/input[2]:224/input[3]:224/filter_count:32/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__11577289863291515496<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:3/input[2]:224/input[3]:224/filter_count:32/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__11577289863291515496<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:3/input[2]:224/input[3]:224/filter_count:32/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__11577289863291515496<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:3/input[2]:224/input[3]:224/filter_count:32/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__15981681849204448988<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:32/input[2]:14/input[3]:14/filter_count:64/filter_height:5/filter_width:5/pad_height:2/pad_width:2/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__15981681849204448988<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:32/input[2]:14/input[3]:14/filter_count:64/filter_height:5/filter_width:5/pad_height:2/pad_width:2/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__15981681849204448988<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:32/input[2]:14/input[3]:14/filter_count:64/filter_height:5/filter_width:5/pad_height:2/pad_width:2/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__15981681849204448988<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:32/input[2]:14/input[3]:14/filter_count:64/filter_height:5/filter_width:5/pad_height:2/pad_width:2/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__15981681849204448988<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:32/input[2]:14/input[3]:14/filter_count:64/filter_height:5/filter_width:5/pad_height:2/pad_width:2/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__15981681849204448988<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:32/input[2]:14/input[3]:14/filter_count:64/filter_height:5/filter_width:5/pad_height:2/pad_width:2/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__15981681849204448988<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:32/input[2]:14/input[3]:14/filter_count:64/filter_height:5/filter_width:5/pad_height:2/pad_width:2/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__15981681849204448988<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:32/input[2]:14/input[3]:14/filter_count:64/filter_height:5/filter_width:5/pad_height:2/pad_width:2/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__13678915300245728453<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:528/input[2]:14/input[3]:14/filter_count:160/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__13678915300245728453<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:528/input[2]:14/input[3]:14/filter_count:160/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__13678915300245728453<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:528/input[2]:14/input[3]:14/filter_count:160/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__13678915300245728453<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:528/input[2]:14/input[3]:14/filter_count:160/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__13678915300245728453<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:528/input[2]:14/input[3]:14/filter_count:160/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__13678915300245728453<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:528/input[2]:14/input[3]:14/filter_count:160/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__13678915300245728453<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:528/input[2]:14/input[3]:14/filter_count:160/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__13678915300245728453<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:528/input[2]:14/input[3]:14/filter_count:160/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__10619789271330040946<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:256/input[2]:12/input[3]:12/filter_count:384/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__10619789271330040946<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:256/input[2]:12/input[3]:12/filter_count:384/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__10619789271330040946<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:256/input[2]:12/input[3]:12/filter_count:384/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__10619789271330040946<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:256/input[2]:12/input[3]:12/filter_count:384/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__10619789271330040946<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:256/input[2]:12/input[3]:12/filter_count:384/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__10619789271330040946<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:256/input[2]:12/input[3]:12/filter_count:384/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__10619789271330040946<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:256/input[2]:12/input[3]:12/filter_count:384/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__10619789271330040946<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:256/input[2]:12/input[3]:12/filter_count:384/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__13680409596138327876<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:1/input[1]:640/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__13680409596138327876<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:1/input[1]:640/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__13680409596138327876<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:1/input[1]:640/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__13680409596138327876<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:1/input[1]:640/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__13680409596138327876<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:1/input[1]:640/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__13680409596138327876<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:1/input[1]:640/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__13680409596138327876<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:1/input[1]:640/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__13680409596138327876<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:1/input[1]:640/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__2649268772222277980<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:1/input[1]:480/input[2]:13/input[3]:13/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__2649268772222277980<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:1/input[1]:480/input[2]:13/input[3]:13/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__2649268772222277980<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:1/input[1]:480/input[2]:13/input[3]:13/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__2649268772222277980<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:1/input[1]:480/input[2]:13/input[3]:13/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__2649268772222277980<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:1/input[1]:480/input[2]:13/input[3]:13/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__2649268772222277980<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:1/input[1]:480/input[2]:13/input[3]:13/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__2649268772222277980<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:1/input[1]:480/input[2]:13/input[3]:13/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__2649268772222277980<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:1/input[1]:480/input[2]:13/input[3]:13/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__16724414524887588321<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:144/input[2]:56/input[3]:56/filter_count:144/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:144/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__16724414524887588321<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:144/input[2]:56/input[3]:56/filter_count:144/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:144/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__16724414524887588321<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:144/input[2]:56/input[3]:56/filter_count:144/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:144/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__16724414524887588321<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:144/input[2]:56/input[3]:56/filter_count:144/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:144/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__16724414524887588321<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:144/input[2]:56/input[3]:56/filter_count:144/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:144/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__16724414524887588321<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:144/input[2]:56/input[3]:56/filter_count:144/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:144/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__16724414524887588321<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:144/input[2]:56/input[3]:56/filter_count:144/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:144/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__16724414524887588321<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:144/input[2]:56/input[3]:56/filter_count:144/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:144/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__11019564957041385411<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:1/input[1]:384/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__11019564957041385411<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:1/input[1]:384/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__11019564957041385411<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:1/input[1]:384/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__11019564957041385411<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:1/input[1]:384/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__11019564957041385411<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:1/input[1]:384/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__11019564957041385411<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:1/input[1]:384/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__11019564957041385411<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:1/input[1]:384/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__11019564957041385411<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:1/input[1]:384/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__12889272076445828432<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:144/input[2]:56/input[3]:56/filter_count:24/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__12889272076445828432<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:144/input[2]:56/input[3]:56/filter_count:24/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__12889272076445828432<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:144/input[2]:56/input[3]:56/filter_count:24/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__12889272076445828432<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:144/input[2]:56/input[3]:56/filter_count:24/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__12889272076445828432<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:144/input[2]:56/input[3]:56/filter_count:24/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__12889272076445828432<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:144/input[2]:56/input[3]:56/filter_count:24/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__12889272076445828432<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:144/input[2]:56/input[3]:56/filter_count:24/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__12889272076445828432<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:144/input[2]:56/input[3]:56/filter_count:24/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__13627725758214777071<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:1/input[1]:512/input[2]:13/input[3]:13/filter_count:160/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__13627725758214777071<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:1/input[1]:512/input[2]:13/input[3]:13/filter_count:160/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__13627725758214777071<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:1/input[1]:512/input[2]:13/input[3]:13/filter_count:160/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__13627725758214777071<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:1/input[1]:512/input[2]:13/input[3]:13/filter_count:160/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__13627725758214777071<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:1/input[1]:512/input[2]:13/input[3]:13/filter_count:160/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__13627725758214777071<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:1/input[1]:512/input[2]:13/input[3]:13/filter_count:160/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__13627725758214777071<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:1/input[1]:512/input[2]:13/input[3]:13/filter_count:160/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__13627725758214777071<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:1/input[1]:512/input[2]:13/input[3]:13/filter_count:160/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__10605477009605945791<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:1/input[1]:384/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__10605477009605945791<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:1/input[1]:384/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__10605477009605945791<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:1/input[1]:384/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__10605477009605945791<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:1/input[1]:384/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__10605477009605945791<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:1/input[1]:384/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__10605477009605945791<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:1/input[1]:384/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__10605477009605945791<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:1/input[1]:384/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__10605477009605945791<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:1/input[1]:384/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__17419028347672368891<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:512/input[2]:14/input[3]:14/filter_count:32/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__17419028347672368891<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:512/input[2]:14/input[3]:14/filter_count:32/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__17419028347672368891<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:512/input[2]:14/input[3]:14/filter_count:32/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__17419028347672368891<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:512/input[2]:14/input[3]:14/filter_count:32/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__17419028347672368891<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:512/input[2]:14/input[3]:14/filter_count:32/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__17419028347672368891<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:512/input[2]:14/input[3]:14/filter_count:32/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__17419028347672368891<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:512/input[2]:14/input[3]:14/filter_count:32/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__17419028347672368891<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:512/input[2]:14/input[3]:14/filter_count:32/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__11565609722490455988<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:1/input[1]:128/input[2]:14/input[3]:14/filter_count:32/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__11565609722490455988<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:1/input[1]:128/input[2]:14/input[3]:14/filter_count:32/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__11565609722490455988<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:1/input[1]:128/input[2]:14/input[3]:14/filter_count:32/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__11565609722490455988<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:1/input[1]:128/input[2]:14/input[3]:14/filter_count:32/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__11565609722490455988<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:1/input[1]:128/input[2]:14/input[3]:14/filter_count:32/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__11565609722490455988<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:1/input[1]:128/input[2]:14/input[3]:14/filter_count:32/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__11565609722490455988<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:1/input[1]:128/input[2]:14/input[3]:14/filter_count:32/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__11565609722490455988<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:1/input[1]:128/input[2]:14/input[3]:14/filter_count:32/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__8857686263146550798<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:3/input[2]:800/input[3]:800/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__8857686263146550798<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:3/input[2]:800/input[3]:800/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__8857686263146550798<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:3/input[2]:800/input[3]:800/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__8857686263146550798<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:3/input[2]:800/input[3]:800/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__8857686263146550798<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:3/input[2]:800/input[3]:800/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__8857686263146550798<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:3/input[2]:800/input[3]:800/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__8857686263146550798<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:3/input[2]:800/input[3]:800/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__8857686263146550798<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:3/input[2]:800/input[3]:800/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__13639767614016771533<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:32/input[2]:7/input[3]:7/filter_count:128/filter_height:5/filter_width:5/pad_height:2/pad_width:2/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__13639767614016771533<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:32/input[2]:7/input[3]:7/filter_count:128/filter_height:5/filter_width:5/pad_height:2/pad_width:2/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__13639767614016771533<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:32/input[2]:7/input[3]:7/filter_count:128/filter_height:5/filter_width:5/pad_height:2/pad_width:2/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__13639767614016771533<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:32/input[2]:7/input[3]:7/filter_count:128/filter_height:5/filter_width:5/pad_height:2/pad_width:2/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__13639767614016771533<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:32/input[2]:7/input[3]:7/filter_count:128/filter_height:5/filter_width:5/pad_height:2/pad_width:2/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__13639767614016771533<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:32/input[2]:7/input[3]:7/filter_count:128/filter_height:5/filter_width:5/pad_height:2/pad_width:2/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__13639767614016771533<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:32/input[2]:7/input[3]:7/filter_count:128/filter_height:5/filter_width:5/pad_height:2/pad_width:2/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__13639767614016771533<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:32/input[2]:7/input[3]:7/filter_count:128/filter_height:5/filter_width:5/pad_height:2/pad_width:2/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__16272202834644277995<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:64/input[2]:400/input[3]:400/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD failed to cudnnSetTensor4dDescriptor",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__16272202834644277995<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:64/input[2]:400/input[3]:400/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD failed to cudnnSetTensor4dDescriptor",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__16272202834644277995<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:64/input[2]:400/input[3]:400/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD failed to cudnnSetTensor4dDescriptor",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__16272202834644277995<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:64/input[2]:400/input[3]:400/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD failed to cudnnSetTensor4dDescriptor",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__16272202834644277995<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:64/input[2]:400/input[3]:400/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD failed to cudnnSetTensor4dDescriptor",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__16272202834644277995<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:64/input[2]:400/input[3]:400/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD failed to cudnnSetTensor4dDescriptor",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__16272202834644277995<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:64/input[2]:400/input[3]:400/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD failed to cudnnSetTensor4dDescriptor",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__16272202834644277995<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:64/input[2]:400/input[3]:400/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD failed to cudnnSetTensor4dDescriptor",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__4959475736084728565<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:1/input[1]:512/input[2]:7/input[3]:7/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__4959475736084728565<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:1/input[1]:512/input[2]:7/input[3]:7/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__4959475736084728565<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:1/input[1]:512/input[2]:7/input[3]:7/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__4959475736084728565<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:1/input[1]:512/input[2]:7/input[3]:7/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__4959475736084728565<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:1/input[1]:512/input[2]:7/input[3]:7/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__4959475736084728565<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:1/input[1]:512/input[2]:7/input[3]:7/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__4959475736084728565<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:1/input[1]:512/input[2]:7/input[3]:7/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__4959475736084728565<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:1/input[1]:512/input[2]:7/input[3]:7/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__4972795948663690583<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:384/input[2]:28/input[3]:28/filter_count:384/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:384/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__4972795948663690583<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:384/input[2]:28/input[3]:28/filter_count:384/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:384/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__4972795948663690583<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:384/input[2]:28/input[3]:28/filter_count:384/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:384/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__4972795948663690583<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:384/input[2]:28/input[3]:28/filter_count:384/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:384/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__4972795948663690583<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:384/input[2]:28/input[3]:28/filter_count:384/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:384/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__4972795948663690583<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:384/input[2]:28/input[3]:28/filter_count:384/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:384/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__4972795948663690583<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:384/input[2]:28/input[3]:28/filter_count:384/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:384/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__4972795948663690583<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:384/input[2]:28/input[3]:28/filter_count:384/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:384/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__12448375135032284182<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:64/input[2]:199/input[3]:199/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__12448375135032284182<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:64/input[2]:199/input[3]:199/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__12448375135032284182<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:64/input[2]:199/input[3]:199/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__12448375135032284182<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:64/input[2]:199/input[3]:199/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__12448375135032284182<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:64/input[2]:199/input[3]:199/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__12448375135032284182<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:64/input[2]:199/input[3]:199/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__12448375135032284182<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:64/input[2]:199/input[3]:199/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__12448375135032284182<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:64/input[2]:199/input[3]:199/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__8700699975786020037<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:832/input[2]:7/input[3]:7/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__8700699975786020037<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:832/input[2]:7/input[3]:7/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__8700699975786020037<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:832/input[2]:7/input[3]:7/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__8700699975786020037<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:832/input[2]:7/input[3]:7/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__8700699975786020037<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:832/input[2]:7/input[3]:7/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__8700699975786020037<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:832/input[2]:7/input[3]:7/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__8700699975786020037<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:832/input[2]:7/input[3]:7/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__8700699975786020037<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:832/input[2]:7/input[3]:7/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__3752412604221858272<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:1/input[1]:608/input[2]:7/input[3]:7/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__3752412604221858272<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:1/input[1]:608/input[2]:7/input[3]:7/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__3752412604221858272<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:1/input[1]:608/input[2]:7/input[3]:7/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__3752412604221858272<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:1/input[1]:608/input[2]:7/input[3]:7/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__3752412604221858272<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:1/input[1]:608/input[2]:7/input[3]:7/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__3752412604221858272<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:1/input[1]:608/input[2]:7/input[3]:7/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__3752412604221858272<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:1/input[1]:608/input[2]:7/input[3]:7/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__3752412604221858272<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:1/input[1]:608/input[2]:7/input[3]:7/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__8965924181340504580<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:160/input[2]:7/input[3]:7/filter_count:960/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__8965924181340504580<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:160/input[2]:7/input[3]:7/filter_count:960/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__8965924181340504580<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:160/input[2]:7/input[3]:7/filter_count:960/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__8965924181340504580<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:160/input[2]:7/input[3]:7/filter_count:960/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__8965924181340504580<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:160/input[2]:7/input[3]:7/filter_count:960/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__8965924181340504580<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:160/input[2]:7/input[3]:7/filter_count:960/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__8965924181340504580<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:160/input[2]:7/input[3]:7/filter_count:960/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__8965924181340504580<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:160/input[2]:7/input[3]:7/filter_count:960/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__3883948256281316512<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:320/input[2]:7/input[3]:7/filter_count:1280/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__3883948256281316512<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:320/input[2]:7/input[3]:7/filter_count:1280/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__3883948256281316512<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:320/input[2]:7/input[3]:7/filter_count:1280/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__3883948256281316512<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:320/input[2]:7/input[3]:7/filter_count:1280/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__3883948256281316512<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:320/input[2]:7/input[3]:7/filter_count:1280/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__3883948256281316512<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:320/input[2]:7/input[3]:7/filter_count:1280/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__3883948256281316512<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:320/input[2]:7/input[3]:7/filter_count:1280/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__3883948256281316512<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:320/input[2]:7/input[3]:7/filter_count:1280/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__11071459659656059334<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:128/input[2]:32/input[3]:32/filter_count:128/filter_height:3/filter_width:3/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__11071459659656059334<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:128/input[2]:32/input[3]:32/filter_count:128/filter_height:3/filter_width:3/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__11071459659656059334<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:128/input[2]:32/input[3]:32/filter_count:128/filter_height:3/filter_width:3/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__11071459659656059334<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:128/input[2]:32/input[3]:32/filter_count:128/filter_height:3/filter_width:3/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__11071459659656059334<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:128/input[2]:32/input[3]:32/filter_count:128/filter_height:3/filter_width:3/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__11071459659656059334<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:128/input[2]:32/input[3]:32/filter_count:128/filter_height:3/filter_width:3/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__11071459659656059334<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:128/input[2]:32/input[3]:32/filter_count:128/filter_height:3/filter_width:3/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__11071459659656059334<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:128/input[2]:32/input[3]:32/filter_count:128/filter_height:3/filter_width:3/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__2420327101660498894<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:192/input[2]:28/input[3]:28/filter_count:96/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__2420327101660498894<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:192/input[2]:28/input[3]:28/filter_count:96/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__2420327101660498894<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:192/input[2]:28/input[3]:28/filter_count:96/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__2420327101660498894<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:192/input[2]:28/input[3]:28/filter_count:96/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__2420327101660498894<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:192/input[2]:28/input[3]:28/filter_count:96/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__2420327101660498894<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:192/input[2]:28/input[3]:28/filter_count:96/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__2420327101660498894<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:192/input[2]:28/input[3]:28/filter_count:96/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__2420327101660498894<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:192/input[2]:28/input[3]:28/filter_count:96/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__17393828788132268648<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:1280/input[2]:1/input[3]:1/filter_count:1000/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__17393828788132268648<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:1280/input[2]:1/input[3]:1/filter_count:1000/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__17393828788132268648<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:1280/input[2]:1/input[3]:1/filter_count:1000/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__17393828788132268648<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:1280/input[2]:1/input[3]:1/filter_count:1000/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__17393828788132268648<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:1280/input[2]:1/input[3]:1/filter_count:1000/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__17393828788132268648<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:1280/input[2]:1/input[3]:1/filter_count:1000/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__17393828788132268648<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:1280/input[2]:1/input[3]:1/filter_count:1000/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__17393828788132268648<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:1280/input[2]:1/input[3]:1/filter_count:1000/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__3161176298056772888<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:256/input[2]:199/input[3]:199/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__3161176298056772888<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:256/input[2]:199/input[3]:199/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__3161176298056772888<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:256/input[2]:199/input[3]:199/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__3161176298056772888<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:256/input[2]:199/input[3]:199/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__3161176298056772888<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:256/input[2]:199/input[3]:199/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__3161176298056772888<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:256/input[2]:199/input[3]:199/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__3161176298056772888<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:256/input[2]:199/input[3]:199/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__3161176298056772888<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:256/input[2]:199/input[3]:199/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__15327998276204830305<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:32/input[2]:28/input[3]:28/filter_count:96/filter_height:5/filter_width:5/pad_height:2/pad_width:2/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__15327998276204830305<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:32/input[2]:28/input[3]:28/filter_count:96/filter_height:5/filter_width:5/pad_height:2/pad_width:2/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__15327998276204830305<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:32/input[2]:28/input[3]:28/filter_count:96/filter_height:5/filter_width:5/pad_height:2/pad_width:2/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__15327998276204830305<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:32/input[2]:28/input[3]:28/filter_count:96/filter_height:5/filter_width:5/pad_height:2/pad_width:2/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__15327998276204830305<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:32/input[2]:28/input[3]:28/filter_count:96/filter_height:5/filter_width:5/pad_height:2/pad_width:2/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__15327998276204830305<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:32/input[2]:28/input[3]:28/filter_count:96/filter_height:5/filter_width:5/pad_height:2/pad_width:2/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__15327998276204830305<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:32/input[2]:28/input[3]:28/filter_count:96/filter_height:5/filter_width:5/pad_height:2/pad_width:2/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__15327998276204830305<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:32/input[2]:28/input[3]:28/filter_count:96/filter_height:5/filter_width:5/pad_height:2/pad_width:2/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__8638040242652728820<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:1/input[1]:800/input[2]:7/input[3]:7/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__8638040242652728820<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:1/input[1]:800/input[2]:7/input[3]:7/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__8638040242652728820<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:1/input[1]:800/input[2]:7/input[3]:7/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__8638040242652728820<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:1/input[1]:800/input[2]:7/input[3]:7/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__8638040242652728820<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:1/input[1]:800/input[2]:7/input[3]:7/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__8638040242652728820<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:1/input[1]:800/input[2]:7/input[3]:7/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__8638040242652728820<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:1/input[1]:800/input[2]:7/input[3]:7/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__8638040242652728820<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:1/input[1]:800/input[2]:7/input[3]:7/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__17144800627473478210<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:1/input[1]:528/input[2]:13/input[3]:13/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__17144800627473478210<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:1/input[1]:528/input[2]:13/input[3]:13/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__17144800627473478210<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:1/input[1]:528/input[2]:13/input[3]:13/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__17144800627473478210<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:1/input[1]:528/input[2]:13/input[3]:13/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__17144800627473478210<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:1/input[1]:528/input[2]:13/input[3]:13/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__17144800627473478210<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:1/input[1]:528/input[2]:13/input[3]:13/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__17144800627473478210<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:1/input[1]:528/input[2]:13/input[3]:13/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__17144800627473478210<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:1/input[1]:528/input[2]:13/input[3]:13/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__1659228898513315938<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:256/input[2]:100/input[3]:100/filter_count:256/filter_height:3/filter_width:3/pad_height:2/pad_width:2/stride_height:1/stride_width:1/dilation_height:2/dilation_width:2/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__1659228898513315938<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:256/input[2]:100/input[3]:100/filter_count:256/filter_height:3/filter_width:3/pad_height:2/pad_width:2/stride_height:1/stride_width:1/dilation_height:2/dilation_width:2/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__1659228898513315938<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:256/input[2]:100/input[3]:100/filter_count:256/filter_height:3/filter_width:3/pad_height:2/pad_width:2/stride_height:1/stride_width:1/dilation_height:2/dilation_width:2/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__1659228898513315938<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:256/input[2]:100/input[3]:100/filter_count:256/filter_height:3/filter_width:3/pad_height:2/pad_width:2/stride_height:1/stride_width:1/dilation_height:2/dilation_width:2/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__1659228898513315938<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:256/input[2]:100/input[3]:100/filter_count:256/filter_height:3/filter_width:3/pad_height:2/pad_width:2/stride_height:1/stride_width:1/dilation_height:2/dilation_width:2/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__1659228898513315938<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:256/input[2]:100/input[3]:100/filter_count:256/filter_height:3/filter_width:3/pad_height:2/pad_width:2/stride_height:1/stride_width:1/dilation_height:2/dilation_width:2/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__1659228898513315938<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:256/input[2]:100/input[3]:100/filter_count:256/filter_height:3/filter_width:3/pad_height:2/pad_width:2/stride_height:1/stride_width:1/dilation_height:2/dilation_width:2/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__1659228898513315938<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:256/input[2]:100/input[3]:100/filter_count:256/filter_height:3/filter_width:3/pad_height:2/pad_width:2/stride_height:1/stride_width:1/dilation_height:2/dilation_width:2/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__16322025586738731386<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:96/input[2]:28/input[3]:28/filter_count:96/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__16322025586738731386<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:96/input[2]:28/input[3]:28/filter_count:96/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__16322025586738731386<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:96/input[2]:28/input[3]:28/filter_count:96/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__16322025586738731386<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:96/input[2]:28/input[3]:28/filter_count:96/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__16322025586738731386<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:96/input[2]:28/input[3]:28/filter_count:96/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__16322025586738731386<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:96/input[2]:28/input[3]:28/filter_count:96/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__16322025586738731386<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:96/input[2]:28/input[3]:28/filter_count:96/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__16322025586738731386<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:96/input[2]:28/input[3]:28/filter_count:96/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__13633451302510418924<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:1/input[1]:832/input[2]:6/input[3]:6/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__13633451302510418924<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:1/input[1]:832/input[2]:6/input[3]:6/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__13633451302510418924<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:1/input[1]:832/input[2]:6/input[3]:6/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__13633451302510418924<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:1/input[1]:832/input[2]:6/input[3]:6/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__13633451302510418924<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:1/input[1]:832/input[2]:6/input[3]:6/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__13633451302510418924<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:1/input[1]:832/input[2]:6/input[3]:6/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__13633451302510418924<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:1/input[1]:832/input[2]:6/input[3]:6/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__13633451302510418924<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:1/input[1]:832/input[2]:6/input[3]:6/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__14933349575401484229<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:1024/input[2]:100/input[3]:100/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__14933349575401484229<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:1024/input[2]:100/input[3]:100/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__14933349575401484229<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:1024/input[2]:100/input[3]:100/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__14933349575401484229<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:1024/input[2]:100/input[3]:100/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__14933349575401484229<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:1024/input[2]:100/input[3]:100/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__14933349575401484229<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:1024/input[2]:100/input[3]:100/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__14933349575401484229<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:1024/input[2]:100/input[3]:100/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__14933349575401484229<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:1024/input[2]:100/input[3]:100/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__1639068900549720660<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:1/input[1]:832/input[2]:7/input[3]:7/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__1639068900549720660<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:1/input[1]:832/input[2]:7/input[3]:7/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__1639068900549720660<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:1/input[1]:832/input[2]:7/input[3]:7/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__1639068900549720660<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:1/input[1]:832/input[2]:7/input[3]:7/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__1639068900549720660<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:1/input[1]:832/input[2]:7/input[3]:7/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__1639068900549720660<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:1/input[1]:832/input[2]:7/input[3]:7/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__1639068900549720660<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:1/input[1]:832/input[2]:7/input[3]:7/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__1639068900549720660<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:1/input[1]:832/input[2]:7/input[3]:7/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__2574158358121789783<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:64/input[2]:28/input[3]:28/filter_count:96/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__2574158358121789783<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:64/input[2]:28/input[3]:28/filter_count:96/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__2574158358121789783<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:64/input[2]:28/input[3]:28/filter_count:96/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__2574158358121789783<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:64/input[2]:28/input[3]:28/filter_count:96/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__2574158358121789783<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:64/input[2]:28/input[3]:28/filter_count:96/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__2574158358121789783<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:64/input[2]:28/input[3]:28/filter_count:96/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__2574158358121789783<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:64/input[2]:28/input[3]:28/filter_count:96/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__2574158358121789783<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:64/input[2]:28/input[3]:28/filter_count:96/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__17644094702410566635<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:576/input[2]:14/input[3]:14/filter_count:160/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__17644094702410566635<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:576/input[2]:14/input[3]:14/filter_count:160/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__17644094702410566635<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:576/input[2]:14/input[3]:14/filter_count:160/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__17644094702410566635<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:576/input[2]:14/input[3]:14/filter_count:160/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__17644094702410566635<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:576/input[2]:14/input[3]:14/filter_count:160/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__17644094702410566635<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:576/input[2]:14/input[3]:14/filter_count:160/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__17644094702410566635<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:576/input[2]:14/input[3]:14/filter_count:160/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__17644094702410566635<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:576/input[2]:14/input[3]:14/filter_count:160/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__1045038387023690528<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:160/input[2]:14/input[3]:14/filter_count:192/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__1045038387023690528<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:160/input[2]:14/input[3]:14/filter_count:192/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__1045038387023690528<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:160/input[2]:14/input[3]:14/filter_count:192/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__1045038387023690528<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:160/input[2]:14/input[3]:14/filter_count:192/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__1045038387023690528<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:160/input[2]:14/input[3]:14/filter_count:192/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__1045038387023690528<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:160/input[2]:14/input[3]:14/filter_count:192/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__1045038387023690528<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:160/input[2]:14/input[3]:14/filter_count:192/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__1045038387023690528<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:160/input[2]:14/input[3]:14/filter_count:192/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__5224746311443582058<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:256/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__5224746311443582058<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:256/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__5224746311443582058<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:256/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__5224746311443582058<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:256/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__5224746311443582058<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:256/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__5224746311443582058<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:256/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__5224746311443582058<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:256/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__5224746311443582058<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:256/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__15139162640679756214<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:128/input[2]:14/input[3]:14/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__15139162640679756214<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:128/input[2]:14/input[3]:14/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__15139162640679756214<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:128/input[2]:14/input[3]:14/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__15139162640679756214<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:128/input[2]:14/input[3]:14/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__15139162640679756214<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:128/input[2]:14/input[3]:14/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__15139162640679756214<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:128/input[2]:14/input[3]:14/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__15139162640679756214<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:128/input[2]:14/input[3]:14/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__15139162640679756214<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:128/input[2]:14/input[3]:14/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__13788911520875671642<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:224/input[2]:7/input[3]:7/filter_count:224/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__13788911520875671642<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:224/input[2]:7/input[3]:7/filter_count:224/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__13788911520875671642<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:224/input[2]:7/input[3]:7/filter_count:224/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__13788911520875671642<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:224/input[2]:7/input[3]:7/filter_count:224/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__13788911520875671642<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:224/input[2]:7/input[3]:7/filter_count:224/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__13788911520875671642<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:224/input[2]:7/input[3]:7/filter_count:224/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__13788911520875671642<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:224/input[2]:7/input[3]:7/filter_count:224/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__13788911520875671642<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:224/input[2]:7/input[3]:7/filter_count:224/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__15432319161527955499<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:1024/input[2]:100/input[3]:100/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__15432319161527955499<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:1024/input[2]:100/input[3]:100/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__15432319161527955499<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:1024/input[2]:100/input[3]:100/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__15432319161527955499<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:1024/input[2]:100/input[3]:100/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__15432319161527955499<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:1024/input[2]:100/input[3]:100/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__15432319161527955499<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:1024/input[2]:100/input[3]:100/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__15432319161527955499<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:1024/input[2]:100/input[3]:100/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__15432319161527955499<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:1024/input[2]:100/input[3]:100/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__16366158616103068298<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:128/input[2]:28/input[3]:28/filter_count:192/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__16366158616103068298<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:128/input[2]:28/input[3]:28/filter_count:192/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__16366158616103068298<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:128/input[2]:28/input[3]:28/filter_count:192/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__16366158616103068298<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:128/input[2]:28/input[3]:28/filter_count:192/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__16366158616103068298<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:128/input[2]:28/input[3]:28/filter_count:192/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__16366158616103068298<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:128/input[2]:28/input[3]:28/filter_count:192/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__16366158616103068298<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:128/input[2]:28/input[3]:28/filter_count:192/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__16366158616103068298<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:128/input[2]:28/input[3]:28/filter_count:192/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__8332351828842117039<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:1/input[1]:64/input[2]:55/input[3]:55/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__8332351828842117039<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:1/input[1]:64/input[2]:55/input[3]:55/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__8332351828842117039<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:1/input[1]:64/input[2]:55/input[3]:55/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__8332351828842117039<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:1/input[1]:64/input[2]:55/input[3]:55/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__8332351828842117039<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:1/input[1]:64/input[2]:55/input[3]:55/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__8332351828842117039<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:1/input[1]:64/input[2]:55/input[3]:55/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__8332351828842117039<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:1/input[1]:64/input[2]:55/input[3]:55/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__8332351828842117039<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:1/input[1]:64/input[2]:55/input[3]:55/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__14192976833899925430<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:128/input[2]:26/input[3]:26/filter_count:256/filter_height:3/filter_width:3/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__14192976833899925430<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:128/input[2]:26/input[3]:26/filter_count:256/filter_height:3/filter_width:3/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__14192976833899925430<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:128/input[2]:26/input[3]:26/filter_count:256/filter_height:3/filter_width:3/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__14192976833899925430<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:128/input[2]:26/input[3]:26/filter_count:256/filter_height:3/filter_width:3/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__14192976833899925430<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:128/input[2]:26/input[3]:26/filter_count:256/filter_height:3/filter_width:3/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__14192976833899925430<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:128/input[2]:26/input[3]:26/filter_count:256/filter_height:3/filter_width:3/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__14192976833899925430<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:128/input[2]:26/input[3]:26/filter_count:256/filter_height:3/filter_width:3/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__14192976833899925430<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:128/input[2]:26/input[3]:26/filter_count:256/filter_height:3/filter_width:3/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__12388934306483241048<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:1024/input[2]:12/input[3]:12/filter_count:125/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__12388934306483241048<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:1024/input[2]:12/input[3]:12/filter_count:125/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__12388934306483241048<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:1024/input[2]:12/input[3]:12/filter_count:125/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__12388934306483241048<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:1024/input[2]:12/input[3]:12/filter_count:125/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__12388934306483241048<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:1024/input[2]:12/input[3]:12/filter_count:125/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__12388934306483241048<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:1024/input[2]:12/input[3]:12/filter_count:125/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__12388934306483241048<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:1024/input[2]:12/input[3]:12/filter_count:125/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__12388934306483241048<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:1024/input[2]:12/input[3]:12/filter_count:125/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__310140893076242184<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:512/input[2]:100/input[3]:100/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD failed to cudnnSetTensor4dDescriptor",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__310140893076242184<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:512/input[2]:100/input[3]:100/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD failed to cudnnSetTensor4dDescriptor",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__310140893076242184<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:512/input[2]:100/input[3]:100/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD failed to cudnnSetTensor4dDescriptor",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__310140893076242184<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:512/input[2]:100/input[3]:100/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD failed to cudnnSetTensor4dDescriptor",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__310140893076242184<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:512/input[2]:100/input[3]:100/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD failed to cudnnSetTensor4dDescriptor",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__310140893076242184<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:512/input[2]:100/input[3]:100/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD failed to cudnnSetTensor4dDescriptor",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__310140893076242184<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:512/input[2]:100/input[3]:100/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD failed to cudnnSetTensor4dDescriptor",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__310140893076242184<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:512/input[2]:100/input[3]:100/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD failed to cudnnSetTensor4dDescriptor",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__16959463500015053299<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:512/input[2]:12/input[3]:12/filter_count:1024/filter_height:3/filter_width:3/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__16959463500015053299<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:512/input[2]:12/input[3]:12/filter_count:1024/filter_height:3/filter_width:3/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__16959463500015053299<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:512/input[2]:12/input[3]:12/filter_count:1024/filter_height:3/filter_width:3/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__16959463500015053299<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:512/input[2]:12/input[3]:12/filter_count:1024/filter_height:3/filter_width:3/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__16959463500015053299<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:512/input[2]:12/input[3]:12/filter_count:1024/filter_height:3/filter_width:3/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__16959463500015053299<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:512/input[2]:12/input[3]:12/filter_count:1024/filter_height:3/filter_width:3/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__16959463500015053299<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:512/input[2]:12/input[3]:12/filter_count:1024/filter_height:3/filter_width:3/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__16959463500015053299<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:512/input[2]:12/input[3]:12/filter_count:1024/filter_height:3/filter_width:3/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__13106884104705623427<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:64/input[2]:56/input[3]:56/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__13106884104705623427<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:64/input[2]:56/input[3]:56/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__13106884104705623427<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:64/input[2]:56/input[3]:56/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__13106884104705623427<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:64/input[2]:56/input[3]:56/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__13106884104705623427<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:64/input[2]:56/input[3]:56/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__13106884104705623427<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:64/input[2]:56/input[3]:56/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__13106884104705623427<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:64/input[2]:56/input[3]:56/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__13106884104705623427<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:64/input[2]:56/input[3]:56/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__6537280592369137394<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:256/input[2]:13/input[3]:13/filter_count:384/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__6537280592369137394<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:256/input[2]:13/input[3]:13/filter_count:384/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__6537280592369137394<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:256/input[2]:13/input[3]:13/filter_count:384/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__6537280592369137394<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:256/input[2]:13/input[3]:13/filter_count:384/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__6537280592369137394<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:256/input[2]:13/input[3]:13/filter_count:384/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__6537280592369137394<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:256/input[2]:13/input[3]:13/filter_count:384/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__6537280592369137394<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:256/input[2]:13/input[3]:13/filter_count:384/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__6537280592369137394<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:256/input[2]:13/input[3]:13/filter_count:384/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__5774194195527126088<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:480/input[2]:14/input[3]:14/filter_count:96/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__5774194195527126088<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:480/input[2]:14/input[3]:14/filter_count:96/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__5774194195527126088<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:480/input[2]:14/input[3]:14/filter_count:96/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__5774194195527126088<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:480/input[2]:14/input[3]:14/filter_count:96/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__5774194195527126088<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:480/input[2]:14/input[3]:14/filter_count:96/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__5774194195527126088<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:480/input[2]:14/input[3]:14/filter_count:96/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__5774194195527126088<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:480/input[2]:14/input[3]:14/filter_count:96/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__5774194195527126088<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:480/input[2]:14/input[3]:14/filter_count:96/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__16018768463980303013<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:1024/input[2]:7/input[3]:7/filter_count:192/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__16018768463980303013<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:1024/input[2]:7/input[3]:7/filter_count:192/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__16018768463980303013<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:1024/input[2]:7/input[3]:7/filter_count:192/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__16018768463980303013<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:1024/input[2]:7/input[3]:7/filter_count:192/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__16018768463980303013<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:1024/input[2]:7/input[3]:7/filter_count:192/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__16018768463980303013<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:1024/input[2]:7/input[3]:7/filter_count:192/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__16018768463980303013<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:1024/input[2]:7/input[3]:7/filter_count:192/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__16018768463980303013<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:1024/input[2]:7/input[3]:7/filter_count:192/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__2679300359503704121<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:256/input[2]:14/input[3]:14/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__2679300359503704121<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:256/input[2]:14/input[3]:14/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__2679300359503704121<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:256/input[2]:14/input[3]:14/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__2679300359503704121<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:256/input[2]:14/input[3]:14/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__2679300359503704121<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:256/input[2]:14/input[3]:14/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__2679300359503704121<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:256/input[2]:14/input[3]:14/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__2679300359503704121<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:256/input[2]:14/input[3]:14/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__2679300359503704121<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:256/input[2]:14/input[3]:14/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__10328384754174181247<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__10328384754174181247<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__10328384754174181247<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__10328384754174181247<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__10328384754174181247<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__10328384754174181247<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__10328384754174181247<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__10328384754174181247<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__16638512679836844052<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:512/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__16638512679836844052<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:512/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__16638512679836844052<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:512/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__16638512679836844052<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:512/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__16638512679836844052<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:512/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__16638512679836844052<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:512/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__16638512679836844052<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:512/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__16638512679836844052<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:512/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__4287056191271545717<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:2048/input[2]:100/input[3]:100/filter_count:304/filter_height:3/filter_width:3/pad_height:24/pad_width:24/stride_height:1/stride_width:1/dilation_height:24/dilation_width:24/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD failed to cudnnSetTensor4dDescriptor",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__4287056191271545717<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:2048/input[2]:100/input[3]:100/filter_count:304/filter_height:3/filter_width:3/pad_height:24/pad_width:24/stride_height:1/stride_width:1/dilation_height:24/dilation_width:24/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD failed to cudnnSetTensor4dDescriptor",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__4287056191271545717<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:2048/input[2]:100/input[3]:100/filter_count:304/filter_height:3/filter_width:3/pad_height:24/pad_width:24/stride_height:1/stride_width:1/dilation_height:24/dilation_width:24/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD failed to cudnnSetTensor4dDescriptor",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__4287056191271545717<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:2048/input[2]:100/input[3]:100/filter_count:304/filter_height:3/filter_width:3/pad_height:24/pad_width:24/stride_height:1/stride_width:1/dilation_height:24/dilation_width:24/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD failed to cudnnSetTensor4dDescriptor",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__4287056191271545717<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:2048/input[2]:100/input[3]:100/filter_count:304/filter_height:3/filter_width:3/pad_height:24/pad_width:24/stride_height:1/stride_width:1/dilation_height:24/dilation_width:24/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD failed to cudnnSetTensor4dDescriptor",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__4287056191271545717<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:2048/input[2]:100/input[3]:100/filter_count:304/filter_height:3/filter_width:3/pad_height:24/pad_width:24/stride_height:1/stride_width:1/dilation_height:24/dilation_width:24/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD failed to cudnnSetTensor4dDescriptor",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__4287056191271545717<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:2048/input[2]:100/input[3]:100/filter_count:304/filter_height:3/filter_width:3/pad_height:24/pad_width:24/stride_height:1/stride_width:1/dilation_height:24/dilation_width:24/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD failed to cudnnSetTensor4dDescriptor",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__4287056191271545717<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:2048/input[2]:100/input[3]:100/filter_count:304/filter_height:3/filter_width:3/pad_height:24/pad_width:24/stride_height:1/stride_width:1/dilation_height:24/dilation_width:24/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD failed to cudnnSetTensor4dDescriptor",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__12161057706613040064<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:256/input[2]:14/input[3]:14/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__12161057706613040064<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:256/input[2]:14/input[3]:14/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__12161057706613040064<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:256/input[2]:14/input[3]:14/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__12161057706613040064<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:256/input[2]:14/input[3]:14/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__12161057706613040064<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:256/input[2]:14/input[3]:14/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__12161057706613040064<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:256/input[2]:14/input[3]:14/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__12161057706613040064<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:256/input[2]:14/input[3]:14/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__12161057706613040064<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:256/input[2]:14/input[3]:14/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__13980355697479897695<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:512/input[2]:28/input[3]:28/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__13980355697479897695<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:512/input[2]:28/input[3]:28/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__13980355697479897695<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:512/input[2]:28/input[3]:28/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__13980355697479897695<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:512/input[2]:28/input[3]:28/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__13980355697479897695<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:512/input[2]:28/input[3]:28/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__13980355697479897695<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:512/input[2]:28/input[3]:28/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__13980355697479897695<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:512/input[2]:28/input[3]:28/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__13980355697479897695<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:512/input[2]:28/input[3]:28/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__12301558193333996840<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__12301558193333996840<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__12301558193333996840<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__12301558193333996840<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__12301558193333996840<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__12301558193333996840<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__12301558193333996840<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__12301558193333996840<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__1697129041833138106<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__1697129041833138106<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__1697129041833138106<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__1697129041833138106<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__1697129041833138106<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__1697129041833138106<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__1697129041833138106<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__1697129041833138106<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__8586302975266953862<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:7/filter_width:7/pad_height:3/pad_width:3/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__8586302975266953862<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:7/filter_width:7/pad_height:3/pad_width:3/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__8586302975266953862<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:7/filter_width:7/pad_height:3/pad_width:3/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__8586302975266953862<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:7/filter_width:7/pad_height:3/pad_width:3/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__8586302975266953862<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:7/filter_width:7/pad_height:3/pad_width:3/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__8586302975266953862<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:7/filter_width:7/pad_height:3/pad_width:3/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__8586302975266953862<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:7/filter_width:7/pad_height:3/pad_width:3/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__8586302975266953862<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:7/filter_width:7/pad_height:3/pad_width:3/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__14579276858520636494<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:64/input[2]:112/input[3]:112/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__14579276858520636494<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:64/input[2]:112/input[3]:112/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__14579276858520636494<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:64/input[2]:112/input[3]:112/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__14579276858520636494<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:64/input[2]:112/input[3]:112/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__14579276858520636494<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:64/input[2]:112/input[3]:112/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__14579276858520636494<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:64/input[2]:112/input[3]:112/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__14579276858520636494<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:64/input[2]:112/input[3]:112/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__14579276858520636494<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:64/input[2]:112/input[3]:112/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__13168397564478026210<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:512/input[2]:28/input[3]:28/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__13168397564478026210<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:512/input[2]:28/input[3]:28/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__13168397564478026210<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:512/input[2]:28/input[3]:28/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__13168397564478026210<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:512/input[2]:28/input[3]:28/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__13168397564478026210<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:512/input[2]:28/input[3]:28/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__13168397564478026210<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:512/input[2]:28/input[3]:28/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__13168397564478026210<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:512/input[2]:28/input[3]:28/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__13168397564478026210<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:512/input[2]:28/input[3]:28/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__7864552091543666003<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:64/input[2]:112/input[3]:112/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__7864552091543666003<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:64/input[2]:112/input[3]:112/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__7864552091543666003<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:64/input[2]:112/input[3]:112/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__7864552091543666003<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:64/input[2]:112/input[3]:112/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__7864552091543666003<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:64/input[2]:112/input[3]:112/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__7864552091543666003<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:64/input[2]:112/input[3]:112/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__7864552091543666003<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:64/input[2]:112/input[3]:112/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__7864552091543666003<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:64/input[2]:112/input[3]:112/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__5883824584100407201<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:1/input[1]:112/input[2]:28/input[3]:28/filter_count:112/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:4/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__5883824584100407201<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:1/input[1]:112/input[2]:28/input[3]:28/filter_count:112/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:4/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__5883824584100407201<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:1/input[1]:112/input[2]:28/input[3]:28/filter_count:112/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:4/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__5883824584100407201<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:1/input[1]:112/input[2]:28/input[3]:28/filter_count:112/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:4/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__5883824584100407201<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:1/input[1]:112/input[2]:28/input[3]:28/filter_count:112/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:4/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__5883824584100407201<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:1/input[1]:112/input[2]:28/input[3]:28/filter_count:112/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:4/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__5883824584100407201<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:1/input[1]:112/input[2]:28/input[3]:28/filter_count:112/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:4/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__5883824584100407201<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:1/input[1]:112/input[2]:28/input[3]:28/filter_count:112/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:4/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__7294631967447529929<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:16/input[2]:55/input[3]:55/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__7294631967447529929<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:16/input[2]:55/input[3]:55/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__7294631967447529929<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:16/input[2]:55/input[3]:55/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__7294631967447529929<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:16/input[2]:55/input[3]:55/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__7294631967447529929<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:16/input[2]:55/input[3]:55/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__7294631967447529929<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:16/input[2]:55/input[3]:55/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__7294631967447529929<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:16/input[2]:55/input[3]:55/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__7294631967447529929<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:16/input[2]:55/input[3]:55/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__17401534409097948837<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:16/input[2]:14/input[3]:14/filter_count:48/filter_height:5/filter_width:5/pad_height:2/pad_width:2/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__17401534409097948837<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:16/input[2]:14/input[3]:14/filter_count:48/filter_height:5/filter_width:5/pad_height:2/pad_width:2/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__17401534409097948837<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:16/input[2]:14/input[3]:14/filter_count:48/filter_height:5/filter_width:5/pad_height:2/pad_width:2/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__17401534409097948837<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:16/input[2]:14/input[3]:14/filter_count:48/filter_height:5/filter_width:5/pad_height:2/pad_width:2/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__17401534409097948837<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:16/input[2]:14/input[3]:14/filter_count:48/filter_height:5/filter_width:5/pad_height:2/pad_width:2/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__17401534409097948837<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:16/input[2]:14/input[3]:14/filter_count:48/filter_height:5/filter_width:5/pad_height:2/pad_width:2/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__17401534409097948837<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:16/input[2]:14/input[3]:14/filter_count:48/filter_height:5/filter_width:5/pad_height:2/pad_width:2/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__17401534409097948837<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:16/input[2]:14/input[3]:14/filter_count:48/filter_height:5/filter_width:5/pad_height:2/pad_width:2/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__16929402243370612992<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:1/input[1]:272/input[2]:14/input[3]:14/filter_count:272/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:272/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__16929402243370612992<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:1/input[1]:272/input[2]:14/input[3]:14/filter_count:272/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:272/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__16929402243370612992<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:1/input[1]:272/input[2]:14/input[3]:14/filter_count:272/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:272/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__16929402243370612992<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:1/input[1]:272/input[2]:14/input[3]:14/filter_count:272/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:272/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__16929402243370612992<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:1/input[1]:272/input[2]:14/input[3]:14/filter_count:272/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:272/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__16929402243370612992<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:1/input[1]:272/input[2]:14/input[3]:14/filter_count:272/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:272/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__16929402243370612992<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:1/input[1]:272/input[2]:14/input[3]:14/filter_count:272/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:272/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__16929402243370612992<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:1/input[1]:272/input[2]:14/input[3]:14/filter_count:272/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:272/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__4609750275717855604<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:112/input[2]:14/input[3]:14/filter_count:224/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__4609750275717855604<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:112/input[2]:14/input[3]:14/filter_count:224/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__4609750275717855604<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:112/input[2]:14/input[3]:14/filter_count:224/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__4609750275717855604<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:112/input[2]:14/input[3]:14/filter_count:224/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__4609750275717855604<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:112/input[2]:14/input[3]:14/filter_count:224/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__4609750275717855604<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:112/input[2]:14/input[3]:14/filter_count:224/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__4609750275717855604<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:112/input[2]:14/input[3]:14/filter_count:224/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__4609750275717855604<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:112/input[2]:14/input[3]:14/filter_count:224/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__7055772436135724031<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:1/input[1]:832/input[2]:6/input[3]:6/filter_count:384/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__7055772436135724031<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:1/input[1]:832/input[2]:6/input[3]:6/filter_count:384/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__7055772436135724031<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:1/input[1]:832/input[2]:6/input[3]:6/filter_count:384/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__7055772436135724031<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:1/input[1]:832/input[2]:6/input[3]:6/filter_count:384/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__7055772436135724031<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:1/input[1]:832/input[2]:6/input[3]:6/filter_count:384/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__7055772436135724031<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:1/input[1]:832/input[2]:6/input[3]:6/filter_count:384/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__7055772436135724031<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:1/input[1]:832/input[2]:6/input[3]:6/filter_count:384/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__7055772436135724031<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:1/input[1]:832/input[2]:6/input[3]:6/filter_count:384/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__15814697207591492543<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:512/input[2]:14/input[3]:14/filter_count:24/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__15814697207591492543<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:512/input[2]:14/input[3]:14/filter_count:24/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__15814697207591492543<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:512/input[2]:14/input[3]:14/filter_count:24/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__15814697207591492543<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:512/input[2]:14/input[3]:14/filter_count:24/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__15814697207591492543<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:512/input[2]:14/input[3]:14/filter_count:24/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__15814697207591492543<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:512/input[2]:14/input[3]:14/filter_count:24/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__15814697207591492543<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:512/input[2]:14/input[3]:14/filter_count:24/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__15814697207591492543<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:512/input[2]:14/input[3]:14/filter_count:24/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__1345244070712327150<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:96/input[2]:14/input[3]:14/filter_count:208/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__1345244070712327150<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:96/input[2]:14/input[3]:14/filter_count:208/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__1345244070712327150<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:96/input[2]:14/input[3]:14/filter_count:208/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__1345244070712327150<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:96/input[2]:14/input[3]:14/filter_count:208/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__1345244070712327150<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:96/input[2]:14/input[3]:14/filter_count:208/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__1345244070712327150<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:96/input[2]:14/input[3]:14/filter_count:208/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__1345244070712327150<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:96/input[2]:14/input[3]:14/filter_count:208/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__1345244070712327150<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:96/input[2]:14/input[3]:14/filter_count:208/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__13545769056383518144<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:48/input[2]:13/input[3]:13/filter_count:192/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__13545769056383518144<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:48/input[2]:13/input[3]:13/filter_count:192/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__13545769056383518144<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:48/input[2]:13/input[3]:13/filter_count:192/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__13545769056383518144<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:48/input[2]:13/input[3]:13/filter_count:192/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__13545769056383518144<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:48/input[2]:13/input[3]:13/filter_count:192/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__13545769056383518144<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:48/input[2]:13/input[3]:13/filter_count:192/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__13545769056383518144<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:48/input[2]:13/input[3]:13/filter_count:192/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__13545769056383518144<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:48/input[2]:13/input[3]:13/filter_count:192/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__17532219393405842464<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:64/input[2]:13/input[3]:13/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__17532219393405842464<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:64/input[2]:13/input[3]:13/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__17532219393405842464<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:64/input[2]:13/input[3]:13/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__17532219393405842464<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:64/input[2]:13/input[3]:13/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__17532219393405842464<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:64/input[2]:13/input[3]:13/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__17532219393405842464<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:64/input[2]:13/input[3]:13/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__17532219393405842464<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:64/input[2]:13/input[3]:13/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__17532219393405842464<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:64/input[2]:13/input[3]:13/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__2973496187577443933<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:96/input[2]:54/input[3]:54/filter_count:256/filter_height:5/filter_width:5/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__2973496187577443933<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:96/input[2]:54/input[3]:54/filter_count:256/filter_height:5/filter_width:5/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__2973496187577443933<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:96/input[2]:54/input[3]:54/filter_count:256/filter_height:5/filter_width:5/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__2973496187577443933<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:96/input[2]:54/input[3]:54/filter_count:256/filter_height:5/filter_width:5/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__2973496187577443933<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:96/input[2]:54/input[3]:54/filter_count:256/filter_height:5/filter_width:5/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__2973496187577443933<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:96/input[2]:54/input[3]:54/filter_count:256/filter_height:5/filter_width:5/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__2973496187577443933<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:96/input[2]:54/input[3]:54/filter_count:256/filter_height:5/filter_width:5/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__2973496187577443933<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:96/input[2]:54/input[3]:54/filter_count:256/filter_height:5/filter_width:5/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__5651110032271641871<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:1/input[1]:128/input[2]:56/input[3]:56/filter_count:32/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__5651110032271641871<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:1/input[1]:128/input[2]:56/input[3]:56/filter_count:32/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__5651110032271641871<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:1/input[1]:128/input[2]:56/input[3]:56/filter_count:32/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__5651110032271641871<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:1/input[1]:128/input[2]:56/input[3]:56/filter_count:32/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__5651110032271641871<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:1/input[1]:128/input[2]:56/input[3]:56/filter_count:32/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__5651110032271641871<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:1/input[1]:128/input[2]:56/input[3]:56/filter_count:32/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__5651110032271641871<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:1/input[1]:128/input[2]:56/input[3]:56/filter_count:32/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__5651110032271641871<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:1/input[1]:128/input[2]:56/input[3]:56/filter_count:32/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__6246203362482580367<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:256/input[2]:12/input[3]:12/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__6246203362482580367<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:256/input[2]:12/input[3]:12/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__6246203362482580367<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:256/input[2]:12/input[3]:12/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__6246203362482580367<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:256/input[2]:12/input[3]:12/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__6246203362482580367<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:256/input[2]:12/input[3]:12/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__6246203362482580367<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:256/input[2]:12/input[3]:12/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__6246203362482580367<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:256/input[2]:12/input[3]:12/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__6246203362482580367<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:256/input[2]:12/input[3]:12/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__10767104277952499077<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:1/input[1]:256/input[2]:27/input[3]:27/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__10767104277952499077<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:1/input[1]:256/input[2]:27/input[3]:27/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__10767104277952499077<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:1/input[1]:256/input[2]:27/input[3]:27/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__10767104277952499077<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:1/input[1]:256/input[2]:27/input[3]:27/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__10767104277952499077<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:1/input[1]:256/input[2]:27/input[3]:27/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__10767104277952499077<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:1/input[1]:256/input[2]:27/input[3]:27/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__10767104277952499077<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:1/input[1]:256/input[2]:27/input[3]:27/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__10767104277952499077<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:1/input[1]:256/input[2]:27/input[3]:27/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__15699825022673145363<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:1/input[1]:288/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__15699825022673145363<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:1/input[1]:288/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__15699825022673145363<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:1/input[1]:288/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__15699825022673145363<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:1/input[1]:288/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__15699825022673145363<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:1/input[1]:288/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__15699825022673145363<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:1/input[1]:288/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__15699825022673145363<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:1/input[1]:288/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__15699825022673145363<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:1/input[1]:288/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__5291984476540063523<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:32/input[2]:112/input[3]:112/filter_count:32/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:32/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__5291984476540063523<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:32/input[2]:112/input[3]:112/filter_count:32/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:32/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__5291984476540063523<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:32/input[2]:112/input[3]:112/filter_count:32/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:32/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__5291984476540063523<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:32/input[2]:112/input[3]:112/filter_count:32/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:32/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__5291984476540063523<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:32/input[2]:112/input[3]:112/filter_count:32/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:32/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__5291984476540063523<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:32/input[2]:112/input[3]:112/filter_count:32/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:32/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__5291984476540063523<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:32/input[2]:112/input[3]:112/filter_count:32/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:32/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__5291984476540063523<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:32/input[2]:112/input[3]:112/filter_count:32/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:32/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__7482878634220941498<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:1/input[1]:16/input[2]:27/input[3]:27/filter_count:32/filter_height:5/filter_width:5/pad_height:2/pad_width:2/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__7482878634220941498<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:1/input[1]:16/input[2]:27/input[3]:27/filter_count:32/filter_height:5/filter_width:5/pad_height:2/pad_width:2/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__7482878634220941498<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:1/input[1]:16/input[2]:27/input[3]:27/filter_count:32/filter_height:5/filter_width:5/pad_height:2/pad_width:2/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__7482878634220941498<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:1/input[1]:16/input[2]:27/input[3]:27/filter_count:32/filter_height:5/filter_width:5/pad_height:2/pad_width:2/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__7482878634220941498<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:1/input[1]:16/input[2]:27/input[3]:27/filter_count:32/filter_height:5/filter_width:5/pad_height:2/pad_width:2/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__7482878634220941498<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:1/input[1]:16/input[2]:27/input[3]:27/filter_count:32/filter_height:5/filter_width:5/pad_height:2/pad_width:2/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__7482878634220941498<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:1/input[1]:16/input[2]:27/input[3]:27/filter_count:32/filter_height:5/filter_width:5/pad_height:2/pad_width:2/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__7482878634220941498<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:1/input[1]:16/input[2]:27/input[3]:27/filter_count:32/filter_height:5/filter_width:5/pad_height:2/pad_width:2/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__6009562148837156860<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:3/input[2]:224/input[3]:224/filter_count:96/filter_height:11/filter_width:11/pad_height:0/pad_width:0/stride_height:4/stride_width:4/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__6009562148837156860<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:3/input[2]:224/input[3]:224/filter_count:96/filter_height:11/filter_width:11/pad_height:0/pad_width:0/stride_height:4/stride_width:4/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__6009562148837156860<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:3/input[2]:224/input[3]:224/filter_count:96/filter_height:11/filter_width:11/pad_height:0/pad_width:0/stride_height:4/stride_width:4/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__6009562148837156860<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:3/input[2]:224/input[3]:224/filter_count:96/filter_height:11/filter_width:11/pad_height:0/pad_width:0/stride_height:4/stride_width:4/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__6009562148837156860<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:3/input[2]:224/input[3]:224/filter_count:96/filter_height:11/filter_width:11/pad_height:0/pad_width:0/stride_height:4/stride_width:4/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__6009562148837156860<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:3/input[2]:224/input[3]:224/filter_count:96/filter_height:11/filter_width:11/pad_height:0/pad_width:0/stride_height:4/stride_width:4/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__6009562148837156860<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:3/input[2]:224/input[3]:224/filter_count:96/filter_height:11/filter_width:11/pad_height:0/pad_width:0/stride_height:4/stride_width:4/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__6009562148837156860<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:3/input[2]:224/input[3]:224/filter_count:96/filter_height:11/filter_width:11/pad_height:0/pad_width:0/stride_height:4/stride_width:4/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__14027509288488142173<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:3/filter_width:3/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__14027509288488142173<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:3/filter_width:3/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__14027509288488142173<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:3/filter_width:3/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__14027509288488142173<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:3/filter_width:3/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__14027509288488142173<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:3/filter_width:3/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__14027509288488142173<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:3/filter_width:3/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__14027509288488142173<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:3/filter_width:3/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__14027509288488142173<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:3/filter_width:3/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__13364002913789469484<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:1/input[1]:256/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__13364002913789469484<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:1/input[1]:256/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__13364002913789469484<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:1/input[1]:256/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__13364002913789469484<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:1/input[1]:256/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__13364002913789469484<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:1/input[1]:256/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__13364002913789469484<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:1/input[1]:256/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__13364002913789469484<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:1/input[1]:256/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__13364002913789469484<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:1/input[1]:256/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__12808394306551760110<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:384/input[2]:12/input[3]:12/filter_count:384/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:2/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__12808394306551760110<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:384/input[2]:12/input[3]:12/filter_count:384/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:2/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__12808394306551760110<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:384/input[2]:12/input[3]:12/filter_count:384/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:2/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__12808394306551760110<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:384/input[2]:12/input[3]:12/filter_count:384/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:2/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__12808394306551760110<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:384/input[2]:12/input[3]:12/filter_count:384/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:2/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__12808394306551760110<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:384/input[2]:12/input[3]:12/filter_count:384/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:2/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__12808394306551760110<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:384/input[2]:12/input[3]:12/filter_count:384/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:2/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__12808394306551760110<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:384/input[2]:12/input[3]:12/filter_count:384/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:2/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__12970742691583392398<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:1/input[1]:480/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__12970742691583392398<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:1/input[1]:480/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__12970742691583392398<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:1/input[1]:480/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__12970742691583392398<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:1/input[1]:480/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__12970742691583392398<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:1/input[1]:480/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__12970742691583392398<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:1/input[1]:480/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__12970742691583392398<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:1/input[1]:480/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__12970742691583392398<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:1/input[1]:480/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__98258492131154788<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:528/input[2]:14/input[3]:14/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__98258492131154788<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:528/input[2]:14/input[3]:14/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__98258492131154788<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:528/input[2]:14/input[3]:14/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__98258492131154788<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:528/input[2]:14/input[3]:14/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__98258492131154788<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:528/input[2]:14/input[3]:14/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__98258492131154788<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:528/input[2]:14/input[3]:14/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__98258492131154788<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:528/input[2]:14/input[3]:14/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__98258492131154788<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:528/input[2]:14/input[3]:14/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__15899585116456914216<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:128/input[2]:55/input[3]:55/filter_count:16/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__15899585116456914216<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:128/input[2]:55/input[3]:55/filter_count:16/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__15899585116456914216<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:128/input[2]:55/input[3]:55/filter_count:16/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__15899585116456914216<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:128/input[2]:55/input[3]:55/filter_count:16/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__15899585116456914216<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:128/input[2]:55/input[3]:55/filter_count:16/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__15899585116456914216<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:128/input[2]:55/input[3]:55/filter_count:16/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__15899585116456914216<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:128/input[2]:55/input[3]:55/filter_count:16/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__15899585116456914216<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:128/input[2]:55/input[3]:55/filter_count:16/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__3718474585642574453<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:1/input[1]:672/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__3718474585642574453<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:1/input[1]:672/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__3718474585642574453<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:1/input[1]:672/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__3718474585642574453<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:1/input[1]:672/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__3718474585642574453<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:1/input[1]:672/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__3718474585642574453<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:1/input[1]:672/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__3718474585642574453<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:1/input[1]:672/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__3718474585642574453<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:1/input[1]:672/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__16308745601208923702<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:832/input[2]:7/input[3]:7/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__16308745601208923702<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:832/input[2]:7/input[3]:7/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__16308745601208923702<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:832/input[2]:7/input[3]:7/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__16308745601208923702<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:832/input[2]:7/input[3]:7/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__16308745601208923702<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:832/input[2]:7/input[3]:7/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__16308745601208923702<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:832/input[2]:7/input[3]:7/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__16308745601208923702<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:832/input[2]:7/input[3]:7/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__16308745601208923702<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:832/input[2]:7/input[3]:7/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__11528566747172749427<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:1/input[1]:800/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__11528566747172749427<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:1/input[1]:800/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__11528566747172749427<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:1/input[1]:800/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__11528566747172749427<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:1/input[1]:800/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__11528566747172749427<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:1/input[1]:800/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__11528566747172749427<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:1/input[1]:800/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__11528566747172749427<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:1/input[1]:800/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__11528566747172749427<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:1/input[1]:800/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__18346765285892052204<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:1/input[1]:416/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__18346765285892052204<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:1/input[1]:416/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__18346765285892052204<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:1/input[1]:416/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__18346765285892052204<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:1/input[1]:416/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__18346765285892052204<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:1/input[1]:416/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__18346765285892052204<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:1/input[1]:416/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__18346765285892052204<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:1/input[1]:416/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__18346765285892052204<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:1/input[1]:416/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__1253691686172694958<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:832/input[2]:7/input[3]:7/filter_count:384/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__1253691686172694958<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:832/input[2]:7/input[3]:7/filter_count:384/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__1253691686172694958<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:832/input[2]:7/input[3]:7/filter_count:384/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__1253691686172694958<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:832/input[2]:7/input[3]:7/filter_count:384/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__1253691686172694958<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:832/input[2]:7/input[3]:7/filter_count:384/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__1253691686172694958<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:832/input[2]:7/input[3]:7/filter_count:384/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__1253691686172694958<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:832/input[2]:7/input[3]:7/filter_count:384/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__1253691686172694958<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:832/input[2]:7/input[3]:7/filter_count:384/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__1434175747540207744<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:64/input[2]:28/input[3]:28/filter_count:384/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__1434175747540207744<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:64/input[2]:28/input[3]:28/filter_count:384/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__1434175747540207744<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:64/input[2]:28/input[3]:28/filter_count:384/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__1434175747540207744<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:64/input[2]:28/input[3]:28/filter_count:384/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__1434175747540207744<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:64/input[2]:28/input[3]:28/filter_count:384/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__1434175747540207744<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:64/input[2]:28/input[3]:28/filter_count:384/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__1434175747540207744<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:64/input[2]:28/input[3]:28/filter_count:384/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__1434175747540207744<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:64/input[2]:28/input[3]:28/filter_count:384/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__17727344372519926108<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:256/input[2]:199/input[3]:199/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__17727344372519926108<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:256/input[2]:199/input[3]:199/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__17727344372519926108<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:256/input[2]:199/input[3]:199/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__17727344372519926108<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:256/input[2]:199/input[3]:199/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__17727344372519926108<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:256/input[2]:199/input[3]:199/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__17727344372519926108<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:256/input[2]:199/input[3]:199/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__17727344372519926108<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:256/input[2]:199/input[3]:199/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__17727344372519926108<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:256/input[2]:199/input[3]:199/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__8578622682347888505<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:384/input[2]:14/input[3]:14/filter_count:96/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__8578622682347888505<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:384/input[2]:14/input[3]:14/filter_count:96/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__8578622682347888505<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:384/input[2]:14/input[3]:14/filter_count:96/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__8578622682347888505<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:384/input[2]:14/input[3]:14/filter_count:96/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__8578622682347888505<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:384/input[2]:14/input[3]:14/filter_count:96/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__8578622682347888505<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:384/input[2]:14/input[3]:14/filter_count:96/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__8578622682347888505<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:384/input[2]:14/input[3]:14/filter_count:96/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__8578622682347888505<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:384/input[2]:14/input[3]:14/filter_count:96/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__12279251011610599773<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:64/input[2]:64/input[3]:64/filter_count:64/filter_height:3/filter_width:3/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__12279251011610599773<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:64/input[2]:64/input[3]:64/filter_count:64/filter_height:3/filter_width:3/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__12279251011610599773<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:64/input[2]:64/input[3]:64/filter_count:64/filter_height:3/filter_width:3/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__12279251011610599773<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:64/input[2]:64/input[3]:64/filter_count:64/filter_height:3/filter_width:3/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__12279251011610599773<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:64/input[2]:64/input[3]:64/filter_count:64/filter_height:3/filter_width:3/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__12279251011610599773<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:64/input[2]:64/input[3]:64/filter_count:64/filter_height:3/filter_width:3/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__12279251011610599773<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:64/input[2]:64/input[3]:64/filter_count:64/filter_height:3/filter_width:3/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__12279251011610599773<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:64/input[2]:64/input[3]:64/filter_count:64/filter_height:3/filter_width:3/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__2072116609808074348<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:576/input[2]:7/input[3]:7/filter_count:160/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__2072116609808074348<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:576/input[2]:7/input[3]:7/filter_count:160/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__2072116609808074348<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:576/input[2]:7/input[3]:7/filter_count:160/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__2072116609808074348<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:576/input[2]:7/input[3]:7/filter_count:160/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__2072116609808074348<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:576/input[2]:7/input[3]:7/filter_count:160/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__2072116609808074348<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:576/input[2]:7/input[3]:7/filter_count:160/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__2072116609808074348<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:576/input[2]:7/input[3]:7/filter_count:160/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__2072116609808074348<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:576/input[2]:7/input[3]:7/filter_count:160/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__10591761978794142303<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:960/input[2]:7/input[3]:7/filter_count:160/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__10591761978794142303<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:960/input[2]:7/input[3]:7/filter_count:160/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__10591761978794142303<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:960/input[2]:7/input[3]:7/filter_count:160/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__10591761978794142303<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:960/input[2]:7/input[3]:7/filter_count:160/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__10591761978794142303<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:960/input[2]:7/input[3]:7/filter_count:160/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__10591761978794142303<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:960/input[2]:7/input[3]:7/filter_count:160/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__10591761978794142303<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:960/input[2]:7/input[3]:7/filter_count:160/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__10591761978794142303<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:960/input[2]:7/input[3]:7/filter_count:160/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__6721434084661973125<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:1/input[1]:928/input[2]:7/input[3]:7/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__6721434084661973125<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:1/input[1]:928/input[2]:7/input[3]:7/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__6721434084661973125<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:1/input[1]:928/input[2]:7/input[3]:7/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__6721434084661973125<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:1/input[1]:928/input[2]:7/input[3]:7/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__6721434084661973125<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:1/input[1]:928/input[2]:7/input[3]:7/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__6721434084661973125<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:1/input[1]:928/input[2]:7/input[3]:7/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__6721434084661973125<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:1/input[1]:928/input[2]:7/input[3]:7/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__6721434084661973125<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:1/input[1]:928/input[2]:7/input[3]:7/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__9262822633063204931<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:960/input[2]:7/input[3]:7/filter_count:320/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__9262822633063204931<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:960/input[2]:7/input[3]:7/filter_count:320/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__9262822633063204931<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:960/input[2]:7/input[3]:7/filter_count:320/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__9262822633063204931<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:960/input[2]:7/input[3]:7/filter_count:320/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__9262822633063204931<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:960/input[2]:7/input[3]:7/filter_count:320/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__9262822633063204931<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:960/input[2]:7/input[3]:7/filter_count:320/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__9262822633063204931<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:960/input[2]:7/input[3]:7/filter_count:320/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__9262822633063204931<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:960/input[2]:7/input[3]:7/filter_count:320/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__13656709652785473624<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:192/input[2]:28/input[3]:28/filter_count:16/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__13656709652785473624<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:192/input[2]:28/input[3]:28/filter_count:16/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__13656709652785473624<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:192/input[2]:28/input[3]:28/filter_count:16/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__13656709652785473624<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:192/input[2]:28/input[3]:28/filter_count:16/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__13656709652785473624<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:192/input[2]:28/input[3]:28/filter_count:16/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__13656709652785473624<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:192/input[2]:28/input[3]:28/filter_count:16/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__13656709652785473624<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:192/input[2]:28/input[3]:28/filter_count:16/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__13656709652785473624<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:192/input[2]:28/input[3]:28/filter_count:16/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__6474718317458539888<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:1/input[1]:160/input[2]:13/input[3]:13/filter_count:320/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__6474718317458539888<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:1/input[1]:160/input[2]:13/input[3]:13/filter_count:320/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__6474718317458539888<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:1/input[1]:160/input[2]:13/input[3]:13/filter_count:320/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__6474718317458539888<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:1/input[1]:160/input[2]:13/input[3]:13/filter_count:320/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__6474718317458539888<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:1/input[1]:160/input[2]:13/input[3]:13/filter_count:320/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__6474718317458539888<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:1/input[1]:160/input[2]:13/input[3]:13/filter_count:320/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__6474718317458539888<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:1/input[1]:160/input[2]:13/input[3]:13/filter_count:320/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__6474718317458539888<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:1/input[1]:160/input[2]:13/input[3]:13/filter_count:320/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__16040745474523587930<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:1/input[1]:528/input[2]:13/input[3]:13/filter_count:32/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__16040745474523587930<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:1/input[1]:528/input[2]:13/input[3]:13/filter_count:32/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__16040745474523587930<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:1/input[1]:528/input[2]:13/input[3]:13/filter_count:32/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__16040745474523587930<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:1/input[1]:528/input[2]:13/input[3]:13/filter_count:32/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__16040745474523587930<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:1/input[1]:528/input[2]:13/input[3]:13/filter_count:32/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__16040745474523587930<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:1/input[1]:528/input[2]:13/input[3]:13/filter_count:32/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__16040745474523587930<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:1/input[1]:528/input[2]:13/input[3]:13/filter_count:32/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__16040745474523587930<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:1/input[1]:528/input[2]:13/input[3]:13/filter_count:32/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__13240503702556320632<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:1/input[1]:992/input[2]:7/input[3]:7/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__13240503702556320632<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:1/input[1]:992/input[2]:7/input[3]:7/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__13240503702556320632<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:1/input[1]:992/input[2]:7/input[3]:7/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__13240503702556320632<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:1/input[1]:992/input[2]:7/input[3]:7/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__13240503702556320632<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:1/input[1]:992/input[2]:7/input[3]:7/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__13240503702556320632<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:1/input[1]:992/input[2]:7/input[3]:7/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__13240503702556320632<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:1/input[1]:992/input[2]:7/input[3]:7/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__13240503702556320632<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:1/input[1]:992/input[2]:7/input[3]:7/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__9905296551043506147<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:16/input[2]:28/input[3]:28/filter_count:32/filter_height:5/filter_width:5/pad_height:2/pad_width:2/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__9905296551043506147<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:16/input[2]:28/input[3]:28/filter_count:32/filter_height:5/filter_width:5/pad_height:2/pad_width:2/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__9905296551043506147<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:16/input[2]:28/input[3]:28/filter_count:32/filter_height:5/filter_width:5/pad_height:2/pad_width:2/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__9905296551043506147<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:16/input[2]:28/input[3]:28/filter_count:32/filter_height:5/filter_width:5/pad_height:2/pad_width:2/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__9905296551043506147<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:16/input[2]:28/input[3]:28/filter_count:32/filter_height:5/filter_width:5/pad_height:2/pad_width:2/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__9905296551043506147<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:16/input[2]:28/input[3]:28/filter_count:32/filter_height:5/filter_width:5/pad_height:2/pad_width:2/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__9905296551043506147<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:16/input[2]:28/input[3]:28/filter_count:32/filter_height:5/filter_width:5/pad_height:2/pad_width:2/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__9905296551043506147<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:16/input[2]:28/input[3]:28/filter_count:32/filter_height:5/filter_width:5/pad_height:2/pad_width:2/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__6459386565734905612<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:64/input[2]:56/input[3]:56/filter_count:192/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__6459386565734905612<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:64/input[2]:56/input[3]:56/filter_count:192/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__6459386565734905612<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:64/input[2]:56/input[3]:56/filter_count:192/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__6459386565734905612<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:64/input[2]:56/input[3]:56/filter_count:192/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__6459386565734905612<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:64/input[2]:56/input[3]:56/filter_count:192/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__6459386565734905612<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:64/input[2]:56/input[3]:56/filter_count:192/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__6459386565734905612<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:64/input[2]:56/input[3]:56/filter_count:192/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__6459386565734905612<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:64/input[2]:56/input[3]:56/filter_count:192/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__749907884000792474<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:1/input[1]:768/input[2]:7/input[3]:7/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__749907884000792474<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:1/input[1]:768/input[2]:7/input[3]:7/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__749907884000792474<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:1/input[1]:768/input[2]:7/input[3]:7/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__749907884000792474<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:1/input[1]:768/input[2]:7/input[3]:7/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__749907884000792474<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:1/input[1]:768/input[2]:7/input[3]:7/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__749907884000792474<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:1/input[1]:768/input[2]:7/input[3]:7/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__749907884000792474<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:1/input[1]:768/input[2]:7/input[3]:7/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__749907884000792474<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:1/input[1]:768/input[2]:7/input[3]:7/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__11218812037149380279<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:512/input[2]:100/input[3]:100/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__11218812037149380279<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:512/input[2]:100/input[3]:100/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__11218812037149380279<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:512/input[2]:100/input[3]:100/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__11218812037149380279<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:512/input[2]:100/input[3]:100/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__11218812037149380279<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:512/input[2]:100/input[3]:100/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__11218812037149380279<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:512/input[2]:100/input[3]:100/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__11218812037149380279<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:512/input[2]:100/input[3]:100/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__11218812037149380279<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:512/input[2]:100/input[3]:100/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__8576477005427472561<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:1/input[1]:528/input[2]:13/input[3]:13/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__8576477005427472561<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:1/input[1]:528/input[2]:13/input[3]:13/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__8576477005427472561<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:1/input[1]:528/input[2]:13/input[3]:13/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__8576477005427472561<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:1/input[1]:528/input[2]:13/input[3]:13/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__8576477005427472561<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:1/input[1]:528/input[2]:13/input[3]:13/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__8576477005427472561<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:1/input[1]:528/input[2]:13/input[3]:13/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__8576477005427472561<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:1/input[1]:528/input[2]:13/input[3]:13/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__8576477005427472561<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:1/input[1]:528/input[2]:13/input[3]:13/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__1075557814309107741<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:64/input[2]:28/input[3]:28/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__1075557814309107741<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:64/input[2]:28/input[3]:28/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__1075557814309107741<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:64/input[2]:28/input[3]:28/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__1075557814309107741<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:64/input[2]:28/input[3]:28/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__1075557814309107741<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:64/input[2]:28/input[3]:28/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__1075557814309107741<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:64/input[2]:28/input[3]:28/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__1075557814309107741<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:64/input[2]:28/input[3]:28/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__1075557814309107741<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:64/input[2]:28/input[3]:28/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__124956025572928589<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:1/input[1]:832/input[2]:6/input[3]:6/filter_count:160/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__124956025572928589<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:1/input[1]:832/input[2]:6/input[3]:6/filter_count:160/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__124956025572928589<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:1/input[1]:832/input[2]:6/input[3]:6/filter_count:160/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__124956025572928589<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:1/input[1]:832/input[2]:6/input[3]:6/filter_count:160/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__124956025572928589<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:1/input[1]:832/input[2]:6/input[3]:6/filter_count:160/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__124956025572928589<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:1/input[1]:832/input[2]:6/input[3]:6/filter_count:160/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__124956025572928589<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:1/input[1]:832/input[2]:6/input[3]:6/filter_count:160/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__124956025572928589<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:1/input[1]:832/input[2]:6/input[3]:6/filter_count:160/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__15741394152993204417<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:256/input[2]:100/input[3]:100/filter_count:256/filter_height:3/filter_width:3/pad_height:5/pad_width:5/stride_height:1/stride_width:1/dilation_height:5/dilation_width:5/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__15741394152993204417<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:256/input[2]:100/input[3]:100/filter_count:256/filter_height:3/filter_width:3/pad_height:5/pad_width:5/stride_height:1/stride_width:1/dilation_height:5/dilation_width:5/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__15741394152993204417<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:256/input[2]:100/input[3]:100/filter_count:256/filter_height:3/filter_width:3/pad_height:5/pad_width:5/stride_height:1/stride_width:1/dilation_height:5/dilation_width:5/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__15741394152993204417<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:256/input[2]:100/input[3]:100/filter_count:256/filter_height:3/filter_width:3/pad_height:5/pad_width:5/stride_height:1/stride_width:1/dilation_height:5/dilation_width:5/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__15741394152993204417<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:256/input[2]:100/input[3]:100/filter_count:256/filter_height:3/filter_width:3/pad_height:5/pad_width:5/stride_height:1/stride_width:1/dilation_height:5/dilation_width:5/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__15741394152993204417<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:256/input[2]:100/input[3]:100/filter_count:256/filter_height:3/filter_width:3/pad_height:5/pad_width:5/stride_height:1/stride_width:1/dilation_height:5/dilation_width:5/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__15741394152993204417<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:256/input[2]:100/input[3]:100/filter_count:256/filter_height:3/filter_width:3/pad_height:5/pad_width:5/stride_height:1/stride_width:1/dilation_height:5/dilation_width:5/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__15741394152993204417<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:256/input[2]:100/input[3]:100/filter_count:256/filter_height:3/filter_width:3/pad_height:5/pad_width:5/stride_height:1/stride_width:1/dilation_height:5/dilation_width:5/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__13169192344929832807<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:576/input[2]:14/input[3]:14/filter_count:224/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__13169192344929832807<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:576/input[2]:14/input[3]:14/filter_count:224/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__13169192344929832807<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:576/input[2]:14/input[3]:14/filter_count:224/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__13169192344929832807<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:576/input[2]:14/input[3]:14/filter_count:224/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__13169192344929832807<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:576/input[2]:14/input[3]:14/filter_count:224/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__13169192344929832807<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:576/input[2]:14/input[3]:14/filter_count:224/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__13169192344929832807<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:576/input[2]:14/input[3]:14/filter_count:224/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__13169192344929832807<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:576/input[2]:14/input[3]:14/filter_count:224/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__6033502540376180966<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:256/input[2]:100/input[3]:100/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__6033502540376180966<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:256/input[2]:100/input[3]:100/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__6033502540376180966<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:256/input[2]:100/input[3]:100/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__6033502540376180966<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:256/input[2]:100/input[3]:100/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__6033502540376180966<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:256/input[2]:100/input[3]:100/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__6033502540376180966<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:256/input[2]:100/input[3]:100/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__6033502540376180966<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:256/input[2]:100/input[3]:100/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__6033502540376180966<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:256/input[2]:100/input[3]:100/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__4492415720741311289<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:128/input[2]:14/input[3]:14/filter_count:192/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__4492415720741311289<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:128/input[2]:14/input[3]:14/filter_count:192/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__4492415720741311289<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:128/input[2]:14/input[3]:14/filter_count:192/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__4492415720741311289<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:128/input[2]:14/input[3]:14/filter_count:192/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__4492415720741311289<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:128/input[2]:14/input[3]:14/filter_count:192/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__4492415720741311289<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:128/input[2]:14/input[3]:14/filter_count:192/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__4492415720741311289<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:128/input[2]:14/input[3]:14/filter_count:192/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__4492415720741311289<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:128/input[2]:14/input[3]:14/filter_count:192/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__16555375563811906306<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:1024/input[2]:100/input[3]:100/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD failed to cudnnSetTensor4dDescriptor",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__16555375563811906306<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:1024/input[2]:100/input[3]:100/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD failed to cudnnSetTensor4dDescriptor",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__16555375563811906306<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:1024/input[2]:100/input[3]:100/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD failed to cudnnSetTensor4dDescriptor",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__16555375563811906306<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:1024/input[2]:100/input[3]:100/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD failed to cudnnSetTensor4dDescriptor",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__16555375563811906306<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:1024/input[2]:100/input[3]:100/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD failed to cudnnSetTensor4dDescriptor",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__16555375563811906306<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:1024/input[2]:100/input[3]:100/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD failed to cudnnSetTensor4dDescriptor",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__16555375563811906306<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:1024/input[2]:100/input[3]:100/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD failed to cudnnSetTensor4dDescriptor",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__16555375563811906306<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:1024/input[2]:100/input[3]:100/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD failed to cudnnSetTensor4dDescriptor",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__17095089582642638140<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:1024/input[2]:7/input[3]:7/filter_count:160/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__17095089582642638140<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:1024/input[2]:7/input[3]:7/filter_count:160/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__17095089582642638140<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:1024/input[2]:7/input[3]:7/filter_count:160/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__17095089582642638140<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:1024/input[2]:7/input[3]:7/filter_count:160/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__17095089582642638140<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:1024/input[2]:7/input[3]:7/filter_count:160/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__17095089582642638140<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:1024/input[2]:7/input[3]:7/filter_count:160/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__17095089582642638140<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:1024/input[2]:7/input[3]:7/filter_count:160/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__17095089582642638140<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:1024/input[2]:7/input[3]:7/filter_count:160/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__12895836372525236342<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:1024/input[2]:7/input[3]:7/filter_count:352/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__12895836372525236342<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:1024/input[2]:7/input[3]:7/filter_count:352/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__12895836372525236342<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:1024/input[2]:7/input[3]:7/filter_count:352/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__12895836372525236342<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:1024/input[2]:7/input[3]:7/filter_count:352/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__12895836372525236342<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:1024/input[2]:7/input[3]:7/filter_count:352/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__12895836372525236342<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:1024/input[2]:7/input[3]:7/filter_count:352/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__12895836372525236342<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:1024/input[2]:7/input[3]:7/filter_count:352/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__12895836372525236342<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:1024/input[2]:7/input[3]:7/filter_count:352/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__12892009898921617258<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:320/input[2]:28/input[3]:28/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__12892009898921617258<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:320/input[2]:28/input[3]:28/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__12892009898921617258<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:320/input[2]:28/input[3]:28/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__12892009898921617258<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:320/input[2]:28/input[3]:28/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__12892009898921617258<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:320/input[2]:28/input[3]:28/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__12892009898921617258<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:320/input[2]:28/input[3]:28/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__12892009898921617258<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:320/input[2]:28/input[3]:28/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__12892009898921617258<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:320/input[2]:28/input[3]:28/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__15903661585554707393<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:256/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__15903661585554707393<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:256/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__15903661585554707393<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:256/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__15903661585554707393<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:256/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__15903661585554707393<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:256/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__15903661585554707393<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:256/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__15903661585554707393<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:256/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__15903661585554707393<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:256/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__779486747125413369<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:1024/input[2]:12/input[3]:12/filter_count:1024/filter_height:3/filter_width:3/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__779486747125413369<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:1024/input[2]:12/input[3]:12/filter_count:1024/filter_height:3/filter_width:3/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__779486747125413369<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:1024/input[2]:12/input[3]:12/filter_count:1024/filter_height:3/filter_width:3/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__779486747125413369<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:1024/input[2]:12/input[3]:12/filter_count:1024/filter_height:3/filter_width:3/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__779486747125413369<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:1024/input[2]:12/input[3]:12/filter_count:1024/filter_height:3/filter_width:3/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__779486747125413369<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:1024/input[2]:12/input[3]:12/filter_count:1024/filter_height:3/filter_width:3/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__779486747125413369<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:1024/input[2]:12/input[3]:12/filter_count:1024/filter_height:3/filter_width:3/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__779486747125413369<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:1024/input[2]:12/input[3]:12/filter_count:1024/filter_height:3/filter_width:3/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__118008862325183851<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:16/input[2]:208/input[3]:208/filter_count:32/filter_height:3/filter_width:3/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__118008862325183851<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:16/input[2]:208/input[3]:208/filter_count:32/filter_height:3/filter_width:3/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__118008862325183851<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:16/input[2]:208/input[3]:208/filter_count:32/filter_height:3/filter_width:3/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__118008862325183851<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:16/input[2]:208/input[3]:208/filter_count:32/filter_height:3/filter_width:3/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__118008862325183851<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:16/input[2]:208/input[3]:208/filter_count:32/filter_height:3/filter_width:3/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__118008862325183851<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:16/input[2]:208/input[3]:208/filter_count:32/filter_height:3/filter_width:3/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__118008862325183851<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:16/input[2]:208/input[3]:208/filter_count:32/filter_height:3/filter_width:3/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__118008862325183851<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:16/input[2]:208/input[3]:208/filter_count:32/filter_height:3/filter_width:3/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__1557930777712989815<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:320/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__1557930777712989815<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:320/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__1557930777712989815<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:320/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__1557930777712989815<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:320/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__1557930777712989815<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:320/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__1557930777712989815<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:320/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__1557930777712989815<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:320/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__1557930777712989815<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:320/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__7598220594316386367<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:256/input[2]:13/input[3]:13/filter_count:512/filter_height:3/filter_width:3/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__7598220594316386367<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:256/input[2]:13/input[3]:13/filter_count:512/filter_height:3/filter_width:3/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__7598220594316386367<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:256/input[2]:13/input[3]:13/filter_count:512/filter_height:3/filter_width:3/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__7598220594316386367<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:256/input[2]:13/input[3]:13/filter_count:512/filter_height:3/filter_width:3/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__7598220594316386367<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:256/input[2]:13/input[3]:13/filter_count:512/filter_height:3/filter_width:3/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__7598220594316386367<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:256/input[2]:13/input[3]:13/filter_count:512/filter_height:3/filter_width:3/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__7598220594316386367<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:256/input[2]:13/input[3]:13/filter_count:512/filter_height:3/filter_width:3/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__7598220594316386367<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:256/input[2]:13/input[3]:13/filter_count:512/filter_height:3/filter_width:3/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__17832252081713507686<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:2048/input[2]:100/input[3]:100/filter_count:304/filter_height:3/filter_width:3/pad_height:12/pad_width:12/stride_height:1/stride_width:1/dilation_height:12/dilation_width:12/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD failed to cudnnSetTensor4dDescriptor",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__17832252081713507686<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:2048/input[2]:100/input[3]:100/filter_count:304/filter_height:3/filter_width:3/pad_height:12/pad_width:12/stride_height:1/stride_width:1/dilation_height:12/dilation_width:12/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD failed to cudnnSetTensor4dDescriptor",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__17832252081713507686<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:2048/input[2]:100/input[3]:100/filter_count:304/filter_height:3/filter_width:3/pad_height:12/pad_width:12/stride_height:1/stride_width:1/dilation_height:12/dilation_width:12/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD failed to cudnnSetTensor4dDescriptor",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__17832252081713507686<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:2048/input[2]:100/input[3]:100/filter_count:304/filter_height:3/filter_width:3/pad_height:12/pad_width:12/stride_height:1/stride_width:1/dilation_height:12/dilation_width:12/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD failed to cudnnSetTensor4dDescriptor",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__17832252081713507686<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:2048/input[2]:100/input[3]:100/filter_count:304/filter_height:3/filter_width:3/pad_height:12/pad_width:12/stride_height:1/stride_width:1/dilation_height:12/dilation_width:12/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD failed to cudnnSetTensor4dDescriptor",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__17832252081713507686<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:2048/input[2]:100/input[3]:100/filter_count:304/filter_height:3/filter_width:3/pad_height:12/pad_width:12/stride_height:1/stride_width:1/dilation_height:12/dilation_width:12/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD failed to cudnnSetTensor4dDescriptor",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__17832252081713507686<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:2048/input[2]:100/input[3]:100/filter_count:304/filter_height:3/filter_width:3/pad_height:12/pad_width:12/stride_height:1/stride_width:1/dilation_height:12/dilation_width:12/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD failed to cudnnSetTensor4dDescriptor",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__17832252081713507686<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:2048/input[2]:100/input[3]:100/filter_count:304/filter_height:3/filter_width:3/pad_height:12/pad_width:12/stride_height:1/stride_width:1/dilation_height:12/dilation_width:12/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD failed to cudnnSetTensor4dDescriptor",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__12672377033579609031<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:192/input[2]:7/input[3]:7/filter_count:320/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__12672377033579609031<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:192/input[2]:7/input[3]:7/filter_count:320/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__12672377033579609031<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:192/input[2]:7/input[3]:7/filter_count:320/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__12672377033579609031<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:192/input[2]:7/input[3]:7/filter_count:320/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__12672377033579609031<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:192/input[2]:7/input[3]:7/filter_count:320/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__12672377033579609031<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:192/input[2]:7/input[3]:7/filter_count:320/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__12672377033579609031<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:192/input[2]:7/input[3]:7/filter_count:320/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__12672377033579609031<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:192/input[2]:7/input[3]:7/filter_count:320/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__9381287018770364271<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:256/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__9381287018770364271<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:256/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__9381287018770364271<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:256/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__9381287018770364271<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:256/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__9381287018770364271<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:256/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__9381287018770364271<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:256/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__9381287018770364271<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:256/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__9381287018770364271<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:256/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__11991109196061151671<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:128/input[2]:28/input[3]:28/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__11991109196061151671<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:128/input[2]:28/input[3]:28/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__11991109196061151671<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:128/input[2]:28/input[3]:28/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__11991109196061151671<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:128/input[2]:28/input[3]:28/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__11991109196061151671<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:128/input[2]:28/input[3]:28/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__11991109196061151671<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:128/input[2]:28/input[3]:28/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__11991109196061151671<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:128/input[2]:28/input[3]:28/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__11991109196061151671<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:128/input[2]:28/input[3]:28/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__5057046312658664989<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:128/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__5057046312658664989<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:128/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__5057046312658664989<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:128/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__5057046312658664989<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:128/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__5057046312658664989<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:128/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__5057046312658664989<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:128/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__5057046312658664989<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:128/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__5057046312658664989<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:128/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__7830552044787699101<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:256/input[2]:28/input[3]:28/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__7830552044787699101<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:256/input[2]:28/input[3]:28/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__7830552044787699101<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:256/input[2]:28/input[3]:28/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__7830552044787699101<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:256/input[2]:28/input[3]:28/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__7830552044787699101<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:256/input[2]:28/input[3]:28/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__7830552044787699101<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:256/input[2]:28/input[3]:28/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__7830552044787699101<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:256/input[2]:28/input[3]:28/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__7830552044787699101<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:256/input[2]:28/input[3]:28/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__9940872911106430581<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:128/input[2]:56/input[3]:56/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__9940872911106430581<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:128/input[2]:56/input[3]:56/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__9940872911106430581<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:128/input[2]:56/input[3]:56/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__9940872911106430581<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:128/input[2]:56/input[3]:56/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__9940872911106430581<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:128/input[2]:56/input[3]:56/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__9940872911106430581<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:128/input[2]:56/input[3]:56/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__9940872911106430581<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:128/input[2]:56/input[3]:56/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__9940872911106430581<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:128/input[2]:56/input[3]:56/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__12755988992407562640<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:256/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__12755988992407562640<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:256/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__12755988992407562640<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:256/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__12755988992407562640<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:256/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__12755988992407562640<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:256/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__12755988992407562640<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:256/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__12755988992407562640<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:256/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__12755988992407562640<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:256/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__10154899191652246071<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:256/input[2]:28/input[3]:28/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__10154899191652246071<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:256/input[2]:28/input[3]:28/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__10154899191652246071<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:256/input[2]:28/input[3]:28/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__10154899191652246071<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:256/input[2]:28/input[3]:28/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__10154899191652246071<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:256/input[2]:28/input[3]:28/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__10154899191652246071<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:256/input[2]:28/input[3]:28/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__10154899191652246071<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:256/input[2]:28/input[3]:28/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__10154899191652246071<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:256/input[2]:28/input[3]:28/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__327276140951920607<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:128/input[2]:27/input[3]:27/filter_count:32/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__327276140951920607<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:128/input[2]:27/input[3]:27/filter_count:32/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__327276140951920607<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:128/input[2]:27/input[3]:27/filter_count:32/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__327276140951920607<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:128/input[2]:27/input[3]:27/filter_count:32/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__327276140951920607<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:128/input[2]:27/input[3]:27/filter_count:32/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__327276140951920607<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:128/input[2]:27/input[3]:27/filter_count:32/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__327276140951920607<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:128/input[2]:27/input[3]:27/filter_count:32/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__327276140951920607<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:128/input[2]:27/input[3]:27/filter_count:32/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__8281372607104593341<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:1/input[1]:136/input[2]:28/input[3]:28/filter_count:136/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:136/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__8281372607104593341<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:1/input[1]:136/input[2]:28/input[3]:28/filter_count:136/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:136/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__8281372607104593341<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:1/input[1]:136/input[2]:28/input[3]:28/filter_count:136/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:136/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__8281372607104593341<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:1/input[1]:136/input[2]:28/input[3]:28/filter_count:136/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:136/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__8281372607104593341<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:1/input[1]:136/input[2]:28/input[3]:28/filter_count:136/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:136/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__8281372607104593341<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:1/input[1]:136/input[2]:28/input[3]:28/filter_count:136/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:136/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__8281372607104593341<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:1/input[1]:136/input[2]:28/input[3]:28/filter_count:136/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:136/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__8281372607104593341<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:1/input[1]:136/input[2]:28/input[3]:28/filter_count:136/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:136/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__17109011874869762936<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:1/input[1]:136/input[2]:28/input[3]:28/filter_count:136/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:4/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__17109011874869762936<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:1/input[1]:136/input[2]:28/input[3]:28/filter_count:136/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:4/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__17109011874869762936<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:1/input[1]:136/input[2]:28/input[3]:28/filter_count:136/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:4/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__17109011874869762936<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:1/input[1]:136/input[2]:28/input[3]:28/filter_count:136/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:4/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__17109011874869762936<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:1/input[1]:136/input[2]:28/input[3]:28/filter_count:136/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:4/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__17109011874869762936<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:1/input[1]:136/input[2]:28/input[3]:28/filter_count:136/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:4/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__17109011874869762936<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:1/input[1]:136/input[2]:28/input[3]:28/filter_count:136/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:4/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__17109011874869762936<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:1/input[1]:136/input[2]:28/input[3]:28/filter_count:136/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:4/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__15379894244763202309<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:48/input[2]:13/input[3]:13/filter_count:192/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__15379894244763202309<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:48/input[2]:13/input[3]:13/filter_count:192/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__15379894244763202309<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:48/input[2]:13/input[3]:13/filter_count:192/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__15379894244763202309<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:48/input[2]:13/input[3]:13/filter_count:192/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__15379894244763202309<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:48/input[2]:13/input[3]:13/filter_count:192/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__15379894244763202309<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:48/input[2]:13/input[3]:13/filter_count:192/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__15379894244763202309<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:48/input[2]:13/input[3]:13/filter_count:192/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__15379894244763202309<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:48/input[2]:13/input[3]:13/filter_count:192/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__8119511847073628280<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:1/input[1]:192/input[2]:27/input[3]:27/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__8119511847073628280<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:1/input[1]:192/input[2]:27/input[3]:27/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__8119511847073628280<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:1/input[1]:192/input[2]:27/input[3]:27/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__8119511847073628280<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:1/input[1]:192/input[2]:27/input[3]:27/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__8119511847073628280<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:1/input[1]:192/input[2]:27/input[3]:27/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__8119511847073628280<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:1/input[1]:192/input[2]:27/input[3]:27/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__8119511847073628280<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:1/input[1]:192/input[2]:27/input[3]:27/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__8119511847073628280<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:1/input[1]:192/input[2]:27/input[3]:27/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__3656752739290940149<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:256/input[2]:13/input[3]:13/filter_count:48/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__3656752739290940149<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:256/input[2]:13/input[3]:13/filter_count:48/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__3656752739290940149<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:256/input[2]:13/input[3]:13/filter_count:48/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__3656752739290940149<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:256/input[2]:13/input[3]:13/filter_count:48/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__3656752739290940149<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:256/input[2]:13/input[3]:13/filter_count:48/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__3656752739290940149<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:256/input[2]:13/input[3]:13/filter_count:48/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__3656752739290940149<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:256/input[2]:13/input[3]:13/filter_count:48/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__3656752739290940149<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:256/input[2]:13/input[3]:13/filter_count:48/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__15729146718882943763<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:1/input[1]:832/input[2]:6/input[3]:6/filter_count:48/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__15729146718882943763<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:1/input[1]:832/input[2]:6/input[3]:6/filter_count:48/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__15729146718882943763<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:1/input[1]:832/input[2]:6/input[3]:6/filter_count:48/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__15729146718882943763<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:1/input[1]:832/input[2]:6/input[3]:6/filter_count:48/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__15729146718882943763<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:1/input[1]:832/input[2]:6/input[3]:6/filter_count:48/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__15729146718882943763<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:1/input[1]:832/input[2]:6/input[3]:6/filter_count:48/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__15729146718882943763<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:1/input[1]:832/input[2]:6/input[3]:6/filter_count:48/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__15729146718882943763<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:1/input[1]:832/input[2]:6/input[3]:6/filter_count:48/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__17231680306118389791<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:512/input[2]:13/input[3]:13/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__17231680306118389791<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:512/input[2]:13/input[3]:13/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__17231680306118389791<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:512/input[2]:13/input[3]:13/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__17231680306118389791<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:512/input[2]:13/input[3]:13/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__17231680306118389791<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:512/input[2]:13/input[3]:13/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__17231680306118389791<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:512/input[2]:13/input[3]:13/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__17231680306118389791<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:512/input[2]:13/input[3]:13/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__17231680306118389791<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:512/input[2]:13/input[3]:13/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__18386369741520431449<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:384/input[2]:13/input[3]:13/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__18386369741520431449<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:384/input[2]:13/input[3]:13/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__18386369741520431449<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:384/input[2]:13/input[3]:13/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__18386369741520431449<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:384/input[2]:13/input[3]:13/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__18386369741520431449<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:384/input[2]:13/input[3]:13/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__18386369741520431449<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:384/input[2]:13/input[3]:13/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__18386369741520431449<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:384/input[2]:13/input[3]:13/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__18386369741520431449<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:384/input[2]:13/input[3]:13/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__15716251480759776399<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:1/input[1]:160/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__15716251480759776399<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:1/input[1]:160/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__15716251480759776399<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:1/input[1]:160/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__15716251480759776399<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:1/input[1]:160/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__15716251480759776399<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:1/input[1]:160/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__15716251480759776399<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:1/input[1]:160/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__15716251480759776399<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:1/input[1]:160/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__15716251480759776399<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:1/input[1]:160/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__6302548282292377773<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:1/input[1]:192/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__6302548282292377773<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:1/input[1]:192/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__6302548282292377773<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:1/input[1]:192/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__6302548282292377773<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:1/input[1]:192/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__6302548282292377773<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:1/input[1]:192/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__6302548282292377773<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:1/input[1]:192/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__6302548282292377773<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:1/input[1]:192/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__6302548282292377773<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:1/input[1]:192/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__9741782480126829334<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:1/input[1]:32/input[2]:27/input[3]:27/filter_count:96/filter_height:5/filter_width:5/pad_height:2/pad_width:2/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__9741782480126829334<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:1/input[1]:32/input[2]:27/input[3]:27/filter_count:96/filter_height:5/filter_width:5/pad_height:2/pad_width:2/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__9741782480126829334<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:1/input[1]:32/input[2]:27/input[3]:27/filter_count:96/filter_height:5/filter_width:5/pad_height:2/pad_width:2/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__9741782480126829334<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:1/input[1]:32/input[2]:27/input[3]:27/filter_count:96/filter_height:5/filter_width:5/pad_height:2/pad_width:2/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__9741782480126829334<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:1/input[1]:32/input[2]:27/input[3]:27/filter_count:96/filter_height:5/filter_width:5/pad_height:2/pad_width:2/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__9741782480126829334<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:1/input[1]:32/input[2]:27/input[3]:27/filter_count:96/filter_height:5/filter_width:5/pad_height:2/pad_width:2/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__9741782480126829334<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:1/input[1]:32/input[2]:27/input[3]:27/filter_count:96/filter_height:5/filter_width:5/pad_height:2/pad_width:2/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__9741782480126829334<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:1/input[1]:32/input[2]:27/input[3]:27/filter_count:96/filter_height:5/filter_width:5/pad_height:2/pad_width:2/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__5440919204575625281<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:1/input[1]:544/input[2]:7/input[3]:7/filter_count:544/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:544/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__5440919204575625281<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:1/input[1]:544/input[2]:7/input[3]:7/filter_count:544/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:544/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__5440919204575625281<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:1/input[1]:544/input[2]:7/input[3]:7/filter_count:544/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:544/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__5440919204575625281<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:1/input[1]:544/input[2]:7/input[3]:7/filter_count:544/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:544/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__5440919204575625281<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:1/input[1]:544/input[2]:7/input[3]:7/filter_count:544/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:544/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__5440919204575625281<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:1/input[1]:544/input[2]:7/input[3]:7/filter_count:544/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:544/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__5440919204575625281<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:1/input[1]:544/input[2]:7/input[3]:7/filter_count:544/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:544/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__5440919204575625281<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:1/input[1]:544/input[2]:7/input[3]:7/filter_count:544/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:544/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__3074163452045284337<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:24/input[2]:14/input[3]:14/filter_count:64/filter_height:5/filter_width:5/pad_height:2/pad_width:2/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__3074163452045284337<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:24/input[2]:14/input[3]:14/filter_count:64/filter_height:5/filter_width:5/pad_height:2/pad_width:2/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__3074163452045284337<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:24/input[2]:14/input[3]:14/filter_count:64/filter_height:5/filter_width:5/pad_height:2/pad_width:2/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__3074163452045284337<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:24/input[2]:14/input[3]:14/filter_count:64/filter_height:5/filter_width:5/pad_height:2/pad_width:2/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__3074163452045284337<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:24/input[2]:14/input[3]:14/filter_count:64/filter_height:5/filter_width:5/pad_height:2/pad_width:2/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__3074163452045284337<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:24/input[2]:14/input[3]:14/filter_count:64/filter_height:5/filter_width:5/pad_height:2/pad_width:2/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__3074163452045284337<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:24/input[2]:14/input[3]:14/filter_count:64/filter_height:5/filter_width:5/pad_height:2/pad_width:2/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__3074163452045284337<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:24/input[2]:14/input[3]:14/filter_count:64/filter_height:5/filter_width:5/pad_height:2/pad_width:2/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__4471115093569823447<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:1/input[1]:512/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__4471115093569823447<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:1/input[1]:512/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__4471115093569823447<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:1/input[1]:512/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__4471115093569823447<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:1/input[1]:512/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__4471115093569823447<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:1/input[1]:512/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__4471115093569823447<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:1/input[1]:512/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__4471115093569823447<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:1/input[1]:512/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__4471115093569823447<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:1/input[1]:512/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__114635572058497542<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:1/input[1]:576/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__114635572058497542<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:1/input[1]:576/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__114635572058497542<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:1/input[1]:576/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__114635572058497542<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:1/input[1]:576/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__114635572058497542<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:1/input[1]:576/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__114635572058497542<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:1/input[1]:576/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__114635572058497542<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:1/input[1]:576/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__114635572058497542<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:1/input[1]:576/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__11590516252436977981<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:1/input[1]:256/input[2]:27/input[3]:27/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__11590516252436977981<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:1/input[1]:256/input[2]:27/input[3]:27/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__11590516252436977981<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:1/input[1]:256/input[2]:27/input[3]:27/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__11590516252436977981<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:1/input[1]:256/input[2]:27/input[3]:27/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__11590516252436977981<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:1/input[1]:256/input[2]:27/input[3]:27/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__11590516252436977981<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:1/input[1]:256/input[2]:27/input[3]:27/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__11590516252436977981<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:1/input[1]:256/input[2]:27/input[3]:27/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__11590516252436977981<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:1/input[1]:256/input[2]:27/input[3]:27/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__17833081323610330459<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:512/input[2]:14/input[3]:14/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__17833081323610330459<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:512/input[2]:14/input[3]:14/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__17833081323610330459<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:512/input[2]:14/input[3]:14/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__17833081323610330459<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:512/input[2]:14/input[3]:14/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__17833081323610330459<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:512/input[2]:14/input[3]:14/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__17833081323610330459<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:512/input[2]:14/input[3]:14/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__17833081323610330459<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:512/input[2]:14/input[3]:14/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__17833081323610330459<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:512/input[2]:14/input[3]:14/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__11192228507655028147<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:1/input[1]:480/input[2]:13/input[3]:13/filter_count:96/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__11192228507655028147<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:1/input[1]:480/input[2]:13/input[3]:13/filter_count:96/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__11192228507655028147<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:1/input[1]:480/input[2]:13/input[3]:13/filter_count:96/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__11192228507655028147<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:1/input[1]:480/input[2]:13/input[3]:13/filter_count:96/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__11192228507655028147<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:1/input[1]:480/input[2]:13/input[3]:13/filter_count:96/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__11192228507655028147<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:1/input[1]:480/input[2]:13/input[3]:13/filter_count:96/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__11192228507655028147<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:1/input[1]:480/input[2]:13/input[3]:13/filter_count:96/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__11192228507655028147<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:1/input[1]:480/input[2]:13/input[3]:13/filter_count:96/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__11995602787379986918<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:32/input[2]:112/input[3]:112/filter_count:16/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__11995602787379986918<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:32/input[2]:112/input[3]:112/filter_count:16/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__11995602787379986918<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:32/input[2]:112/input[3]:112/filter_count:16/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__11995602787379986918<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:32/input[2]:112/input[3]:112/filter_count:16/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__11995602787379986918<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:32/input[2]:112/input[3]:112/filter_count:16/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__11995602787379986918<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:32/input[2]:112/input[3]:112/filter_count:16/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__11995602787379986918<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:32/input[2]:112/input[3]:112/filter_count:16/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__11995602787379986918<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:32/input[2]:112/input[3]:112/filter_count:16/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__15001495479754903251<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:384/input[2]:12/input[3]:12/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:2/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__15001495479754903251<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:384/input[2]:12/input[3]:12/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:2/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__15001495479754903251<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:384/input[2]:12/input[3]:12/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:2/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__15001495479754903251<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:384/input[2]:12/input[3]:12/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:2/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__15001495479754903251<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:384/input[2]:12/input[3]:12/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:2/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__15001495479754903251<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:384/input[2]:12/input[3]:12/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:2/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__15001495479754903251<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:384/input[2]:12/input[3]:12/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:2/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__15001495479754903251<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:384/input[2]:12/input[3]:12/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:2/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__2929806377115036078<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:1/input[1]:480/input[2]:13/input[3]:13/filter_count:16/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__2929806377115036078<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:1/input[1]:480/input[2]:13/input[3]:13/filter_count:16/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__2929806377115036078<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:1/input[1]:480/input[2]:13/input[3]:13/filter_count:16/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__2929806377115036078<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:1/input[1]:480/input[2]:13/input[3]:13/filter_count:16/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__2929806377115036078<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:1/input[1]:480/input[2]:13/input[3]:13/filter_count:16/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__2929806377115036078<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:1/input[1]:480/input[2]:13/input[3]:13/filter_count:16/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__2929806377115036078<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:1/input[1]:480/input[2]:13/input[3]:13/filter_count:16/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__2929806377115036078<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:1/input[1]:480/input[2]:13/input[3]:13/filter_count:16/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__3174631807111741116<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:96/input[2]:56/input[3]:56/filter_count:24/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__3174631807111741116<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:96/input[2]:56/input[3]:56/filter_count:24/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__3174631807111741116<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:96/input[2]:56/input[3]:56/filter_count:24/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__3174631807111741116<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:96/input[2]:56/input[3]:56/filter_count:24/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__3174631807111741116<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:96/input[2]:56/input[3]:56/filter_count:24/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__3174631807111741116<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:96/input[2]:56/input[3]:56/filter_count:24/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__3174631807111741116<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:96/input[2]:56/input[3]:56/filter_count:24/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__3174631807111741116<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:96/input[2]:56/input[3]:56/filter_count:24/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__7809290002932028022<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:1/input[1]:832/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__7809290002932028022<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:1/input[1]:832/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__7809290002932028022<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:1/input[1]:832/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__7809290002932028022<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:1/input[1]:832/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__7809290002932028022<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:1/input[1]:832/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__7809290002932028022<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:1/input[1]:832/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__7809290002932028022<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:1/input[1]:832/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__7809290002932028022<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:1/input[1]:832/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__7466239390065346357<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:1/input[1]:416/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__7466239390065346357<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:1/input[1]:416/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__7466239390065346357<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:1/input[1]:416/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__7466239390065346357<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:1/input[1]:416/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__7466239390065346357<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:1/input[1]:416/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__7466239390065346357<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:1/input[1]:416/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__7466239390065346357<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:1/input[1]:416/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__7466239390065346357<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:1/input[1]:416/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__4181094022726787882<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:528/input[2]:14/input[3]:14/filter_count:32/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__4181094022726787882<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:528/input[2]:14/input[3]:14/filter_count:32/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__4181094022726787882<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:528/input[2]:14/input[3]:14/filter_count:32/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__4181094022726787882<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:528/input[2]:14/input[3]:14/filter_count:32/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__4181094022726787882<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:528/input[2]:14/input[3]:14/filter_count:32/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__4181094022726787882<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:528/input[2]:14/input[3]:14/filter_count:32/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__4181094022726787882<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:528/input[2]:14/input[3]:14/filter_count:32/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__4181094022726787882<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:528/input[2]:14/input[3]:14/filter_count:32/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__15517853207744983808<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:1/input[1]:736/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__15517853207744983808<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:1/input[1]:736/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__15517853207744983808<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:1/input[1]:736/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__15517853207744983808<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:1/input[1]:736/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__15517853207744983808<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:1/input[1]:736/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__15517853207744983808<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:1/input[1]:736/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__15517853207744983808<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:1/input[1]:736/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__15517853207744983808<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:1/input[1]:736/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__4014735847207117486<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:24/input[2]:56/input[3]:56/filter_count:144/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__4014735847207117486<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:24/input[2]:56/input[3]:56/filter_count:144/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__4014735847207117486<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:24/input[2]:56/input[3]:56/filter_count:144/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__4014735847207117486<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:24/input[2]:56/input[3]:56/filter_count:144/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__4014735847207117486<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:24/input[2]:56/input[3]:56/filter_count:144/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__4014735847207117486<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:24/input[2]:56/input[3]:56/filter_count:144/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__4014735847207117486<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:24/input[2]:56/input[3]:56/filter_count:144/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__4014735847207117486<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:24/input[2]:56/input[3]:56/filter_count:144/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__14381471328508771823<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:32/input[2]:14/input[3]:14/filter_count:128/filter_height:5/filter_width:5/pad_height:2/pad_width:2/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__14381471328508771823<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:32/input[2]:14/input[3]:14/filter_count:128/filter_height:5/filter_width:5/pad_height:2/pad_width:2/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__14381471328508771823<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:32/input[2]:14/input[3]:14/filter_count:128/filter_height:5/filter_width:5/pad_height:2/pad_width:2/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__14381471328508771823<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:32/input[2]:14/input[3]:14/filter_count:128/filter_height:5/filter_width:5/pad_height:2/pad_width:2/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__14381471328508771823<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:32/input[2]:14/input[3]:14/filter_count:128/filter_height:5/filter_width:5/pad_height:2/pad_width:2/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__14381471328508771823<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:32/input[2]:14/input[3]:14/filter_count:128/filter_height:5/filter_width:5/pad_height:2/pad_width:2/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__14381471328508771823<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:32/input[2]:14/input[3]:14/filter_count:128/filter_height:5/filter_width:5/pad_height:2/pad_width:2/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__14381471328508771823<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:32/input[2]:14/input[3]:14/filter_count:128/filter_height:5/filter_width:5/pad_height:2/pad_width:2/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__16425765489206416313<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:832/input[2]:7/input[3]:7/filter_count:160/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__16425765489206416313<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:832/input[2]:7/input[3]:7/filter_count:160/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__16425765489206416313<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:832/input[2]:7/input[3]:7/filter_count:160/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__16425765489206416313<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:832/input[2]:7/input[3]:7/filter_count:160/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__16425765489206416313<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:832/input[2]:7/input[3]:7/filter_count:160/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__16425765489206416313<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:832/input[2]:7/input[3]:7/filter_count:160/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__16425765489206416313<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:832/input[2]:7/input[3]:7/filter_count:160/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__16425765489206416313<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:832/input[2]:7/input[3]:7/filter_count:160/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__7054182596056114367<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:32/input[2]:28/input[3]:28/filter_count:192/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__7054182596056114367<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:32/input[2]:28/input[3]:28/filter_count:192/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__7054182596056114367<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:32/input[2]:28/input[3]:28/filter_count:192/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__7054182596056114367<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:32/input[2]:28/input[3]:28/filter_count:192/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__7054182596056114367<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:32/input[2]:28/input[3]:28/filter_count:192/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__7054182596056114367<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:32/input[2]:28/input[3]:28/filter_count:192/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__7054182596056114367<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:32/input[2]:28/input[3]:28/filter_count:192/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__7054182596056114367<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:32/input[2]:28/input[3]:28/filter_count:192/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__1928653545434803107<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:1/input[1]:864/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__1928653545434803107<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:1/input[1]:864/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__1928653545434803107<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:1/input[1]:864/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__1928653545434803107<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:1/input[1]:864/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__1928653545434803107<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:1/input[1]:864/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__1928653545434803107<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:1/input[1]:864/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__1928653545434803107<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:1/input[1]:864/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__1928653545434803107<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:1/input[1]:864/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__13843182093923952381<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:144/input[2]:28/input[3]:28/filter_count:32/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__13843182093923952381<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:144/input[2]:28/input[3]:28/filter_count:32/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__13843182093923952381<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:144/input[2]:28/input[3]:28/filter_count:32/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__13843182093923952381<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:144/input[2]:28/input[3]:28/filter_count:32/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__13843182093923952381<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:144/input[2]:28/input[3]:28/filter_count:32/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__13843182093923952381<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:144/input[2]:28/input[3]:28/filter_count:32/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__13843182093923952381<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:144/input[2]:28/input[3]:28/filter_count:32/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__13843182093923952381<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:144/input[2]:28/input[3]:28/filter_count:32/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__4227617969350582405<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:192/input[2]:28/input[3]:28/filter_count:192/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:192/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__4227617969350582405<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:192/input[2]:28/input[3]:28/filter_count:192/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:192/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__4227617969350582405<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:192/input[2]:28/input[3]:28/filter_count:192/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:192/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__4227617969350582405<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:192/input[2]:28/input[3]:28/filter_count:192/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:192/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__4227617969350582405<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:192/input[2]:28/input[3]:28/filter_count:192/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:192/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__4227617969350582405<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:192/input[2]:28/input[3]:28/filter_count:192/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:192/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__4227617969350582405<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:192/input[2]:28/input[3]:28/filter_count:192/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:192/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__4227617969350582405<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:192/input[2]:28/input[3]:28/filter_count:192/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:192/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__3538666090942584914<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:576/input[2]:14/input[3]:14/filter_count:576/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:576/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__3538666090942584914<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:576/input[2]:14/input[3]:14/filter_count:576/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:576/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__3538666090942584914<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:576/input[2]:14/input[3]:14/filter_count:576/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:576/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__3538666090942584914<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:576/input[2]:14/input[3]:14/filter_count:576/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:576/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__3538666090942584914<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:576/input[2]:14/input[3]:14/filter_count:576/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:576/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__3538666090942584914<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:576/input[2]:14/input[3]:14/filter_count:576/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:576/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__3538666090942584914<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:576/input[2]:14/input[3]:14/filter_count:576/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:576/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__3538666090942584914<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:576/input[2]:14/input[3]:14/filter_count:576/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:576/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__15270365293401413008<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:1/input[1]:896/input[2]:7/input[3]:7/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__15270365293401413008<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:1/input[1]:896/input[2]:7/input[3]:7/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__15270365293401413008<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:1/input[1]:896/input[2]:7/input[3]:7/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__15270365293401413008<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:1/input[1]:896/input[2]:7/input[3]:7/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__15270365293401413008<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:1/input[1]:896/input[2]:7/input[3]:7/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__15270365293401413008<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:1/input[1]:896/input[2]:7/input[3]:7/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__15270365293401413008<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:1/input[1]:896/input[2]:7/input[3]:7/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__15270365293401413008<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:1/input[1]:896/input[2]:7/input[3]:7/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__14432469205306730518<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:576/input[2]:14/input[3]:14/filter_count:576/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:576/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__14432469205306730518<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:576/input[2]:14/input[3]:14/filter_count:576/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:576/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__14432469205306730518<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:576/input[2]:14/input[3]:14/filter_count:576/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:576/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__14432469205306730518<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:576/input[2]:14/input[3]:14/filter_count:576/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:576/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__14432469205306730518<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:576/input[2]:14/input[3]:14/filter_count:576/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:576/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__14432469205306730518<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:576/input[2]:14/input[3]:14/filter_count:576/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:576/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__14432469205306730518<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:576/input[2]:14/input[3]:14/filter_count:576/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:576/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__14432469205306730518<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:576/input[2]:14/input[3]:14/filter_count:576/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:576/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__3430837407541565976<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:1/input[2]:64/input[3]:64/filter_count:64/filter_height:3/filter_width:3/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__3430837407541565976<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:1/input[2]:64/input[3]:64/filter_count:64/filter_height:3/filter_width:3/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__3430837407541565976<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:1/input[2]:64/input[3]:64/filter_count:64/filter_height:3/filter_width:3/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__3430837407541565976<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:1/input[2]:64/input[3]:64/filter_count:64/filter_height:3/filter_width:3/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__3430837407541565976<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:1/input[2]:64/input[3]:64/filter_count:64/filter_height:3/filter_width:3/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__3430837407541565976<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:1/input[2]:64/input[3]:64/filter_count:64/filter_height:3/filter_width:3/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__3430837407541565976<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:1/input[2]:64/input[3]:64/filter_count:64/filter_height:3/filter_width:3/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__3430837407541565976<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:1/input[2]:64/input[3]:64/filter_count:64/filter_height:3/filter_width:3/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__230646304257146060<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:96/input[2]:28/input[3]:28/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__230646304257146060<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:96/input[2]:28/input[3]:28/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__230646304257146060<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:96/input[2]:28/input[3]:28/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__230646304257146060<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:96/input[2]:28/input[3]:28/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__230646304257146060<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:96/input[2]:28/input[3]:28/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__230646304257146060<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:96/input[2]:28/input[3]:28/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__230646304257146060<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:96/input[2]:28/input[3]:28/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__230646304257146060<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:96/input[2]:28/input[3]:28/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__2281153969545101356<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:1/input[1]:1024/input[2]:1/input[3]:1/filter_count:1000/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__2281153969545101356<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:1/input[1]:1024/input[2]:1/input[3]:1/filter_count:1000/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__2281153969545101356<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:1/input[1]:1024/input[2]:1/input[3]:1/filter_count:1000/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__2281153969545101356<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:1/input[1]:1024/input[2]:1/input[3]:1/filter_count:1000/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__2281153969545101356<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:1/input[1]:1024/input[2]:1/input[3]:1/filter_count:1000/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__2281153969545101356<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:1/input[1]:1024/input[2]:1/input[3]:1/filter_count:1000/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__2281153969545101356<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:1/input[1]:1024/input[2]:1/input[3]:1/filter_count:1000/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__2281153969545101356<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:1/input[1]:1024/input[2]:1/input[3]:1/filter_count:1000/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__12401635154024824820<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:128/input[2]:16/input[3]:16/filter_count:256/filter_height:3/filter_width:3/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__12401635154024824820<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:128/input[2]:16/input[3]:16/filter_count:256/filter_height:3/filter_width:3/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__12401635154024824820<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:128/input[2]:16/input[3]:16/filter_count:256/filter_height:3/filter_width:3/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__12401635154024824820<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:128/input[2]:16/input[3]:16/filter_count:256/filter_height:3/filter_width:3/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__12401635154024824820<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:128/input[2]:16/input[3]:16/filter_count:256/filter_height:3/filter_width:3/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__12401635154024824820<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:128/input[2]:16/input[3]:16/filter_count:256/filter_height:3/filter_width:3/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__12401635154024824820<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:128/input[2]:16/input[3]:16/filter_count:256/filter_height:3/filter_width:3/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__12401635154024824820<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:128/input[2]:16/input[3]:16/filter_count:256/filter_height:3/filter_width:3/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__12812158252801400378<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:1/input[1]:32/input[2]:13/input[3]:13/filter_count:128/filter_height:5/filter_width:5/pad_height:2/pad_width:2/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__12812158252801400378<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:1/input[1]:32/input[2]:13/input[3]:13/filter_count:128/filter_height:5/filter_width:5/pad_height:2/pad_width:2/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__12812158252801400378<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:1/input[1]:32/input[2]:13/input[3]:13/filter_count:128/filter_height:5/filter_width:5/pad_height:2/pad_width:2/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__12812158252801400378<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:1/input[1]:32/input[2]:13/input[3]:13/filter_count:128/filter_height:5/filter_width:5/pad_height:2/pad_width:2/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__12812158252801400378<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:1/input[1]:32/input[2]:13/input[3]:13/filter_count:128/filter_height:5/filter_width:5/pad_height:2/pad_width:2/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__12812158252801400378<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:1/input[1]:32/input[2]:13/input[3]:13/filter_count:128/filter_height:5/filter_width:5/pad_height:2/pad_width:2/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__12812158252801400378<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:1/input[1]:32/input[2]:13/input[3]:13/filter_count:128/filter_height:5/filter_width:5/pad_height:2/pad_width:2/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__12812158252801400378<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:1/input[1]:32/input[2]:13/input[3]:13/filter_count:128/filter_height:5/filter_width:5/pad_height:2/pad_width:2/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__8849673836353494804<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:256/input[2]:16/input[3]:16/filter_count:256/filter_height:3/filter_width:3/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__8849673836353494804<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:256/input[2]:16/input[3]:16/filter_count:256/filter_height:3/filter_width:3/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__8849673836353494804<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:256/input[2]:16/input[3]:16/filter_count:256/filter_height:3/filter_width:3/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__8849673836353494804<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:256/input[2]:16/input[3]:16/filter_count:256/filter_height:3/filter_width:3/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__8849673836353494804<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:256/input[2]:16/input[3]:16/filter_count:256/filter_height:3/filter_width:3/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__8849673836353494804<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:256/input[2]:16/input[3]:16/filter_count:256/filter_height:3/filter_width:3/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__8849673836353494804<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:256/input[2]:16/input[3]:16/filter_count:256/filter_height:3/filter_width:3/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__8849673836353494804<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:256/input[2]:16/input[3]:16/filter_count:256/filter_height:3/filter_width:3/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__5283300838216404682<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:128/input[2]:14/input[3]:14/filter_count:160/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__5283300838216404682<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:128/input[2]:14/input[3]:14/filter_count:160/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__5283300838216404682<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:128/input[2]:14/input[3]:14/filter_count:160/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__5283300838216404682<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:128/input[2]:14/input[3]:14/filter_count:160/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__5283300838216404682<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:128/input[2]:14/input[3]:14/filter_count:160/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__5283300838216404682<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:128/input[2]:14/input[3]:14/filter_count:160/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__5283300838216404682<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:128/input[2]:14/input[3]:14/filter_count:160/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__5283300838216404682<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:128/input[2]:14/input[3]:14/filter_count:160/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__8549384043421900094<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:1/input[1]:528/input[2]:13/input[3]:13/filter_count:160/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__8549384043421900094<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:1/input[1]:528/input[2]:13/input[3]:13/filter_count:160/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__8549384043421900094<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:1/input[1]:528/input[2]:13/input[3]:13/filter_count:160/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__8549384043421900094<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:1/input[1]:528/input[2]:13/input[3]:13/filter_count:160/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__8549384043421900094<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:1/input[1]:528/input[2]:13/input[3]:13/filter_count:160/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__8549384043421900094<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:1/input[1]:528/input[2]:13/input[3]:13/filter_count:160/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__8549384043421900094<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:1/input[1]:528/input[2]:13/input[3]:13/filter_count:160/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__8549384043421900094<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:1/input[1]:528/input[2]:13/input[3]:13/filter_count:160/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__16789593852747237241<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:256/input[2]:28/input[3]:28/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__16789593852747237241<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:256/input[2]:28/input[3]:28/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__16789593852747237241<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:256/input[2]:28/input[3]:28/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__16789593852747237241<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:256/input[2]:28/input[3]:28/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__16789593852747237241<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:256/input[2]:28/input[3]:28/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__16789593852747237241<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:256/input[2]:28/input[3]:28/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__16789593852747237241<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:256/input[2]:28/input[3]:28/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__16789593852747237241<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:256/input[2]:28/input[3]:28/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__12214396263859311657<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:1/input[1]:832/input[2]:6/input[3]:6/filter_count:32/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__12214396263859311657<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:1/input[1]:832/input[2]:6/input[3]:6/filter_count:32/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__12214396263859311657<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:1/input[1]:832/input[2]:6/input[3]:6/filter_count:32/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__12214396263859311657<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:1/input[1]:832/input[2]:6/input[3]:6/filter_count:32/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__12214396263859311657<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:1/input[1]:832/input[2]:6/input[3]:6/filter_count:32/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__12214396263859311657<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:1/input[1]:832/input[2]:6/input[3]:6/filter_count:32/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__12214396263859311657<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:1/input[1]:832/input[2]:6/input[3]:6/filter_count:32/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__12214396263859311657<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:1/input[1]:832/input[2]:6/input[3]:6/filter_count:32/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__13579049267917411946<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:512/input[2]:100/input[3]:100/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__13579049267917411946<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:512/input[2]:100/input[3]:100/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__13579049267917411946<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:512/input[2]:100/input[3]:100/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__13579049267917411946<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:512/input[2]:100/input[3]:100/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__13579049267917411946<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:512/input[2]:100/input[3]:100/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__13579049267917411946<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:512/input[2]:100/input[3]:100/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__13579049267917411946<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:512/input[2]:100/input[3]:100/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__13579049267917411946<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:512/input[2]:100/input[3]:100/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__6162321340479005012<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:256/input[2]:100/input[3]:100/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__6162321340479005012<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:256/input[2]:100/input[3]:100/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__6162321340479005012<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:256/input[2]:100/input[3]:100/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__6162321340479005012<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:256/input[2]:100/input[3]:100/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__6162321340479005012<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:256/input[2]:100/input[3]:100/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__6162321340479005012<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:256/input[2]:100/input[3]:100/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__6162321340479005012<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:256/input[2]:100/input[3]:100/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__6162321340479005012<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:256/input[2]:100/input[3]:100/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__14582320161453482827<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:576/input[2]:14/input[3]:14/filter_count:96/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__14582320161453482827<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:576/input[2]:14/input[3]:14/filter_count:96/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__14582320161453482827<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:576/input[2]:14/input[3]:14/filter_count:96/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__14582320161453482827<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:576/input[2]:14/input[3]:14/filter_count:96/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__14582320161453482827<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:576/input[2]:14/input[3]:14/filter_count:96/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__14582320161453482827<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:576/input[2]:14/input[3]:14/filter_count:96/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__14582320161453482827<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:576/input[2]:14/input[3]:14/filter_count:96/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__14582320161453482827<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:576/input[2]:14/input[3]:14/filter_count:96/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__4907009221597460180<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:512/input[2]:100/input[3]:100/filter_count:512/filter_height:3/filter_width:3/pad_height:5/pad_width:5/stride_height:1/stride_width:1/dilation_height:5/dilation_width:5/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__4907009221597460180<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:512/input[2]:100/input[3]:100/filter_count:512/filter_height:3/filter_width:3/pad_height:5/pad_width:5/stride_height:1/stride_width:1/dilation_height:5/dilation_width:5/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__4907009221597460180<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:512/input[2]:100/input[3]:100/filter_count:512/filter_height:3/filter_width:3/pad_height:5/pad_width:5/stride_height:1/stride_width:1/dilation_height:5/dilation_width:5/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__4907009221597460180<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:512/input[2]:100/input[3]:100/filter_count:512/filter_height:3/filter_width:3/pad_height:5/pad_width:5/stride_height:1/stride_width:1/dilation_height:5/dilation_width:5/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__4907009221597460180<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:512/input[2]:100/input[3]:100/filter_count:512/filter_height:3/filter_width:3/pad_height:5/pad_width:5/stride_height:1/stride_width:1/dilation_height:5/dilation_width:5/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__4907009221597460180<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:512/input[2]:100/input[3]:100/filter_count:512/filter_height:3/filter_width:3/pad_height:5/pad_width:5/stride_height:1/stride_width:1/dilation_height:5/dilation_width:5/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__4907009221597460180<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:512/input[2]:100/input[3]:100/filter_count:512/filter_height:3/filter_width:3/pad_height:5/pad_width:5/stride_height:1/stride_width:1/dilation_height:5/dilation_width:5/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__4907009221597460180<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:512/input[2]:100/input[3]:100/filter_count:512/filter_height:3/filter_width:3/pad_height:5/pad_width:5/stride_height:1/stride_width:1/dilation_height:5/dilation_width:5/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__14175138174942404156<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:256/input[2]:8/input[3]:8/filter_count:256/filter_height:3/filter_width:3/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__14175138174942404156<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:256/input[2]:8/input[3]:8/filter_count:256/filter_height:3/filter_width:3/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__14175138174942404156<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:256/input[2]:8/input[3]:8/filter_count:256/filter_height:3/filter_width:3/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__14175138174942404156<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:256/input[2]:8/input[3]:8/filter_count:256/filter_height:3/filter_width:3/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__14175138174942404156<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:256/input[2]:8/input[3]:8/filter_count:256/filter_height:3/filter_width:3/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__14175138174942404156<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:256/input[2]:8/input[3]:8/filter_count:256/filter_height:3/filter_width:3/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__14175138174942404156<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:256/input[2]:8/input[3]:8/filter_count:256/filter_height:3/filter_width:3/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__14175138174942404156<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:256/input[2]:8/input[3]:8/filter_count:256/filter_height:3/filter_width:3/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__16961530857230821012<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:512/input[2]:100/input[3]:100/filter_count:512/filter_height:3/filter_width:3/pad_height:17/pad_width:17/stride_height:1/stride_width:1/dilation_height:17/dilation_width:17/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__16961530857230821012<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:512/input[2]:100/input[3]:100/filter_count:512/filter_height:3/filter_width:3/pad_height:17/pad_width:17/stride_height:1/stride_width:1/dilation_height:17/dilation_width:17/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__16961530857230821012<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:512/input[2]:100/input[3]:100/filter_count:512/filter_height:3/filter_width:3/pad_height:17/pad_width:17/stride_height:1/stride_width:1/dilation_height:17/dilation_width:17/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__16961530857230821012<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:512/input[2]:100/input[3]:100/filter_count:512/filter_height:3/filter_width:3/pad_height:17/pad_width:17/stride_height:1/stride_width:1/dilation_height:17/dilation_width:17/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__16961530857230821012<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:512/input[2]:100/input[3]:100/filter_count:512/filter_height:3/filter_width:3/pad_height:17/pad_width:17/stride_height:1/stride_width:1/dilation_height:17/dilation_width:17/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__16961530857230821012<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:512/input[2]:100/input[3]:100/filter_count:512/filter_height:3/filter_width:3/pad_height:17/pad_width:17/stride_height:1/stride_width:1/dilation_height:17/dilation_width:17/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__16961530857230821012<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:512/input[2]:100/input[3]:100/filter_count:512/filter_height:3/filter_width:3/pad_height:17/pad_width:17/stride_height:1/stride_width:1/dilation_height:17/dilation_width:17/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__16961530857230821012<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:512/input[2]:100/input[3]:100/filter_count:512/filter_height:3/filter_width:3/pad_height:17/pad_width:17/stride_height:1/stride_width:1/dilation_height:17/dilation_width:17/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__13529055723686234354<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:128/input[2]:28/input[3]:28/filter_count:160/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__13529055723686234354<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:128/input[2]:28/input[3]:28/filter_count:160/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__13529055723686234354<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:128/input[2]:28/input[3]:28/filter_count:160/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__13529055723686234354<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:128/input[2]:28/input[3]:28/filter_count:160/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__13529055723686234354<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:128/input[2]:28/input[3]:28/filter_count:160/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__13529055723686234354<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:128/input[2]:28/input[3]:28/filter_count:160/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__13529055723686234354<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:128/input[2]:28/input[3]:28/filter_count:160/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__13529055723686234354<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:128/input[2]:28/input[3]:28/filter_count:160/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__4867954812249902477<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:64/input[2]:52/input[3]:52/filter_count:128/filter_height:3/filter_width:3/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__4867954812249902477<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:64/input[2]:52/input[3]:52/filter_count:128/filter_height:3/filter_width:3/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__4867954812249902477<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:64/input[2]:52/input[3]:52/filter_count:128/filter_height:3/filter_width:3/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__4867954812249902477<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:64/input[2]:52/input[3]:52/filter_count:128/filter_height:3/filter_width:3/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__4867954812249902477<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:64/input[2]:52/input[3]:52/filter_count:128/filter_height:3/filter_width:3/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__4867954812249902477<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:64/input[2]:52/input[3]:52/filter_count:128/filter_height:3/filter_width:3/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__4867954812249902477<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:64/input[2]:52/input[3]:52/filter_count:128/filter_height:3/filter_width:3/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__4867954812249902477<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:64/input[2]:52/input[3]:52/filter_count:128/filter_height:3/filter_width:3/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__17058904980315095466<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:256/input[2]:14/input[3]:14/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__17058904980315095466<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:256/input[2]:14/input[3]:14/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__17058904980315095466<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:256/input[2]:14/input[3]:14/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__17058904980315095466<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:256/input[2]:14/input[3]:14/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__17058904980315095466<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:256/input[2]:14/input[3]:14/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__17058904980315095466<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:256/input[2]:14/input[3]:14/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__17058904980315095466<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:256/input[2]:14/input[3]:14/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__17058904980315095466<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:256/input[2]:14/input[3]:14/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__2928005750715271384<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:128/input[2]:28/input[3]:28/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__2928005750715271384<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:128/input[2]:28/input[3]:28/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__2928005750715271384<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:128/input[2]:28/input[3]:28/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__2928005750715271384<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:128/input[2]:28/input[3]:28/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__2928005750715271384<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:128/input[2]:28/input[3]:28/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__2928005750715271384<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:128/input[2]:28/input[3]:28/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__2928005750715271384<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:128/input[2]:28/input[3]:28/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__2928005750715271384<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:128/input[2]:28/input[3]:28/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__11367813071859073765<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:64/input[2]:13/input[3]:13/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__11367813071859073765<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:64/input[2]:13/input[3]:13/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__11367813071859073765<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:64/input[2]:13/input[3]:13/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__11367813071859073765<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:64/input[2]:13/input[3]:13/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__11367813071859073765<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:64/input[2]:13/input[3]:13/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__11367813071859073765<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:64/input[2]:13/input[3]:13/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__11367813071859073765<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:64/input[2]:13/input[3]:13/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__11367813071859073765<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:64/input[2]:13/input[3]:13/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__14588263526202482829<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:1/input[1]:512/input[2]:13/input[3]:13/filter_count:144/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__14588263526202482829<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:1/input[1]:512/input[2]:13/input[3]:13/filter_count:144/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__14588263526202482829<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:1/input[1]:512/input[2]:13/input[3]:13/filter_count:144/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__14588263526202482829<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:1/input[1]:512/input[2]:13/input[3]:13/filter_count:144/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__14588263526202482829<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:1/input[1]:512/input[2]:13/input[3]:13/filter_count:144/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__14588263526202482829<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:1/input[1]:512/input[2]:13/input[3]:13/filter_count:144/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__14588263526202482829<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:1/input[1]:512/input[2]:13/input[3]:13/filter_count:144/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__14588263526202482829<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:1/input[1]:512/input[2]:13/input[3]:13/filter_count:144/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__6298249107325714156<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:128/input[2]:56/input[3]:56/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__6298249107325714156<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:128/input[2]:56/input[3]:56/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__6298249107325714156<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:128/input[2]:56/input[3]:56/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__6298249107325714156<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:128/input[2]:56/input[3]:56/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__6298249107325714156<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:128/input[2]:56/input[3]:56/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__6298249107325714156<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:128/input[2]:56/input[3]:56/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__6298249107325714156<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:128/input[2]:56/input[3]:56/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__6298249107325714156<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:128/input[2]:56/input[3]:56/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__9562225249255800104<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__9562225249255800104<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__9562225249255800104<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__9562225249255800104<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__9562225249255800104<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__9562225249255800104<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__9562225249255800104<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__9562225249255800104<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__14385595200097480636<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:512/input[2]:7/input[3]:7/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__14385595200097480636<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:512/input[2]:7/input[3]:7/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__14385595200097480636<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:512/input[2]:7/input[3]:7/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__14385595200097480636<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:512/input[2]:7/input[3]:7/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__14385595200097480636<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:512/input[2]:7/input[3]:7/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__14385595200097480636<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:512/input[2]:7/input[3]:7/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__14385595200097480636<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:512/input[2]:7/input[3]:7/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__14385595200097480636<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:512/input[2]:7/input[3]:7/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__17943835395491718644<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:512/input[2]:14/input[3]:14/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__17943835395491718644<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:512/input[2]:14/input[3]:14/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__17943835395491718644<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:512/input[2]:14/input[3]:14/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__17943835395491718644<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:512/input[2]:14/input[3]:14/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__17943835395491718644<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:512/input[2]:14/input[3]:14/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__17943835395491718644<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:512/input[2]:14/input[3]:14/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__17943835395491718644<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:512/input[2]:14/input[3]:14/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__17943835395491718644<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:512/input[2]:14/input[3]:14/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__9070928575328259436<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__9070928575328259436<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__9070928575328259436<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__9070928575328259436<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__9070928575328259436<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__9070928575328259436<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__9070928575328259436<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__9070928575328259436<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__2872861084407136926<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:2048/input[2]:7/input[3]:7/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__2872861084407136926<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:2048/input[2]:7/input[3]:7/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__2872861084407136926<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:2048/input[2]:7/input[3]:7/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__2872861084407136926<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:2048/input[2]:7/input[3]:7/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__2872861084407136926<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:2048/input[2]:7/input[3]:7/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__2872861084407136926<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:2048/input[2]:7/input[3]:7/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__2872861084407136926<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:2048/input[2]:7/input[3]:7/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__2872861084407136926<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:2048/input[2]:7/input[3]:7/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__6263338175559636724<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__6263338175559636724<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__6263338175559636724<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__6263338175559636724<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__6263338175559636724<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__6263338175559636724<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__6263338175559636724<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__6263338175559636724<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__14640196378248879381<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__14640196378248879381<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__14640196378248879381<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__14640196378248879381<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__14640196378248879381<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__14640196378248879381<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__14640196378248879381<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__14640196378248879381<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__10351068418695972412<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:128/input[2]:112/input[3]:112/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__10351068418695972412<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:128/input[2]:112/input[3]:112/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__10351068418695972412<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:128/input[2]:112/input[3]:112/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__10351068418695972412<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:128/input[2]:112/input[3]:112/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__10351068418695972412<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:128/input[2]:112/input[3]:112/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__10351068418695972412<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:128/input[2]:112/input[3]:112/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__10351068418695972412<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:128/input[2]:112/input[3]:112/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__10351068418695972412<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:128/input[2]:112/input[3]:112/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__8242993018864188740<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:64/input[2]:112/input[3]:112/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__8242993018864188740<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:64/input[2]:112/input[3]:112/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__8242993018864188740<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:64/input[2]:112/input[3]:112/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__8242993018864188740<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:64/input[2]:112/input[3]:112/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__8242993018864188740<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:64/input[2]:112/input[3]:112/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__8242993018864188740<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:64/input[2]:112/input[3]:112/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__8242993018864188740<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:64/input[2]:112/input[3]:112/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__8242993018864188740<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:64/input[2]:112/input[3]:112/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__3128501535788430015<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:1024/input[2]:14/input[3]:14/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__3128501535788430015<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:1024/input[2]:14/input[3]:14/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__3128501535788430015<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:1024/input[2]:14/input[3]:14/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__3128501535788430015<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:1024/input[2]:14/input[3]:14/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__3128501535788430015<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:1024/input[2]:14/input[3]:14/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__3128501535788430015<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:1024/input[2]:14/input[3]:14/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__3128501535788430015<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:1024/input[2]:14/input[3]:14/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__3128501535788430015<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:1024/input[2]:14/input[3]:14/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__15128697251547281564<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:128/input[2]:28/input[3]:28/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__15128697251547281564<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:128/input[2]:28/input[3]:28/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__15128697251547281564<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:128/input[2]:28/input[3]:28/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__15128697251547281564<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:128/input[2]:28/input[3]:28/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__15128697251547281564<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:128/input[2]:28/input[3]:28/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__15128697251547281564<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:128/input[2]:28/input[3]:28/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__15128697251547281564<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:128/input[2]:28/input[3]:28/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__15128697251547281564<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:128/input[2]:28/input[3]:28/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__16169773638883887620<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:16/input[2]:55/input[3]:55/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__16169773638883887620<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:16/input[2]:55/input[3]:55/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__16169773638883887620<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:16/input[2]:55/input[3]:55/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__16169773638883887620<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:16/input[2]:55/input[3]:55/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__16169773638883887620<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:16/input[2]:55/input[3]:55/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__16169773638883887620<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:16/input[2]:55/input[3]:55/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__16169773638883887620<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:16/input[2]:55/input[3]:55/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__16169773638883887620<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:16/input[2]:55/input[3]:55/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__972010337835526156<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:1/input[1]:136/input[2]:14/input[3]:14/filter_count:136/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:4/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__972010337835526156<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:1/input[1]:136/input[2]:14/input[3]:14/filter_count:136/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:4/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__972010337835526156<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:1/input[1]:136/input[2]:14/input[3]:14/filter_count:136/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:4/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__972010337835526156<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:1/input[1]:136/input[2]:14/input[3]:14/filter_count:136/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:4/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__972010337835526156<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:1/input[1]:136/input[2]:14/input[3]:14/filter_count:136/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:4/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__972010337835526156<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:1/input[1]:136/input[2]:14/input[3]:14/filter_count:136/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:4/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__972010337835526156<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:1/input[1]:136/input[2]:14/input[3]:14/filter_count:136/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:4/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__972010337835526156<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:1/input[1]:136/input[2]:14/input[3]:14/filter_count:136/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:4/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__6359866969157171536<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:1/input[1]:272/input[2]:14/input[3]:14/filter_count:272/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:4/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__6359866969157171536<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:1/input[1]:272/input[2]:14/input[3]:14/filter_count:272/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:4/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__6359866969157171536<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:1/input[1]:272/input[2]:14/input[3]:14/filter_count:272/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:4/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__6359866969157171536<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:1/input[1]:272/input[2]:14/input[3]:14/filter_count:272/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:4/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__6359866969157171536<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:1/input[1]:272/input[2]:14/input[3]:14/filter_count:272/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:4/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__6359866969157171536<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:1/input[1]:272/input[2]:14/input[3]:14/filter_count:272/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:4/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__6359866969157171536<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:1/input[1]:272/input[2]:14/input[3]:14/filter_count:272/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:4/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__6359866969157171536<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:1/input[1]:272/input[2]:14/input[3]:14/filter_count:272/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:4/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__7688604381410044393<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:1/input[1]:272/input[2]:14/input[3]:14/filter_count:272/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:272/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__7688604381410044393<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:1/input[1]:272/input[2]:14/input[3]:14/filter_count:272/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:272/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__7688604381410044393<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:1/input[1]:272/input[2]:14/input[3]:14/filter_count:272/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:272/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__7688604381410044393<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:1/input[1]:272/input[2]:14/input[3]:14/filter_count:272/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:272/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__7688604381410044393<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:1/input[1]:272/input[2]:14/input[3]:14/filter_count:272/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:272/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__7688604381410044393<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:1/input[1]:272/input[2]:14/input[3]:14/filter_count:272/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:272/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__7688604381410044393<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:1/input[1]:272/input[2]:14/input[3]:14/filter_count:272/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:272/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__7688604381410044393<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:1/input[1]:272/input[2]:14/input[3]:14/filter_count:272/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:272/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__10089576711009153973<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:24/input[2]:56/input[3]:56/filter_count:112/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:4/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__10089576711009153973<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:24/input[2]:56/input[3]:56/filter_count:112/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:4/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__10089576711009153973<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:24/input[2]:56/input[3]:56/filter_count:112/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:4/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__10089576711009153973<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:24/input[2]:56/input[3]:56/filter_count:112/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:4/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__10089576711009153973<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:24/input[2]:56/input[3]:56/filter_count:112/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:4/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__10089576711009153973<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:24/input[2]:56/input[3]:56/filter_count:112/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:4/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__10089576711009153973<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:24/input[2]:56/input[3]:56/filter_count:112/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:4/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__10089576711009153973<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:24/input[2]:56/input[3]:56/filter_count:112/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:4/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__15914800424517040869<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:384/input[2]:13/input[3]:13/filter_count:48/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__15914800424517040869<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:384/input[2]:13/input[3]:13/filter_count:48/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__15914800424517040869<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:384/input[2]:13/input[3]:13/filter_count:48/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__15914800424517040869<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:384/input[2]:13/input[3]:13/filter_count:48/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__15914800424517040869<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:384/input[2]:13/input[3]:13/filter_count:48/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__15914800424517040869<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:384/input[2]:13/input[3]:13/filter_count:48/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__15914800424517040869<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:384/input[2]:13/input[3]:13/filter_count:48/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__15914800424517040869<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:384/input[2]:13/input[3]:13/filter_count:48/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__4337218548239653944<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:1/input[1]:48/input[2]:6/input[3]:6/filter_count:128/filter_height:5/filter_width:5/pad_height:2/pad_width:2/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__4337218548239653944<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:1/input[1]:48/input[2]:6/input[3]:6/filter_count:128/filter_height:5/filter_width:5/pad_height:2/pad_width:2/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__4337218548239653944<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:1/input[1]:48/input[2]:6/input[3]:6/filter_count:128/filter_height:5/filter_width:5/pad_height:2/pad_width:2/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__4337218548239653944<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:1/input[1]:48/input[2]:6/input[3]:6/filter_count:128/filter_height:5/filter_width:5/pad_height:2/pad_width:2/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__4337218548239653944<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:1/input[1]:48/input[2]:6/input[3]:6/filter_count:128/filter_height:5/filter_width:5/pad_height:2/pad_width:2/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__4337218548239653944<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:1/input[1]:48/input[2]:6/input[3]:6/filter_count:128/filter_height:5/filter_width:5/pad_height:2/pad_width:2/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__4337218548239653944<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:1/input[1]:48/input[2]:6/input[3]:6/filter_count:128/filter_height:5/filter_width:5/pad_height:2/pad_width:2/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__4337218548239653944<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:1/input[1]:48/input[2]:6/input[3]:6/filter_count:128/filter_height:5/filter_width:5/pad_height:2/pad_width:2/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__2562839765583816880<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:512/input[2]:13/input[3]:13/filter_count:1000/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__2562839765583816880<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:512/input[2]:13/input[3]:13/filter_count:1000/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__2562839765583816880<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:512/input[2]:13/input[3]:13/filter_count:1000/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__2562839765583816880<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:512/input[2]:13/input[3]:13/filter_count:1000/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__2562839765583816880<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:512/input[2]:13/input[3]:13/filter_count:1000/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__2562839765583816880<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:512/input[2]:13/input[3]:13/filter_count:1000/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__2562839765583816880<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:512/input[2]:13/input[3]:13/filter_count:1000/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__2562839765583816880<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:512/input[2]:13/input[3]:13/filter_count:1000/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__6830662759055045042<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:1/input[1]:832/input[2]:6/input[3]:6/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__6830662759055045042<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:1/input[1]:832/input[2]:6/input[3]:6/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__6830662759055045042<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:1/input[1]:832/input[2]:6/input[3]:6/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__6830662759055045042<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:1/input[1]:832/input[2]:6/input[3]:6/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__6830662759055045042<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:1/input[1]:832/input[2]:6/input[3]:6/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__6830662759055045042<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:1/input[1]:832/input[2]:6/input[3]:6/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__6830662759055045042<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:1/input[1]:832/input[2]:6/input[3]:6/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__6830662759055045042<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:1/input[1]:832/input[2]:6/input[3]:6/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__15540098221680123473<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:1/input[1]:128/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__15540098221680123473<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:1/input[1]:128/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__15540098221680123473<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:1/input[1]:128/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__15540098221680123473<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:1/input[1]:128/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__15540098221680123473<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:1/input[1]:128/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__15540098221680123473<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:1/input[1]:128/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__15540098221680123473<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:1/input[1]:128/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__15540098221680123473<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:1/input[1]:128/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__3043237967567955884<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:1/input[1]:192/input[2]:27/input[3]:27/filter_count:16/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__3043237967567955884<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:1/input[1]:192/input[2]:27/input[3]:27/filter_count:16/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__3043237967567955884<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:1/input[1]:192/input[2]:27/input[3]:27/filter_count:16/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__3043237967567955884<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:1/input[1]:192/input[2]:27/input[3]:27/filter_count:16/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__3043237967567955884<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:1/input[1]:192/input[2]:27/input[3]:27/filter_count:16/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__3043237967567955884<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:1/input[1]:192/input[2]:27/input[3]:27/filter_count:16/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__3043237967567955884<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:1/input[1]:192/input[2]:27/input[3]:27/filter_count:16/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__3043237967567955884<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:1/input[1]:192/input[2]:27/input[3]:27/filter_count:16/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__3930636241252563940<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:1/input[1]:224/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__3930636241252563940<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:1/input[1]:224/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__3930636241252563940<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:1/input[1]:224/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__3930636241252563940<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:1/input[1]:224/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__3930636241252563940<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:1/input[1]:224/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__3930636241252563940<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:1/input[1]:224/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__3930636241252563940<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:1/input[1]:224/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__3930636241252563940<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:1/input[1]:224/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__18283338308808173294<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:1/input[1]:128/input[2]:28/input[3]:28/filter_count:32/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__18283338308808173294<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:1/input[1]:128/input[2]:28/input[3]:28/filter_count:32/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__18283338308808173294<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:1/input[1]:128/input[2]:28/input[3]:28/filter_count:32/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__18283338308808173294<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:1/input[1]:128/input[2]:28/input[3]:28/filter_count:32/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__18283338308808173294<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:1/input[1]:128/input[2]:28/input[3]:28/filter_count:32/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__18283338308808173294<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:1/input[1]:128/input[2]:28/input[3]:28/filter_count:32/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__18283338308808173294<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:1/input[1]:128/input[2]:28/input[3]:28/filter_count:32/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__18283338308808173294<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:1/input[1]:128/input[2]:28/input[3]:28/filter_count:32/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__6309800528572562598<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:1/input[1]:256/input[2]:27/input[3]:27/filter_count:32/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__6309800528572562598<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:1/input[1]:256/input[2]:27/input[3]:27/filter_count:32/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__6309800528572562598<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:1/input[1]:256/input[2]:27/input[3]:27/filter_count:32/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__6309800528572562598<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:1/input[1]:256/input[2]:27/input[3]:27/filter_count:32/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__6309800528572562598<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:1/input[1]:256/input[2]:27/input[3]:27/filter_count:32/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__6309800528572562598<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:1/input[1]:256/input[2]:27/input[3]:27/filter_count:32/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__6309800528572562598<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:1/input[1]:256/input[2]:27/input[3]:27/filter_count:32/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__6309800528572562598<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:1/input[1]:256/input[2]:27/input[3]:27/filter_count:32/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__14674577036701251069<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:1/input[1]:256/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__14674577036701251069<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:1/input[1]:256/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__14674577036701251069<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:1/input[1]:256/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__14674577036701251069<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:1/input[1]:256/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__14674577036701251069<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:1/input[1]:256/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__14674577036701251069<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:1/input[1]:256/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__14674577036701251069<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:1/input[1]:256/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__14674577036701251069<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:1/input[1]:256/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__4180845995860635516<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:512/input[2]:12/input[3]:12/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__4180845995860635516<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:512/input[2]:12/input[3]:12/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__4180845995860635516<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:512/input[2]:12/input[3]:12/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__4180845995860635516<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:512/input[2]:12/input[3]:12/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__4180845995860635516<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:512/input[2]:12/input[3]:12/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__4180845995860635516<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:512/input[2]:12/input[3]:12/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__4180845995860635516<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:512/input[2]:12/input[3]:12/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__4180845995860635516<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:512/input[2]:12/input[3]:12/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__2120557780659131677<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:1/input[1]:128/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__2120557780659131677<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:1/input[1]:128/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__2120557780659131677<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:1/input[1]:128/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__2120557780659131677<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:1/input[1]:128/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__2120557780659131677<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:1/input[1]:128/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__2120557780659131677<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:1/input[1]:128/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__2120557780659131677<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:1/input[1]:128/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__2120557780659131677<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:1/input[1]:128/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__17271315264594299431<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:1/input[1]:480/input[2]:13/input[3]:13/filter_count:192/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__17271315264594299431<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:1/input[1]:480/input[2]:13/input[3]:13/filter_count:192/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__17271315264594299431<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:1/input[1]:480/input[2]:13/input[3]:13/filter_count:192/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__17271315264594299431<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:1/input[1]:480/input[2]:13/input[3]:13/filter_count:192/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__17271315264594299431<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:1/input[1]:480/input[2]:13/input[3]:13/filter_count:192/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__17271315264594299431<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:1/input[1]:480/input[2]:13/input[3]:13/filter_count:192/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__17271315264594299431<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:1/input[1]:480/input[2]:13/input[3]:13/filter_count:192/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__17271315264594299431<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:1/input[1]:480/input[2]:13/input[3]:13/filter_count:192/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__1351179328154132865<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:144/input[2]:14/input[3]:14/filter_count:288/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__1351179328154132865<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:144/input[2]:14/input[3]:14/filter_count:288/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__1351179328154132865<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:144/input[2]:14/input[3]:14/filter_count:288/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__1351179328154132865<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:144/input[2]:14/input[3]:14/filter_count:288/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__1351179328154132865<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:144/input[2]:14/input[3]:14/filter_count:288/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__1351179328154132865<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:144/input[2]:14/input[3]:14/filter_count:288/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__1351179328154132865<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:144/input[2]:14/input[3]:14/filter_count:288/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__1351179328154132865<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:144/input[2]:14/input[3]:14/filter_count:288/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__13051816163919761267<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:480/input[2]:14/input[3]:14/filter_count:16/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__13051816163919761267<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:480/input[2]:14/input[3]:14/filter_count:16/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__13051816163919761267<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:480/input[2]:14/input[3]:14/filter_count:16/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__13051816163919761267<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:480/input[2]:14/input[3]:14/filter_count:16/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__13051816163919761267<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:480/input[2]:14/input[3]:14/filter_count:16/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__13051816163919761267<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:480/input[2]:14/input[3]:14/filter_count:16/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__13051816163919761267<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:480/input[2]:14/input[3]:14/filter_count:16/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__13051816163919761267<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:480/input[2]:14/input[3]:14/filter_count:16/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__3830852759700652469<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:16/input[2]:112/input[3]:112/filter_count:96/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__3830852759700652469<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:16/input[2]:112/input[3]:112/filter_count:96/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__3830852759700652469<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:16/input[2]:112/input[3]:112/filter_count:96/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__3830852759700652469<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:16/input[2]:112/input[3]:112/filter_count:96/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__3830852759700652469<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:16/input[2]:112/input[3]:112/filter_count:96/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__3830852759700652469<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:16/input[2]:112/input[3]:112/filter_count:96/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__3830852759700652469<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:16/input[2]:112/input[3]:112/filter_count:96/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__3830852759700652469<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:16/input[2]:112/input[3]:112/filter_count:96/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__6932479544753593227<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:96/input[2]:26/input[3]:26/filter_count:256/filter_height:5/filter_width:5/pad_height:2/pad_width:2/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:2/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__6932479544753593227<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:96/input[2]:26/input[3]:26/filter_count:256/filter_height:5/filter_width:5/pad_height:2/pad_width:2/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:2/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__6932479544753593227<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:96/input[2]:26/input[3]:26/filter_count:256/filter_height:5/filter_width:5/pad_height:2/pad_width:2/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:2/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__6932479544753593227<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:96/input[2]:26/input[3]:26/filter_count:256/filter_height:5/filter_width:5/pad_height:2/pad_width:2/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:2/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__6932479544753593227<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:96/input[2]:26/input[3]:26/filter_count:256/filter_height:5/filter_width:5/pad_height:2/pad_width:2/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:2/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__6932479544753593227<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:96/input[2]:26/input[3]:26/filter_count:256/filter_height:5/filter_width:5/pad_height:2/pad_width:2/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:2/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__6932479544753593227<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:96/input[2]:26/input[3]:26/filter_count:256/filter_height:5/filter_width:5/pad_height:2/pad_width:2/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:2/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__6932479544753593227<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:96/input[2]:26/input[3]:26/filter_count:256/filter_height:5/filter_width:5/pad_height:2/pad_width:2/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:2/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__12335377408300587202<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:1/input[1]:288/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__12335377408300587202<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:1/input[1]:288/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__12335377408300587202<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:1/input[1]:288/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__12335377408300587202<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:1/input[1]:288/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__12335377408300587202<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:1/input[1]:288/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__12335377408300587202<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:1/input[1]:288/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__12335377408300587202<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:1/input[1]:288/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__12335377408300587202<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:1/input[1]:288/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__6237919692003755528<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:160/input[2]:14/input[3]:14/filter_count:320/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__6237919692003755528<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:160/input[2]:14/input[3]:14/filter_count:320/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__6237919692003755528<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:160/input[2]:14/input[3]:14/filter_count:320/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__6237919692003755528<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:160/input[2]:14/input[3]:14/filter_count:320/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__6237919692003755528<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:160/input[2]:14/input[3]:14/filter_count:320/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__6237919692003755528<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:160/input[2]:14/input[3]:14/filter_count:320/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__6237919692003755528<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:160/input[2]:14/input[3]:14/filter_count:320/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__6237919692003755528<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:160/input[2]:14/input[3]:14/filter_count:320/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__18023355759516697796<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:64/input[2]:55/input[3]:55/filter_count:16/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__18023355759516697796<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:64/input[2]:55/input[3]:55/filter_count:16/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__18023355759516697796<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:64/input[2]:55/input[3]:55/filter_count:16/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__18023355759516697796<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:64/input[2]:55/input[3]:55/filter_count:16/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__18023355759516697796<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:64/input[2]:55/input[3]:55/filter_count:16/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__18023355759516697796<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:64/input[2]:55/input[3]:55/filter_count:16/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__18023355759516697796<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:64/input[2]:55/input[3]:55/filter_count:16/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__18023355759516697796<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:64/input[2]:55/input[3]:55/filter_count:16/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__6339505475346237008<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:512/input[2]:14/input[3]:14/filter_count:144/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__6339505475346237008<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:512/input[2]:14/input[3]:14/filter_count:144/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__6339505475346237008<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:512/input[2]:14/input[3]:14/filter_count:144/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__6339505475346237008<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:512/input[2]:14/input[3]:14/filter_count:144/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__6339505475346237008<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:512/input[2]:14/input[3]:14/filter_count:144/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__6339505475346237008<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:512/input[2]:14/input[3]:14/filter_count:144/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__6339505475346237008<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:512/input[2]:14/input[3]:14/filter_count:144/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__6339505475346237008<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:512/input[2]:14/input[3]:14/filter_count:144/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__4514867126541267301<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:96/input[2]:112/input[3]:112/filter_count:96/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:96/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__4514867126541267301<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:96/input[2]:112/input[3]:112/filter_count:96/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:96/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__4514867126541267301<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:96/input[2]:112/input[3]:112/filter_count:96/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:96/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__4514867126541267301<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:96/input[2]:112/input[3]:112/filter_count:96/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:96/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__4514867126541267301<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:96/input[2]:112/input[3]:112/filter_count:96/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:96/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__4514867126541267301<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:96/input[2]:112/input[3]:112/filter_count:96/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:96/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__4514867126541267301<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:96/input[2]:112/input[3]:112/filter_count:96/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:96/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__4514867126541267301<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:96/input[2]:112/input[3]:112/filter_count:96/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:96/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__670533858076067383<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:1/input[1]:320/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__670533858076067383<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:1/input[1]:320/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__670533858076067383<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:1/input[1]:320/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__670533858076067383<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:1/input[1]:320/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__670533858076067383<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:1/input[1]:320/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__670533858076067383<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:1/input[1]:320/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__670533858076067383<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:1/input[1]:320/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__670533858076067383<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:1/input[1]:320/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__5168181768677779517<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:1/input[1]:128/input[2]:13/input[3]:13/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__5168181768677779517<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:1/input[1]:128/input[2]:13/input[3]:13/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__5168181768677779517<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:1/input[1]:128/input[2]:13/input[3]:13/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__5168181768677779517<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:1/input[1]:128/input[2]:13/input[3]:13/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__5168181768677779517<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:1/input[1]:128/input[2]:13/input[3]:13/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__5168181768677779517<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:1/input[1]:128/input[2]:13/input[3]:13/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__5168181768677779517<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:1/input[1]:128/input[2]:13/input[3]:13/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__5168181768677779517<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:1/input[1]:128/input[2]:13/input[3]:13/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__14393016835965374467<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:1/input[1]:704/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__14393016835965374467<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:1/input[1]:704/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__14393016835965374467<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:1/input[1]:704/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__14393016835965374467<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:1/input[1]:704/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__14393016835965374467<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:1/input[1]:704/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__14393016835965374467<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:1/input[1]:704/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__14393016835965374467<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:1/input[1]:704/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__14393016835965374467<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:1/input[1]:704/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__13009955720426689851<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:1/input[1]:768/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__13009955720426689851<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:1/input[1]:768/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__13009955720426689851<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:1/input[1]:768/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__13009955720426689851<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:1/input[1]:768/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__13009955720426689851<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:1/input[1]:768/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__13009955720426689851<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:1/input[1]:768/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__13009955720426689851<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:1/input[1]:768/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__13009955720426689851<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:1/input[1]:768/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__5452294292262303092<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:128/input[2]:199/input[3]:199/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__5452294292262303092<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:128/input[2]:199/input[3]:199/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__5452294292262303092<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:128/input[2]:199/input[3]:199/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__5452294292262303092<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:128/input[2]:199/input[3]:199/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__5452294292262303092<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:128/input[2]:199/input[3]:199/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__5452294292262303092<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:128/input[2]:199/input[3]:199/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__5452294292262303092<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:128/input[2]:199/input[3]:199/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__5452294292262303092<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:128/input[2]:199/input[3]:199/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__1494202957548002979<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:832/input[2]:7/input[3]:7/filter_count:192/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__1494202957548002979<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:832/input[2]:7/input[3]:7/filter_count:192/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__1494202957548002979<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:832/input[2]:7/input[3]:7/filter_count:192/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__1494202957548002979<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:832/input[2]:7/input[3]:7/filter_count:192/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__1494202957548002979<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:832/input[2]:7/input[3]:7/filter_count:192/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__1494202957548002979<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:832/input[2]:7/input[3]:7/filter_count:192/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__1494202957548002979<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:832/input[2]:7/input[3]:7/filter_count:192/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__1494202957548002979<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:832/input[2]:7/input[3]:7/filter_count:192/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__10477223231936199684<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:160/input[2]:7/input[3]:7/filter_count:320/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__10477223231936199684<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:160/input[2]:7/input[3]:7/filter_count:320/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__10477223231936199684<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:160/input[2]:7/input[3]:7/filter_count:320/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__10477223231936199684<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:160/input[2]:7/input[3]:7/filter_count:320/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__10477223231936199684<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:160/input[2]:7/input[3]:7/filter_count:320/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__10477223231936199684<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:160/input[2]:7/input[3]:7/filter_count:320/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__10477223231936199684<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:160/input[2]:7/input[3]:7/filter_count:320/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__10477223231936199684<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:160/input[2]:7/input[3]:7/filter_count:320/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__8221520561120285748<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:1/input[1]:544/input[2]:7/input[3]:7/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__8221520561120285748<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:1/input[1]:544/input[2]:7/input[3]:7/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__8221520561120285748<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:1/input[1]:544/input[2]:7/input[3]:7/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__8221520561120285748<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:1/input[1]:544/input[2]:7/input[3]:7/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__8221520561120285748<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:1/input[1]:544/input[2]:7/input[3]:7/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__8221520561120285748<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:1/input[1]:544/input[2]:7/input[3]:7/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__8221520561120285748<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:1/input[1]:544/input[2]:7/input[3]:7/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__8221520561120285748<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:1/input[1]:544/input[2]:7/input[3]:7/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__995781860295843966<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:1/input[1]:448/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__995781860295843966<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:1/input[1]:448/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__995781860295843966<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:1/input[1]:448/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__995781860295843966<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:1/input[1]:448/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__995781860295843966<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:1/input[1]:448/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__995781860295843966<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:1/input[1]:448/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__995781860295843966<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:1/input[1]:448/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__995781860295843966<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:1/input[1]:448/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__16403170060639865380<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:1/input[1]:928/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__16403170060639865380<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:1/input[1]:928/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__16403170060639865380<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:1/input[1]:928/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__16403170060639865380<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:1/input[1]:928/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__16403170060639865380<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:1/input[1]:928/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__16403170060639865380<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:1/input[1]:928/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__16403170060639865380<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:1/input[1]:928/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__16403170060639865380<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:1/input[1]:928/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__18432505984245721748<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:1/input[1]:896/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__18432505984245721748<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:1/input[1]:896/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__18432505984245721748<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:1/input[1]:896/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__18432505984245721748<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:1/input[1]:896/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__18432505984245721748<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:1/input[1]:896/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__18432505984245721748<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:1/input[1]:896/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__18432505984245721748<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:1/input[1]:896/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__18432505984245721748<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:1/input[1]:896/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__16909330632506389045<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:384/input[2]:28/input[3]:28/filter_count:384/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:384/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__16909330632506389045<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:384/input[2]:28/input[3]:28/filter_count:384/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:384/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__16909330632506389045<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:384/input[2]:28/input[3]:28/filter_count:384/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:384/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__16909330632506389045<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:384/input[2]:28/input[3]:28/filter_count:384/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:384/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__16909330632506389045<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:384/input[2]:28/input[3]:28/filter_count:384/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:384/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__16909330632506389045<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:384/input[2]:28/input[3]:28/filter_count:384/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:384/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__16909330632506389045<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:384/input[2]:28/input[3]:28/filter_count:384/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:384/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__16909330632506389045<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:384/input[2]:28/input[3]:28/filter_count:384/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:384/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__15068298120463786504<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:1/input[1]:512/input[2]:13/input[3]:13/filter_count:32/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__15068298120463786504<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:1/input[1]:512/input[2]:13/input[3]:13/filter_count:32/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__15068298120463786504<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:1/input[1]:512/input[2]:13/input[3]:13/filter_count:32/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__15068298120463786504<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:1/input[1]:512/input[2]:13/input[3]:13/filter_count:32/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__15068298120463786504<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:1/input[1]:512/input[2]:13/input[3]:13/filter_count:32/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__15068298120463786504<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:1/input[1]:512/input[2]:13/input[3]:13/filter_count:32/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__15068298120463786504<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:1/input[1]:512/input[2]:13/input[3]:13/filter_count:32/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__15068298120463786504<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:1/input[1]:512/input[2]:13/input[3]:13/filter_count:32/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__14326440837465517151<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:1/input[1]:480/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__14326440837465517151<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:1/input[1]:480/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__14326440837465517151<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:1/input[1]:480/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__14326440837465517151<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:1/input[1]:480/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__14326440837465517151<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:1/input[1]:480/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__14326440837465517151<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:1/input[1]:480/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__14326440837465517151<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:1/input[1]:480/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__14326440837465517151<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:1/input[1]:480/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__7240335983645887293<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:1/input[1]:960/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__7240335983645887293<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:1/input[1]:960/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__7240335983645887293<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:1/input[1]:960/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__7240335983645887293<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:1/input[1]:960/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__7240335983645887293<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:1/input[1]:960/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__7240335983645887293<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:1/input[1]:960/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__7240335983645887293<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:1/input[1]:960/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__7240335983645887293<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:1/input[1]:960/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__3508945788052142604<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:1/input[1]:112/input[2]:13/input[3]:13/filter_count:224/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__3508945788052142604<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:1/input[1]:112/input[2]:13/input[3]:13/filter_count:224/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__3508945788052142604<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:1/input[1]:112/input[2]:13/input[3]:13/filter_count:224/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__3508945788052142604<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:1/input[1]:112/input[2]:13/input[3]:13/filter_count:224/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__3508945788052142604<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:1/input[1]:112/input[2]:13/input[3]:13/filter_count:224/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__3508945788052142604<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:1/input[1]:112/input[2]:13/input[3]:13/filter_count:224/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__3508945788052142604<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:1/input[1]:112/input[2]:13/input[3]:13/filter_count:224/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__3508945788052142604<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:1/input[1]:112/input[2]:13/input[3]:13/filter_count:224/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__15290371352394127559<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:1/input[1]:512/input[2]:13/input[3]:13/filter_count:24/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__15290371352394127559<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:1/input[1]:512/input[2]:13/input[3]:13/filter_count:24/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__15290371352394127559<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:1/input[1]:512/input[2]:13/input[3]:13/filter_count:24/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__15290371352394127559<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:1/input[1]:512/input[2]:13/input[3]:13/filter_count:24/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__15290371352394127559<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:1/input[1]:512/input[2]:13/input[3]:13/filter_count:24/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__15290371352394127559<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:1/input[1]:512/input[2]:13/input[3]:13/filter_count:24/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__15290371352394127559<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:1/input[1]:512/input[2]:13/input[3]:13/filter_count:24/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__15290371352394127559<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:1/input[1]:512/input[2]:13/input[3]:13/filter_count:24/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__11884789225813939908<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:192/input[2]:7/input[3]:7/filter_count:384/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__11884789225813939908<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:192/input[2]:7/input[3]:7/filter_count:384/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__11884789225813939908<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:192/input[2]:7/input[3]:7/filter_count:384/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__11884789225813939908<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:192/input[2]:7/input[3]:7/filter_count:384/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__11884789225813939908<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:192/input[2]:7/input[3]:7/filter_count:384/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__11884789225813939908<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:192/input[2]:7/input[3]:7/filter_count:384/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__11884789225813939908<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:192/input[2]:7/input[3]:7/filter_count:384/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__11884789225813939908<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:192/input[2]:7/input[3]:7/filter_count:384/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__5529794847985927785<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:48/input[2]:7/input[3]:7/filter_count:128/filter_height:5/filter_width:5/pad_height:2/pad_width:2/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__5529794847985927785<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:48/input[2]:7/input[3]:7/filter_count:128/filter_height:5/filter_width:5/pad_height:2/pad_width:2/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__5529794847985927785<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:48/input[2]:7/input[3]:7/filter_count:128/filter_height:5/filter_width:5/pad_height:2/pad_width:2/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__5529794847985927785<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:48/input[2]:7/input[3]:7/filter_count:128/filter_height:5/filter_width:5/pad_height:2/pad_width:2/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__5529794847985927785<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:48/input[2]:7/input[3]:7/filter_count:128/filter_height:5/filter_width:5/pad_height:2/pad_width:2/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__5529794847985927785<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:48/input[2]:7/input[3]:7/filter_count:128/filter_height:5/filter_width:5/pad_height:2/pad_width:2/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__5529794847985927785<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:48/input[2]:7/input[3]:7/filter_count:128/filter_height:5/filter_width:5/pad_height:2/pad_width:2/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__5529794847985927785<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:48/input[2]:7/input[3]:7/filter_count:128/filter_height:5/filter_width:5/pad_height:2/pad_width:2/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__3665417485103352688<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:832/input[2]:7/input[3]:7/filter_count:32/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__3665417485103352688<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:832/input[2]:7/input[3]:7/filter_count:32/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__3665417485103352688<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:832/input[2]:7/input[3]:7/filter_count:32/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__3665417485103352688<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:832/input[2]:7/input[3]:7/filter_count:32/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__3665417485103352688<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:832/input[2]:7/input[3]:7/filter_count:32/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__3665417485103352688<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:832/input[2]:7/input[3]:7/filter_count:32/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__3665417485103352688<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:832/input[2]:7/input[3]:7/filter_count:32/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__3665417485103352688<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:832/input[2]:7/input[3]:7/filter_count:32/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__10195652698245888212<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:1/input[1]:672/input[2]:7/input[3]:7/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__10195652698245888212<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:1/input[1]:672/input[2]:7/input[3]:7/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__10195652698245888212<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:1/input[1]:672/input[2]:7/input[3]:7/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__10195652698245888212<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:1/input[1]:672/input[2]:7/input[3]:7/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__10195652698245888212<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:1/input[1]:672/input[2]:7/input[3]:7/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__10195652698245888212<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:1/input[1]:672/input[2]:7/input[3]:7/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__10195652698245888212<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:1/input[1]:672/input[2]:7/input[3]:7/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__10195652698245888212<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:1/input[1]:672/input[2]:7/input[3]:7/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__11642544894090319085<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:960/input[2]:7/input[3]:7/filter_count:960/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:960/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__11642544894090319085<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:960/input[2]:7/input[3]:7/filter_count:960/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:960/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__11642544894090319085<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:960/input[2]:7/input[3]:7/filter_count:960/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:960/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__11642544894090319085<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:960/input[2]:7/input[3]:7/filter_count:960/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:960/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__11642544894090319085<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:960/input[2]:7/input[3]:7/filter_count:960/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:960/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__11642544894090319085<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:960/input[2]:7/input[3]:7/filter_count:960/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:960/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__11642544894090319085<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:960/input[2]:7/input[3]:7/filter_count:960/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:960/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__11642544894090319085<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:960/input[2]:7/input[3]:7/filter_count:960/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:960/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__10445561953826416545<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:64/input[2]:32/input[3]:32/filter_count:128/filter_height:3/filter_width:3/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__10445561953826416545<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:64/input[2]:32/input[3]:32/filter_count:128/filter_height:3/filter_width:3/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__10445561953826416545<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:64/input[2]:32/input[3]:32/filter_count:128/filter_height:3/filter_width:3/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__10445561953826416545<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:64/input[2]:32/input[3]:32/filter_count:128/filter_height:3/filter_width:3/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__10445561953826416545<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:64/input[2]:32/input[3]:32/filter_count:128/filter_height:3/filter_width:3/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__10445561953826416545<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:64/input[2]:32/input[3]:32/filter_count:128/filter_height:3/filter_width:3/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__10445561953826416545<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:64/input[2]:32/input[3]:32/filter_count:128/filter_height:3/filter_width:3/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__10445561953826416545<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:64/input[2]:32/input[3]:32/filter_count:128/filter_height:3/filter_width:3/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__5436253109781300155<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:1/input[1]:512/input[2]:13/input[3]:13/filter_count:112/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__5436253109781300155<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:1/input[1]:512/input[2]:13/input[3]:13/filter_count:112/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__5436253109781300155<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:1/input[1]:512/input[2]:13/input[3]:13/filter_count:112/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__5436253109781300155<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:1/input[1]:512/input[2]:13/input[3]:13/filter_count:112/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__5436253109781300155<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:1/input[1]:512/input[2]:13/input[3]:13/filter_count:112/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__5436253109781300155<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:1/input[1]:512/input[2]:13/input[3]:13/filter_count:112/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__5436253109781300155<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:1/input[1]:512/input[2]:13/input[3]:13/filter_count:112/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__5436253109781300155<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:1/input[1]:512/input[2]:13/input[3]:13/filter_count:112/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__18121406941540699140<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:1/input[1]:736/input[2]:7/input[3]:7/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__18121406941540699140<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:1/input[1]:736/input[2]:7/input[3]:7/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__18121406941540699140<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:1/input[1]:736/input[2]:7/input[3]:7/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__18121406941540699140<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:1/input[1]:736/input[2]:7/input[3]:7/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__18121406941540699140<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:1/input[1]:736/input[2]:7/input[3]:7/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__18121406941540699140<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:1/input[1]:736/input[2]:7/input[3]:7/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__18121406941540699140<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:1/input[1]:736/input[2]:7/input[3]:7/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__18121406941540699140<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:1/input[1]:736/input[2]:7/input[3]:7/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__11090351917531343346<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:480/input[2]:14/input[3]:14/filter_count:192/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__11090351917531343346<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:480/input[2]:14/input[3]:14/filter_count:192/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__11090351917531343346<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:480/input[2]:14/input[3]:14/filter_count:192/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__11090351917531343346<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:480/input[2]:14/input[3]:14/filter_count:192/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__11090351917531343346<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:480/input[2]:14/input[3]:14/filter_count:192/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__11090351917531343346<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:480/input[2]:14/input[3]:14/filter_count:192/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__11090351917531343346<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:480/input[2]:14/input[3]:14/filter_count:192/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__11090351917531343346<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:480/input[2]:14/input[3]:14/filter_count:192/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__8489613993998248489<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:192/input[2]:28/input[3]:28/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__8489613993998248489<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:192/input[2]:28/input[3]:28/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__8489613993998248489<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:192/input[2]:28/input[3]:28/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__8489613993998248489<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:192/input[2]:28/input[3]:28/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__8489613993998248489<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:192/input[2]:28/input[3]:28/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__8489613993998248489<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:192/input[2]:28/input[3]:28/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__8489613993998248489<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:192/input[2]:28/input[3]:28/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__8489613993998248489<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:192/input[2]:28/input[3]:28/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__5560699537725816344<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:96/input[2]:28/input[3]:28/filter_count:96/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__5560699537725816344<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:96/input[2]:28/input[3]:28/filter_count:96/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__5560699537725816344<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:96/input[2]:28/input[3]:28/filter_count:96/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__5560699537725816344<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:96/input[2]:28/input[3]:28/filter_count:96/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__5560699537725816344<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:96/input[2]:28/input[3]:28/filter_count:96/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__5560699537725816344<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:96/input[2]:28/input[3]:28/filter_count:96/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__5560699537725816344<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:96/input[2]:28/input[3]:28/filter_count:96/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__5560699537725816344<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:96/input[2]:28/input[3]:28/filter_count:96/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__9116135508566071309<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:64/input[2]:14/input[3]:14/filter_count:96/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__9116135508566071309<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:64/input[2]:14/input[3]:14/filter_count:96/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__9116135508566071309<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:64/input[2]:14/input[3]:14/filter_count:96/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__9116135508566071309<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:64/input[2]:14/input[3]:14/filter_count:96/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__9116135508566071309<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:64/input[2]:14/input[3]:14/filter_count:96/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__9116135508566071309<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:64/input[2]:14/input[3]:14/filter_count:96/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__9116135508566071309<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:64/input[2]:14/input[3]:14/filter_count:96/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__9116135508566071309<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:64/input[2]:14/input[3]:14/filter_count:96/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__4963210424433599508<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:160/input[2]:14/input[3]:14/filter_count:160/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__4963210424433599508<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:160/input[2]:14/input[3]:14/filter_count:160/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__4963210424433599508<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:160/input[2]:14/input[3]:14/filter_count:160/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__4963210424433599508<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:160/input[2]:14/input[3]:14/filter_count:160/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__4963210424433599508<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:160/input[2]:14/input[3]:14/filter_count:160/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__4963210424433599508<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:160/input[2]:14/input[3]:14/filter_count:160/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__4963210424433599508<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:160/input[2]:14/input[3]:14/filter_count:160/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__4963210424433599508<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:160/input[2]:14/input[3]:14/filter_count:160/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__12257998807915311908<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:512/input[2]:100/input[3]:100/filter_count:512/filter_height:3/filter_width:3/pad_height:9/pad_width:9/stride_height:1/stride_width:1/dilation_height:9/dilation_width:9/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__12257998807915311908<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:512/input[2]:100/input[3]:100/filter_count:512/filter_height:3/filter_width:3/pad_height:9/pad_width:9/stride_height:1/stride_width:1/dilation_height:9/dilation_width:9/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__12257998807915311908<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:512/input[2]:100/input[3]:100/filter_count:512/filter_height:3/filter_width:3/pad_height:9/pad_width:9/stride_height:1/stride_width:1/dilation_height:9/dilation_width:9/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__12257998807915311908<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:512/input[2]:100/input[3]:100/filter_count:512/filter_height:3/filter_width:3/pad_height:9/pad_width:9/stride_height:1/stride_width:1/dilation_height:9/dilation_width:9/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__12257998807915311908<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:512/input[2]:100/input[3]:100/filter_count:512/filter_height:3/filter_width:3/pad_height:9/pad_width:9/stride_height:1/stride_width:1/dilation_height:9/dilation_width:9/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__12257998807915311908<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:512/input[2]:100/input[3]:100/filter_count:512/filter_height:3/filter_width:3/pad_height:9/pad_width:9/stride_height:1/stride_width:1/dilation_height:9/dilation_width:9/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__12257998807915311908<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:512/input[2]:100/input[3]:100/filter_count:512/filter_height:3/filter_width:3/pad_height:9/pad_width:9/stride_height:1/stride_width:1/dilation_height:9/dilation_width:9/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__12257998807915311908<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:512/input[2]:100/input[3]:100/filter_count:512/filter_height:3/filter_width:3/pad_height:9/pad_width:9/stride_height:1/stride_width:1/dilation_height:9/dilation_width:9/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__10388139115557651280<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:192/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__10388139115557651280<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:192/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__10388139115557651280<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:192/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__10388139115557651280<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:192/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__10388139115557651280<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:192/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__10388139115557651280<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:192/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__10388139115557651280<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:192/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__10388139115557651280<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:192/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__12198960507689519729<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:192/input[2]:7/input[3]:7/filter_count:224/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__12198960507689519729<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:192/input[2]:7/input[3]:7/filter_count:224/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__12198960507689519729<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:192/input[2]:7/input[3]:7/filter_count:224/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__12198960507689519729<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:192/input[2]:7/input[3]:7/filter_count:224/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__12198960507689519729<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:192/input[2]:7/input[3]:7/filter_count:224/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__12198960507689519729<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:192/input[2]:7/input[3]:7/filter_count:224/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__12198960507689519729<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:192/input[2]:7/input[3]:7/filter_count:224/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__12198960507689519729<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:192/input[2]:7/input[3]:7/filter_count:224/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__13348320634927797247<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:256/input[2]:28/input[3]:28/filter_count:32/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__13348320634927797247<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:256/input[2]:28/input[3]:28/filter_count:32/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__13348320634927797247<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:256/input[2]:28/input[3]:28/filter_count:32/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__13348320634927797247<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:256/input[2]:28/input[3]:28/filter_count:32/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__13348320634927797247<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:256/input[2]:28/input[3]:28/filter_count:32/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__13348320634927797247<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:256/input[2]:28/input[3]:28/filter_count:32/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__13348320634927797247<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:256/input[2]:28/input[3]:28/filter_count:32/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__13348320634927797247<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:256/input[2]:28/input[3]:28/filter_count:32/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__12848057424107778243<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:1024/input[2]:7/input[3]:7/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__12848057424107778243<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:1024/input[2]:7/input[3]:7/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__12848057424107778243<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:1024/input[2]:7/input[3]:7/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__12848057424107778243<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:1024/input[2]:7/input[3]:7/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__12848057424107778243<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:1024/input[2]:7/input[3]:7/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__12848057424107778243<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:1024/input[2]:7/input[3]:7/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__12848057424107778243<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:1024/input[2]:7/input[3]:7/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__12848057424107778243<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:1024/input[2]:7/input[3]:7/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__8480388862092924848<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:3/input[2]:416/input[3]:416/filter_count:16/filter_height:3/filter_width:3/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__8480388862092924848<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:3/input[2]:416/input[3]:416/filter_count:16/filter_height:3/filter_width:3/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__8480388862092924848<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:3/input[2]:416/input[3]:416/filter_count:16/filter_height:3/filter_width:3/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__8480388862092924848<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:3/input[2]:416/input[3]:416/filter_count:16/filter_height:3/filter_width:3/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__8480388862092924848<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:3/input[2]:416/input[3]:416/filter_count:16/filter_height:3/filter_width:3/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__8480388862092924848<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:3/input[2]:416/input[3]:416/filter_count:16/filter_height:3/filter_width:3/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__8480388862092924848<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:3/input[2]:416/input[3]:416/filter_count:16/filter_height:3/filter_width:3/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__8480388862092924848<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:3/input[2]:416/input[3]:416/filter_count:16/filter_height:3/filter_width:3/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__75158071466409667<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:384/input[2]:13/input[3]:13/filter_count:384/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:2/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__75158071466409667<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:384/input[2]:13/input[3]:13/filter_count:384/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:2/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__75158071466409667<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:384/input[2]:13/input[3]:13/filter_count:384/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:2/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__75158071466409667<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:384/input[2]:13/input[3]:13/filter_count:384/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:2/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__75158071466409667<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:384/input[2]:13/input[3]:13/filter_count:384/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:2/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__75158071466409667<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:384/input[2]:13/input[3]:13/filter_count:384/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:2/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__75158071466409667<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:384/input[2]:13/input[3]:13/filter_count:384/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:2/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__75158071466409667<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:384/input[2]:13/input[3]:13/filter_count:384/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:2/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__17213637575625633055<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:160/input[2]:7/input[3]:7/filter_count:224/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__17213637575625633055<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:160/input[2]:7/input[3]:7/filter_count:224/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__17213637575625633055<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:160/input[2]:7/input[3]:7/filter_count:224/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__17213637575625633055<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:160/input[2]:7/input[3]:7/filter_count:224/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__17213637575625633055<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:160/input[2]:7/input[3]:7/filter_count:224/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__17213637575625633055<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:160/input[2]:7/input[3]:7/filter_count:224/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__17213637575625633055<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:160/input[2]:7/input[3]:7/filter_count:224/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__17213637575625633055<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:160/input[2]:7/input[3]:7/filter_count:224/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__13564343922843240531<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:2048/input[2]:100/input[3]:100/filter_count:304/filter_height:3/filter_width:3/pad_height:6/pad_width:6/stride_height:1/stride_width:1/dilation_height:6/dilation_width:6/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD failed to cudnnSetTensor4dDescriptor",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__13564343922843240531<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:2048/input[2]:100/input[3]:100/filter_count:304/filter_height:3/filter_width:3/pad_height:6/pad_width:6/stride_height:1/stride_width:1/dilation_height:6/dilation_width:6/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD failed to cudnnSetTensor4dDescriptor",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__13564343922843240531<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:2048/input[2]:100/input[3]:100/filter_count:304/filter_height:3/filter_width:3/pad_height:6/pad_width:6/stride_height:1/stride_width:1/dilation_height:6/dilation_width:6/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD failed to cudnnSetTensor4dDescriptor",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__13564343922843240531<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:2048/input[2]:100/input[3]:100/filter_count:304/filter_height:3/filter_width:3/pad_height:6/pad_width:6/stride_height:1/stride_width:1/dilation_height:6/dilation_width:6/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD failed to cudnnSetTensor4dDescriptor",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__13564343922843240531<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:2048/input[2]:100/input[3]:100/filter_count:304/filter_height:3/filter_width:3/pad_height:6/pad_width:6/stride_height:1/stride_width:1/dilation_height:6/dilation_width:6/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD failed to cudnnSetTensor4dDescriptor",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__13564343922843240531<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:2048/input[2]:100/input[3]:100/filter_count:304/filter_height:3/filter_width:3/pad_height:6/pad_width:6/stride_height:1/stride_width:1/dilation_height:6/dilation_width:6/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD failed to cudnnSetTensor4dDescriptor",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__13564343922843240531<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:2048/input[2]:100/input[3]:100/filter_count:304/filter_height:3/filter_width:3/pad_height:6/pad_width:6/stride_height:1/stride_width:1/dilation_height:6/dilation_width:6/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD failed to cudnnSetTensor4dDescriptor",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__13564343922843240531<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:2048/input[2]:100/input[3]:100/filter_count:304/filter_height:3/filter_width:3/pad_height:6/pad_width:6/stride_height:1/stride_width:1/dilation_height:6/dilation_width:6/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD failed to cudnnSetTensor4dDescriptor",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__5166164685744749187<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:144/input[2]:56/input[3]:56/filter_count:144/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:144/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__5166164685744749187<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:144/input[2]:56/input[3]:56/filter_count:144/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:144/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__5166164685744749187<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:144/input[2]:56/input[3]:56/filter_count:144/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:144/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__5166164685744749187<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:144/input[2]:56/input[3]:56/filter_count:144/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:144/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__5166164685744749187<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:144/input[2]:56/input[3]:56/filter_count:144/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:144/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__5166164685744749187<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:144/input[2]:56/input[3]:56/filter_count:144/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:144/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__5166164685744749187<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:144/input[2]:56/input[3]:56/filter_count:144/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:144/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__5166164685744749187<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:144/input[2]:56/input[3]:56/filter_count:144/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:144/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__16657387963186277128<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:256/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__16657387963186277128<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:256/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__16657387963186277128<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:256/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__16657387963186277128<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:256/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__16657387963186277128<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:256/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__16657387963186277128<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:256/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__16657387963186277128<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:256/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__16657387963186277128<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:256/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__14716849201188773238<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:512/input[2]:7/input[3]:7/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__14716849201188773238<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:512/input[2]:7/input[3]:7/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__14716849201188773238<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:512/input[2]:7/input[3]:7/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__14716849201188773238<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:512/input[2]:7/input[3]:7/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__14716849201188773238<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:512/input[2]:7/input[3]:7/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__14716849201188773238<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:512/input[2]:7/input[3]:7/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__14716849201188773238<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:512/input[2]:7/input[3]:7/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__14716849201188773238<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:512/input[2]:7/input[3]:7/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__4394929117217488063<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:1024/input[2]:14/input[3]:14/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__4394929117217488063<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:1024/input[2]:14/input[3]:14/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__4394929117217488063<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:1024/input[2]:14/input[3]:14/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__4394929117217488063<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:1024/input[2]:14/input[3]:14/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__4394929117217488063<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:1024/input[2]:14/input[3]:14/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__4394929117217488063<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:1024/input[2]:14/input[3]:14/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__4394929117217488063<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:1024/input[2]:14/input[3]:14/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__4394929117217488063<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:1024/input[2]:14/input[3]:14/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__15969503444992457156<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:128/input[2]:100/input[3]:100/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__15969503444992457156<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:128/input[2]:100/input[3]:100/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__15969503444992457156<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:128/input[2]:100/input[3]:100/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__15969503444992457156<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:128/input[2]:100/input[3]:100/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__15969503444992457156<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:128/input[2]:100/input[3]:100/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__15969503444992457156<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:128/input[2]:100/input[3]:100/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__15969503444992457156<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:128/input[2]:100/input[3]:100/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__15969503444992457156<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:128/input[2]:100/input[3]:100/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__5981565955212840185<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:64/input[2]:56/input[3]:56/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__5981565955212840185<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:64/input[2]:56/input[3]:56/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__5981565955212840185<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:64/input[2]:56/input[3]:56/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__5981565955212840185<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:64/input[2]:56/input[3]:56/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__5981565955212840185<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:64/input[2]:56/input[3]:56/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__5981565955212840185<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:64/input[2]:56/input[3]:56/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__5981565955212840185<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:64/input[2]:56/input[3]:56/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__5981565955212840185<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:64/input[2]:56/input[3]:56/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__16971164566866137272<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:512/input[2]:14/input[3]:14/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__16971164566866137272<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:512/input[2]:14/input[3]:14/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__16971164566866137272<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:512/input[2]:14/input[3]:14/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__16971164566866137272<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:512/input[2]:14/input[3]:14/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__16971164566866137272<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:512/input[2]:14/input[3]:14/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__16971164566866137272<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:512/input[2]:14/input[3]:14/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__16971164566866137272<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:512/input[2]:14/input[3]:14/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__16971164566866137272<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:512/input[2]:14/input[3]:14/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__3471640941490868128<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:3/input[2]:112/input[3]:112/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__3471640941490868128<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:3/input[2]:112/input[3]:112/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__3471640941490868128<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:3/input[2]:112/input[3]:112/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__3471640941490868128<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:3/input[2]:112/input[3]:112/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__3471640941490868128<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:3/input[2]:112/input[3]:112/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__3471640941490868128<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:3/input[2]:112/input[3]:112/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__3471640941490868128<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:3/input[2]:112/input[3]:112/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__3471640941490868128<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:3/input[2]:112/input[3]:112/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_DROPOUT_FWD_FLOAT32__BatchSize_128__14874554712254526533/input[0]:1/input[1]:1024/input[2]:1/input[3]:1/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_DROPOUT_FWD_FLOAT32__BatchSize_128__7059844864622109039/input[0]:128/input[1]:512/input[2]:13/input[3]:13/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_DROPOUT_FWD_FLOAT32__BatchSize_128__402683540774037342/input[0]:128/input[1]:1024/input[2]:1/input[3]:1/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_DROPOUT_FWD_FLOAT32__BatchSize_128__18341856093365895807/input[0]:128/input[1]:64/input[2]:32/input[3]:32/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_DROPOUT_FWD_FLOAT32__BatchSize_128__13705821161794981523/input[0]:128/input[1]:128/input[2]:16/input[3]:16/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_DROPOUT_FWD_FLOAT32__BatchSize_128__16930707074709615899/input[0]:128/input[1]:256/input[2]:8/input[3]:8/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_DROPOUT_FWD_FLOAT32__BatchSize_128__5528603025886191828/input[0]:1/input[1]:4096/input[2]:-1/input[3]:-1/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_DROPOUT_FWD_FLOAT32__BatchSize_128__663994574542691333/input[0]:128/input[1]:256/input[2]:4/input[3]:4/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_DROPOUT_FWD_FLOAT32__BatchSize_128__9538753626685623055/input[0]:128/input[1]:512/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_DROPOUT_FWD_FLOAT32__BatchSize_128__17983908109240499243/input[0]:128/input[1]:4096/input[2]:-1/input[3]:-1/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_ADD_FWD_FLOAT32__BatchSize_128__8602742229904642917/input[0]:1/input[1]:272/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_ADD_FWD_FLOAT32__BatchSize_128__4889074840031823528/input[0]:1/input[1]:136/input[2]:28/input[3]:28/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_MUL_FWD_FLOAT32__BatchSize_128__16222927563893588573/input[0]:1/input[1]:224/input[2]:28/input[3]:28/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_ADD_FWD_FLOAT32__BatchSize_128__11859752660777327245/input[0]:1/input[1]:512/input[2]:28/input[3]:28/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_MUL_FWD_FLOAT32__BatchSize_128__4000415970715328467/input[0]:1/input[1]:64/input[2]:112/input[3]:112/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_ADD_FWD_FLOAT32__BatchSize_128__9318785962376274809/input[0]:1/input[1]:64/input[2]:112/input[3]:112/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_MUL_FWD_FLOAT32__BatchSize_128__15696134578862174127/input[0]:1/input[1]:64/input[2]:56/input[3]:56/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_MUL_FWD_FLOAT32__BatchSize_128__12115055749141559869/input[0]:1/input[1]:96/input[2]:56/input[3]:56/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_ADD_FWD_FLOAT32__BatchSize_128__7999923905992250117/input[0]:1/input[1]:64/input[2]:56/input[3]:56/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_ADD_FWD_FLOAT32__BatchSize_128__2231529591258613399/input[0]:1/input[1]:96/input[2]:56/input[3]:56/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_MUL_FWD_FLOAT32__BatchSize_128__957349887576585773/input[0]:1/input[1]:160/input[2]:56/input[3]:56/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_ADD_FWD_FLOAT32__BatchSize_128__13519700469997357703/input[0]:1/input[1]:160/input[2]:56/input[3]:56/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_MUL_FWD_FLOAT32__BatchSize_128__4654115189533878229/input[0]:1/input[1]:192/input[2]:56/input[3]:56/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_ADD_FWD_FLOAT32__BatchSize_128__6520963700839004131/input[0]:1/input[1]:224/input[2]:56/input[3]:56/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_MUL_FWD_FLOAT32__BatchSize_128__17053357981798058825/input[0]:1/input[1]:224/input[2]:56/input[3]:56/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_MUL_FWD_FLOAT32__BatchSize_128__9643064084508125139/input[0]:1/input[1]:256/input[2]:28/input[3]:28/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_ADD_FWD_FLOAT32__BatchSize_128__9782505467313199890/input[0]:1/input[1]:128/input[2]:56/input[3]:56/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_MUL_FWD_FLOAT32__BatchSize_128__3536697556171614136/input[0]:1/input[1]:128/input[2]:56/input[3]:56/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_ADD_FWD_FLOAT32__BatchSize_128__2753412083357664843/input[0]:1/input[1]:192/input[2]:28/input[3]:28/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_MUL_FWD_FLOAT32__BatchSize_128__9725536377354172375/input[0]:1/input[1]:256/input[2]:56/input[3]:56/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_ADD_FWD_FLOAT32__BatchSize_128__3471893346082442109/input[0]:1/input[1]:256/input[2]:56/input[3]:56/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_ADD_FWD_FLOAT32__BatchSize_128__6338189746645876471/input[0]:1/input[1]:224/input[2]:28/input[3]:28/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_MUL_FWD_FLOAT32__BatchSize_128__12777339716578591577/input[0]:1/input[1]:160/input[2]:28/input[3]:28/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_ADD_FWD_FLOAT32__BatchSize_128__17744202666092157823/input[0]:1/input[1]:192/input[2]:56/input[3]:56/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_ADD_FWD_FLOAT32__BatchSize_128__541722311841333235/input[0]:1/input[1]:160/input[2]:28/input[3]:28/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_ADD_FWD_FLOAT32__BatchSize_128__3393339380923550428/input[0]:1/input[1]:544/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_MUL_FWD_FLOAT32__BatchSize_128__6022924009766559957/input[0]:1/input[1]:288/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_MUL_FWD_FLOAT32__BatchSize_128__3116659330295674489/input[0]:1/input[1]:288/input[2]:28/input[3]:28/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_ADD_FWD_FLOAT32__BatchSize_128__3676525976393866105/input[0]:1/input[1]:256/input[2]:28/input[3]:28/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_ADD_FWD_FLOAT32__BatchSize_128__8842715452079885173/input[0]:128/input[1]:8/input[2]:28/input[3]:28/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_ADD_FWD_FLOAT32__BatchSize_128__4867194204076968481/input[0]:1/input[1]:256/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_ADD_FWD_FLOAT32__BatchSize_128__9717580908195891373/input[0]:1/input[1]:576/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_MUL_FWD_FLOAT32__BatchSize_128__1295899415286569345/input[0]:1/input[1]:320/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_ADD_FWD_FLOAT32__BatchSize_128__18197114862367277709/input[0]:128/input[1]:16/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_MUL_FWD_FLOAT32__BatchSize_128__17082498959024507477/input[0]:1/input[1]:320/input[2]:28/input[3]:28/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_ADD_FWD_FLOAT32__BatchSize_128__867762959831255308/input[0]:1/input[1]:608/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_ADD_FWD_FLOAT32__BatchSize_128__3076969826191117192/input[0]:1/input[1]:10/input[2]:-1/input[3]:-1/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD failed to cudnnSetTensor4dDescriptor",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_ADD_FWD_FLOAT32__BatchSize_128__16520072241565817983/input[0]:1/input[1]:288/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_MUL_FWD_FLOAT32__BatchSize_128__13464714521111639462/input[0]:1/input[1]:608/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_ADD_FWD_FLOAT32__BatchSize_128__12046384574013777195/input[0]:1/input[1]:320/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_MUL_FWD_FLOAT32__BatchSize_128__7606112692828955931/input[0]:1/input[1]:352/input[2]:28/input[3]:28/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_ADD_FWD_FLOAT32__BatchSize_128__6613418539027937023/input[0]:1/input[1]:320/input[2]:28/input[3]:28/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_MUL_FWD_FLOAT32__BatchSize_128__9273318575461893565/input[0]:1/input[1]:640/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_ADD_FWD_FLOAT32__BatchSize_128__16093886381364091313/input[0]:1/input[1]:352/input[2]:28/input[3]:28/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_ADD_FWD_FLOAT32__BatchSize_128__10988244649517747641/input[0]:1/input[1]:352/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_MUL_FWD_FLOAT32__BatchSize_128__7002485435070303673/input[0]:1/input[1]:384/input[2]:28/input[3]:28/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_ADD_FWD_FLOAT32__BatchSize_128__3920345303339563287/input[0]:1/input[1]:640/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_ADD_FWD_FLOAT32__BatchSize_128__9903594805643085694/input[0]:1/input[1]:672/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_MUL_FWD_FLOAT32__BatchSize_128__3362140663394824467/input[0]:1/input[1]:352/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_MUL_FWD_FLOAT32__BatchSize_128__4586366833977621460/input[0]:1/input[1]:672/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_ADD_FWD_FLOAT32__BatchSize_128__202845539991917333/input[0]:1/input[1]:512/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_ADD_FWD_FLOAT32__BatchSize_128__15563169499806609683/input[0]:1/input[1]:384/input[2]:28/input[3]:28/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_MUL_FWD_FLOAT32__BatchSize_128__14529507170416616086/input[0]:1/input[1]:864/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_MUL_FWD_FLOAT32__BatchSize_128__11280536348425139756/input[0]:1/input[1]:704/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_ADD_FWD_FLOAT32__BatchSize_128__3051799380943161990/input[0]:1/input[1]:704/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_ADD_FWD_FLOAT32__BatchSize_128__8506393240186216314/input[0]:128/input[1]:24/input[2]:56/input[3]:56/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_MUL_FWD_FLOAT32__BatchSize_128__15963677223175319307/input[0]:1/input[1]:736/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_ADD_FWD_FLOAT32__BatchSize_128__9184390632879201852/input[0]:1/input[1]:864/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_MUL_FWD_FLOAT32__BatchSize_128__17738657224718187953/input[0]:1/input[1]:384/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_ADD_FWD_FLOAT32__BatchSize_128__4682320396779946267/input[0]:1/input[1]:384/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_ADD_FWD_FLOAT32__BatchSize_128__13809155009492560943/input[0]:1/input[1]:416/input[2]:28/input[3]:28/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_MUL_FWD_FLOAT32__BatchSize_128__18049707595352205496/input[0]:1/input[1]:896/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_ADD_FWD_FLOAT32__BatchSize_128__7736322753082889121/input[0]:1/input[1]:736/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_MUL_FWD_FLOAT32__BatchSize_128__681545501379711109/input[0]:1/input[1]:416/input[2]:28/input[3]:28/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_ADD_FWD_FLOAT32__BatchSize_128__5524753707947758610/input[0]:1/input[1]:896/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_MUL_FWD_FLOAT32__BatchSize_128__9023139260052505180/input[0]:1/input[1]:832/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_MUL_FWD_FLOAT32__BatchSize_128__3672828123752986197/input[0]:1/input[1]:416/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_MUL_FWD_FLOAT32__BatchSize_128__16589866989282454139/input[0]:1/input[1]:768/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_ADD_FWD_FLOAT32__BatchSize_128__136229250273447514/input[0]:1/input[1]:448/input[2]:28/input[3]:28/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_MUL_FWD_FLOAT32__BatchSize_128__17680305320347694731/input[0]:1/input[1]:256/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_MUL_FWD_FLOAT32__BatchSize_128__10200186871024356796/input[0]:1/input[1]:448/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_ADD_FWD_FLOAT32__BatchSize_128__9524601857314425599/input[0]:1/input[1]:416/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_ADD_FWD_FLOAT32__BatchSize_128__5831496819014899409/input[0]:1/input[1]:768/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_ADD_FWD_FLOAT32__BatchSize_128__16596821321162573344/input[0]:1/input[1]:800/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_MUL_FWD_FLOAT32__BatchSize_128__35955332915386683/input[0]:1/input[1]:928/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_ADD_FWD_FLOAT32__BatchSize_128__429691266213522750/input[0]:1/input[1]:480/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_MUL_FWD_FLOAT32__BatchSize_128__5802165028729305738/input[0]:1/input[1]:800/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_ADD_FWD_FLOAT32__BatchSize_128__4276441343181353238/input[0]:1/input[1]:448/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_ADD_FWD_FLOAT32__BatchSize_128__14694698084686069494/input[0]:1/input[1]:832/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_MUL_FWD_FLOAT32__BatchSize_128__12907385504867176852/input[0]:1/input[1]:480/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_MUL_FWD_FLOAT32__BatchSize_128__11730708899326371868/input[0]:1/input[1]:128/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_MUL_FWD_FLOAT32__BatchSize_128__885802583756205794/input[0]:1/input[1]:544/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_MUL_FWD_FLOAT32__BatchSize_128__10553069481933062347/input[0]:1/input[1]:576/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_ADD_FWD_FLOAT32__BatchSize_128__13162071708262147473/input[0]:1/input[1]:928/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_ADD_FWD_FLOAT32__BatchSize_128__11633705738314619348/input[0]:1/input[1]:608/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_ADD_FWD_FLOAT32__BatchSize_128__1449445236630639798/input[0]:1/input[1]:128/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_MUL_FWD_FLOAT32__BatchSize_128__3213557803215457016/input[0]:1/input[1]:480/input[2]:28/input[3]:28/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_MUL_FWD_FLOAT32__BatchSize_128__1703933990638347646/input[0]:1/input[1]:608/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_ADD_FWD_FLOAT32__BatchSize_128__11118954956718831186/input[0]:1/input[1]:480/input[2]:28/input[3]:28/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_MUL_FWD_FLOAT32__BatchSize_128__7977493492987359641/input[0]:1/input[1]:960/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_ADD_FWD_FLOAT32__BatchSize_128__2639856623970827361/input[0]:1/input[1]:576/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_ADD_FWD_FLOAT32__BatchSize_128__13447097118241428040/input[0]:1/input[1]:544/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_MUL_FWD_FLOAT32__BatchSize_128__12972066382209445823/input[0]:1/input[1]:512/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_ADD_FWD_FLOAT32__BatchSize_128__15592428674322566451/input[0]:1/input[1]:960/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_MUL_FWD_FLOAT32__BatchSize_128__15405744767238863032/input[0]:1/input[1]:128/input[2]:28/input[3]:28/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_ADD_FWD_FLOAT32__BatchSize_128__6295362665763949595/input[0]:1/input[1]:992/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_MUL_FWD_FLOAT32__BatchSize_128__11079206260717270646/input[0]:1/input[1]:544/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_ADD_FWD_FLOAT32__BatchSize_128__7141192142365787154/input[0]:1/input[1]:128/input[2]:28/input[3]:28/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_MUL_FWD_FLOAT32__BatchSize_128__3462536996000281607/input[0]:1/input[1]:576/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_MUL_FWD_FLOAT32__BatchSize_128__15993571055945074656/input[0]:1/input[1]:672/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_MUL_FWD_FLOAT32__BatchSize_128__16252138283960709297/input[0]:1/input[1]:992/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_MUL_FWD_FLOAT32__BatchSize_128__18306965781554308883/input[0]:1/input[1]:768/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_MUL_FWD_FLOAT32__BatchSize_128__2456163856224280729/input[0]:1/input[1]:640/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_ADD_FWD_FLOAT32__BatchSize_128__14081531414377019306/input[0]:128/input[1]:256/input[2]:199/input[3]:199/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_ADD_FWD_FLOAT32__BatchSize_128__11355323369507703507/input[0]:1/input[1]:288/input[2]:28/input[3]:28/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_MUL_FWD_FLOAT32__BatchSize_128__14207999948591134031/input[0]:1/input[1]:1024/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_ADD_FWD_FLOAT32__BatchSize_128__15016216026979619901/input[0]:1/input[1]:928/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_ADD_FWD_FLOAT32__BatchSize_128__10718746709237308467/input[0]:1/input[1]:640/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_ADD_FWD_FLOAT32__BatchSize_128__8357093187731720677/input[0]:1/input[1]:1024/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_MUL_FWD_FLOAT32__BatchSize_128__5436105508891870305/input[0]:1/input[1]:960/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_MUL_FWD_FLOAT32__BatchSize_128__5268318793114351851/input[0]:1/input[1]:512/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_ADD_FWD_FLOAT32__BatchSize_128__14249126530000944711/input[0]:128/input[1]:1/input[2]:64/input[3]:64/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_ADD_FWD_FLOAT32__BatchSize_128__18277369239987271883/input[0]:1/input[1]:960/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_MUL_FWD_FLOAT32__BatchSize_128__2303855167187015924/input[0]:1/input[1]:704/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_MUL_FWD_FLOAT32__BatchSize_128__8316387375803532013/input[0]:128/input[1]:1/input[2]:64/input[3]:64/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_MUL_FWD_FLOAT32__BatchSize_128__7464402879249980934/input[0]:128/input[1]:192/input[2]:56/input[3]:56/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_ADD_FWD_FLOAT32__BatchSize_128__11542783995717599641/input[0]:128/input[1]:128/input[2]:32/input[3]:32/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_ADD_FWD_FLOAT32__BatchSize_128__11709550072729247979/input[0]:1/input[1]:992/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_MUL_FWD_FLOAT32__BatchSize_128__14935327387696276264/input[0]:1/input[1]:128/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_MUL_FWD_FLOAT32__BatchSize_128__1465361566616640577/input[0]:1/input[1]:992/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_ADD_FWD_FLOAT32__BatchSize_128__3036678588698513765/input[0]:128/input[1]:256/input[2]:16/input[3]:16/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_ADD_FWD_FLOAT32__BatchSize_128__5249445878335953849/input[0]:1/input[1]:768/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_MUL_FWD_FLOAT32__BatchSize_128__3676653527546892447/input[0]:1/input[1]:1024/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_MUL_FWD_FLOAT32__BatchSize_128__6035594608291911650/input[0]:1/input[1]:800/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_ADD_FWD_FLOAT32__BatchSize_128__9642408784420826165/input[0]:1/input[1]:1024/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_ADD_FWD_FLOAT32__BatchSize_128__12190785993967510622/input[0]:1/input[1]:704/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_ADD_FWD_FLOAT32__BatchSize_128__16506838349363571528/input[0]:1/input[1]:800/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_ADD_FWD_FLOAT32__BatchSize_128__7719798096482253642/input[0]:1/input[1]:672/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_MUL_FWD_FLOAT32__BatchSize_128__9514650020721788819/input[0]:1/input[1]:736/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_ADD_FWD_FLOAT32__BatchSize_128__3664941208885918521/input[0]:1/input[1]:736/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_ADD_FWD_FLOAT32__BatchSize_128__16123732482287921214/input[0]:1/input[1]:832/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_MUL_FWD_FLOAT32__BatchSize_128__2973173839693035756/input[0]:128/input[1]:64/input[2]:112/input[3]:112/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_ADD_FWD_FLOAT32__BatchSize_128__18431680023426794561/input[0]:1/input[1]:512/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_ADD_FWD_FLOAT32__BatchSize_128__11498950499483239494/input[0]:128/input[1]:64/input[2]:112/input[3]:112/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_ADD_FWD_FLOAT32__BatchSize_128__15078136808460378796/input[0]:128/input[1]:192/input[2]:56/input[3]:56/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_MUL_FWD_FLOAT32__BatchSize_128__4996319056361291910/input[0]:1/input[1]:864/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_MUL_FWD_FLOAT32__BatchSize_128__1315298900013000231/input[0]:1/input[1]:512/input[2]:28/input[3]:28/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_ADD_FWD_FLOAT32__BatchSize_128__17546256012648053804/input[0]:1/input[1]:864/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_MUL_FWD_FLOAT32__BatchSize_128__3312400187810042696/input[0]:128/input[1]:64/input[2]:56/input[3]:56/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_MUL_FWD_FLOAT32__BatchSize_128__4902696826534833950/input[0]:128/input[1]:96/input[2]:28/input[3]:28/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_MUL_FWD_FLOAT32__BatchSize_128__16000812086280587588/input[0]:128/input[1]:64/input[2]:28/input[3]:28/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_ADD_FWD_FLOAT32__BatchSize_128__1738219589844204087/input[0]:128/input[1]:512/input[2]:100/input[3]:100/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_MUL_FWD_FLOAT32__BatchSize_128__7572149762790397076/input[0]:1/input[1]:832/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_ADD_FWD_FLOAT32__BatchSize_128__1728045460296915495/input[0]:128/input[1]:32/input[2]:28/input[3]:28/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_MUL_FWD_FLOAT32__BatchSize_128__8551381917492099420/input[0]:1/input[1]:896/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_ADD_FWD_FLOAT32__BatchSize_128__17500794213419701172/input[0]:128/input[1]:96/input[2]:28/input[3]:28/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_MUL_FWD_FLOAT32__BatchSize_128__3515896971825751394/input[0]:128/input[1]:224/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_MUL_FWD_FLOAT32__BatchSize_128__4859044290618184826/input[0]:128/input[1]:160/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_MUL_FWD_FLOAT32__BatchSize_128__17573577638705566123/input[0]:128/input[1]:128/input[2]:28/input[3]:28/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_ADD_FWD_FLOAT32__BatchSize_128__13869455035643741686/input[0]:1/input[1]:896/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_MUL_FWD_FLOAT32__BatchSize_128__7400258329898461335/input[0]:1/input[1]:928/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_MUL_FWD_FLOAT32__BatchSize_128__17386149515984404592/input[0]:128/input[1]:64/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_MUL_FWD_FLOAT32__BatchSize_128__11410442627855547934/input[0]:128/input[1]:96/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_ADD_FWD_FLOAT32__BatchSize_128__14065550617447867365/input[0]:128/input[1]:128/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_ADD_FWD_FLOAT32__BatchSize_128__8760168078350770050/input[0]:1/input[1]:128/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_MUL_FWD_FLOAT32__BatchSize_128__7659037478881594386/input[0]:128/input[1]:192/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_ADD_FWD_FLOAT32__BatchSize_128__5160753033663511770/input[0]:128/input[1]:64/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_ADD_FWD_FLOAT32__BatchSize_128__11726883026593476671/input[0]:128/input[1]:1024/input[2]:100/input[3]:100/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_ADD_FWD_FLOAT32__BatchSize_128__15896846132408021176/input[0]:128/input[1]:192/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_ADD_FWD_FLOAT32__BatchSize_128__9663694549647055304/input[0]:128/input[1]:224/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_ADD_FWD_FLOAT32__BatchSize_128__17706012286997702864/input[0]:128/input[1]:160/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_ADD_FWD_FLOAT32__BatchSize_128__2921893092905779892/input[0]:128/input[1]:96/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_MUL_FWD_FLOAT32__BatchSize_128__9245566870541569488/input[0]:128/input[1]:256/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_MUL_FWD_FLOAT32__BatchSize_128__16257068218681899274/input[0]:128/input[1]:160/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_MUL_FWD_FLOAT32__BatchSize_128__16131387623150485132/input[0]:128/input[1]:256/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_ADD_FWD_FLOAT32__BatchSize_128__6289868681804465568/input[0]:128/input[1]:160/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_ADD_FWD_FLOAT32__BatchSize_128__12328870842149517530/input[0]:128/input[1]:256/input[2]:8/input[3]:8/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_ADD_FWD_FLOAT32__BatchSize_128__3934023198703415674/input[0]:128/input[1]:256/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_MUL_FWD_FLOAT32__BatchSize_128__8495038592888692559/input[0]:128/input[1]:128/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_ADD_FWD_FLOAT32__BatchSize_128__10769968453352262078/input[0]:128/input[1]:352/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_MUL_FWD_FLOAT32__BatchSize_128__1139113796806332166/input[0]:128/input[1]:320/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_MUL_FWD_FLOAT32__BatchSize_128__10374336630329007463/input[0]:128/input[1]:128/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_ADD_FWD_FLOAT32__BatchSize_128__14193041908497393068/input[0]:128/input[1]:192/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_ADD_FWD_FLOAT32__BatchSize_128__4120691850972078541/input[0]:128/input[1]:128/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_ADD_FWD_FLOAT32__BatchSize_128__17218676028722520310/input[0]:1/input[1]:8/input[2]:-1/input[3]:-1/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD failed to cudnnSetTensor4dDescriptor",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_MUL_FWD_FLOAT32__BatchSize_128__14085589548115980342/input[0]:128/input[1]:224/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_ADD_FWD_FLOAT32__BatchSize_128__7555037439557170670/input[0]:128/input[1]:64/input[2]:28/input[3]:28/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_MUL_FWD_FLOAT32__BatchSize_128__2567107226118747412/input[0]:128/input[1]:352/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_MUL_FWD_FLOAT32__BatchSize_128__11614202227398649485/input[0]:128/input[1]:32/input[2]:28/input[3]:28/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_ADD_FWD_FLOAT32__BatchSize_128__13337514348088636332/input[0]:128/input[1]:320/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_ADD_FWD_FLOAT32__BatchSize_128__11978317872429573260/input[0]:128/input[1]:2048/input[2]:100/input[3]:100/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD failed to cudnnSetTensor4dDescriptor",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_ADD_FWD_FLOAT32__BatchSize_128__9894607138728858300/input[0]:128/input[1]:64/input[2]:64/input[3]:64/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_MUL_FWD_FLOAT32__BatchSize_128__10439549439521700577/input[0]:1/input[1]:192/input[2]:28/input[3]:28/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_MUL_FWD_FLOAT32__BatchSize_128__13201550915717165808/input[0]:1/input[1]:448/input[2]:28/input[3]:28/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_ADD_FWD_FLOAT32__BatchSize_128__8479361399082224796/input[0]:128/input[1]:224/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_MUL_FWD_FLOAT32__BatchSize_128__8223994299342444806/input[0]:128/input[1]:192/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_ADD_FWD_FLOAT32__BatchSize_128__950618074392442140/input[0]:128/input[1]:304/input[2]:100/input[3]:100/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_ADD_FWD_FLOAT32__BatchSize_128__1852862554614835749/input[0]:128/input[1]:2048/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_ADD_FWD_FLOAT32__BatchSize_128__4885645646132727830/input[0]:128/input[1]:1024/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_ADD_FWD_FLOAT32__BatchSize_128__16388021820960134678/input[0]:128/input[1]:512/input[2]:28/input[3]:28/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_ADD_FWD_FLOAT32__BatchSize_128__4987539310922689793/input[0]:128/input[1]:128/input[2]:28/input[3]:28/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_ADD_FWD_FLOAT32__BatchSize_128__7568471555481043494/input[0]:128/input[1]:256/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_ADD_FWD_FLOAT32__BatchSize_128__8418180691010534597/input[0]:128/input[1]:3/input[2]:112/input[3]:112/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_MUL_FWD_FLOAT32__BatchSize_128__13980807015759396975/input[0]:128/input[1]:3/input[2]:112/input[3]:112/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_ADD_FWD_FLOAT32__BatchSize_128__14235160675187721934/input[0]:128/input[1]:512/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_ADD_FWD_FLOAT32__BatchSize_128__11182065411661639650/input[0]:128/input[1]:64/input[2]:56/input[3]:56/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_ADD_FWD_FLOAT32__BatchSize_128__3883187674744536966/input[0]:128/input[1]:256/input[2]:56/input[3]:56/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_POOLING_FWD_FLOAT32__BatchSize_128__4987670874941180316<CUDNN_POOLING_MAX>/input[0]:128/input[1]:128/input[2]:55/input[3]:55/filter_height:3/filter_width:3/pad_height:0/pad_width:0/stride_height:2/stride_width:2/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_POOLING_FWD_FLOAT32__BatchSize_128__4987670874941180316<CUDNN_POOLING_MAX_DETERMINISTIC>/input[0]:128/input[1]:128/input[2]:55/input[3]:55/filter_height:3/filter_width:3/pad_height:0/pad_width:0/stride_height:2/stride_width:2/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_POOLING_FWD_FLOAT32__BatchSize_128__6554634258335844894<CUDNN_POOLING_MAX>/input[0]:128/input[1]:480/input[2]:14/input[3]:14/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_POOLING_FWD_FLOAT32__BatchSize_128__6554634258335844894<CUDNN_POOLING_MAX_DETERMINISTIC>/input[0]:128/input[1]:480/input[2]:14/input[3]:14/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_POOLING_FWD_FLOAT32__BatchSize_128__10014929859010889653<CUDNN_POOLING_MAX>/input[0]:1/input[1]:192/input[2]:55/input[3]:55/filter_height:3/filter_width:3/pad_height:0/pad_width:0/stride_height:2/stride_width:2/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_POOLING_FWD_FLOAT32__BatchSize_128__10014929859010889653<CUDNN_POOLING_MAX_DETERMINISTIC>/input[0]:1/input[1]:192/input[2]:55/input[3]:55/filter_height:3/filter_width:3/pad_height:0/pad_width:0/stride_height:2/stride_width:2/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_POOLING_FWD_FLOAT32__BatchSize_128__15146903995428275415<CUDNN_POOLING_AVERAGE_COUNT_INCLUDE_PADDING>/input[0]:128/input[1]:24/input[2]:56/input[3]:56/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_POOLING_FWD_FLOAT32__BatchSize_128__15146903995428275415<CUDNN_POOLING_AVERAGE_COUNT_EXCLUDE_PADDING>/input[0]:128/input[1]:24/input[2]:56/input[3]:56/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_POOLING_FWD_FLOAT32__BatchSize_128__2472086423123290291<CUDNN_POOLING_AVERAGE_COUNT_INCLUDE_PADDING>/input[0]:1/input[1]:136/input[2]:28/input[3]:28/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_POOLING_FWD_FLOAT32__BatchSize_128__2472086423123290291<CUDNN_POOLING_AVERAGE_COUNT_EXCLUDE_PADDING>/input[0]:1/input[1]:136/input[2]:28/input[3]:28/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_POOLING_FWD_FLOAT32__BatchSize_128__7573435973572634799<CUDNN_POOLING_AVERAGE_COUNT_INCLUDE_PADDING>/input[0]:1/input[1]:272/input[2]:14/input[3]:14/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_POOLING_FWD_FLOAT32__BatchSize_128__7573435973572634799<CUDNN_POOLING_AVERAGE_COUNT_EXCLUDE_PADDING>/input[0]:1/input[1]:272/input[2]:14/input[3]:14/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_POOLING_FWD_FLOAT32__BatchSize_128__12046916340716316446<CUDNN_POOLING_MAX>/input[0]:1/input[1]:832/input[2]:6/input[3]:6/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_POOLING_FWD_FLOAT32__BatchSize_128__12046916340716316446<CUDNN_POOLING_MAX_DETERMINISTIC>/input[0]:1/input[1]:832/input[2]:6/input[3]:6/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_POOLING_FWD_FLOAT32__BatchSize_128__12188622744918645100<CUDNN_POOLING_MAX>/input[0]:1/input[1]:64/input[2]:112/input[3]:112/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_POOLING_FWD_FLOAT32__BatchSize_128__12188622744918645100<CUDNN_POOLING_MAX_DETERMINISTIC>/input[0]:1/input[1]:64/input[2]:112/input[3]:112/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_POOLING_FWD_FLOAT32__BatchSize_128__9583991673165301151<CUDNN_POOLING_AVERAGE_COUNT_INCLUDE_PADDING>/input[0]:1/input[1]:1024/input[2]:6/input[3]:6/filter_height:7/filter_width:7/pad_height:0/pad_width:1/stride_height:1/stride_width:1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/POOLING_FWD failed to cudnnGetPooling2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_POOLING_FWD_FLOAT32__BatchSize_128__9583991673165301151<CUDNN_POOLING_AVERAGE_COUNT_EXCLUDE_PADDING>/input[0]:1/input[1]:1024/input[2]:6/input[3]:6/filter_height:7/filter_width:7/pad_height:0/pad_width:1/stride_height:1/stride_width:1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/POOLING_FWD failed to cudnnGetPooling2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_POOLING_FWD_FLOAT32__BatchSize_128__14261809621156750017<CUDNN_POOLING_MAX>/input[0]:1/input[1]:192/input[2]:27/input[3]:27/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_POOLING_FWD_FLOAT32__BatchSize_128__14261809621156750017<CUDNN_POOLING_MAX_DETERMINISTIC>/input[0]:1/input[1]:192/input[2]:27/input[3]:27/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_POOLING_FWD_FLOAT32__BatchSize_128__1901401565630734524<CUDNN_POOLING_MAX>/input[0]:128/input[1]:96/input[2]:109/input[3]:109/filter_height:3/filter_width:3/pad_height:0/pad_width:0/stride_height:2/stride_width:2/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_POOLING_FWD_FLOAT32__BatchSize_128__1901401565630734524<CUDNN_POOLING_MAX_DETERMINISTIC>/input[0]:128/input[1]:96/input[2]:109/input[3]:109/filter_height:3/filter_width:3/pad_height:0/pad_width:0/stride_height:2/stride_width:2/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_POOLING_FWD_FLOAT32__BatchSize_128__13223476246407754740<CUDNN_POOLING_MAX>/input[0]:128/input[1]:256/input[2]:25/input[3]:25/filter_height:3/filter_width:3/pad_height:0/pad_width:0/stride_height:2/stride_width:2/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_POOLING_FWD_FLOAT32__BatchSize_128__13223476246407754740<CUDNN_POOLING_MAX_DETERMINISTIC>/input[0]:128/input[1]:256/input[2]:25/input[3]:25/filter_height:3/filter_width:3/pad_height:0/pad_width:0/stride_height:2/stride_width:2/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_POOLING_FWD_FLOAT32__BatchSize_128__18025819889999712314<CUDNN_POOLING_AVERAGE_COUNT_INCLUDE_PADDING>/input[0]:1/input[1]:128/input[2]:56/input[3]:56/filter_height:2/filter_width:2/pad_height:0/pad_width:0/stride_height:2/stride_width:2/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_POOLING_FWD_FLOAT32__BatchSize_128__18025819889999712314<CUDNN_POOLING_AVERAGE_COUNT_EXCLUDE_PADDING>/input[0]:1/input[1]:128/input[2]:56/input[3]:56/filter_height:2/filter_width:2/pad_height:0/pad_width:0/stride_height:2/stride_width:2/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_POOLING_FWD_FLOAT32__BatchSize_128__12892920817041115801<CUDNN_POOLING_MAX>/input[0]:1/input[1]:256/input[2]:27/input[3]:27/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_POOLING_FWD_FLOAT32__BatchSize_128__12892920817041115801<CUDNN_POOLING_MAX_DETERMINISTIC>/input[0]:1/input[1]:256/input[2]:27/input[3]:27/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_POOLING_FWD_FLOAT32__BatchSize_128__11897532277767615078<CUDNN_POOLING_MAX>/input[0]:128/input[1]:512/input[2]:12/input[3]:12/filter_height:2/filter_width:2/pad_height:0/pad_width:0/stride_height:2/stride_width:2/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_POOLING_FWD_FLOAT32__BatchSize_128__11897532277767615078<CUDNN_POOLING_MAX_DETERMINISTIC>/input[0]:128/input[1]:512/input[2]:12/input[3]:12/filter_height:2/filter_width:2/pad_height:0/pad_width:0/stride_height:2/stride_width:2/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_POOLING_FWD_FLOAT32__BatchSize_128__12740391965218566735<CUDNN_POOLING_MAX>/input[0]:1/input[1]:480/input[2]:27/input[3]:27/filter_height:3/filter_width:3/pad_height:0/pad_width:0/stride_height:2/stride_width:2/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_POOLING_FWD_FLOAT32__BatchSize_128__12740391965218566735<CUDNN_POOLING_MAX_DETERMINISTIC>/input[0]:1/input[1]:480/input[2]:27/input[3]:27/filter_height:3/filter_width:3/pad_height:0/pad_width:0/stride_height:2/stride_width:2/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_POOLING_FWD_FLOAT32__BatchSize_128__16584370666109172630<CUDNN_POOLING_AVERAGE_COUNT_INCLUDE_PADDING>/input[0]:1/input[1]:256/input[2]:28/input[3]:28/filter_height:2/filter_width:2/pad_height:0/pad_width:0/stride_height:2/stride_width:2/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_POOLING_FWD_FLOAT32__BatchSize_128__16584370666109172630<CUDNN_POOLING_AVERAGE_COUNT_EXCLUDE_PADDING>/input[0]:1/input[1]:256/input[2]:28/input[3]:28/filter_height:2/filter_width:2/pad_height:0/pad_width:0/stride_height:2/stride_width:2/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_POOLING_FWD_FLOAT32__BatchSize_128__2688241428392343040<CUDNN_POOLING_MAX>/input[0]:128/input[1]:96/input[2]:54/input[3]:54/filter_height:3/filter_width:3/pad_height:0/pad_width:0/stride_height:2/stride_width:2/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_POOLING_FWD_FLOAT32__BatchSize_128__2688241428392343040<CUDNN_POOLING_MAX_DETERMINISTIC>/input[0]:128/input[1]:96/input[2]:54/input[3]:54/filter_height:3/filter_width:3/pad_height:0/pad_width:0/stride_height:2/stride_width:2/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_POOLING_FWD_FLOAT32__BatchSize_128__15272039671985705637<CUDNN_POOLING_MAX>/input[0]:128/input[1]:8/input[2]:28/input[3]:28/filter_height:2/filter_width:2/pad_height:0/pad_width:0/stride_height:2/stride_width:2/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_POOLING_FWD_FLOAT32__BatchSize_128__15272039671985705637<CUDNN_POOLING_MAX_DETERMINISTIC>/input[0]:128/input[1]:8/input[2]:28/input[3]:28/filter_height:2/filter_width:2/pad_height:0/pad_width:0/stride_height:2/stride_width:2/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_POOLING_FWD_FLOAT32__BatchSize_128__30349846265042425<CUDNN_POOLING_MAX>/input[0]:128/input[1]:16/input[2]:14/input[3]:14/filter_height:3/filter_width:3/pad_height:0/pad_width:0/stride_height:3/stride_width:3/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_POOLING_FWD_FLOAT32__BatchSize_128__30349846265042425<CUDNN_POOLING_MAX_DETERMINISTIC>/input[0]:128/input[1]:16/input[2]:14/input[3]:14/filter_height:3/filter_width:3/pad_height:0/pad_width:0/stride_height:3/stride_width:3/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_POOLING_FWD_FLOAT32__BatchSize_128__14568780168263494705<CUDNN_POOLING_AVERAGE_COUNT_INCLUDE_PADDING>/input[0]:128/input[1]:1000/input[2]:13/input[3]:13/filter_height:13/filter_width:13/pad_height:0/pad_width:0/stride_height:13/stride_width:13/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_POOLING_FWD_FLOAT32__BatchSize_128__14568780168263494705<CUDNN_POOLING_AVERAGE_COUNT_EXCLUDE_PADDING>/input[0]:128/input[1]:1000/input[2]:13/input[3]:13/filter_height:13/filter_width:13/pad_height:0/pad_width:0/stride_height:13/stride_width:13/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_POOLING_FWD_FLOAT32__BatchSize_128__10732800990514878085<CUDNN_POOLING_MAX>/input[0]:128/input[1]:64/input[2]:111/input[3]:111/filter_height:3/filter_width:3/pad_height:0/pad_width:0/stride_height:2/stride_width:2/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_POOLING_FWD_FLOAT32__BatchSize_128__10732800990514878085<CUDNN_POOLING_MAX_DETERMINISTIC>/input[0]:128/input[1]:64/input[2]:111/input[3]:111/filter_height:3/filter_width:3/pad_height:0/pad_width:0/stride_height:2/stride_width:2/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_POOLING_FWD_FLOAT32__BatchSize_128__4772049457172707298<CUDNN_POOLING_MAX>/input[0]:128/input[1]:512/input[2]:14/input[3]:14/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_POOLING_FWD_FLOAT32__BatchSize_128__4772049457172707298<CUDNN_POOLING_MAX_DETERMINISTIC>/input[0]:128/input[1]:512/input[2]:14/input[3]:14/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_POOLING_FWD_FLOAT32__BatchSize_128__954531217519849600<CUDNN_POOLING_MAX>/input[0]:128/input[1]:256/input[2]:26/input[3]:26/filter_height:3/filter_width:3/pad_height:0/pad_width:0/stride_height:2/stride_width:2/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_POOLING_FWD_FLOAT32__BatchSize_128__954531217519849600<CUDNN_POOLING_MAX_DETERMINISTIC>/input[0]:128/input[1]:256/input[2]:26/input[3]:26/filter_height:3/filter_width:3/pad_height:0/pad_width:0/stride_height:2/stride_width:2/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_POOLING_FWD_FLOAT32__BatchSize_128__11544484622659589566<CUDNN_POOLING_MAX>/input[0]:128/input[1]:256/input[2]:12/input[3]:12/filter_height:3/filter_width:3/pad_height:0/pad_width:1/stride_height:2/stride_width:2/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_POOLING_FWD_FLOAT32__BatchSize_128__11544484622659589566<CUDNN_POOLING_MAX_DETERMINISTIC>/input[0]:128/input[1]:256/input[2]:12/input[3]:12/filter_height:3/filter_width:3/pad_height:0/pad_width:1/stride_height:2/stride_width:2/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_POOLING_FWD_FLOAT32__BatchSize_128__3219630457710520779<CUDNN_POOLING_MAX>/input[0]:1/input[1]:480/input[2]:13/input[3]:13/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_POOLING_FWD_FLOAT32__BatchSize_128__3219630457710520779<CUDNN_POOLING_MAX_DETERMINISTIC>/input[0]:1/input[1]:480/input[2]:13/input[3]:13/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_POOLING_FWD_FLOAT32__BatchSize_128__2213622606922862094<CUDNN_POOLING_MAX>/input[0]:128/input[1]:832/input[2]:14/input[3]:14/filter_height:3/filter_width:3/pad_height:0/pad_width:2/stride_height:2/stride_width:2/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_POOLING_FWD_FLOAT32__BatchSize_128__2213622606922862094<CUDNN_POOLING_MAX_DETERMINISTIC>/input[0]:128/input[1]:832/input[2]:14/input[3]:14/filter_height:3/filter_width:3/pad_height:0/pad_width:2/stride_height:2/stride_width:2/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_POOLING_FWD_FLOAT32__BatchSize_128__3795202866414374941<CUDNN_POOLING_MAX>/input[0]:128/input[1]:528/input[2]:14/input[3]:14/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_POOLING_FWD_FLOAT32__BatchSize_128__3795202866414374941<CUDNN_POOLING_MAX_DETERMINISTIC>/input[0]:128/input[1]:528/input[2]:14/input[3]:14/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_POOLING_FWD_FLOAT32__BatchSize_128__16320534206257659956<CUDNN_POOLING_MAX>/input[0]:128/input[1]:128/input[2]:400/input[3]:400/filter_height:3/filter_width:3/pad_height:0/pad_width:0/stride_height:2/stride_width:2/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD failed to cudnnSetTensor4dDescriptor",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_POOLING_FWD_FLOAT32__BatchSize_128__16320534206257659956<CUDNN_POOLING_MAX_DETERMINISTIC>/input[0]:128/input[1]:128/input[2]:400/input[3]:400/filter_height:3/filter_width:3/pad_height:0/pad_width:0/stride_height:2/stride_width:2/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD failed to cudnnSetTensor4dDescriptor",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_POOLING_FWD_FLOAT32__BatchSize_128__3774412604688307255<CUDNN_POOLING_MAX>/input[0]:1/input[1]:512/input[2]:13/input[3]:13/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_POOLING_FWD_FLOAT32__BatchSize_128__3774412604688307255<CUDNN_POOLING_MAX_DETERMINISTIC>/input[0]:1/input[1]:512/input[2]:13/input[3]:13/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_POOLING_FWD_FLOAT32__BatchSize_128__15538013285487836495<CUDNN_POOLING_MAX>/input[0]:128/input[1]:832/input[2]:7/input[3]:7/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_POOLING_FWD_FLOAT32__BatchSize_128__15538013285487836495<CUDNN_POOLING_MAX_DETERMINISTIC>/input[0]:128/input[1]:832/input[2]:7/input[3]:7/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_POOLING_FWD_FLOAT32__BatchSize_128__17896406744012089780<CUDNN_POOLING_AVERAGE_COUNT_INCLUDE_PADDING>/input[0]:1/input[1]:512/input[2]:14/input[3]:14/filter_height:2/filter_width:2/pad_height:0/pad_width:0/stride_height:2/stride_width:2/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_POOLING_FWD_FLOAT32__BatchSize_128__17896406744012089780<CUDNN_POOLING_AVERAGE_COUNT_EXCLUDE_PADDING>/input[0]:1/input[1]:512/input[2]:14/input[3]:14/filter_height:2/filter_width:2/pad_height:0/pad_width:0/stride_height:2/stride_width:2/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_POOLING_FWD_FLOAT32__BatchSize_128__745201977981313116<CUDNN_POOLING_MAX>/input[0]:128/input[1]:128/input[2]:32/input[3]:32/filter_height:2/filter_width:2/pad_height:0/pad_width:0/stride_height:2/stride_width:2/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_POOLING_FWD_FLOAT32__BatchSize_128__745201977981313116<CUDNN_POOLING_MAX_DETERMINISTIC>/input[0]:128/input[1]:128/input[2]:32/input[3]:32/filter_height:2/filter_width:2/pad_height:0/pad_width:0/stride_height:2/stride_width:2/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_POOLING_FWD_FLOAT32__BatchSize_128__12756378019358793297<CUDNN_POOLING_MAX>/input[0]:128/input[1]:64/input[2]:64/input[3]:64/filter_height:2/filter_width:2/pad_height:0/pad_width:0/stride_height:2/stride_width:2/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_POOLING_FWD_FLOAT32__BatchSize_128__12756378019358793297<CUDNN_POOLING_MAX_DETERMINISTIC>/input[0]:128/input[1]:64/input[2]:64/input[3]:64/filter_height:2/filter_width:2/pad_height:0/pad_width:0/stride_height:2/stride_width:2/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_POOLING_FWD_FLOAT32__BatchSize_128__17252000733506113433<CUDNN_POOLING_MAX>/input[0]:128/input[1]:192/input[2]:56/input[3]:56/filter_height:3/filter_width:3/pad_height:0/pad_width:2/stride_height:2/stride_width:2/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_POOLING_FWD_FLOAT32__BatchSize_128__17252000733506113433<CUDNN_POOLING_MAX_DETERMINISTIC>/input[0]:128/input[1]:192/input[2]:56/input[3]:56/filter_height:3/filter_width:3/pad_height:0/pad_width:2/stride_height:2/stride_width:2/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_POOLING_FWD_FLOAT32__BatchSize_128__16216068964442360280<CUDNN_POOLING_MAX>/input[0]:128/input[1]:256/input[2]:16/input[3]:16/filter_height:2/filter_width:2/pad_height:0/pad_width:0/stride_height:2/stride_width:2/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_POOLING_FWD_FLOAT32__BatchSize_128__16216068964442360280<CUDNN_POOLING_MAX_DETERMINISTIC>/input[0]:128/input[1]:256/input[2]:16/input[3]:16/filter_height:2/filter_width:2/pad_height:0/pad_width:0/stride_height:2/stride_width:2/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_POOLING_FWD_FLOAT32__BatchSize_128__3502244002183751412<CUDNN_POOLING_MAX>/input[0]:128/input[1]:64/input[2]:112/input[3]:112/filter_height:3/filter_width:3/pad_height:0/pad_width:2/stride_height:2/stride_width:2/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_POOLING_FWD_FLOAT32__BatchSize_128__3502244002183751412<CUDNN_POOLING_MAX_DETERMINISTIC>/input[0]:128/input[1]:64/input[2]:112/input[3]:112/filter_height:3/filter_width:3/pad_height:0/pad_width:2/stride_height:2/stride_width:2/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_POOLING_FWD_FLOAT32__BatchSize_128__14389414007329128210<CUDNN_POOLING_MAX>/input[0]:128/input[1]:192/input[2]:56/input[3]:56/filter_height:3/filter_width:3/pad_height:0/pad_width:1/stride_height:2/stride_width:2/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_POOLING_FWD_FLOAT32__BatchSize_128__14389414007329128210<CUDNN_POOLING_MAX_DETERMINISTIC>/input[0]:128/input[1]:192/input[2]:56/input[3]:56/filter_height:3/filter_width:3/pad_height:0/pad_width:1/stride_height:2/stride_width:2/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_POOLING_FWD_FLOAT32__BatchSize_128__4824363524686328776<CUDNN_POOLING_MAX>/input[0]:1/input[1]:528/input[2]:13/input[3]:13/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_POOLING_FWD_FLOAT32__BatchSize_128__4824363524686328776<CUDNN_POOLING_MAX_DETERMINISTIC>/input[0]:1/input[1]:528/input[2]:13/input[3]:13/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_POOLING_FWD_FLOAT32__BatchSize_128__14520331911326150431<CUDNN_POOLING_AVERAGE_COUNT_INCLUDE_PADDING>/input[0]:128/input[1]:192/input[2]:28/input[3]:28/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_POOLING_FWD_FLOAT32__BatchSize_128__14520331911326150431<CUDNN_POOLING_AVERAGE_COUNT_EXCLUDE_PADDING>/input[0]:128/input[1]:192/input[2]:28/input[3]:28/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_POOLING_FWD_FLOAT32__BatchSize_128__7591051439236236770<CUDNN_POOLING_MAX>/input[0]:1/input[1]:832/input[2]:13/input[3]:13/filter_height:3/filter_width:3/pad_height:0/pad_width:0/stride_height:2/stride_width:2/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_POOLING_FWD_FLOAT32__BatchSize_128__7591051439236236770<CUDNN_POOLING_MAX_DETERMINISTIC>/input[0]:1/input[1]:832/input[2]:13/input[3]:13/filter_height:3/filter_width:3/pad_height:0/pad_width:0/stride_height:2/stride_width:2/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_POOLING_FWD_FLOAT32__BatchSize_128__13727657301277361991<CUDNN_POOLING_AVERAGE_COUNT_INCLUDE_PADDING>/input[0]:128/input[1]:256/input[2]:28/input[3]:28/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_POOLING_FWD_FLOAT32__BatchSize_128__13727657301277361991<CUDNN_POOLING_AVERAGE_COUNT_EXCLUDE_PADDING>/input[0]:128/input[1]:256/input[2]:28/input[3]:28/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_POOLING_FWD_FLOAT32__BatchSize_128__11485013337624778164<CUDNN_POOLING_AVERAGE_COUNT_INCLUDE_PADDING>/input[0]:128/input[1]:576/input[2]:14/input[3]:14/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_POOLING_FWD_FLOAT32__BatchSize_128__11485013337624778164<CUDNN_POOLING_AVERAGE_COUNT_EXCLUDE_PADDING>/input[0]:128/input[1]:576/input[2]:14/input[3]:14/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_POOLING_FWD_FLOAT32__BatchSize_128__12924893865057950128<CUDNN_POOLING_MAX>/input[0]:128/input[1]:320/input[2]:28/input[3]:28/filter_height:3/filter_width:3/pad_height:0/pad_width:1/stride_height:2/stride_width:2/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_POOLING_FWD_FLOAT32__BatchSize_128__12924893865057950128<CUDNN_POOLING_MAX_DETERMINISTIC>/input[0]:128/input[1]:320/input[2]:28/input[3]:28/filter_height:3/filter_width:3/pad_height:0/pad_width:1/stride_height:2/stride_width:2/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_POOLING_FWD_FLOAT32__BatchSize_128__6873445933493553392<CUDNN_POOLING_MAX>/input[0]:128/input[1]:256/input[2]:8/input[3]:8/filter_height:2/filter_width:2/pad_height:0/pad_width:0/stride_height:2/stride_width:2/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_POOLING_FWD_FLOAT32__BatchSize_128__6873445933493553392<CUDNN_POOLING_MAX_DETERMINISTIC>/input[0]:128/input[1]:256/input[2]:8/input[3]:8/filter_height:2/filter_width:2/pad_height:0/pad_width:0/stride_height:2/stride_width:2/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_POOLING_FWD_FLOAT32__BatchSize_128__6599230399380967157<CUDNN_POOLING_MAX>/input[0]:128/input[1]:576/input[2]:14/input[3]:14/filter_height:3/filter_width:3/pad_height:0/pad_width:1/stride_height:2/stride_width:2/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_POOLING_FWD_FLOAT32__BatchSize_128__6599230399380967157<CUDNN_POOLING_MAX_DETERMINISTIC>/input[0]:128/input[1]:576/input[2]:14/input[3]:14/filter_height:3/filter_width:3/pad_height:0/pad_width:1/stride_height:2/stride_width:2/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_POOLING_FWD_FLOAT32__BatchSize_128__5451929663193097839<CUDNN_POOLING_MAX>/input[0]:128/input[1]:1024/input[2]:7/input[3]:7/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_POOLING_FWD_FLOAT32__BatchSize_128__5451929663193097839<CUDNN_POOLING_MAX_DETERMINISTIC>/input[0]:128/input[1]:1024/input[2]:7/input[3]:7/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_POOLING_FWD_FLOAT32__BatchSize_128__15919742622928504700<CUDNN_POOLING_AVERAGE_COUNT_INCLUDE_PADDING>/input[0]:128/input[1]:1024/input[2]:7/input[3]:7/filter_height:7/filter_width:7/pad_height:0/pad_width:0/stride_height:1/stride_width:1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_POOLING_FWD_FLOAT32__BatchSize_128__15919742622928504700<CUDNN_POOLING_AVERAGE_COUNT_EXCLUDE_PADDING>/input[0]:128/input[1]:1024/input[2]:7/input[3]:7/filter_height:7/filter_width:7/pad_height:0/pad_width:0/stride_height:1/stride_width:1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_POOLING_FWD_FLOAT32__BatchSize_128__6736393049128911225<CUDNN_POOLING_MAX>/input[0]:128/input[1]:16/input[2]:416/input[3]:416/filter_height:2/filter_width:2/pad_height:0/pad_width:0/stride_height:2/stride_width:2/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_POOLING_FWD_FLOAT32__BatchSize_128__6736393049128911225<CUDNN_POOLING_MAX_DETERMINISTIC>/input[0]:128/input[1]:16/input[2]:416/input[3]:416/filter_height:2/filter_width:2/pad_height:0/pad_width:0/stride_height:2/stride_width:2/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_POOLING_FWD_FLOAT32__BatchSize_128__6906416060005709103<CUDNN_POOLING_MAX>/input[0]:128/input[1]:480/input[2]:28/input[3]:28/filter_height:3/filter_width:3/pad_height:0/pad_width:2/stride_height:2/stride_width:2/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_POOLING_FWD_FLOAT32__BatchSize_128__6906416060005709103<CUDNN_POOLING_MAX_DETERMINISTIC>/input[0]:128/input[1]:480/input[2]:28/input[3]:28/filter_height:3/filter_width:3/pad_height:0/pad_width:2/stride_height:2/stride_width:2/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_POOLING_FWD_FLOAT32__BatchSize_128__7663263071795423919<CUDNN_POOLING_MAX>/input[0]:128/input[1]:32/input[2]:208/input[3]:208/filter_height:2/filter_width:2/pad_height:0/pad_width:0/stride_height:2/stride_width:2/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_POOLING_FWD_FLOAT32__BatchSize_128__7663263071795423919<CUDNN_POOLING_MAX_DETERMINISTIC>/input[0]:128/input[1]:32/input[2]:208/input[3]:208/filter_height:2/filter_width:2/pad_height:0/pad_width:0/stride_height:2/stride_width:2/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_POOLING_FWD_FLOAT32__BatchSize_128__3674469098584854392<CUDNN_POOLING_MAX>/input[0]:128/input[1]:128/input[2]:52/input[3]:52/filter_height:2/filter_width:2/pad_height:0/pad_width:0/stride_height:2/stride_width:2/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_POOLING_FWD_FLOAT32__BatchSize_128__3674469098584854392<CUDNN_POOLING_MAX_DETERMINISTIC>/input[0]:128/input[1]:128/input[2]:52/input[3]:52/filter_height:2/filter_width:2/pad_height:0/pad_width:0/stride_height:2/stride_width:2/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_POOLING_FWD_FLOAT32__BatchSize_128__3805536138759449524<CUDNN_POOLING_MAX>/input[0]:128/input[1]:256/input[2]:26/input[3]:26/filter_height:2/filter_width:2/pad_height:0/pad_width:0/stride_height:2/stride_width:2/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_POOLING_FWD_FLOAT32__BatchSize_128__3805536138759449524<CUDNN_POOLING_MAX_DETERMINISTIC>/input[0]:128/input[1]:256/input[2]:26/input[3]:26/filter_height:2/filter_width:2/pad_height:0/pad_width:0/stride_height:2/stride_width:2/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_POOLING_FWD_FLOAT32__BatchSize_128__18076217970140493262<CUDNN_POOLING_MAX>/input[0]:128/input[1]:256/input[2]:27/input[3]:27/filter_height:3/filter_width:3/pad_height:0/pad_width:1/stride_height:2/stride_width:2/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_POOLING_FWD_FLOAT32__BatchSize_128__18076217970140493262<CUDNN_POOLING_MAX_DETERMINISTIC>/input[0]:128/input[1]:256/input[2]:27/input[3]:27/filter_height:3/filter_width:3/pad_height:0/pad_width:1/stride_height:2/stride_width:2/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_POOLING_FWD_FLOAT32__BatchSize_128__10778577188711766178<CUDNN_POOLING_MAX>/input[0]:128/input[1]:512/input[2]:13/input[3]:13/filter_height:2/filter_width:2/pad_height:0/pad_width:0/stride_height:1/stride_width:1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_POOLING_FWD_FLOAT32__BatchSize_128__10778577188711766178<CUDNN_POOLING_MAX_DETERMINISTIC>/input[0]:128/input[1]:512/input[2]:13/input[3]:13/filter_height:2/filter_width:2/pad_height:0/pad_width:0/stride_height:1/stride_width:1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_POOLING_FWD_FLOAT32__BatchSize_128__7633103954448191294<CUDNN_POOLING_MAX>/input[0]:128/input[1]:256/input[2]:13/input[3]:13/filter_height:3/filter_width:3/pad_height:0/pad_width:1/stride_height:2/stride_width:2/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_POOLING_FWD_FLOAT32__BatchSize_128__7633103954448191294<CUDNN_POOLING_MAX_DETERMINISTIC>/input[0]:128/input[1]:256/input[2]:13/input[3]:13/filter_height:3/filter_width:3/pad_height:0/pad_width:1/stride_height:2/stride_width:2/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_POOLING_FWD_FLOAT32__BatchSize_128__2663553416683724345<CUDNN_POOLING_MAX>/input[0]:128/input[1]:96/input[2]:54/input[3]:54/filter_height:3/filter_width:3/pad_height:0/pad_width:2/stride_height:2/stride_width:2/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_POOLING_FWD_FLOAT32__BatchSize_128__2663553416683724345<CUDNN_POOLING_MAX_DETERMINISTIC>/input[0]:128/input[1]:96/input[2]:54/input[3]:54/filter_height:3/filter_width:3/pad_height:0/pad_width:2/stride_height:2/stride_width:2/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_POOLING_FWD_FLOAT32__BatchSize_128__1253180533452451524<CUDNN_POOLING_MAX>/input[0]:128/input[1]:24/input[2]:112/input[3]:112/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_POOLING_FWD_FLOAT32__BatchSize_128__1253180533452451524<CUDNN_POOLING_MAX_DETERMINISTIC>/input[0]:128/input[1]:24/input[2]:112/input[3]:112/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_POOLING_FWD_FLOAT32__BatchSize_128__9178069187549969374<CUDNN_POOLING_MAX>/input[0]:128/input[1]:512/input[2]:28/input[3]:28/filter_height:2/filter_width:2/pad_height:0/pad_width:0/stride_height:2/stride_width:2/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_POOLING_FWD_FLOAT32__BatchSize_128__9178069187549969374<CUDNN_POOLING_MAX_DETERMINISTIC>/input[0]:128/input[1]:512/input[2]:28/input[3]:28/filter_height:2/filter_width:2/pad_height:0/pad_width:0/stride_height:2/stride_width:2/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_POOLING_FWD_FLOAT32__BatchSize_128__2070394493293175691<CUDNN_POOLING_AVERAGE_COUNT_INCLUDE_PADDING>/input[0]:1/input[1]:544/input[2]:7/input[3]:7/filter_height:7/filter_width:7/pad_height:0/pad_width:0/stride_height:1/stride_width:1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_POOLING_FWD_FLOAT32__BatchSize_128__2070394493293175691<CUDNN_POOLING_AVERAGE_COUNT_EXCLUDE_PADDING>/input[0]:1/input[1]:544/input[2]:7/input[3]:7/filter_height:7/filter_width:7/pad_height:0/pad_width:0/stride_height:1/stride_width:1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_POOLING_FWD_FLOAT32__BatchSize_128__17248544316990788801<CUDNN_POOLING_MAX>/input[0]:128/input[1]:64/input[2]:104/input[3]:104/filter_height:2/filter_width:2/pad_height:0/pad_width:0/stride_height:2/stride_width:2/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_POOLING_FWD_FLOAT32__BatchSize_128__17248544316990788801<CUDNN_POOLING_MAX_DETERMINISTIC>/input[0]:128/input[1]:64/input[2]:104/input[3]:104/filter_height:2/filter_width:2/pad_height:0/pad_width:0/stride_height:2/stride_width:2/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_POOLING_FWD_FLOAT32__BatchSize_128__10093265983642525405<CUDNN_POOLING_MAX>/input[0]:128/input[1]:64/input[2]:224/input[3]:224/filter_height:2/filter_width:2/pad_height:0/pad_width:0/stride_height:2/stride_width:2/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_POOLING_FWD_FLOAT32__BatchSize_128__10093265983642525405<CUDNN_POOLING_MAX_DETERMINISTIC>/input[0]:128/input[1]:64/input[2]:224/input[3]:224/filter_height:2/filter_width:2/pad_height:0/pad_width:0/stride_height:2/stride_width:2/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_POOLING_FWD_FLOAT32__BatchSize_128__6302790647592549560<CUDNN_POOLING_MAX>/input[0]:128/input[1]:128/input[2]:112/input[3]:112/filter_height:2/filter_width:2/pad_height:0/pad_width:0/stride_height:2/stride_width:2/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_POOLING_FWD_FLOAT32__BatchSize_128__6302790647592549560<CUDNN_POOLING_MAX_DETERMINISTIC>/input[0]:128/input[1]:128/input[2]:112/input[3]:112/filter_height:2/filter_width:2/pad_height:0/pad_width:0/stride_height:2/stride_width:2/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_POOLING_FWD_FLOAT32__BatchSize_128__14350319107604291581<CUDNN_POOLING_MAX>/input[0]:128/input[1]:64/input[2]:112/input[3]:112/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_POOLING_FWD_FLOAT32__BatchSize_128__14350319107604291581<CUDNN_POOLING_MAX_DETERMINISTIC>/input[0]:128/input[1]:64/input[2]:112/input[3]:112/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_POOLING_FWD_FLOAT32__BatchSize_128__11539098735059178700<CUDNN_POOLING_MAX>/input[0]:128/input[1]:256/input[2]:56/input[3]:56/filter_height:2/filter_width:2/pad_height:0/pad_width:0/stride_height:2/stride_width:2/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_POOLING_FWD_FLOAT32__BatchSize_128__11539098735059178700<CUDNN_POOLING_MAX_DETERMINISTIC>/input[0]:128/input[1]:256/input[2]:56/input[3]:56/filter_height:2/filter_width:2/pad_height:0/pad_width:0/stride_height:2/stride_width:2/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_POOLING_FWD_FLOAT32__BatchSize_128__8402713719283813794<CUDNN_POOLING_MAX>/input[0]:128/input[1]:512/input[2]:14/input[3]:14/filter_height:2/filter_width:2/pad_height:0/pad_width:0/stride_height:2/stride_width:2/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_POOLING_FWD_FLOAT32__BatchSize_128__8402713719283813794<CUDNN_POOLING_MAX_DETERMINISTIC>/input[0]:128/input[1]:512/input[2]:14/input[3]:14/filter_height:2/filter_width:2/pad_height:0/pad_width:0/stride_height:2/stride_width:2/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_SOFTMAX_FWD_FLOAT32__BatchSize_128__10869317846957800128<CUDNN_SOFTMAX_FAST, CUDNN_SOFTMAX_MODE_INSTANCE>/input[0]:1/input[1]:1000/input[2]:-1/input[3]:-1/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_SOFTMAX_FWD_FLOAT32__BatchSize_128__10869317846957800128<CUDNN_SOFTMAX_FAST, CUDNN_SOFTMAX_MODE_CHANNEL>/input[0]:1/input[1]:1000/input[2]:-1/input[3]:-1/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_SOFTMAX_FWD_FLOAT32__BatchSize_128__10869317846957800128<CUDNN_SOFTMAX_ACCURATE, CUDNN_SOFTMAX_MODE_INSTANCE>/input[0]:1/input[1]:1000/input[2]:-1/input[3]:-1/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_SOFTMAX_FWD_FLOAT32__BatchSize_128__10869317846957800128<CUDNN_SOFTMAX_ACCURATE, CUDNN_SOFTMAX_MODE_CHANNEL>/input[0]:1/input[1]:1000/input[2]:-1/input[3]:-1/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_SOFTMAX_FWD_FLOAT32__BatchSize_128__10869317846957800128<CUDNN_SOFTMAX_LOG, CUDNN_SOFTMAX_MODE_INSTANCE>/input[0]:1/input[1]:1000/input[2]:-1/input[3]:-1/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_SOFTMAX_FWD_FLOAT32__BatchSize_128__10869317846957800128<CUDNN_SOFTMAX_LOG, CUDNN_SOFTMAX_MODE_CHANNEL>/input[0]:1/input[1]:1000/input[2]:-1/input[3]:-1/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_SOFTMAX_FWD_FLOAT32__BatchSize_128__15296824738350132482<CUDNN_SOFTMAX_FAST, CUDNN_SOFTMAX_MODE_INSTANCE>/input[0]:128/input[1]:19/input[2]:10000/input[3]:-1/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_SOFTMAX_FWD_FLOAT32__BatchSize_128__15296824738350132482<CUDNN_SOFTMAX_FAST, CUDNN_SOFTMAX_MODE_CHANNEL>/input[0]:128/input[1]:19/input[2]:10000/input[3]:-1/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_SOFTMAX_FWD_FLOAT32__BatchSize_128__15296824738350132482<CUDNN_SOFTMAX_ACCURATE, CUDNN_SOFTMAX_MODE_INSTANCE>/input[0]:128/input[1]:19/input[2]:10000/input[3]:-1/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_SOFTMAX_FWD_FLOAT32__BatchSize_128__15296824738350132482<CUDNN_SOFTMAX_ACCURATE, CUDNN_SOFTMAX_MODE_CHANNEL>/input[0]:128/input[1]:19/input[2]:10000/input[3]:-1/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_SOFTMAX_FWD_FLOAT32__BatchSize_128__15296824738350132482<CUDNN_SOFTMAX_LOG, CUDNN_SOFTMAX_MODE_INSTANCE>/input[0]:128/input[1]:19/input[2]:10000/input[3]:-1/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_SOFTMAX_FWD_FLOAT32__BatchSize_128__15296824738350132482<CUDNN_SOFTMAX_LOG, CUDNN_SOFTMAX_MODE_CHANNEL>/input[0]:128/input[1]:19/input[2]:10000/input[3]:-1/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    }
  ]
}
