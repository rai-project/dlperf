{
  "context": {
    "date": "2019-09-15 21:37:27",
    "executable": "./scope",
    "num_cpus": 20,
    "mhz_per_cpu": 4500,
    "cpu_scaling_enabled": true,
    "caches": [
      {
        "type": "Data",
        "level": 1,
        "size": 32000000,
        "num_sharing": 2
      },
      {
        "type": "Instruction",
        "level": 1,
        "size": 32000000,
        "num_sharing": 2
      },
      {
        "type": "Unified",
        "level": 2,
        "size": 1024000000,
        "num_sharing": 2
      },
      {
        "type": "Unified",
        "level": 3,
        "size": 14080000000,
        "num_sharing": 20
      }
    ],
    "library_build_type": "release"
  },
  "benchmarks": [
    {
      "name": "LAYER_CUBLAS_GEMM_FWD_FLOAT32__BatchSize_128__17676855649145509353/input[0]:128/input[1]:1000/input[2]:512/input[3]:0/input[4]:1/input[5]:1/input[6]:1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 22365,
      "real_time": 3.1298224338977703e+04,
      "cpu_time": 3.6464241940530956e+04,
      "time_unit": "ns",
      "items_per_second": 2.0939207058588232e+12,
      "K": 5.1200000000000000e+02,
      "M": 1.2800000000000000e+02,
      "N": 1.0000000000000000e+03,
      "alpha": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cublas_gemm_fwd.cpp": 7.2770906096155412e+18,
      "benchmark_func:void iLAYER_CUBLAS_GEMM_FWD_Impl(benchmark::State&) [with T = float]": 7.4787548781531884e+18,
      "beta": 1.0000000000000000e+00,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUBLAS_GEMM_FWD_Impl": 1.7610984762236383e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 1.0000000000000000e+03,
      "input[2]": 5.1200000000000000e+02,
      "input[3]": 0.0000000000000000e+00,
      "input[4]": 1.0000000000000000e+00,
      "input[5]": 1.0000000000000000e+00,
      "input[6]": 1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "lda": 1.2800000000000000e+02,
      "ldb": 1.0000000000000000e+03,
      "num_iterations": 2.2365000000000000e+04,
      "predicted_flops": 4.1878414117176465e+12,
      "predicted_flops_count": 1.3107200000000000e+08,
      "transA": 0.0000000000000000e+00,
      "transB": 1.0000000000000000e+00
    },
    {
      "name": "LAYER_CUBLAS_GEMM_FWD_FLOAT32__BatchSize_128__16937435199922785188/input[0]:128/input[1]:1000/input[2]:2048/input[3]:0/input[4]:1/input[5]:1/input[6]:1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 6734,
      "real_time": 1.0396514743503621e+05,
      "cpu_time": 1.0926046183546406e+05,
      "time_unit": "ns",
      "items_per_second": 2.5214603784773511e+12,
      "K": 2.0480000000000000e+03,
      "M": 1.2800000000000000e+02,
      "N": 1.0000000000000000e+03,
      "alpha": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cublas_gemm_fwd.cpp": 7.2770906096155412e+18,
      "benchmark_func:void iLAYER_CUBLAS_GEMM_FWD_Impl(benchmark::State&) [with T = float]": 7.4787548781531884e+18,
      "beta": 1.0000000000000000e+00,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUBLAS_GEMM_FWD_Impl": 1.7610984762236383e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 1.0000000000000000e+03,
      "input[2]": 2.0480000000000000e+03,
      "input[3]": 0.0000000000000000e+00,
      "input[4]": 1.0000000000000000e+00,
      "input[5]": 1.0000000000000000e+00,
      "input[6]": 1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "lda": 1.2800000000000000e+02,
      "ldb": 1.0000000000000000e+03,
      "num_iterations": 6.7340000000000000e+03,
      "predicted_flops": 5.0429207569547021e+12,
      "predicted_flops_count": 5.2428800000000000e+08,
      "transA": 0.0000000000000000e+00,
      "transB": 1.0000000000000000e+00
    },
    {
      "name": "LAYER_CUBLAS_GEMM_FWD_FLOAT32__BatchSize_128__4694614461405789430/input[0]:128/input[1]:512/input[2]:512/input[3]:0/input[4]:1/input[5]:1/input[6]:1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 36391,
      "real_time": 1.9235102475157186e+04,
      "cpu_time": 2.4400407271028038e+04,
      "time_unit": "ns",
      "items_per_second": 1.7444373921759312e+12,
      "K": 5.1200000000000000e+02,
      "M": 1.2800000000000000e+02,
      "N": 5.1200000000000000e+02,
      "alpha": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cublas_gemm_fwd.cpp": 7.2770906096155412e+18,
      "benchmark_func:void iLAYER_CUBLAS_GEMM_FWD_Impl(benchmark::State&) [with T = float]": 7.4787548781531884e+18,
      "beta": 1.0000000000000000e+00,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUBLAS_GEMM_FWD_Impl": 1.7610984762236383e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 5.1200000000000000e+02,
      "input[3]": 0.0000000000000000e+00,
      "input[4]": 1.0000000000000000e+00,
      "input[5]": 1.0000000000000000e+00,
      "input[6]": 1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "lda": 1.2800000000000000e+02,
      "ldb": 5.1200000000000000e+02,
      "num_iterations": 3.6391000000000000e+04,
      "predicted_flops": 3.4888747843518623e+12,
      "predicted_flops_count": 6.7108864000000000e+07,
      "transA": 0.0000000000000000e+00,
      "transB": 1.0000000000000000e+00
    },
    {
      "name": "LAYER_CUBLAS_GEMM_FWD_FLOAT32__BatchSize_128__10764868209387565776/input[0]:128/input[1]:4096/input[2]:4096/input[3]:0/input[4]:1/input[5]:1/input[6]:1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 1150,
      "real_time": 6.0912444990168768e+05,
      "cpu_time": 6.1957668608697434e+05,
      "time_unit": "ns",
      "items_per_second": 3.5255252819790806e+12,
      "K": 4.0960000000000000e+03,
      "M": 1.2800000000000000e+02,
      "N": 4.0960000000000000e+03,
      "alpha": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cublas_gemm_fwd.cpp": 7.2770906096155412e+18,
      "benchmark_func:void iLAYER_CUBLAS_GEMM_FWD_Impl(benchmark::State&) [with T = float]": 7.4787548781531884e+18,
      "beta": 1.0000000000000000e+00,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUBLAS_GEMM_FWD_Impl": 1.7610984762236383e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 4.0960000000000000e+03,
      "input[2]": 4.0960000000000000e+03,
      "input[3]": 0.0000000000000000e+00,
      "input[4]": 1.0000000000000000e+00,
      "input[5]": 1.0000000000000000e+00,
      "input[6]": 1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "lda": 1.2800000000000000e+02,
      "ldb": 4.0960000000000000e+03,
      "num_iterations": 1.1500000000000000e+03,
      "predicted_flops": 7.0510505639581611e+12,
      "predicted_flops_count": 4.2949672960000000e+09,
      "transA": 0.0000000000000000e+00,
      "transB": 1.0000000000000000e+00
    },
    {
      "name": "LAYER_CUBLAS_GEMM_FWD_FLOAT32__BatchSize_128__12192339566104258143/input[0]:128/input[1]:1000/input[2]:4096/input[3]:0/input[4]:1/input[5]:1/input[6]:1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 3552,
      "real_time": 1.9715168532088315e+05,
      "cpu_time": 2.0287348536036105e+05,
      "time_unit": "ns",
      "items_per_second": 2.6593127984002334e+12,
      "K": 4.0960000000000000e+03,
      "M": 1.2800000000000000e+02,
      "N": 1.0000000000000000e+03,
      "alpha": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cublas_gemm_fwd.cpp": 7.2770906096155412e+18,
      "benchmark_func:void iLAYER_CUBLAS_GEMM_FWD_Impl(benchmark::State&) [with T = float]": 7.4787548781531884e+18,
      "beta": 1.0000000000000000e+00,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUBLAS_GEMM_FWD_Impl": 1.7610984762236383e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 1.0000000000000000e+03,
      "input[2]": 4.0960000000000000e+03,
      "input[3]": 0.0000000000000000e+00,
      "input[4]": 1.0000000000000000e+00,
      "input[5]": 1.0000000000000000e+00,
      "input[6]": 1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "lda": 1.2800000000000000e+02,
      "ldb": 1.0000000000000000e+03,
      "num_iterations": 3.5520000000000000e+03,
      "predicted_flops": 5.3186255968004668e+12,
      "predicted_flops_count": 1.0485760000000000e+09,
      "transA": 0.0000000000000000e+00,
      "transB": 1.0000000000000000e+00
    },
    {
      "name": "LAYER_CUBLAS_GEMM_FWD_FLOAT32__BatchSize_128__10967186961755427398/input[0]:128/input[1]:4096/input[2]:512/input[3]:0/input[4]:1/input[5]:1/input[6]:1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 7099,
      "real_time": 9.8614980732644719e+04,
      "cpu_time": 1.0390522087617454e+05,
      "time_unit": "ns",
      "items_per_second": 2.7220555538894839e+12,
      "K": 5.1200000000000000e+02,
      "M": 1.2800000000000000e+02,
      "N": 4.0960000000000000e+03,
      "alpha": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cublas_gemm_fwd.cpp": 7.2770906096155412e+18,
      "benchmark_func:void iLAYER_CUBLAS_GEMM_FWD_Impl(benchmark::State&) [with T = float]": 7.4787548781531884e+18,
      "beta": 1.0000000000000000e+00,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUBLAS_GEMM_FWD_Impl": 1.7610984762236383e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 4.0960000000000000e+03,
      "input[2]": 5.1200000000000000e+02,
      "input[3]": 0.0000000000000000e+00,
      "input[4]": 1.0000000000000000e+00,
      "input[5]": 1.0000000000000000e+00,
      "input[6]": 1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "lda": 1.2800000000000000e+02,
      "ldb": 4.0960000000000000e+03,
      "num_iterations": 7.0990000000000000e+03,
      "predicted_flops": 5.4441111077789678e+12,
      "predicted_flops_count": 5.3687091200000000e+08,
      "transA": 0.0000000000000000e+00,
      "transB": 1.0000000000000000e+00
    },
    {
      "name": "LAYER_CUBLAS_GEMV_FWD_FLOAT32__BatchSize_128__1885253562452235648/input[0]:4096/input[1]:18432/input[2]:1/input[3]:1/input[4]:1/input[5]:-1/input[6]:0/input[7]:0/batch_size:128/manual_time",
      "iterations": 1047,
      "real_time": 6.6841029385932023e+05,
      "cpu_time": 6.7993334097422287e+05,
      "time_unit": "ns",
      "items_per_second": 1.1295079189173871e+11,
      "K": 1.8432000000000000e+04,
      "M": 4.0960000000000000e+03,
      "alpha": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cublas_gemv_fwd.cpp": 1.1852848766119408e+19,
      "benchmark_func:void iLAYER_CUBLAS_GEMV_FWD_Impl(benchmark::State&) [with T = float]": 4.8895028309123133e+18,
      "beta": 1.0000000000000000e+00,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUBLAS_GEMV_FWD_Impl": 8.8227505551773747e+18,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 4.0960000000000000e+03,
      "input[1]": 1.8432000000000000e+04,
      "input[2]": 1.0000000000000000e+00,
      "input[3]": 1.0000000000000000e+00,
      "input[4]": 1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": 0.0000000000000000e+00,
      "input[7]": 0.0000000000000000e+00,
      "lda": 4.0960000000000000e+03,
      "num_iterations": 1.0470000000000000e+03,
      "predicted_flops": 1.1295079189173871e+11,
      "predicted_flops_count": 7.5497472000000000e+07,
      "transA": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUBLAS_GEMV_FWD_FLOAT32__BatchSize_128__5615474277073359473/input[0]:1024/input[1]:4096/input[2]:1/input[3]:1/input[4]:1/input[5]:-1/input[6]:0/input[7]:0/batch_size:128/manual_time",
      "iterations": 14321,
      "real_time": 4.8864158708653405e+04,
      "cpu_time": 5.4072310034210372e+04,
      "time_unit": "ns",
      "items_per_second": 8.5836001495657120e+10,
      "K": 4.0960000000000000e+03,
      "M": 1.0240000000000000e+03,
      "alpha": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cublas_gemv_fwd.cpp": 1.1852848766119408e+19,
      "benchmark_func:void iLAYER_CUBLAS_GEMV_FWD_Impl(benchmark::State&) [with T = float]": 4.8895028309123133e+18,
      "beta": 1.0000000000000000e+00,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUBLAS_GEMV_FWD_Impl": 8.8227505551773747e+18,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 4.0960000000000000e+03,
      "input[2]": 1.0000000000000000e+00,
      "input[3]": 1.0000000000000000e+00,
      "input[4]": 1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": 0.0000000000000000e+00,
      "input[7]": 0.0000000000000000e+00,
      "lda": 1.0240000000000000e+03,
      "num_iterations": 1.4321000000000000e+04,
      "predicted_flops": 8.5836001495657120e+10,
      "predicted_flops_count": 4.1943040000000000e+06,
      "transA": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUBLAS_GEMV_FWD_FLOAT32__BatchSize_128__17151817648129995468/input[0]:1000/input[1]:1024/input[2]:1/input[3]:1/input[4]:1/input[5]:-1/input[6]:0/input[7]:0/batch_size:128/manual_time",
      "iterations": 44042,
      "real_time": 1.5896190389966610e+04,
      "cpu_time": 2.1067338222603918e+04,
      "time_unit": "ns",
      "items_per_second": 6.4417950142716614e+10,
      "K": 1.0240000000000000e+03,
      "M": 1.0000000000000000e+03,
      "alpha": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cublas_gemv_fwd.cpp": 1.1852848766119408e+19,
      "benchmark_func:void iLAYER_CUBLAS_GEMV_FWD_Impl(benchmark::State&) [with T = float]": 4.8895028309123133e+18,
      "beta": 1.0000000000000000e+00,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUBLAS_GEMV_FWD_Impl": 8.8227505551773747e+18,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+03,
      "input[1]": 1.0240000000000000e+03,
      "input[2]": 1.0000000000000000e+00,
      "input[3]": 1.0000000000000000e+00,
      "input[4]": 1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": 0.0000000000000000e+00,
      "input[7]": 0.0000000000000000e+00,
      "lda": 1.0000000000000000e+03,
      "num_iterations": 4.4042000000000000e+04,
      "predicted_flops": 6.4417950142716614e+10,
      "predicted_flops_count": 1.0240000000000000e+06,
      "transA": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUBLAS_GEMV_FWD_FLOAT32__BatchSize_128__1660754998456486955/input[0]:10/input[1]:256/input[2]:0/input[3]:1/input[4]:0/input[5]:-1/input[6]:0/input[7]:0/batch_size:128/manual_time",
      "iterations": 143861,
      "real_time": 4.8723391163339447e+03,
      "cpu_time": 1.0108039996940503e+04,
      "time_unit": "ns",
      "items_per_second": 5.2541498834058994e+08,
      "K": 2.5600000000000000e+02,
      "M": 1.0000000000000000e+01,
      "alpha": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cublas_gemv_fwd.cpp": 1.1852848766119408e+19,
      "benchmark_func:void iLAYER_CUBLAS_GEMV_FWD_Impl(benchmark::State&) [with T = float]": 4.8895028309123133e+18,
      "beta": 0.0000000000000000e+00,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUBLAS_GEMV_FWD_Impl": 8.8227505551773747e+18,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+01,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 0.0000000000000000e+00,
      "input[3]": 1.0000000000000000e+00,
      "input[4]": 0.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": 0.0000000000000000e+00,
      "input[7]": 0.0000000000000000e+00,
      "lda": 1.0000000000000000e+01,
      "num_iterations": 1.4386100000000000e+05,
      "predicted_flops": 5.2541498834058994e+08,
      "predicted_flops_count": 2.5600000000000000e+03,
      "transA": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUBLAS_GEMV_FWD_FLOAT32__BatchSize_128__7316101744961235287/input[0]:4096/input[1]:9216/input[2]:1/input[3]:1/input[4]:1/input[5]:-1/input[6]:0/input[7]:0/batch_size:128/manual_time",
      "iterations": 2040,
      "real_time": 3.4315237575998146e+05,
      "cpu_time": 3.5001427303918212e+05,
      "time_unit": "ns",
      "items_per_second": 1.1000575448850577e+11,
      "K": 9.2160000000000000e+03,
      "M": 4.0960000000000000e+03,
      "alpha": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cublas_gemv_fwd.cpp": 1.1852848766119408e+19,
      "benchmark_func:void iLAYER_CUBLAS_GEMV_FWD_Impl(benchmark::State&) [with T = float]": 4.8895028309123133e+18,
      "beta": 1.0000000000000000e+00,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUBLAS_GEMV_FWD_Impl": 8.8227505551773747e+18,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 4.0960000000000000e+03,
      "input[1]": 9.2160000000000000e+03,
      "input[2]": 1.0000000000000000e+00,
      "input[3]": 1.0000000000000000e+00,
      "input[4]": 1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": 0.0000000000000000e+00,
      "input[7]": 0.0000000000000000e+00,
      "lda": 4.0960000000000000e+03,
      "num_iterations": 2.0400000000000000e+03,
      "predicted_flops": 1.1000575448850577e+11,
      "predicted_flops_count": 3.7748736000000000e+07,
      "transA": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUBLAS_GEMV_FWD_FLOAT32__BatchSize_128__3960740257363593187/input[0]:4096/input[1]:4096/input[2]:1/input[3]:1/input[4]:1/input[5]:-1/input[6]:0/input[7]:0/batch_size:128/manual_time",
      "iterations": 4523,
      "real_time": 1.5472274377180019e+05,
      "cpu_time": 1.6024737077159993e+05,
      "time_unit": "ns",
      "items_per_second": 1.0843406464368698e+11,
      "K": 4.0960000000000000e+03,
      "M": 4.0960000000000000e+03,
      "alpha": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cublas_gemv_fwd.cpp": 1.1852848766119408e+19,
      "benchmark_func:void iLAYER_CUBLAS_GEMV_FWD_Impl(benchmark::State&) [with T = float]": 4.8895028309123133e+18,
      "beta": 1.0000000000000000e+00,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUBLAS_GEMV_FWD_Impl": 8.8227505551773747e+18,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 4.0960000000000000e+03,
      "input[1]": 4.0960000000000000e+03,
      "input[2]": 1.0000000000000000e+00,
      "input[3]": 1.0000000000000000e+00,
      "input[4]": 1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": 0.0000000000000000e+00,
      "input[7]": 0.0000000000000000e+00,
      "lda": 4.0960000000000000e+03,
      "num_iterations": 4.5230000000000000e+03,
      "predicted_flops": 1.0843406464368698e+11,
      "predicted_flops_count": 1.6777216000000000e+07,
      "transA": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUBLAS_GEMV_FWD_FLOAT32__BatchSize_128__1973303644173646720/input[0]:1000/input[1]:4096/input[2]:1/input[3]:1/input[4]:1/input[5]:-1/input[6]:0/input[7]:0/batch_size:128/manual_time",
      "iterations": 14090,
      "real_time": 4.9672507020239827e+04,
      "cpu_time": 5.4917645138407788e+04,
      "time_unit": "ns",
      "items_per_second": 8.2460102090901550e+10,
      "K": 4.0960000000000000e+03,
      "M": 1.0000000000000000e+03,
      "alpha": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cublas_gemv_fwd.cpp": 1.1852848766119408e+19,
      "benchmark_func:void iLAYER_CUBLAS_GEMV_FWD_Impl(benchmark::State&) [with T = float]": 4.8895028309123133e+18,
      "beta": 1.0000000000000000e+00,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUBLAS_GEMV_FWD_Impl": 8.8227505551773747e+18,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+03,
      "input[1]": 4.0960000000000000e+03,
      "input[2]": 1.0000000000000000e+00,
      "input[3]": 1.0000000000000000e+00,
      "input[4]": 1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": 0.0000000000000000e+00,
      "input[7]": 0.0000000000000000e+00,
      "lda": 1.0000000000000000e+03,
      "num_iterations": 1.4090000000000000e+04,
      "predicted_flops": 8.2460102090901550e+10,
      "predicted_flops_count": 4.0960000000000000e+06,
      "transA": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUBLAS_GEMV_FWD_FLOAT32__BatchSize_128__8611919153945511522/input[0]:1024/input[1]:1024/input[2]:0/input[3]:1/input[4]:0/input[5]:-1/input[6]:0/input[7]:0/batch_size:128/manual_time",
      "iterations": 44256,
      "real_time": 1.5814642471769879e+04,
      "cpu_time": 2.1012054297722556e+04,
      "time_unit": "ns",
      "items_per_second": 6.6304123022178551e+10,
      "K": 1.0240000000000000e+03,
      "M": 1.0240000000000000e+03,
      "alpha": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cublas_gemv_fwd.cpp": 1.1852848766119408e+19,
      "benchmark_func:void iLAYER_CUBLAS_GEMV_FWD_Impl(benchmark::State&) [with T = float]": 4.8895028309123133e+18,
      "beta": 0.0000000000000000e+00,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUBLAS_GEMV_FWD_Impl": 8.8227505551773747e+18,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0240000000000000e+03,
      "input[1]": 1.0240000000000000e+03,
      "input[2]": 0.0000000000000000e+00,
      "input[3]": 1.0000000000000000e+00,
      "input[4]": 0.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": 0.0000000000000000e+00,
      "input[7]": 0.0000000000000000e+00,
      "lda": 1.0240000000000000e+03,
      "num_iterations": 4.4256000000000000e+04,
      "predicted_flops": 6.6304123022178551e+10,
      "predicted_flops_count": 1.0485760000000000e+06,
      "transA": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUBLAS_GEMV_FWD_FLOAT32__BatchSize_128__17035014280979531381/input[0]:8/input[1]:1024/input[2]:0/input[3]:1/input[4]:0/input[5]:-1/input[6]:0/input[7]:0/batch_size:128/manual_time",
      "iterations": 115879,
      "real_time": 6.2440914737989933e+03,
      "cpu_time": 1.1499205887172646e+04,
      "time_unit": "ns",
      "items_per_second": 1.3119602802705052e+09,
      "K": 1.0240000000000000e+03,
      "M": 8.0000000000000000e+00,
      "alpha": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cublas_gemv_fwd.cpp": 1.1852848766119408e+19,
      "benchmark_func:void iLAYER_CUBLAS_GEMV_FWD_Impl(benchmark::State&) [with T = float]": 4.8895028309123133e+18,
      "beta": 0.0000000000000000e+00,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUBLAS_GEMV_FWD_Impl": 8.8227505551773747e+18,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 8.0000000000000000e+00,
      "input[1]": 1.0240000000000000e+03,
      "input[2]": 0.0000000000000000e+00,
      "input[3]": 1.0000000000000000e+00,
      "input[4]": 0.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": 0.0000000000000000e+00,
      "input[7]": 0.0000000000000000e+00,
      "lda": 8.0000000000000000e+00,
      "num_iterations": 1.1587900000000000e+05,
      "predicted_flops": 1.3119602802705052e+09,
      "predicted_flops_count": 8.1920000000000000e+03,
      "transA": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUBLAS_GEMV_FWD_FLOAT32__BatchSize_128__8314068294429619807/input[0]:200/input[1]:4096/input[2]:1/input[3]:1/input[4]:1/input[5]:-1/input[6]:0/input[7]:0/batch_size:128/manual_time",
      "iterations": 31648,
      "real_time": 2.2107452966859732e+04,
      "cpu_time": 2.7285859643581767e+04,
      "time_unit": "ns",
      "items_per_second": 3.7055376810165558e+10,
      "K": 4.0960000000000000e+03,
      "M": 2.0000000000000000e+02,
      "alpha": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cublas_gemv_fwd.cpp": 1.1852848766119408e+19,
      "benchmark_func:void iLAYER_CUBLAS_GEMV_FWD_Impl(benchmark::State&) [with T = float]": 4.8895028309123133e+18,
      "beta": 1.0000000000000000e+00,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUBLAS_GEMV_FWD_Impl": 8.8227505551773747e+18,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 2.0000000000000000e+02,
      "input[1]": 4.0960000000000000e+03,
      "input[2]": 1.0000000000000000e+00,
      "input[3]": 1.0000000000000000e+00,
      "input[4]": 1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": 0.0000000000000000e+00,
      "input[7]": 0.0000000000000000e+00,
      "lda": 2.0000000000000000e+02,
      "num_iterations": 3.1648000000000000e+04,
      "predicted_flops": 3.7055376810165558e+10,
      "predicted_flops_count": 8.1920000000000000e+05,
      "transA": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUBLAS_GEMV_FWD_FLOAT32__BatchSize_128__1633669750846757249/input[0]:1000/input[1]:544/input[2]:1/input[3]:1/input[4]:1/input[5]:-1/input[6]:0/input[7]:0/batch_size:128/manual_time",
      "iterations": 81148,
      "real_time": 8.6585746966516363e+03,
      "cpu_time": 1.3919697182917260e+04,
      "time_unit": "ns",
      "items_per_second": 6.2827892471767975e+10,
      "K": 5.4400000000000000e+02,
      "M": 1.0000000000000000e+03,
      "alpha": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cublas_gemv_fwd.cpp": 1.1852848766119408e+19,
      "benchmark_func:void iLAYER_CUBLAS_GEMV_FWD_Impl(benchmark::State&) [with T = float]": 4.8895028309123133e+18,
      "beta": 1.0000000000000000e+00,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUBLAS_GEMV_FWD_Impl": 8.8227505551773747e+18,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+03,
      "input[1]": 5.4400000000000000e+02,
      "input[2]": 1.0000000000000000e+00,
      "input[3]": 1.0000000000000000e+00,
      "input[4]": 1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": 0.0000000000000000e+00,
      "input[7]": 0.0000000000000000e+00,
      "lda": 1.0000000000000000e+03,
      "num_iterations": 8.1148000000000000e+04,
      "predicted_flops": 6.2827892471767975e+10,
      "predicted_flops_count": 5.4400000000000000e+05,
      "transA": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__4766757501735142039<CUDNN_ACTIVATION_RELU>/input[0]:128/input[1]:16/input[2]:55/input[3]:55/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 5658,
      "real_time": 1.2366545817347050e+05,
      "cpu_time": 1.2904270360553947e+05,
      "time_unit": "ns",
      "items_per_second": 5.0096446424916367e+10,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 1.6000000000000000e+01,
      "input[2]": 5.5000000000000000e+01,
      "input[3]": 5.5000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 1.6000000000000000e+01,
      "input_height": 5.5000000000000000e+01,
      "input_size": 6.1952000000000000e+06,
      "input_width": 5.5000000000000000e+01,
      "num_iterations": 5.6580000000000000e+03,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 1.6000000000000000e+01,
      "output_height": 5.5000000000000000e+01,
      "output_size": 6.1952000000000000e+06,
      "output_width": 5.5000000000000000e+01,
      "predicted_flops": 5.0096446424916367e+10,
      "predicted_flops_count": 6.1952000000000000e+06
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__4766757501735142039<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:128/input[1]:16/input[2]:55/input[3]:55/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 5648,
      "real_time": 1.2396244735020610e+05,
      "cpu_time": 1.2935701664306958e+05,
      "time_unit": "ns",
      "items_per_second": 4.9976425380647339e+10,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 1.6000000000000000e+01,
      "input[2]": 5.5000000000000000e+01,
      "input[3]": 5.5000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 1.6000000000000000e+01,
      "input_height": 5.5000000000000000e+01,
      "input_size": 6.1952000000000000e+06,
      "input_width": 5.5000000000000000e+01,
      "num_iterations": 5.6480000000000000e+03,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 1.6000000000000000e+01,
      "output_height": 5.5000000000000000e+01,
      "output_size": 6.1952000000000000e+06,
      "output_width": 5.5000000000000000e+01,
      "predicted_flops": 4.9976425380647339e+10,
      "predicted_flops_count": 6.1952000000000000e+06
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__5194913184951549321<CUDNN_ACTIVATION_RELU>/input[0]:128/input[1]:112/input[2]:56/input[3]:56/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 765,
      "real_time": 9.1508078355390858e+05,
      "cpu_time": 9.3261042614372133e+05,
      "time_unit": "ns",
      "items_per_second": 4.9129756419315620e+10,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 1.1200000000000000e+02,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 1.1200000000000000e+02,
      "input_height": 5.6000000000000000e+01,
      "input_size": 4.4957696000000000e+07,
      "input_width": 5.6000000000000000e+01,
      "num_iterations": 7.6500000000000000e+02,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 1.1200000000000000e+02,
      "output_height": 5.6000000000000000e+01,
      "output_size": 4.4957696000000000e+07,
      "output_width": 5.6000000000000000e+01,
      "predicted_flops": 4.9129756419315620e+10,
      "predicted_flops_count": 4.4957696000000000e+07
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__5194913184951549321<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:128/input[1]:112/input[2]:56/input[3]:56/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 764,
      "real_time": 9.1473972789043596e+05,
      "cpu_time": 9.3230940575913480e+05,
      "time_unit": "ns",
      "items_per_second": 4.9148074178084526e+10,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 1.1200000000000000e+02,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 1.1200000000000000e+02,
      "input_height": 5.6000000000000000e+01,
      "input_size": 4.4957696000000000e+07,
      "input_width": 5.6000000000000000e+01,
      "num_iterations": 7.6400000000000000e+02,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 1.1200000000000000e+02,
      "output_height": 5.6000000000000000e+01,
      "output_size": 4.4957696000000000e+07,
      "output_width": 5.6000000000000000e+01,
      "predicted_flops": 4.9148074178084526e+10,
      "predicted_flops_count": 4.4957696000000000e+07
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__5798228081268702451<CUDNN_ACTIVATION_RELU>/input[0]:128/input[1]:192/input[2]:28/input[3]:28/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 1866,
      "real_time": 3.7531601442877576e+05,
      "cpu_time": 3.8255943997860939e+05,
      "time_unit": "ns",
      "items_per_second": 5.1336962078010231e+10,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 1.9200000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 1.9200000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 1.9267584000000000e+07,
      "input_width": 2.8000000000000000e+01,
      "num_iterations": 1.8660000000000000e+03,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 1.9200000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 1.9267584000000000e+07,
      "output_width": 2.8000000000000000e+01,
      "predicted_flops": 5.1336962078010231e+10,
      "predicted_flops_count": 1.9267584000000000e+07
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__5798228081268702451<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:128/input[1]:192/input[2]:28/input[3]:28/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 1864,
      "real_time": 3.7549231043087959e+05,
      "cpu_time": 3.8272569206006505e+05,
      "time_unit": "ns",
      "items_per_second": 5.1312859051335403e+10,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 1.9200000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 1.9200000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 1.9267584000000000e+07,
      "input_width": 2.8000000000000000e+01,
      "num_iterations": 1.8640000000000000e+03,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 1.9200000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 1.9267584000000000e+07,
      "output_width": 2.8000000000000000e+01,
      "predicted_flops": 5.1312859051335403e+10,
      "predicted_flops_count": 1.9267584000000000e+07
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__6391337342107196727<CUDNN_ACTIVATION_RELU>/input[0]:1/input[1]:136/input[2]:28/input[3]:28/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 121007,
      "real_time": 5.7937310986017274e+03,
      "cpu_time": 1.0963824076298337e+04,
      "time_unit": "ns",
      "items_per_second": 1.8403339434536907e+10,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 1.3600000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 1.3600000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 1.0662400000000000e+05,
      "input_width": 2.8000000000000000e+01,
      "num_iterations": 1.2100700000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 1.3600000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 1.0662400000000000e+05,
      "output_width": 2.8000000000000000e+01,
      "predicted_flops": 1.8403339434536907e+10,
      "predicted_flops_count": 1.0662400000000000e+05
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__6391337342107196727<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1/input[1]:136/input[2]:28/input[3]:28/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 120336,
      "real_time": 5.7914575442296546e+03,
      "cpu_time": 1.0904617820097112e+04,
      "time_unit": "ns",
      "items_per_second": 1.8410564039485245e+10,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 1.3600000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 1.3600000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 1.0662400000000000e+05,
      "input_width": 2.8000000000000000e+01,
      "num_iterations": 1.2033600000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 1.3600000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 1.0662400000000000e+05,
      "output_width": 2.8000000000000000e+01,
      "predicted_flops": 1.8410564039485245e+10,
      "predicted_flops_count": 1.0662400000000000e+05
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__7784745323467852026<CUDNN_ACTIVATION_RELU>/input[0]:1/input[1]:272/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 126074,
      "real_time": 5.5309226017185247e+03,
      "cpu_time": 1.0686979067866379e+04,
      "time_unit": "ns",
      "items_per_second": 9.6388982162641945e+09,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 2.7200000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 2.7200000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 5.3312000000000000e+04,
      "input_width": 1.4000000000000000e+01,
      "num_iterations": 1.2607400000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 2.7200000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 5.3312000000000000e+04,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 9.6388982162641945e+09,
      "predicted_flops_count": 5.3312000000000000e+04
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__7784745323467852026<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1/input[1]:272/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 126655,
      "real_time": 5.5310684308177715e+03,
      "cpu_time": 1.0693231384487475e+04,
      "time_unit": "ns",
      "items_per_second": 9.6386440823907490e+09,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 2.7200000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 2.7200000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 5.3312000000000000e+04,
      "input_width": 1.4000000000000000e+01,
      "num_iterations": 1.2665500000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 2.7200000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 5.3312000000000000e+04,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 9.6386440823907490e+09,
      "predicted_flops_count": 5.3312000000000000e+04
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__6616252567149605233<CUDNN_ACTIVATION_RELU>/input[0]:128/input[1]:24/input[2]:112/input[3]:112/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 905,
      "real_time": 7.7241833420799661e+05,
      "cpu_time": 7.8644771270724293e+05,
      "time_unit": "ns",
      "items_per_second": 4.9888986697230904e+10,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 2.4000000000000000e+01,
      "input[2]": 1.1200000000000000e+02,
      "input[3]": 1.1200000000000000e+02,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 2.4000000000000000e+01,
      "input_height": 1.1200000000000000e+02,
      "input_size": 3.8535168000000000e+07,
      "input_width": 1.1200000000000000e+02,
      "num_iterations": 9.0500000000000000e+02,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 2.4000000000000000e+01,
      "output_height": 1.1200000000000000e+02,
      "output_size": 3.8535168000000000e+07,
      "output_width": 1.1200000000000000e+02,
      "predicted_flops": 4.9888986697230904e+10,
      "predicted_flops_count": 3.8535168000000000e+07
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__6616252567149605233<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:128/input[1]:24/input[2]:112/input[3]:112/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 906,
      "real_time": 7.7303427804279944e+05,
      "cpu_time": 7.8706206291390397e+05,
      "time_unit": "ns",
      "items_per_second": 4.9849235790119102e+10,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 2.4000000000000000e+01,
      "input[2]": 1.1200000000000000e+02,
      "input[3]": 1.1200000000000000e+02,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 2.4000000000000000e+01,
      "input_height": 1.1200000000000000e+02,
      "input_size": 3.8535168000000000e+07,
      "input_width": 1.1200000000000000e+02,
      "num_iterations": 9.0600000000000000e+02,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 2.4000000000000000e+01,
      "output_height": 1.1200000000000000e+02,
      "output_size": 3.8535168000000000e+07,
      "output_width": 1.1200000000000000e+02,
      "predicted_flops": 4.9849235790119102e+10,
      "predicted_flops_count": 3.8535168000000000e+07
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__1492073206292568976<CUDNN_ACTIVATION_RELU>/input[0]:128/input[1]:64/input[2]:55/input[3]:55/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 1441,
      "real_time": 4.8573806028865476e+05,
      "cpu_time": 4.9437168285906478e+05,
      "time_unit": "ns",
      "items_per_second": 5.1016796965166290e+10,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 5.5000000000000000e+01,
      "input[3]": 5.5000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 5.5000000000000000e+01,
      "input_size": 2.4780800000000000e+07,
      "input_width": 5.5000000000000000e+01,
      "num_iterations": 1.4410000000000000e+03,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 5.5000000000000000e+01,
      "output_size": 2.4780800000000000e+07,
      "output_width": 5.5000000000000000e+01,
      "predicted_flops": 5.1016796965166290e+10,
      "predicted_flops_count": 2.4780800000000000e+07
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__1492073206292568976<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:128/input[1]:64/input[2]:55/input[3]:55/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 1440,
      "real_time": 4.8597184490467451e+05,
      "cpu_time": 4.9464498263889708e+05,
      "time_unit": "ns",
      "items_per_second": 5.0992254509848946e+10,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 5.5000000000000000e+01,
      "input[3]": 5.5000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 5.5000000000000000e+01,
      "input_size": 2.4780800000000000e+07,
      "input_width": 5.5000000000000000e+01,
      "num_iterations": 1.4400000000000000e+03,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 5.5000000000000000e+01,
      "output_size": 2.4780800000000000e+07,
      "output_width": 5.5000000000000000e+01,
      "predicted_flops": 5.0992254509848946e+10,
      "predicted_flops_count": 2.4780800000000000e+07
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__17160497613309952170<CUDNN_ACTIVATION_RELU>/input[0]:128/input[1]:48/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 25000,
      "real_time": 2.8016752906696638e+04,
      "cpu_time": 3.3193464439982563e+04,
      "time_unit": "ns",
      "items_per_second": 4.2982282922306931e+10,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 4.8000000000000000e+01,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 4.8000000000000000e+01,
      "input_height": 1.4000000000000000e+01,
      "input_size": 1.2042240000000000e+06,
      "input_width": 1.4000000000000000e+01,
      "num_iterations": 2.5000000000000000e+04,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 4.8000000000000000e+01,
      "output_height": 1.4000000000000000e+01,
      "output_size": 1.2042240000000000e+06,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 4.2982282922306931e+10,
      "predicted_flops_count": 1.2042240000000000e+06
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__17160497613309952170<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:128/input[1]:48/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 24911,
      "real_time": 2.8083550183139880e+04,
      "cpu_time": 3.3289356067590110e+04,
      "time_unit": "ns",
      "items_per_second": 4.2880048717023064e+10,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 4.8000000000000000e+01,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 4.8000000000000000e+01,
      "input_height": 1.4000000000000000e+01,
      "input_size": 1.2042240000000000e+06,
      "input_width": 1.4000000000000000e+01,
      "num_iterations": 2.4911000000000000e+04,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 4.8000000000000000e+01,
      "output_height": 1.4000000000000000e+01,
      "output_size": 1.2042240000000000e+06,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 4.2880048717023064e+10,
      "predicted_flops_count": 1.2042240000000000e+06
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__16709145530537253138<CUDNN_ACTIVATION_RELU>/input[0]:128/input[1]:16/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 74617,
      "real_time": 9.3608411713812093e+03,
      "cpu_time": 1.4537968184186553e+04,
      "time_unit": "ns",
      "items_per_second": 4.2881616368753273e+10,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 1.6000000000000000e+01,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 1.6000000000000000e+01,
      "input_height": 1.4000000000000000e+01,
      "input_size": 4.0140800000000000e+05,
      "input_width": 1.4000000000000000e+01,
      "num_iterations": 7.4617000000000000e+04,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 1.6000000000000000e+01,
      "output_height": 1.4000000000000000e+01,
      "output_size": 4.0140800000000000e+05,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 4.2881616368753273e+10,
      "predicted_flops_count": 4.0140800000000000e+05
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__16709145530537253138<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:128/input[1]:16/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 74709,
      "real_time": 9.3787986743437341e+03,
      "cpu_time": 1.4560288291909030e+04,
      "time_unit": "ns",
      "items_per_second": 4.2799511316739922e+10,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 1.6000000000000000e+01,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 1.6000000000000000e+01,
      "input_height": 1.4000000000000000e+01,
      "input_size": 4.0140800000000000e+05,
      "input_width": 1.4000000000000000e+01,
      "num_iterations": 7.4709000000000000e+04,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 1.6000000000000000e+01,
      "output_height": 1.4000000000000000e+01,
      "output_size": 4.0140800000000000e+05,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 4.2799511316739922e+10,
      "predicted_flops_count": 4.0140800000000000e+05
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__17328317262907191043<CUDNN_ACTIVATION_RELU>/input[0]:1/input[1]:32/input[2]:6/input[3]:6/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 137226,
      "real_time": 5.1095091290828532e+03,
      "cpu_time": 1.0266356412047749e+04,
      "time_unit": "ns",
      "items_per_second": 2.2546197117897737e+08,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 3.2000000000000000e+01,
      "input[2]": 6.0000000000000000e+00,
      "input[3]": 6.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 3.2000000000000000e+01,
      "input_height": 6.0000000000000000e+00,
      "input_size": 1.1520000000000000e+03,
      "input_width": 6.0000000000000000e+00,
      "num_iterations": 1.3722600000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 3.2000000000000000e+01,
      "output_height": 6.0000000000000000e+00,
      "output_size": 1.1520000000000000e+03,
      "output_width": 6.0000000000000000e+00,
      "predicted_flops": 2.2546197117897737e+08,
      "predicted_flops_count": 1.1520000000000000e+03
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__17328317262907191043<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1/input[1]:32/input[2]:6/input[3]:6/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 137011,
      "real_time": 5.5431650909163836e+03,
      "cpu_time": 1.0858863135075484e+04,
      "time_unit": "ns",
      "items_per_second": 2.0782350536298999e+08,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 3.2000000000000000e+01,
      "input[2]": 6.0000000000000000e+00,
      "input[3]": 6.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 3.2000000000000000e+01,
      "input_height": 6.0000000000000000e+00,
      "input_size": 1.1520000000000000e+03,
      "input_width": 6.0000000000000000e+00,
      "num_iterations": 1.3701100000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 3.2000000000000000e+01,
      "output_height": 6.0000000000000000e+00,
      "output_size": 1.1520000000000000e+03,
      "output_width": 6.0000000000000000e+00,
      "predicted_flops": 2.0782350536298999e+08,
      "predicted_flops_count": 1.1520000000000000e+03
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__14387487927722068168<CUDNN_ACTIVATION_RELU>/input[0]:1/input[1]:192/input[2]:6/input[3]:6/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 119149,
      "real_time": 5.7305420429225887e+03,
      "cpu_time": 1.1117526206681323e+04,
      "time_unit": "ns",
      "items_per_second": 1.2061686221352396e+09,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 1.9200000000000000e+02,
      "input[2]": 6.0000000000000000e+00,
      "input[3]": 6.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 1.9200000000000000e+02,
      "input_height": 6.0000000000000000e+00,
      "input_size": 6.9120000000000000e+03,
      "input_width": 6.0000000000000000e+00,
      "num_iterations": 1.1914900000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 1.9200000000000000e+02,
      "output_height": 6.0000000000000000e+00,
      "output_size": 6.9120000000000000e+03,
      "output_width": 6.0000000000000000e+00,
      "predicted_flops": 1.2061686221352396e+09,
      "predicted_flops_count": 6.9120000000000000e+03
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__14387487927722068168<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1/input[1]:192/input[2]:6/input[3]:6/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 137324,
      "real_time": 5.0706589047133884e+03,
      "cpu_time": 1.0224291383886311e+04,
      "time_unit": "ns",
      "items_per_second": 1.3631364542337897e+09,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 1.9200000000000000e+02,
      "input[2]": 6.0000000000000000e+00,
      "input[3]": 6.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 1.9200000000000000e+02,
      "input_height": 6.0000000000000000e+00,
      "input_size": 6.9120000000000000e+03,
      "input_width": 6.0000000000000000e+00,
      "num_iterations": 1.3732400000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 1.9200000000000000e+02,
      "output_height": 6.0000000000000000e+00,
      "output_size": 6.9120000000000000e+03,
      "output_width": 6.0000000000000000e+00,
      "predicted_flops": 1.3631364542337897e+09,
      "predicted_flops_count": 6.9120000000000000e+03
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__3690569681699314221<CUDNN_ACTIVATION_RELU>/input[0]:128/input[1]:128/input[2]:27/input[3]:27/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 2992,
      "real_time": 2.3392771230948303e+05,
      "cpu_time": 2.3988120120323234e+05,
      "time_unit": "ns",
      "items_per_second": 5.1058234537848785e+10,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 1.2800000000000000e+02,
      "input[2]": 2.7000000000000000e+01,
      "input[3]": 2.7000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 1.2800000000000000e+02,
      "input_height": 2.7000000000000000e+01,
      "input_size": 1.1943936000000000e+07,
      "input_width": 2.7000000000000000e+01,
      "num_iterations": 2.9920000000000000e+03,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 2.7000000000000000e+01,
      "output_size": 1.1943936000000000e+07,
      "output_width": 2.7000000000000000e+01,
      "predicted_flops": 5.1058234537848785e+10,
      "predicted_flops_count": 1.1943936000000000e+07
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__3690569681699314221<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:128/input[1]:128/input[2]:27/input[3]:27/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 2989,
      "real_time": 2.3419101092925930e+05,
      "cpu_time": 2.4016847808632941e+05,
      "time_unit": "ns",
      "items_per_second": 5.1000830273574570e+10,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 1.2800000000000000e+02,
      "input[2]": 2.7000000000000000e+01,
      "input[3]": 2.7000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 1.2800000000000000e+02,
      "input_height": 2.7000000000000000e+01,
      "input_size": 1.1943936000000000e+07,
      "input_width": 2.7000000000000000e+01,
      "num_iterations": 2.9890000000000000e+03,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 2.7000000000000000e+01,
      "output_size": 1.1943936000000000e+07,
      "output_width": 2.7000000000000000e+01,
      "predicted_flops": 5.1000830273574570e+10,
      "predicted_flops_count": 1.1943936000000000e+07
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__2085018503842899052<CUDNN_ACTIVATION_RELU>/input[0]:1/input[1]:160/input[2]:28/input[3]:28/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 118479,
      "real_time": 5.9022937337861758e+03,
      "cpu_time": 1.1074036445281681e+04,
      "time_unit": "ns",
      "items_per_second": 2.1252754548956230e+10,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 1.6000000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 1.6000000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 1.2544000000000000e+05,
      "input_width": 2.8000000000000000e+01,
      "num_iterations": 1.1847900000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 1.6000000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 1.2544000000000000e+05,
      "output_width": 2.8000000000000000e+01,
      "predicted_flops": 2.1252754548956230e+10,
      "predicted_flops_count": 1.2544000000000000e+05
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__2085018503842899052<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1/input[1]:160/input[2]:28/input[3]:28/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 118919,
      "real_time": 5.9043120378421836e+03,
      "cpu_time": 1.1096256460285396e+04,
      "time_unit": "ns",
      "items_per_second": 2.1245489600824665e+10,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 1.6000000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 1.6000000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 1.2544000000000000e+05,
      "input_width": 2.8000000000000000e+01,
      "num_iterations": 1.1891900000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 1.6000000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 1.2544000000000000e+05,
      "output_width": 2.8000000000000000e+01,
      "predicted_flops": 2.1245489600824665e+10,
      "predicted_flops_count": 1.2544000000000000e+05
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__2438092847813789227<CUDNN_ACTIVATION_RELU>/input[0]:128/input[1]:32/input[2]:27/input[3]:27/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 11240,
      "real_time": 6.2270001329568498e+04,
      "cpu_time": 6.7483140480454531e+04,
      "time_unit": "ns",
      "items_per_second": 4.7952207102043617e+10,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 3.2000000000000000e+01,
      "input[2]": 2.7000000000000000e+01,
      "input[3]": 2.7000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 3.2000000000000000e+01,
      "input_height": 2.7000000000000000e+01,
      "input_size": 2.9859840000000000e+06,
      "input_width": 2.7000000000000000e+01,
      "num_iterations": 1.1240000000000000e+04,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 3.2000000000000000e+01,
      "output_height": 2.7000000000000000e+01,
      "output_size": 2.9859840000000000e+06,
      "output_width": 2.7000000000000000e+01,
      "predicted_flops": 4.7952207102043617e+10,
      "predicted_flops_count": 2.9859840000000000e+06
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__2438092847813789227<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:128/input[1]:32/input[2]:27/input[3]:27/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 11216,
      "real_time": 6.2370199727116582e+04,
      "cpu_time": 6.7581347806727106e+04,
      "time_unit": "ns",
      "items_per_second": 4.7875171364920120e+10,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 3.2000000000000000e+01,
      "input[2]": 2.7000000000000000e+01,
      "input[3]": 2.7000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 3.2000000000000000e+01,
      "input_height": 2.7000000000000000e+01,
      "input_size": 2.9859840000000000e+06,
      "input_width": 2.7000000000000000e+01,
      "num_iterations": 1.1216000000000000e+04,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 3.2000000000000000e+01,
      "output_height": 2.7000000000000000e+01,
      "output_size": 2.9859840000000000e+06,
      "output_width": 2.7000000000000000e+01,
      "predicted_flops": 4.7875171364920120e+10,
      "predicted_flops_count": 2.9859840000000000e+06
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__11921838210132704273<CUDNN_ACTIVATION_RELU>/input[0]:1/input[1]:48/input[2]:6/input[3]:6/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 137921,
      "real_time": 5.0499194989754778e+03,
      "cpu_time": 1.0177155676074148e+04,
      "time_unit": "ns",
      "items_per_second": 3.4218367250222003e+08,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 4.8000000000000000e+01,
      "input[2]": 6.0000000000000000e+00,
      "input[3]": 6.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 4.8000000000000000e+01,
      "input_height": 6.0000000000000000e+00,
      "input_size": 1.7280000000000000e+03,
      "input_width": 6.0000000000000000e+00,
      "num_iterations": 1.3792100000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 4.8000000000000000e+01,
      "output_height": 6.0000000000000000e+00,
      "output_size": 1.7280000000000000e+03,
      "output_width": 6.0000000000000000e+00,
      "predicted_flops": 3.4218367250222003e+08,
      "predicted_flops_count": 1.7280000000000000e+03
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__11921838210132704273<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1/input[1]:48/input[2]:6/input[3]:6/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 138385,
      "real_time": 5.0832352889573858e+03,
      "cpu_time": 1.0253030957105373e+04,
      "time_unit": "ns",
      "items_per_second": 3.3994098281341350e+08,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 4.8000000000000000e+01,
      "input[2]": 6.0000000000000000e+00,
      "input[3]": 6.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 4.8000000000000000e+01,
      "input_height": 6.0000000000000000e+00,
      "input_size": 1.7280000000000000e+03,
      "input_width": 6.0000000000000000e+00,
      "num_iterations": 1.3838500000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 4.8000000000000000e+01,
      "output_height": 6.0000000000000000e+00,
      "output_size": 1.7280000000000000e+03,
      "output_width": 6.0000000000000000e+00,
      "predicted_flops": 3.3994098281341350e+08,
      "predicted_flops_count": 1.7280000000000000e+03
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__5520895430017230184<CUDNN_ACTIVATION_RELU>/input[0]:1/input[1]:224/input[2]:28/input[3]:28/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 112744,
      "real_time": 6.1894668562964407e+03,
      "cpu_time": 1.1281874733898503e+04,
      "time_unit": "ns",
      "items_per_second": 2.8373364633393066e+10,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 2.2400000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 2.2400000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 1.7561600000000000e+05,
      "input_width": 2.8000000000000000e+01,
      "num_iterations": 1.1274400000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 2.2400000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 1.7561600000000000e+05,
      "output_width": 2.8000000000000000e+01,
      "predicted_flops": 2.8373364633393066e+10,
      "predicted_flops_count": 1.7561600000000000e+05
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__5520895430017230184<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1/input[1]:224/input[2]:28/input[3]:28/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 112712,
      "real_time": 6.2137596982609339e+03,
      "cpu_time": 1.1333413452024839e+04,
      "time_unit": "ns",
      "items_per_second": 2.8262438286622227e+10,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 2.2400000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 2.2400000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 1.7561600000000000e+05,
      "input_width": 2.8000000000000000e+01,
      "num_iterations": 1.1271200000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 2.2400000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 1.7561600000000000e+05,
      "output_width": 2.8000000000000000e+01,
      "predicted_flops": 2.8262438286622227e+10,
      "predicted_flops_count": 1.7561600000000000e+05
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__3347073775340954534<CUDNN_ACTIVATION_RELU>/input[0]:1/input[1]:64/input[2]:13/input[3]:13/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 136755,
      "real_time": 5.1087141513678116e+03,
      "cpu_time": 1.0245052977973537e+04,
      "time_unit": "ns",
      "items_per_second": 2.1171668015725865e+09,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 1.3000000000000000e+01,
      "input[3]": 1.3000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 1.3000000000000000e+01,
      "input_size": 1.0816000000000000e+04,
      "input_width": 1.3000000000000000e+01,
      "num_iterations": 1.3675500000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 1.3000000000000000e+01,
      "output_size": 1.0816000000000000e+04,
      "output_width": 1.3000000000000000e+01,
      "predicted_flops": 2.1171668015725865e+09,
      "predicted_flops_count": 1.0816000000000000e+04
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__3347073775340954534<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1/input[1]:64/input[2]:13/input[3]:13/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 136819,
      "real_time": 5.6129846364183513e+03,
      "cpu_time": 1.1029774439220735e+04,
      "time_unit": "ns",
      "items_per_second": 1.9269605567460978e+09,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 1.3000000000000000e+01,
      "input[3]": 1.3000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 1.3000000000000000e+01,
      "input_size": 1.0816000000000000e+04,
      "input_width": 1.3000000000000000e+01,
      "num_iterations": 1.3681900000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 1.3000000000000000e+01,
      "output_size": 1.0816000000000000e+04,
      "output_width": 1.3000000000000000e+01,
      "predicted_flops": 1.9269605567460978e+09,
      "predicted_flops_count": 1.0816000000000000e+04
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__4706172207893919367<CUDNN_ACTIVATION_RELU>/input[0]:1/input[1]:64/input[2]:55/input[3]:55/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 98880,
      "real_time": 6.9711952050919926e+03,
      "cpu_time": 1.2355147481825381e+04,
      "time_unit": "ns",
      "items_per_second": 2.7771421442708721e+10,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 5.5000000000000000e+01,
      "input[3]": 5.5000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 5.5000000000000000e+01,
      "input_size": 1.9360000000000000e+05,
      "input_width": 5.5000000000000000e+01,
      "num_iterations": 9.8880000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 5.5000000000000000e+01,
      "output_size": 1.9360000000000000e+05,
      "output_width": 5.5000000000000000e+01,
      "predicted_flops": 2.7771421442708721e+10,
      "predicted_flops_count": 1.9360000000000000e+05
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__4706172207893919367<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1/input[1]:64/input[2]:55/input[3]:55/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 111620,
      "real_time": 6.2566946705410328e+03,
      "cpu_time": 1.1373156360892195e+04,
      "time_unit": "ns",
      "items_per_second": 3.0942855644138199e+10,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 5.5000000000000000e+01,
      "input[3]": 5.5000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 5.5000000000000000e+01,
      "input_size": 1.9360000000000000e+05,
      "input_width": 5.5000000000000000e+01,
      "num_iterations": 1.1162000000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 5.5000000000000000e+01,
      "output_size": 1.9360000000000000e+05,
      "output_width": 5.5000000000000000e+01,
      "predicted_flops": 3.0942855644138199e+10,
      "predicted_flops_count": 1.9360000000000000e+05
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__10053889073009322567<CUDNN_ACTIVATION_RELU>/input[0]:128/input[1]:192/input[2]:13/input[3]:13/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 8272,
      "real_time": 8.4572458597893623e+04,
      "cpu_time": 8.9835967480713065e+04,
      "time_unit": "ns",
      "items_per_second": 4.9109888359133545e+10,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 1.9200000000000000e+02,
      "input[2]": 1.3000000000000000e+01,
      "input[3]": 1.3000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 1.9200000000000000e+02,
      "input_height": 1.3000000000000000e+01,
      "input_size": 4.1533440000000000e+06,
      "input_width": 1.3000000000000000e+01,
      "num_iterations": 8.2720000000000000e+03,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 1.9200000000000000e+02,
      "output_height": 1.3000000000000000e+01,
      "output_size": 4.1533440000000000e+06,
      "output_width": 1.3000000000000000e+01,
      "predicted_flops": 4.9109888359133545e+10,
      "predicted_flops_count": 4.1533440000000000e+06
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__10053889073009322567<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:128/input[1]:192/input[2]:13/input[3]:13/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 8260,
      "real_time": 8.4757553455439556e+04,
      "cpu_time": 9.0025424455227854e+04,
      "time_unit": "ns",
      "items_per_second": 4.9002641424561394e+10,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 1.9200000000000000e+02,
      "input[2]": 1.3000000000000000e+01,
      "input[3]": 1.3000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 1.9200000000000000e+02,
      "input_height": 1.3000000000000000e+01,
      "input_size": 4.1533440000000000e+06,
      "input_width": 1.3000000000000000e+01,
      "num_iterations": 8.2600000000000000e+03,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 1.9200000000000000e+02,
      "output_height": 1.3000000000000000e+01,
      "output_size": 4.1533440000000000e+06,
      "output_width": 1.3000000000000000e+01,
      "predicted_flops": 4.9002641424561394e+10,
      "predicted_flops_count": 4.1533440000000000e+06
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__11468939099632256613<CUDNN_ACTIVATION_RELU>/input[0]:128/input[1]:64/input[2]:13/input[3]:13/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 22250,
      "real_time": 3.1465491531021093e+04,
      "cpu_time": 3.6630815415754048e+04,
      "time_unit": "ns",
      "items_per_second": 4.3998931293830421e+10,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 1.3000000000000000e+01,
      "input[3]": 1.3000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 1.3000000000000000e+01,
      "input_size": 1.3844480000000000e+06,
      "input_width": 1.3000000000000000e+01,
      "num_iterations": 2.2250000000000000e+04,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 1.3000000000000000e+01,
      "output_size": 1.3844480000000000e+06,
      "output_width": 1.3000000000000000e+01,
      "predicted_flops": 4.3998931293830421e+10,
      "predicted_flops_count": 1.3844480000000000e+06
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__11468939099632256613<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:128/input[1]:64/input[2]:13/input[3]:13/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 22207,
      "real_time": 3.1511725246909351e+04,
      "cpu_time": 3.6731604449076483e+04,
      "time_unit": "ns",
      "items_per_second": 4.3934376463116241e+10,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 1.3000000000000000e+01,
      "input[3]": 1.3000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 1.3000000000000000e+01,
      "input_size": 1.3844480000000000e+06,
      "input_width": 1.3000000000000000e+01,
      "num_iterations": 2.2207000000000000e+04,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 1.3000000000000000e+01,
      "output_size": 1.3844480000000000e+06,
      "output_width": 1.3000000000000000e+01,
      "predicted_flops": 4.3934376463116241e+10,
      "predicted_flops_count": 1.3844480000000000e+06
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__1940379314062000542<CUDNN_ACTIVATION_RELU>/input[0]:128/input[1]:48/input[2]:13/input[3]:13/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 28074,
      "real_time": 2.4953119811656663e+04,
      "cpu_time": 3.0131254897778159e+04,
      "time_unit": "ns",
      "items_per_second": 4.1611470142300568e+10,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 4.8000000000000000e+01,
      "input[2]": 1.3000000000000000e+01,
      "input[3]": 1.3000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 4.8000000000000000e+01,
      "input_height": 1.3000000000000000e+01,
      "input_size": 1.0383360000000000e+06,
      "input_width": 1.3000000000000000e+01,
      "num_iterations": 2.8074000000000000e+04,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 4.8000000000000000e+01,
      "output_height": 1.3000000000000000e+01,
      "output_size": 1.0383360000000000e+06,
      "output_width": 1.3000000000000000e+01,
      "predicted_flops": 4.1611470142300568e+10,
      "predicted_flops_count": 1.0383360000000000e+06
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__1940379314062000542<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:128/input[1]:48/input[2]:13/input[3]:13/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 27825,
      "real_time": 2.5360101319209680e+04,
      "cpu_time": 3.0711544150893729e+04,
      "time_unit": "ns",
      "items_per_second": 4.0943685000717445e+10,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 4.8000000000000000e+01,
      "input[2]": 1.3000000000000000e+01,
      "input[3]": 1.3000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 4.8000000000000000e+01,
      "input_height": 1.3000000000000000e+01,
      "input_size": 1.0383360000000000e+06,
      "input_width": 1.3000000000000000e+01,
      "num_iterations": 2.7825000000000000e+04,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 4.8000000000000000e+01,
      "output_height": 1.3000000000000000e+01,
      "output_size": 1.0383360000000000e+06,
      "output_width": 1.3000000000000000e+01,
      "predicted_flops": 4.0943685000717445e+10,
      "predicted_flops_count": 1.0383360000000000e+06
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__9876695692234492599<CUDNN_ACTIVATION_RELU>/input[0]:128/input[1]:384/input[2]:13/input[3]:13/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 4264,
      "real_time": 1.6422472084976936e+05,
      "cpu_time": 1.6979971083492416e+05,
      "time_unit": "ns",
      "items_per_second": 5.0581227704438301e+10,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 3.8400000000000000e+02,
      "input[2]": 1.3000000000000000e+01,
      "input[3]": 1.3000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 3.8400000000000000e+02,
      "input_height": 1.3000000000000000e+01,
      "input_size": 8.3066880000000000e+06,
      "input_width": 1.3000000000000000e+01,
      "num_iterations": 4.2640000000000000e+03,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 3.8400000000000000e+02,
      "output_height": 1.3000000000000000e+01,
      "output_size": 8.3066880000000000e+06,
      "output_width": 1.3000000000000000e+01,
      "predicted_flops": 5.0581227704438301e+10,
      "predicted_flops_count": 8.3066880000000000e+06
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__9876695692234492599<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:128/input[1]:384/input[2]:13/input[3]:13/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 4255,
      "real_time": 1.6446070976844811e+05,
      "cpu_time": 1.7001602373681354e+05,
      "time_unit": "ns",
      "items_per_second": 5.0508647394842041e+10,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 3.8400000000000000e+02,
      "input[2]": 1.3000000000000000e+01,
      "input[3]": 1.3000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 3.8400000000000000e+02,
      "input_height": 1.3000000000000000e+01,
      "input_size": 8.3066880000000000e+06,
      "input_width": 1.3000000000000000e+01,
      "num_iterations": 4.2550000000000000e+03,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 3.8400000000000000e+02,
      "output_height": 1.3000000000000000e+01,
      "output_size": 8.3066880000000000e+06,
      "output_width": 1.3000000000000000e+01,
      "predicted_flops": 5.0508647394842041e+10,
      "predicted_flops_count": 8.3066880000000000e+06
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__11112938498448767206<CUDNN_ACTIVATION_RELU>/input[0]:1/input[1]:64/input[2]:112/input[3]:112/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 34190,
      "real_time": 2.0480165539554404e+04,
      "cpu_time": 2.5673575080433442e+04,
      "time_unit": "ns",
      "items_per_second": 3.9199683149507751e+10,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 1.1200000000000000e+02,
      "input[3]": 1.1200000000000000e+02,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 1.1200000000000000e+02,
      "input_size": 8.0281600000000000e+05,
      "input_width": 1.1200000000000000e+02,
      "num_iterations": 3.4190000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 1.1200000000000000e+02,
      "output_size": 8.0281600000000000e+05,
      "output_width": 1.1200000000000000e+02,
      "predicted_flops": 3.9199683149507751e+10,
      "predicted_flops_count": 8.0281600000000000e+05
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__11112938498448767206<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1/input[1]:64/input[2]:112/input[3]:112/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 34103,
      "real_time": 2.0527657859120889e+04,
      "cpu_time": 2.5696845233538137e+04,
      "time_unit": "ns",
      "items_per_second": 3.9108991659430405e+10,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 1.1200000000000000e+02,
      "input[3]": 1.1200000000000000e+02,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 1.1200000000000000e+02,
      "input_size": 8.0281600000000000e+05,
      "input_width": 1.1200000000000000e+02,
      "num_iterations": 3.4103000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 1.1200000000000000e+02,
      "output_size": 8.0281600000000000e+05,
      "output_width": 1.1200000000000000e+02,
      "predicted_flops": 3.9108991659430405e+10,
      "predicted_flops_count": 8.0281600000000000e+05
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__8389815448405428378<CUDNN_ACTIVATION_RELU>/input[0]:1/input[1]:64/input[2]:56/input[3]:56/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 111587,
      "real_time": 6.2962677984975762e+03,
      "cpu_time": 1.1398328810692214e+04,
      "time_unit": "ns",
      "items_per_second": 3.1876661924686916e+10,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 2.0070400000000000e+05,
      "input_width": 5.6000000000000000e+01,
      "num_iterations": 1.1158700000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 5.6000000000000000e+01,
      "output_size": 2.0070400000000000e+05,
      "output_width": 5.6000000000000000e+01,
      "predicted_flops": 3.1876661924686916e+10,
      "predicted_flops_count": 2.0070400000000000e+05
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__8389815448405428378<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1/input[1]:64/input[2]:56/input[3]:56/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 111083,
      "real_time": 6.3112148098297494e+03,
      "cpu_time": 1.1421652602112832e+04,
      "time_unit": "ns",
      "items_per_second": 3.1801167611567028e+10,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 2.0070400000000000e+05,
      "input_width": 5.6000000000000000e+01,
      "num_iterations": 1.1108300000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 5.6000000000000000e+01,
      "output_size": 2.0070400000000000e+05,
      "output_width": 5.6000000000000000e+01,
      "predicted_flops": 3.1801167611567028e+10,
      "predicted_flops_count": 2.0070400000000000e+05
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__13008855741978255737<CUDNN_ACTIVATION_RELU>/input[0]:1/input[1]:128/input[2]:6/input[3]:6/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 137938,
      "real_time": 5.0943705981791945e+03,
      "cpu_time": 1.0238369194864388e+04,
      "time_unit": "ns",
      "items_per_second": 9.0452783345737934e+08,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 1.2800000000000000e+02,
      "input[2]": 6.0000000000000000e+00,
      "input[3]": 6.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 1.2800000000000000e+02,
      "input_height": 6.0000000000000000e+00,
      "input_size": 4.6080000000000000e+03,
      "input_width": 6.0000000000000000e+00,
      "num_iterations": 1.3793800000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 6.0000000000000000e+00,
      "output_size": 4.6080000000000000e+03,
      "output_width": 6.0000000000000000e+00,
      "predicted_flops": 9.0452783345737934e+08,
      "predicted_flops_count": 4.6080000000000000e+03
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__13008855741978255737<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1/input[1]:128/input[2]:6/input[3]:6/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 119947,
      "real_time": 5.7952350494519742e+03,
      "cpu_time": 1.1240898138351164e+04,
      "time_unit": "ns",
      "items_per_second": 7.9513599719061530e+08,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 1.2800000000000000e+02,
      "input[2]": 6.0000000000000000e+00,
      "input[3]": 6.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 1.2800000000000000e+02,
      "input_height": 6.0000000000000000e+00,
      "input_size": 4.6080000000000000e+03,
      "input_width": 6.0000000000000000e+00,
      "num_iterations": 1.1994700000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 6.0000000000000000e+00,
      "output_size": 4.6080000000000000e+03,
      "output_width": 6.0000000000000000e+00,
      "predicted_flops": 7.9513599719061530e+08,
      "predicted_flops_count": 4.6080000000000000e+03
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__404216268009676040<CUDNN_ACTIVATION_RELU>/input[0]:1/input[1]:96/input[2]:56/input[3]:56/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 90371,
      "real_time": 7.3700482106585114e+03,
      "cpu_time": 1.2694615662118158e+04,
      "time_unit": "ns",
      "items_per_second": 4.0848579465818817e+10,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 9.6000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 9.6000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 3.0105600000000000e+05,
      "input_width": 5.6000000000000000e+01,
      "num_iterations": 9.0371000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 9.6000000000000000e+01,
      "output_height": 5.6000000000000000e+01,
      "output_size": 3.0105600000000000e+05,
      "output_width": 5.6000000000000000e+01,
      "predicted_flops": 4.0848579465818817e+10,
      "predicted_flops_count": 3.0105600000000000e+05
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__404216268009676040<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1/input[1]:96/input[2]:56/input[3]:56/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 99897,
      "real_time": 7.0184431338562690e+03,
      "cpu_time": 1.2188650680174955e+04,
      "time_unit": "ns",
      "items_per_second": 4.2894983154844688e+10,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 9.6000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 9.6000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 3.0105600000000000e+05,
      "input_width": 5.6000000000000000e+01,
      "num_iterations": 9.9897000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 9.6000000000000000e+01,
      "output_height": 5.6000000000000000e+01,
      "output_size": 3.0105600000000000e+05,
      "output_width": 5.6000000000000000e+01,
      "predicted_flops": 4.2894983154844688e+10,
      "predicted_flops_count": 3.0105600000000000e+05
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__11598021558777893144<CUDNN_ACTIVATION_RELU>/input[0]:1/input[1]:160/input[2]:56/input[3]:56/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 49472,
      "real_time": 1.4127205841705591e+04,
      "cpu_time": 1.9258445726884042e+04,
      "time_unit": "ns",
      "items_per_second": 3.5517285273690193e+10,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 1.6000000000000000e+02,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 1.6000000000000000e+02,
      "input_height": 5.6000000000000000e+01,
      "input_size": 5.0176000000000000e+05,
      "input_width": 5.6000000000000000e+01,
      "num_iterations": 4.9472000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 1.6000000000000000e+02,
      "output_height": 5.6000000000000000e+01,
      "output_size": 5.0176000000000000e+05,
      "output_width": 5.6000000000000000e+01,
      "predicted_flops": 3.5517285273690193e+10,
      "predicted_flops_count": 5.0176000000000000e+05
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__11598021558777893144<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1/input[1]:160/input[2]:56/input[3]:56/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 49465,
      "real_time": 1.4193462519838180e+04,
      "cpu_time": 1.9336508763811380e+04,
      "time_unit": "ns",
      "items_per_second": 3.5351486594528351e+10,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 1.6000000000000000e+02,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 1.6000000000000000e+02,
      "input_height": 5.6000000000000000e+01,
      "input_size": 5.0176000000000000e+05,
      "input_width": 5.6000000000000000e+01,
      "num_iterations": 4.9465000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 1.6000000000000000e+02,
      "output_height": 5.6000000000000000e+01,
      "output_size": 5.0176000000000000e+05,
      "output_width": 5.6000000000000000e+01,
      "predicted_flops": 3.5351486594528351e+10,
      "predicted_flops_count": 5.0176000000000000e+05
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__3426667249210137038<CUDNN_ACTIVATION_RELU>/input[0]:1/input[1]:16/input[2]:27/input[3]:27/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 136812,
      "real_time": 5.1114140552133395e+03,
      "cpu_time": 1.0271502382824929e+04,
      "time_unit": "ns",
      "items_per_second": 2.2819517014285727e+09,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 1.6000000000000000e+01,
      "input[2]": 2.7000000000000000e+01,
      "input[3]": 2.7000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 1.6000000000000000e+01,
      "input_height": 2.7000000000000000e+01,
      "input_size": 1.1664000000000000e+04,
      "input_width": 2.7000000000000000e+01,
      "num_iterations": 1.3681200000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 1.6000000000000000e+01,
      "output_height": 2.7000000000000000e+01,
      "output_size": 1.1664000000000000e+04,
      "output_width": 2.7000000000000000e+01,
      "predicted_flops": 2.2819517014285727e+09,
      "predicted_flops_count": 1.1664000000000000e+04
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__3426667249210137038<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1/input[1]:16/input[2]:27/input[3]:27/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 136666,
      "real_time": 5.2841832607485985e+03,
      "cpu_time": 1.0504830499175803e+04,
      "time_unit": "ns",
      "items_per_second": 2.2073420667752519e+09,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 1.6000000000000000e+01,
      "input[2]": 2.7000000000000000e+01,
      "input[3]": 2.7000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 1.6000000000000000e+01,
      "input_height": 2.7000000000000000e+01,
      "input_size": 1.1664000000000000e+04,
      "input_width": 2.7000000000000000e+01,
      "num_iterations": 1.3666600000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 1.6000000000000000e+01,
      "output_height": 2.7000000000000000e+01,
      "output_size": 1.1664000000000000e+04,
      "output_width": 2.7000000000000000e+01,
      "predicted_flops": 2.2073420667752519e+09,
      "predicted_flops_count": 1.1664000000000000e+04
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__17090033127250641120<CUDNN_ACTIVATION_RELU>/input[0]:1/input[1]:192/input[2]:56/input[3]:56/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 40901,
      "real_time": 1.6626466936293484e+04,
      "cpu_time": 2.1787568250151104e+04,
      "time_unit": "ns",
      "items_per_second": 3.6214067745545227e+10,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 1.9200000000000000e+02,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 1.9200000000000000e+02,
      "input_height": 5.6000000000000000e+01,
      "input_size": 6.0211200000000000e+05,
      "input_width": 5.6000000000000000e+01,
      "num_iterations": 4.0901000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 1.9200000000000000e+02,
      "output_height": 5.6000000000000000e+01,
      "output_size": 6.0211200000000000e+05,
      "output_width": 5.6000000000000000e+01,
      "predicted_flops": 3.6214067745545227e+10,
      "predicted_flops_count": 6.0211200000000000e+05
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__17090033127250641120<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1/input[1]:192/input[2]:56/input[3]:56/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 42083,
      "real_time": 1.6653825341766293e+04,
      "cpu_time": 2.1848667181515993e+04,
      "time_unit": "ns",
      "items_per_second": 3.6154576359700218e+10,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 1.9200000000000000e+02,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 1.9200000000000000e+02,
      "input_height": 5.6000000000000000e+01,
      "input_size": 6.0211200000000000e+05,
      "input_width": 5.6000000000000000e+01,
      "num_iterations": 4.2083000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 1.9200000000000000e+02,
      "output_height": 5.6000000000000000e+01,
      "output_size": 6.0211200000000000e+05,
      "output_width": 5.6000000000000000e+01,
      "predicted_flops": 3.6154576359700218e+10,
      "predicted_flops_count": 6.0211200000000000e+05
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__4689638324051192956<CUDNN_ACTIVATION_RELU>/input[0]:1/input[1]:224/input[2]:56/input[3]:56/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 37799,
      "real_time": 1.8506782055946300e+04,
      "cpu_time": 2.3694917484573707e+04,
      "time_unit": "ns",
      "items_per_second": 3.7957112040139664e+10,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 2.2400000000000000e+02,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 2.2400000000000000e+02,
      "input_height": 5.6000000000000000e+01,
      "input_size": 7.0246400000000000e+05,
      "input_width": 5.6000000000000000e+01,
      "num_iterations": 3.7799000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 2.2400000000000000e+02,
      "output_height": 5.6000000000000000e+01,
      "output_size": 7.0246400000000000e+05,
      "output_width": 5.6000000000000000e+01,
      "predicted_flops": 3.7957112040139664e+10,
      "predicted_flops_count": 7.0246400000000000e+05
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__4689638324051192956<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1/input[1]:224/input[2]:56/input[3]:56/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 37687,
      "real_time": 1.8604143764251174e+04,
      "cpu_time": 2.3767133282043374e+04,
      "time_unit": "ns",
      "items_per_second": 3.7758469774342476e+10,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 2.2400000000000000e+02,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 2.2400000000000000e+02,
      "input_height": 5.6000000000000000e+01,
      "input_size": 7.0246400000000000e+05,
      "input_width": 5.6000000000000000e+01,
      "num_iterations": 3.7687000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 2.2400000000000000e+02,
      "output_height": 5.6000000000000000e+01,
      "output_size": 7.0246400000000000e+05,
      "output_width": 5.6000000000000000e+01,
      "predicted_flops": 3.7758469774342476e+10,
      "predicted_flops_count": 7.0246400000000000e+05
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__10922300483511070290<CUDNN_ACTIVATION_RELU>/input[0]:128/input[1]:96/input[2]:109/input[3]:109/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 206,
      "real_time": 3.3921848437794060e+06,
      "cpu_time": 3.5673434951455020e+06,
      "time_unit": "ns",
      "items_per_second": 4.3038258445061897e+10,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 9.6000000000000000e+01,
      "input[2]": 1.0900000000000000e+02,
      "input[3]": 1.0900000000000000e+02,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 9.6000000000000000e+01,
      "input_height": 1.0900000000000000e+02,
      "input_size": 1.4599372800000000e+08,
      "input_width": 1.0900000000000000e+02,
      "num_iterations": 2.0600000000000000e+02,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 9.6000000000000000e+01,
      "output_height": 1.0900000000000000e+02,
      "output_size": 1.4599372800000000e+08,
      "output_width": 1.0900000000000000e+02,
      "predicted_flops": 4.3038258445061897e+10,
      "predicted_flops_count": 1.4599372800000000e+08
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__10922300483511070290<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:128/input[1]:96/input[2]:109/input[3]:109/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 207,
      "real_time": 3.3863826906803437e+06,
      "cpu_time": 3.5614056763284164e+06,
      "time_unit": "ns",
      "items_per_second": 4.3111999243850677e+10,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 9.6000000000000000e+01,
      "input[2]": 1.0900000000000000e+02,
      "input[3]": 1.0900000000000000e+02,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 9.6000000000000000e+01,
      "input_height": 1.0900000000000000e+02,
      "input_size": 1.4599372800000000e+08,
      "input_width": 1.0900000000000000e+02,
      "num_iterations": 2.0700000000000000e+02,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 9.6000000000000000e+01,
      "output_height": 1.0900000000000000e+02,
      "output_size": 1.4599372800000000e+08,
      "output_width": 1.0900000000000000e+02,
      "predicted_flops": 4.3111999243850677e+10,
      "predicted_flops_count": 1.4599372800000000e+08
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__4421964639979822548<CUDNN_ACTIVATION_RELU>/input[0]:1/input[1]:192/input[2]:28/input[3]:28/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 102793,
      "real_time": 6.7595249082923983e+03,
      "cpu_time": 1.2289144056519217e+04,
      "time_unit": "ns",
      "items_per_second": 2.2269020684476864e+10,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 1.9200000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 1.9200000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 1.5052800000000000e+05,
      "input_width": 2.8000000000000000e+01,
      "num_iterations": 1.0279300000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 1.9200000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 1.5052800000000000e+05,
      "output_width": 2.8000000000000000e+01,
      "predicted_flops": 2.2269020684476864e+10,
      "predicted_flops_count": 1.5052800000000000e+05
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__4421964639979822548<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1/input[1]:192/input[2]:28/input[3]:28/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 102960,
      "real_time": 6.4912606430283122e+03,
      "cpu_time": 1.1867702670952916e+04,
      "time_unit": "ns",
      "items_per_second": 2.3189332285042168e+10,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 1.9200000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 1.9200000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 1.5052800000000000e+05,
      "input_width": 2.8000000000000000e+01,
      "num_iterations": 1.0296000000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 1.9200000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 1.5052800000000000e+05,
      "output_width": 2.8000000000000000e+01,
      "predicted_flops": 2.3189332285042168e+10,
      "predicted_flops_count": 1.5052800000000000e+05
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__11288725732342988941<CUDNN_ACTIVATION_RELU>/input[0]:1/input[1]:128/input[2]:56/input[3]:56/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 74726,
      "real_time": 9.3773043638339368e+03,
      "cpu_time": 1.4555968431329966e+04,
      "time_unit": "ns",
      "items_per_second": 4.2806331588013336e+10,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 1.2800000000000000e+02,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 1.2800000000000000e+02,
      "input_height": 5.6000000000000000e+01,
      "input_size": 4.0140800000000000e+05,
      "input_width": 5.6000000000000000e+01,
      "num_iterations": 7.4726000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 5.6000000000000000e+01,
      "output_size": 4.0140800000000000e+05,
      "output_width": 5.6000000000000000e+01,
      "predicted_flops": 4.2806331588013336e+10,
      "predicted_flops_count": 4.0140800000000000e+05
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__11288725732342988941<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1/input[1]:128/input[2]:56/input[3]:56/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 74451,
      "real_time": 9.4061994862551946e+03,
      "cpu_time": 1.4580417993051027e+04,
      "time_unit": "ns",
      "items_per_second": 4.2674833824921249e+10,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 1.2800000000000000e+02,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 1.2800000000000000e+02,
      "input_height": 5.6000000000000000e+01,
      "input_size": 4.0140800000000000e+05,
      "input_width": 5.6000000000000000e+01,
      "num_iterations": 7.4451000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 5.6000000000000000e+01,
      "output_size": 4.0140800000000000e+05,
      "output_width": 5.6000000000000000e+01,
      "predicted_flops": 4.2674833824921249e+10,
      "predicted_flops_count": 4.0140800000000000e+05
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__7522329841868264703<CUDNN_ACTIVATION_RELU>/input[0]:128/input[1]:512/input[2]:12/input[3]:12/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 3763,
      "real_time": 1.8604309206447704e+05,
      "cpu_time": 1.9171880175382656e+05,
      "time_unit": "ns",
      "items_per_second": 5.0725796347920029e+10,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 1.2000000000000000e+01,
      "input[3]": 1.2000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 1.2000000000000000e+01,
      "input_size": 9.4371840000000000e+06,
      "input_width": 1.2000000000000000e+01,
      "num_iterations": 3.7630000000000000e+03,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 1.2000000000000000e+01,
      "output_size": 9.4371840000000000e+06,
      "output_width": 1.2000000000000000e+01,
      "predicted_flops": 5.0725796347920029e+10,
      "predicted_flops_count": 9.4371840000000000e+06
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__7522329841868264703<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:128/input[1]:512/input[2]:12/input[3]:12/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 3757,
      "real_time": 1.8632144292956329e+05,
      "cpu_time": 1.9198068219320645e+05,
      "time_unit": "ns",
      "items_per_second": 5.0650015648320305e+10,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 1.2000000000000000e+01,
      "input[3]": 1.2000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 1.2000000000000000e+01,
      "input_size": 9.4371840000000000e+06,
      "input_width": 1.2000000000000000e+01,
      "num_iterations": 3.7570000000000000e+03,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 1.2000000000000000e+01,
      "output_size": 9.4371840000000000e+06,
      "output_width": 1.2000000000000000e+01,
      "predicted_flops": 5.0650015648320305e+10,
      "predicted_flops_count": 9.4371840000000000e+06
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__3492501323084921491<CUDNN_ACTIVATION_RELU>/input[0]:1/input[1]:192/input[2]:27/input[3]:27/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 116308,
      "real_time": 6.0110085939018045e+03,
      "cpu_time": 1.1172131254949500e+04,
      "time_unit": "ns",
      "items_per_second": 2.3285276973651005e+10,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 1.9200000000000000e+02,
      "input[2]": 2.7000000000000000e+01,
      "input[3]": 2.7000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 1.9200000000000000e+02,
      "input_height": 2.7000000000000000e+01,
      "input_size": 1.3996800000000000e+05,
      "input_width": 2.7000000000000000e+01,
      "num_iterations": 1.1630800000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 1.9200000000000000e+02,
      "output_height": 2.7000000000000000e+01,
      "output_size": 1.3996800000000000e+05,
      "output_width": 2.7000000000000000e+01,
      "predicted_flops": 2.3285276973651005e+10,
      "predicted_flops_count": 1.3996800000000000e+05
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__3492501323084921491<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1/input[1]:192/input[2]:27/input[3]:27/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 116004,
      "real_time": 6.2620334788570408e+03,
      "cpu_time": 1.1566204872242388e+04,
      "time_unit": "ns",
      "items_per_second": 2.2351844727848251e+10,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 1.9200000000000000e+02,
      "input[2]": 2.7000000000000000e+01,
      "input[3]": 2.7000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 1.9200000000000000e+02,
      "input_height": 2.7000000000000000e+01,
      "input_size": 1.3996800000000000e+05,
      "input_width": 2.7000000000000000e+01,
      "num_iterations": 1.1600400000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 1.9200000000000000e+02,
      "output_height": 2.7000000000000000e+01,
      "output_size": 1.3996800000000000e+05,
      "output_width": 2.7000000000000000e+01,
      "predicted_flops": 2.2351844727848251e+10,
      "predicted_flops_count": 1.3996800000000000e+05
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__1711419874698263545<CUDNN_ACTIVATION_RELU>/input[0]:128/input[1]:256/input[2]:25/input[3]:25/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 1753,
      "real_time": 3.9929158194216382e+05,
      "cpu_time": 4.0680374729031947e+05,
      "time_unit": "ns",
      "items_per_second": 5.1290838390293106e+10,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 2.5000000000000000e+01,
      "input[3]": 2.5000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 2.5000000000000000e+01,
      "input_size": 2.0480000000000000e+07,
      "input_width": 2.5000000000000000e+01,
      "num_iterations": 1.7530000000000000e+03,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 2.5000000000000000e+01,
      "output_size": 2.0480000000000000e+07,
      "output_width": 2.5000000000000000e+01,
      "predicted_flops": 5.1290838390293106e+10,
      "predicted_flops_count": 2.0480000000000000e+07
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__1711419874698263545<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:128/input[1]:256/input[2]:25/input[3]:25/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 1752,
      "real_time": 3.9949632842414244e+05,
      "cpu_time": 4.0700928481730015e+05,
      "time_unit": "ns",
      "items_per_second": 5.1264551243275826e+10,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 2.5000000000000000e+01,
      "input[3]": 2.5000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 2.5000000000000000e+01,
      "input_size": 2.0480000000000000e+07,
      "input_width": 2.5000000000000000e+01,
      "num_iterations": 1.7520000000000000e+03,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 2.5000000000000000e+01,
      "output_size": 2.0480000000000000e+07,
      "output_width": 2.5000000000000000e+01,
      "predicted_flops": 5.1264551243275826e+10,
      "predicted_flops_count": 2.0480000000000000e+07
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__16506615735362298912<CUDNN_ACTIVATION_RELU>/input[0]:1/input[1]:32/input[2]:27/input[3]:27/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 132056,
      "real_time": 5.3047078052636389e+03,
      "cpu_time": 1.0467422873626707e+04,
      "time_unit": "ns",
      "items_per_second": 4.3976031963254604e+09,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 3.2000000000000000e+01,
      "input[2]": 2.7000000000000000e+01,
      "input[3]": 2.7000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 3.2000000000000000e+01,
      "input_height": 2.7000000000000000e+01,
      "input_size": 2.3328000000000000e+04,
      "input_width": 2.7000000000000000e+01,
      "num_iterations": 1.3205600000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 3.2000000000000000e+01,
      "output_height": 2.7000000000000000e+01,
      "output_size": 2.3328000000000000e+04,
      "output_width": 2.7000000000000000e+01,
      "predicted_flops": 4.3976031963254604e+09,
      "predicted_flops_count": 2.3328000000000000e+04
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__16506615735362298912<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1/input[1]:32/input[2]:27/input[3]:27/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 131851,
      "real_time": 5.2930370032704304e+03,
      "cpu_time": 1.0485323797304922e+04,
      "time_unit": "ns",
      "items_per_second": 4.4072996250708685e+09,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 3.2000000000000000e+01,
      "input[2]": 2.7000000000000000e+01,
      "input[3]": 2.7000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 3.2000000000000000e+01,
      "input_height": 2.7000000000000000e+01,
      "input_size": 2.3328000000000000e+04,
      "input_width": 2.7000000000000000e+01,
      "num_iterations": 1.3185100000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 3.2000000000000000e+01,
      "output_height": 2.7000000000000000e+01,
      "output_size": 2.3328000000000000e+04,
      "output_width": 2.7000000000000000e+01,
      "predicted_flops": 4.4072996250708685e+09,
      "predicted_flops_count": 2.3328000000000000e+04
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__15643481193937761859<CUDNN_ACTIVATION_RELU>/input[0]:1/input[1]:96/input[2]:27/input[3]:27/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 124795,
      "real_time": 5.6167845312599138e+03,
      "cpu_time": 1.0759873127909259e+04,
      "time_unit": "ns",
      "items_per_second": 1.2459797880888573e+10,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 9.6000000000000000e+01,
      "input[2]": 2.7000000000000000e+01,
      "input[3]": 2.7000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 9.6000000000000000e+01,
      "input_height": 2.7000000000000000e+01,
      "input_size": 6.9984000000000000e+04,
      "input_width": 2.7000000000000000e+01,
      "num_iterations": 1.2479500000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 9.6000000000000000e+01,
      "output_height": 2.7000000000000000e+01,
      "output_size": 6.9984000000000000e+04,
      "output_width": 2.7000000000000000e+01,
      "predicted_flops": 1.2459797880888573e+10,
      "predicted_flops_count": 6.9984000000000000e+04
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__15643481193937761859<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1/input[1]:96/input[2]:27/input[3]:27/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 124821,
      "real_time": 5.7173100167558086e+03,
      "cpu_time": 1.0906604906185719e+04,
      "time_unit": "ns",
      "items_per_second": 1.2240721562220137e+10,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 9.6000000000000000e+01,
      "input[2]": 2.7000000000000000e+01,
      "input[3]": 2.7000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 9.6000000000000000e+01,
      "input_height": 2.7000000000000000e+01,
      "input_size": 6.9984000000000000e+04,
      "input_width": 2.7000000000000000e+01,
      "num_iterations": 1.2482100000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 9.6000000000000000e+01,
      "output_height": 2.7000000000000000e+01,
      "output_size": 6.9984000000000000e+04,
      "output_width": 2.7000000000000000e+01,
      "predicted_flops": 1.2240721562220137e+10,
      "predicted_flops_count": 6.9984000000000000e+04
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__4522224137620633537<CUDNN_ACTIVATION_RELU>/input[0]:1/input[1]:64/input[2]:27/input[3]:27/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 112407,
      "real_time": 6.2078821707970519e+03,
      "cpu_time": 1.1726276041506189e+04,
      "time_unit": "ns",
      "items_per_second": 7.5156065653884144e+09,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 2.7000000000000000e+01,
      "input[3]": 2.7000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 2.7000000000000000e+01,
      "input_size": 4.6656000000000000e+04,
      "input_width": 2.7000000000000000e+01,
      "num_iterations": 1.1240700000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 2.7000000000000000e+01,
      "output_size": 4.6656000000000000e+04,
      "output_width": 2.7000000000000000e+01,
      "predicted_flops": 7.5156065653884144e+09,
      "predicted_flops_count": 4.6656000000000000e+04
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__4522224137620633537<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1/input[1]:64/input[2]:27/input[3]:27/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 111850,
      "real_time": 5.8037586167934960e+03,
      "cpu_time": 1.1115157291042897e+04,
      "time_unit": "ns",
      "items_per_second": 8.0389284049474926e+09,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 2.7000000000000000e+01,
      "input[3]": 2.7000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 2.7000000000000000e+01,
      "input_size": 4.6656000000000000e+04,
      "input_width": 2.7000000000000000e+01,
      "num_iterations": 1.1185000000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 2.7000000000000000e+01,
      "output_size": 4.6656000000000000e+04,
      "output_width": 2.7000000000000000e+01,
      "predicted_flops": 8.0389284049474926e+09,
      "predicted_flops_count": 4.6656000000000000e+04
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__14052554398038873058<CUDNN_ACTIVATION_RELU>/input[0]:128/input[1]:208/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 6665,
      "real_time": 1.0500099212016816e+05,
      "cpu_time": 1.1032844621137119e+05,
      "time_unit": "ns",
      "items_per_second": 4.9697663751861732e+10,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 2.0800000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 2.0800000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 5.2183040000000000e+06,
      "input_width": 1.4000000000000000e+01,
      "num_iterations": 6.6650000000000000e+03,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 2.0800000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 5.2183040000000000e+06,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 4.9697663751861732e+10,
      "predicted_flops_count": 5.2183040000000000e+06
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__14052554398038873058<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:128/input[1]:208/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 6652,
      "real_time": 1.0524014355633683e+05,
      "cpu_time": 1.1056761815987638e+05,
      "time_unit": "ns",
      "items_per_second": 4.9584729017464272e+10,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 2.0800000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 2.0800000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 5.2183040000000000e+06,
      "input_width": 1.4000000000000000e+01,
      "num_iterations": 6.6520000000000000e+03,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 2.0800000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 5.2183040000000000e+06,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 4.9584729017464272e+10,
      "predicted_flops_count": 5.2183040000000000e+06
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__13834392779313692946<CUDNN_ACTIVATION_RELU>/input[0]:1/input[1]:512/input[2]:28/input[3]:28/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 74734,
      "real_time": 9.3806119579875285e+03,
      "cpu_time": 1.4559175877138417e+04,
      "time_unit": "ns",
      "items_per_second": 4.2791238119406883e+10,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 4.0140800000000000e+05,
      "input_width": 2.8000000000000000e+01,
      "num_iterations": 7.4734000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 4.0140800000000000e+05,
      "output_width": 2.8000000000000000e+01,
      "predicted_flops": 4.2791238119406883e+10,
      "predicted_flops_count": 4.0140800000000000e+05
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__13834392779313692946<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1/input[1]:512/input[2]:28/input[3]:28/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 74306,
      "real_time": 9.4019893675294898e+03,
      "cpu_time": 1.4588880897843082e+04,
      "time_unit": "ns",
      "items_per_second": 4.2693943197414597e+10,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 4.0140800000000000e+05,
      "input_width": 2.8000000000000000e+01,
      "num_iterations": 7.4306000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 4.0140800000000000e+05,
      "output_width": 2.8000000000000000e+01,
      "predicted_flops": 4.2693943197414597e+10,
      "predicted_flops_count": 4.0140800000000000e+05
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__3117977759906910434<CUDNN_ACTIVATION_RELU>/input[0]:1/input[1]:256/input[2]:56/input[3]:56/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 34178,
      "real_time": 2.0493145184266006e+04,
      "cpu_time": 2.5703389168437781e+04,
      "time_unit": "ns",
      "items_per_second": 3.9174855434898148e+10,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 5.6000000000000000e+01,
      "input_size": 8.0281600000000000e+05,
      "input_width": 5.6000000000000000e+01,
      "num_iterations": 3.4178000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 5.6000000000000000e+01,
      "output_size": 8.0281600000000000e+05,
      "output_width": 5.6000000000000000e+01,
      "predicted_flops": 3.9174855434898148e+10,
      "predicted_flops_count": 8.0281600000000000e+05
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__3117977759906910434<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1/input[1]:256/input[2]:56/input[3]:56/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 34084,
      "real_time": 2.0733599236137718e+04,
      "cpu_time": 2.6010823582991889e+04,
      "time_unit": "ns",
      "items_per_second": 3.8720532352179756e+10,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 5.6000000000000000e+01,
      "input_size": 8.0281600000000000e+05,
      "input_width": 5.6000000000000000e+01,
      "num_iterations": 3.4084000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 5.6000000000000000e+01,
      "output_size": 8.0281600000000000e+05,
      "output_width": 5.6000000000000000e+01,
      "predicted_flops": 3.8720532352179756e+10,
      "predicted_flops_count": 8.0281600000000000e+05
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__3521402535742402018<CUDNN_ACTIVATION_RELU>/input[0]:1/input[1]:1024/input[2]:-1/input[3]:-1/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 120623,
      "real_time": 5.1194221706949374e+03,
      "cpu_time": 1.0289667335335987e+04,
      "time_unit": "ns",
      "items_per_second": 2.0002257400486994e+08,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 1.0240000000000000e+03,
      "input[2]": -1.0000000000000000e+00,
      "input[3]": -1.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 1.0240000000000000e+03,
      "input_height": 1.0000000000000000e+00,
      "input_size": 1.0240000000000000e+03,
      "input_width": 1.0000000000000000e+00,
      "num_iterations": 1.2062300000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 1.0240000000000000e+03,
      "output_height": 1.0000000000000000e+00,
      "output_size": 1.0240000000000000e+03,
      "output_width": 1.0000000000000000e+00,
      "predicted_flops": 2.0002257400486994e+08,
      "predicted_flops_count": 1.0240000000000000e+03
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__3521402535742402018<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1/input[1]:1024/input[2]:-1/input[3]:-1/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 138875,
      "real_time": 5.0158890718659814e+03,
      "cpu_time": 1.0150882311433121e+04,
      "time_unit": "ns",
      "items_per_second": 2.0415124523857492e+08,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 1.0240000000000000e+03,
      "input[2]": -1.0000000000000000e+00,
      "input[3]": -1.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 1.0240000000000000e+03,
      "input_height": 1.0000000000000000e+00,
      "input_size": 1.0240000000000000e+03,
      "input_width": 1.0000000000000000e+00,
      "num_iterations": 1.3887500000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 1.0240000000000000e+03,
      "output_height": 1.0000000000000000e+00,
      "output_size": 1.0240000000000000e+03,
      "output_width": 1.0000000000000000e+00,
      "predicted_flops": 2.0415124523857492e+08,
      "predicted_flops_count": 1.0240000000000000e+03
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__6807071951388914076<CUDNN_ACTIVATION_RELU>/input[0]:1/input[1]:384/input[2]:6/input[3]:6/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 137256,
      "real_time": 5.0747127964791962e+03,
      "cpu_time": 1.0201068222890479e+04,
      "time_unit": "ns",
      "items_per_second": 2.7240950482145519e+09,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 3.8400000000000000e+02,
      "input[2]": 6.0000000000000000e+00,
      "input[3]": 6.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 3.8400000000000000e+02,
      "input_height": 6.0000000000000000e+00,
      "input_size": 1.3824000000000000e+04,
      "input_width": 6.0000000000000000e+00,
      "num_iterations": 1.3725600000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 3.8400000000000000e+02,
      "output_height": 6.0000000000000000e+00,
      "output_size": 1.3824000000000000e+04,
      "output_width": 6.0000000000000000e+00,
      "predicted_flops": 2.7240950482145519e+09,
      "predicted_flops_count": 1.3824000000000000e+04
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__6807071951388914076<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1/input[1]:384/input[2]:6/input[3]:6/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 135660,
      "real_time": 5.1088721507107903e+03,
      "cpu_time": 1.0241125836625095e+04,
      "time_unit": "ns",
      "items_per_second": 2.7058809835506816e+09,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 3.8400000000000000e+02,
      "input[2]": 6.0000000000000000e+00,
      "input[3]": 6.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 3.8400000000000000e+02,
      "input_height": 6.0000000000000000e+00,
      "input_size": 1.3824000000000000e+04,
      "input_width": 6.0000000000000000e+00,
      "num_iterations": 1.3566000000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 3.8400000000000000e+02,
      "output_height": 6.0000000000000000e+00,
      "output_size": 1.3824000000000000e+04,
      "output_width": 6.0000000000000000e+00,
      "predicted_flops": 2.7058809835506816e+09,
      "predicted_flops_count": 1.3824000000000000e+04
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__17820315011612243101<CUDNN_ACTIVATION_RELU>/input[0]:128/input[1]:112/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 11893,
      "real_time": 5.8821352497525506e+04,
      "cpu_time": 6.4025023291171558e+04,
      "time_unit": "ns",
      "items_per_second": 4.7769319825112915e+10,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 1.1200000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 1.1200000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 2.8098560000000000e+06,
      "input_width": 1.4000000000000000e+01,
      "num_iterations": 1.1893000000000000e+04,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 1.1200000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 2.8098560000000000e+06,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 4.7769319825112915e+10,
      "predicted_flops_count": 2.8098560000000000e+06
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__17820315011612243101<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:128/input[1]:112/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 11876,
      "real_time": 5.8927087344734216e+04,
      "cpu_time": 6.4153513893450327e+04,
      "time_unit": "ns",
      "items_per_second": 4.7683605734012100e+10,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 1.1200000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 1.1200000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 2.8098560000000000e+06,
      "input_width": 1.4000000000000000e+01,
      "num_iterations": 1.1876000000000000e+04,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 1.1200000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 2.8098560000000000e+06,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 4.7683605734012100e+10,
      "predicted_flops_count": 2.8098560000000000e+06
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__293481316760285886<CUDNN_ACTIVATION_RELU>/input[0]:128/input[1]:1000/input[2]:13/input[3]:13/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 1657,
      "real_time": 4.2246164185375505e+05,
      "cpu_time": 4.3025118286025216e+05,
      "time_unit": "ns",
      "items_per_second": 5.1204648793862381e+10,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 1.0000000000000000e+03,
      "input[2]": 1.3000000000000000e+01,
      "input[3]": 1.3000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 1.0000000000000000e+03,
      "input_height": 1.3000000000000000e+01,
      "input_size": 2.1632000000000000e+07,
      "input_width": 1.3000000000000000e+01,
      "num_iterations": 1.6570000000000000e+03,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 1.0000000000000000e+03,
      "output_height": 1.3000000000000000e+01,
      "output_size": 2.1632000000000000e+07,
      "output_width": 1.3000000000000000e+01,
      "predicted_flops": 5.1204648793862381e+10,
      "predicted_flops_count": 2.1632000000000000e+07
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__293481316760285886<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:128/input[1]:1000/input[2]:13/input[3]:13/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 1656,
      "real_time": 4.2280975578365184e+05,
      "cpu_time": 4.3062335446843621e+05,
      "time_unit": "ns",
      "items_per_second": 5.1162490231348663e+10,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 1.0000000000000000e+03,
      "input[2]": 1.3000000000000000e+01,
      "input[3]": 1.3000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 1.0000000000000000e+03,
      "input_height": 1.3000000000000000e+01,
      "input_size": 2.1632000000000000e+07,
      "input_width": 1.3000000000000000e+01,
      "num_iterations": 1.6560000000000000e+03,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 1.0000000000000000e+03,
      "output_height": 1.3000000000000000e+01,
      "output_size": 2.1632000000000000e+07,
      "output_width": 1.3000000000000000e+01,
      "predicted_flops": 5.1162490231348663e+10,
      "predicted_flops_count": 2.1632000000000000e+07
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__502896168059433249<CUDNN_ACTIVATION_RELU>/input[0]:1/input[1]:128/input[2]:13/input[3]:13/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 133042,
      "real_time": 5.2538459548086530e+03,
      "cpu_time": 1.0369933720156912e+04,
      "time_unit": "ns",
      "items_per_second": 4.1173647240648575e+09,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 1.2800000000000000e+02,
      "input[2]": 1.3000000000000000e+01,
      "input[3]": 1.3000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 1.2800000000000000e+02,
      "input_height": 1.3000000000000000e+01,
      "input_size": 2.1632000000000000e+04,
      "input_width": 1.3000000000000000e+01,
      "num_iterations": 1.3304200000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 1.3000000000000000e+01,
      "output_size": 2.1632000000000000e+04,
      "output_width": 1.3000000000000000e+01,
      "predicted_flops": 4.1173647240648575e+09,
      "predicted_flops_count": 2.1632000000000000e+04
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__502896168059433249<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1/input[1]:128/input[2]:13/input[3]:13/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 132903,
      "real_time": 5.2498339805666428e+03,
      "cpu_time": 1.0368688607454569e+04,
      "time_unit": "ns",
      "items_per_second": 4.1205112542749667e+09,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 1.2800000000000000e+02,
      "input[2]": 1.3000000000000000e+01,
      "input[3]": 1.3000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 1.2800000000000000e+02,
      "input_height": 1.3000000000000000e+01,
      "input_size": 2.1632000000000000e+04,
      "input_width": 1.3000000000000000e+01,
      "num_iterations": 1.3290300000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 1.3000000000000000e+01,
      "output_size": 2.1632000000000000e+04,
      "output_width": 1.3000000000000000e+01,
      "predicted_flops": 4.1205112542749667e+09,
      "predicted_flops_count": 2.1632000000000000e+04
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__7051596880887468266<CUDNN_ACTIVATION_RELU>/input[0]:128/input[1]:8/input[2]:28/input[3]:28/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 34182,
      "real_time": 2.0499239947365364e+04,
      "cpu_time": 2.5652102422359265e+04,
      "time_unit": "ns",
      "items_per_second": 3.9163208102414589e+10,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 8.0000000000000000e+00,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 8.0000000000000000e+00,
      "input_height": 2.8000000000000000e+01,
      "input_size": 8.0281600000000000e+05,
      "input_width": 2.8000000000000000e+01,
      "num_iterations": 3.4182000000000000e+04,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 8.0000000000000000e+00,
      "output_height": 2.8000000000000000e+01,
      "output_size": 8.0281600000000000e+05,
      "output_width": 2.8000000000000000e+01,
      "predicted_flops": 3.9163208102414589e+10,
      "predicted_flops_count": 8.0281600000000000e+05
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__7051596880887468266<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:128/input[1]:8/input[2]:28/input[3]:28/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 34071,
      "real_time": 2.0580636789272947e+04,
      "cpu_time": 2.5760102785451523e+04,
      "time_unit": "ns",
      "items_per_second": 3.9008316808663780e+10,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 8.0000000000000000e+00,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 8.0000000000000000e+00,
      "input_height": 2.8000000000000000e+01,
      "input_size": 8.0281600000000000e+05,
      "input_width": 2.8000000000000000e+01,
      "num_iterations": 3.4071000000000000e+04,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 8.0000000000000000e+00,
      "output_height": 2.8000000000000000e+01,
      "output_size": 8.0281600000000000e+05,
      "output_width": 2.8000000000000000e+01,
      "predicted_flops": 3.9008316808663780e+10,
      "predicted_flops_count": 8.0281600000000000e+05
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__11362622006370161458<CUDNN_ACTIVATION_RELU>/input[0]:1/input[1]:576/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 119296,
      "real_time": 5.8349927824318311e+03,
      "cpu_time": 1.1064898554821460e+04,
      "time_unit": "ns",
      "items_per_second": 1.9348095911945362e+10,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 5.7600000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 5.7600000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 1.1289600000000000e+05,
      "input_width": 1.4000000000000000e+01,
      "num_iterations": 1.1929600000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 5.7600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 1.1289600000000000e+05,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 1.9348095911945362e+10,
      "predicted_flops_count": 1.1289600000000000e+05
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__11362622006370161458<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1/input[1]:576/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 119359,
      "real_time": 5.9045004320324188e+03,
      "cpu_time": 1.1181419272923953e+04,
      "time_unit": "ns",
      "items_per_second": 1.9120330551172386e+10,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 5.7600000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 5.7600000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 1.1289600000000000e+05,
      "input_width": 1.4000000000000000e+01,
      "num_iterations": 1.1935900000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 5.7600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 1.1289600000000000e+05,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 1.9120330551172386e+10,
      "predicted_flops_count": 1.1289600000000000e+05
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__2913345447427522790<CUDNN_ACTIVATION_RELU>/input[0]:1/input[1]:256/input[2]:28/input[3]:28/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 98460,
      "real_time": 6.4725174392153003e+03,
      "cpu_time": 1.1641158480570712e+04,
      "time_unit": "ns",
      "items_per_second": 3.1008645690776611e+10,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 2.0070400000000000e+05,
      "input_width": 2.8000000000000000e+01,
      "num_iterations": 9.8460000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 2.0070400000000000e+05,
      "output_width": 2.8000000000000000e+01,
      "predicted_flops": 3.1008645690776611e+10,
      "predicted_flops_count": 2.0070400000000000e+05
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__2913345447427522790<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1/input[1]:256/input[2]:28/input[3]:28/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 110900,
      "real_time": 6.3231659741537305e+03,
      "cpu_time": 1.1451943336364822e+04,
      "time_unit": "ns",
      "items_per_second": 3.1741061490460320e+10,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 2.0070400000000000e+05,
      "input_width": 2.8000000000000000e+01,
      "num_iterations": 1.1090000000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 2.0070400000000000e+05,
      "output_width": 2.8000000000000000e+01,
      "predicted_flops": 3.1741061490460320e+10,
      "predicted_flops_count": 2.0070400000000000e+05
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__18314163827723913184<CUDNN_ACTIVATION_RELU>/input[0]:1/input[1]:288/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 126183,
      "real_time": 5.5452158256963903e+03,
      "cpu_time": 1.0708460711796786e+04,
      "time_unit": "ns",
      "items_per_second": 1.0179585750012001e+10,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 2.8800000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 2.8800000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 5.6448000000000000e+04,
      "input_width": 1.4000000000000000e+01,
      "num_iterations": 1.2618300000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 2.8800000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 5.6448000000000000e+04,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 1.0179585750012001e+10,
      "predicted_flops_count": 5.6448000000000000e+04
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__18314163827723913184<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1/input[1]:288/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 126746,
      "real_time": 5.5573966264900328e+03,
      "cpu_time": 1.0723189623329445e+04,
      "time_unit": "ns",
      "items_per_second": 1.0157273952867334e+10,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 2.8800000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 2.8800000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 5.6448000000000000e+04,
      "input_width": 1.4000000000000000e+01,
      "num_iterations": 1.2674600000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 2.8800000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 5.6448000000000000e+04,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 1.0157273952867334e+10,
      "predicted_flops_count": 5.6448000000000000e+04
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__6404210537747550654<CUDNN_ACTIVATION_RELU>/input[0]:1/input[1]:256/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 127833,
      "real_time": 5.4824045716904566e+03,
      "cpu_time": 1.0665348767511325e+04,
      "time_unit": "ns",
      "items_per_second": 9.1521884866166725e+09,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 5.0176000000000000e+04,
      "input_width": 1.4000000000000000e+01,
      "num_iterations": 1.2783300000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 5.0176000000000000e+04,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 9.1521884866166725e+09,
      "predicted_flops_count": 5.0176000000000000e+04
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__6404210537747550654<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1/input[1]:256/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 127859,
      "real_time": 5.5072055302460758e+03,
      "cpu_time": 1.0675789870068769e+04,
      "time_unit": "ns",
      "items_per_second": 9.1109728381170483e+09,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 5.0176000000000000e+04,
      "input_width": 1.4000000000000000e+01,
      "num_iterations": 1.2785900000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 5.0176000000000000e+04,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 9.1109728381170483e+09,
      "predicted_flops_count": 5.0176000000000000e+04
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__9727171201631670604<CUDNN_ACTIVATION_RELU>/input[0]:1/input[1]:288/input[2]:28/input[3]:28/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 108240,
      "real_time": 6.9994767790682681e+03,
      "cpu_time": 1.2421283490444364e+04,
      "time_unit": "ns",
      "items_per_second": 3.2258411182279278e+10,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 2.8800000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 2.8800000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 2.2579200000000000e+05,
      "input_width": 2.8000000000000000e+01,
      "num_iterations": 1.0824000000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 2.8800000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 2.2579200000000000e+05,
      "output_width": 2.8000000000000000e+01,
      "predicted_flops": 3.2258411182279278e+10,
      "predicted_flops_count": 2.2579200000000000e+05
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__9727171201631670604<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1/input[1]:288/input[2]:28/input[3]:28/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 96473,
      "real_time": 7.2335447970166770e+03,
      "cpu_time": 1.2722100950550608e+04,
      "time_unit": "ns",
      "items_per_second": 3.1214571325129993e+10,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 2.8800000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 2.8800000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 2.2579200000000000e+05,
      "input_width": 2.8000000000000000e+01,
      "num_iterations": 9.6473000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 2.8800000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 2.2579200000000000e+05,
      "output_width": 2.8000000000000000e+01,
      "predicted_flops": 3.1214571325129993e+10,
      "predicted_flops_count": 2.2579200000000000e+05
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__1151422461893528909<CUDNN_ACTIVATION_RELU>/input[0]:1/input[1]:208/input[2]:13/input[3]:13/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 130297,
      "real_time": 5.3647584713390734e+03,
      "cpu_time": 1.0538613813067928e+04,
      "time_unit": "ns",
      "items_per_second": 6.5523919087499704e+09,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 2.0800000000000000e+02,
      "input[2]": 1.3000000000000000e+01,
      "input[3]": 1.3000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 2.0800000000000000e+02,
      "input_height": 1.3000000000000000e+01,
      "input_size": 3.5152000000000000e+04,
      "input_width": 1.3000000000000000e+01,
      "num_iterations": 1.3029700000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 2.0800000000000000e+02,
      "output_height": 1.3000000000000000e+01,
      "output_size": 3.5152000000000000e+04,
      "output_width": 1.3000000000000000e+01,
      "predicted_flops": 6.5523919087499704e+09,
      "predicted_flops_count": 3.5152000000000000e+04
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__1151422461893528909<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1/input[1]:208/input[2]:13/input[3]:13/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 130495,
      "real_time": 5.3648745987494913e+03,
      "cpu_time": 1.0530246860022100e+04,
      "time_unit": "ns",
      "items_per_second": 6.5522500764870901e+09,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 2.0800000000000000e+02,
      "input[2]": 1.3000000000000000e+01,
      "input[3]": 1.3000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 2.0800000000000000e+02,
      "input_height": 1.3000000000000000e+01,
      "input_size": 3.5152000000000000e+04,
      "input_width": 1.3000000000000000e+01,
      "num_iterations": 1.3049500000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 2.0800000000000000e+02,
      "output_height": 1.3000000000000000e+01,
      "output_size": 3.5152000000000000e+04,
      "output_width": 1.3000000000000000e+01,
      "predicted_flops": 6.5522500764870901e+09,
      "predicted_flops_count": 3.5152000000000000e+04
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__10421255572259519808<CUDNN_ACTIVATION_RELU>/input[0]:1/input[1]:192/input[2]:13/input[3]:13/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 131395,
      "real_time": 5.3375807451946102e+03,
      "cpu_time": 1.0500138437483731e+04,
      "time_unit": "ns",
      "items_per_second": 6.0791586205440960e+09,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 1.9200000000000000e+02,
      "input[2]": 1.3000000000000000e+01,
      "input[3]": 1.3000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 1.9200000000000000e+02,
      "input_height": 1.3000000000000000e+01,
      "input_size": 3.2448000000000000e+04,
      "input_width": 1.3000000000000000e+01,
      "num_iterations": 1.3139500000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 1.9200000000000000e+02,
      "output_height": 1.3000000000000000e+01,
      "output_size": 3.2448000000000000e+04,
      "output_width": 1.3000000000000000e+01,
      "predicted_flops": 6.0791586205440960e+09,
      "predicted_flops_count": 3.2448000000000000e+04
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__10421255572259519808<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1/input[1]:192/input[2]:13/input[3]:13/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 131601,
      "real_time": 5.3036883140472082e+03,
      "cpu_time": 1.0454085500897556e+04,
      "time_unit": "ns",
      "items_per_second": 6.1180065793193560e+09,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 1.9200000000000000e+02,
      "input[2]": 1.3000000000000000e+01,
      "input[3]": 1.3000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 1.9200000000000000e+02,
      "input_height": 1.3000000000000000e+01,
      "input_size": 3.2448000000000000e+04,
      "input_width": 1.3000000000000000e+01,
      "num_iterations": 1.3160100000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 1.9200000000000000e+02,
      "output_height": 1.3000000000000000e+01,
      "output_size": 3.2448000000000000e+04,
      "output_width": 1.3000000000000000e+01,
      "predicted_flops": 6.1180065793193560e+09,
      "predicted_flops_count": 3.2448000000000000e+04
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__8114687299045535362<CUDNN_ACTIVATION_RELU>/input[0]:128/input[1]:64/input[2]:111/input[3]:111/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 311,
      "real_time": 2.2544877714450527e+06,
      "cpu_time": 2.3345296623794055e+06,
      "time_unit": "ns",
      "items_per_second": 4.4770095131323265e+10,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 1.1100000000000000e+02,
      "input[3]": 1.1100000000000000e+02,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 1.1100000000000000e+02,
      "input_size": 1.0093363200000000e+08,
      "input_width": 1.1100000000000000e+02,
      "num_iterations": 3.1100000000000000e+02,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 1.1100000000000000e+02,
      "output_size": 1.0093363200000000e+08,
      "output_width": 1.1100000000000000e+02,
      "predicted_flops": 4.4770095131323265e+10,
      "predicted_flops_count": 1.0093363200000000e+08
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__8114687299045535362<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:128/input[1]:64/input[2]:111/input[3]:111/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 311,
      "real_time": 2.2499772092668861e+06,
      "cpu_time": 2.3296100610946412e+06,
      "time_unit": "ns",
      "items_per_second": 4.4859846395016319e+10,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 1.1100000000000000e+02,
      "input[3]": 1.1100000000000000e+02,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 1.1100000000000000e+02,
      "input_size": 1.0093363200000000e+08,
      "input_width": 1.1100000000000000e+02,
      "num_iterations": 3.1100000000000000e+02,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 1.1100000000000000e+02,
      "output_size": 1.0093363200000000e+08,
      "output_width": 1.1100000000000000e+02,
      "predicted_flops": 4.4859846395016319e+10,
      "predicted_flops_count": 1.0093363200000000e+08
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__13566731214077738676<CUDNN_ACTIVATION_RELU>/input[0]:1/input[1]:320/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 125981,
      "real_time": 5.5564035922399717e+03,
      "cpu_time": 1.0710379993836676e+04,
      "time_unit": "ns",
      "items_per_second": 1.1287876943927227e+10,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 3.2000000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 3.2000000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 6.2720000000000000e+04,
      "input_width": 1.4000000000000000e+01,
      "num_iterations": 1.2598100000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 3.2000000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 6.2720000000000000e+04,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 1.1287876943927227e+10,
      "predicted_flops_count": 6.2720000000000000e+04
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__13566731214077738676<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1/input[1]:320/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 125338,
      "real_time": 5.5665955486938383e+03,
      "cpu_time": 1.0718677017353511e+04,
      "time_unit": "ns",
      "items_per_second": 1.1267209814572716e+10,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 3.2000000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 3.2000000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 6.2720000000000000e+04,
      "input_width": 1.4000000000000000e+01,
      "num_iterations": 1.2533800000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 3.2000000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 6.2720000000000000e+04,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 1.1267209814572716e+10,
      "predicted_flops_count": 6.2720000000000000e+04
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__15129018207522813395<CUDNN_ACTIVATION_RELU>/input[0]:128/input[1]:144/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 9428,
      "real_time": 7.4178878154825812e+04,
      "cpu_time": 7.9404383538299109e+04,
      "time_unit": "ns",
      "items_per_second": 4.8702165493250618e+10,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 1.4400000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 1.4400000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 3.6126720000000000e+06,
      "input_width": 1.4000000000000000e+01,
      "num_iterations": 9.4280000000000000e+03,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 1.4400000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 3.6126720000000000e+06,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 4.8702165493250618e+10,
      "predicted_flops_count": 3.6126720000000000e+06
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__15129018207522813395<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:128/input[1]:144/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 9423,
      "real_time": 7.4320004939687336e+04,
      "cpu_time": 7.9554951714039635e+04,
      "time_unit": "ns",
      "items_per_second": 4.8609684605534943e+10,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 1.4400000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 1.4400000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 3.6126720000000000e+06,
      "input_width": 1.4000000000000000e+01,
      "num_iterations": 9.4230000000000000e+03,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 1.4400000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 3.6126720000000000e+06,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 4.8609684605534943e+10,
      "predicted_flops_count": 3.6126720000000000e+06
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__4660233605633977696<CUDNN_ACTIVATION_RELU>/input[0]:1/input[1]:320/input[2]:28/input[3]:28/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 105167,
      "real_time": 6.6844977916196967e+03,
      "cpu_time": 1.1819159413154150e+04,
      "time_unit": "ns",
      "items_per_second": 3.7531615361519951e+10,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 3.2000000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 3.2000000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 2.5088000000000000e+05,
      "input_width": 2.8000000000000000e+01,
      "num_iterations": 1.0516700000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 3.2000000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 2.5088000000000000e+05,
      "output_width": 2.8000000000000000e+01,
      "predicted_flops": 3.7531615361519951e+10,
      "predicted_flops_count": 2.5088000000000000e+05
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__4660233605633977696<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1/input[1]:320/input[2]:28/input[3]:28/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 104692,
      "real_time": 7.1035605159770894e+03,
      "cpu_time": 1.2505568677580752e+04,
      "time_unit": "ns",
      "items_per_second": 3.5317500207920967e+10,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 3.2000000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 3.2000000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 2.5088000000000000e+05,
      "input_width": 2.8000000000000000e+01,
      "num_iterations": 1.0469200000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 3.2000000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 2.5088000000000000e+05,
      "output_width": 2.8000000000000000e+01,
      "predicted_flops": 3.5317500207920967e+10,
      "predicted_flops_count": 2.5088000000000000e+05
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__1684633279113941651<CUDNN_ACTIVATION_RELU>/input[0]:1/input[1]:608/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 106460,
      "real_time": 6.5770111876777719e+03,
      "cpu_time": 1.2078666710428237e+04,
      "time_unit": "ns",
      "items_per_second": 1.8118868373413265e+10,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 6.0800000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 6.0800000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 1.1916800000000000e+05,
      "input_width": 1.4000000000000000e+01,
      "num_iterations": 1.0646000000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 6.0800000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 1.1916800000000000e+05,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 1.8118868373413265e+10,
      "predicted_flops_count": 1.1916800000000000e+05
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__1684633279113941651<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1/input[1]:608/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 107034,
      "real_time": 5.8255158042336134e+03,
      "cpu_time": 1.0999234925382820e+04,
      "time_unit": "ns",
      "items_per_second": 2.0456214351593777e+10,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 6.0800000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 6.0800000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 1.1916800000000000e+05,
      "input_width": 1.4000000000000000e+01,
      "num_iterations": 1.0703400000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 6.0800000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 1.1916800000000000e+05,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 2.0456214351593777e+10,
      "predicted_flops_count": 1.1916800000000000e+05
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__15770506917211922534<CUDNN_ACTIVATION_RELU>/input[0]:128/input[1]:96/input[2]:54/input[3]:54/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 978,
      "real_time": 7.1530502913510217e+05,
      "cpu_time": 7.2801692535824666e+05,
      "time_unit": "ns",
      "items_per_second": 5.0093046379563927e+10,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 9.6000000000000000e+01,
      "input[2]": 5.4000000000000000e+01,
      "input[3]": 5.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 9.6000000000000000e+01,
      "input_height": 5.4000000000000000e+01,
      "input_size": 3.5831808000000000e+07,
      "input_width": 5.4000000000000000e+01,
      "num_iterations": 9.7800000000000000e+02,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 9.6000000000000000e+01,
      "output_height": 5.4000000000000000e+01,
      "output_size": 3.5831808000000000e+07,
      "output_width": 5.4000000000000000e+01,
      "predicted_flops": 5.0093046379563927e+10,
      "predicted_flops_count": 3.5831808000000000e+07
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__15770506917211922534<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:128/input[1]:96/input[2]:54/input[3]:54/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 978,
      "real_time": 7.1578545552766020e+05,
      "cpu_time": 7.2854653987714369e+05,
      "time_unit": "ns",
      "items_per_second": 5.0059424543050591e+10,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 9.6000000000000000e+01,
      "input[2]": 5.4000000000000000e+01,
      "input[3]": 5.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 9.6000000000000000e+01,
      "input_height": 5.4000000000000000e+01,
      "input_size": 3.5831808000000000e+07,
      "input_width": 5.4000000000000000e+01,
      "num_iterations": 9.7800000000000000e+02,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 9.6000000000000000e+01,
      "output_height": 5.4000000000000000e+01,
      "output_size": 3.5831808000000000e+07,
      "output_width": 5.4000000000000000e+01,
      "predicted_flops": 5.0059424543050591e+10,
      "predicted_flops_count": 3.5831808000000000e+07
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__14137666469494555182<CUDNN_ACTIVATION_RELU>/input[0]:1/input[1]:352/input[2]:28/input[3]:28/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 103841,
      "real_time": 6.7787825183811919e+03,
      "cpu_time": 1.1877998478475649e+04,
      "time_unit": "ns",
      "items_per_second": 4.0710555214257355e+10,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 3.5200000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 3.5200000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 2.7596800000000000e+05,
      "input_width": 2.8000000000000000e+01,
      "num_iterations": 1.0384100000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 3.5200000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 2.7596800000000000e+05,
      "output_width": 2.8000000000000000e+01,
      "predicted_flops": 4.0710555214257355e+10,
      "predicted_flops_count": 2.7596800000000000e+05
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__14137666469494555182<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1/input[1]:352/input[2]:28/input[3]:28/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 102889,
      "real_time": 6.7985701457292635e+03,
      "cpu_time": 1.1900895304722744e+04,
      "time_unit": "ns",
      "items_per_second": 4.0592064814298935e+10,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 3.5200000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 3.5200000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 2.7596800000000000e+05,
      "input_width": 2.8000000000000000e+01,
      "num_iterations": 1.0288900000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 3.5200000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 2.7596800000000000e+05,
      "output_width": 2.8000000000000000e+01,
      "predicted_flops": 4.0592064814298935e+10,
      "predicted_flops_count": 2.7596800000000000e+05
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__4491877982492294206<CUDNN_ACTIVATION_RELU>/input[0]:128/input[1]:256/input[2]:27/input[3]:27/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 1497,
      "real_time": 4.6752262855870626e+05,
      "cpu_time": 4.7592428724101791e+05,
      "time_unit": "ns",
      "items_per_second": 5.1094579258424980e+10,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 2.7000000000000000e+01,
      "input[3]": 2.7000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 2.7000000000000000e+01,
      "input_size": 2.3887872000000000e+07,
      "input_width": 2.7000000000000000e+01,
      "num_iterations": 1.4970000000000000e+03,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 2.7000000000000000e+01,
      "output_size": 2.3887872000000000e+07,
      "output_width": 2.7000000000000000e+01,
      "predicted_flops": 5.1094579258424980e+10,
      "predicted_flops_count": 2.3887872000000000e+07
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__4491877982492294206<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:128/input[1]:256/input[2]:27/input[3]:27/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 1497,
      "real_time": 4.6771956560573349e+05,
      "cpu_time": 4.7611002805589029e+05,
      "time_unit": "ns",
      "items_per_second": 5.1073065479019104e+10,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 2.7000000000000000e+01,
      "input[3]": 2.7000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 2.7000000000000000e+01,
      "input_size": 2.3887872000000000e+07,
      "input_width": 2.7000000000000000e+01,
      "num_iterations": 1.4970000000000000e+03,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 2.7000000000000000e+01,
      "output_size": 2.3887872000000000e+07,
      "output_width": 2.7000000000000000e+01,
      "predicted_flops": 5.1073065479019104e+10,
      "predicted_flops_count": 2.3887872000000000e+07
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__3759549508981743739<CUDNN_ACTIVATION_RELU>/input[0]:128/input[1]:288/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 4871,
      "real_time": 1.4372178039399191e+05,
      "cpu_time": 1.4920206528413427e+05,
      "time_unit": "ns",
      "items_per_second": 5.0273131742403915e+10,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 2.8800000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 2.8800000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 7.2253440000000000e+06,
      "input_width": 1.4000000000000000e+01,
      "num_iterations": 4.8710000000000000e+03,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 2.8800000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 7.2253440000000000e+06,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 5.0273131742403915e+10,
      "predicted_flops_count": 7.2253440000000000e+06
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__3759549508981743739<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:128/input[1]:288/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 4859,
      "real_time": 1.4404966213697664e+05,
      "cpu_time": 1.4952012739250093e+05,
      "time_unit": "ns",
      "items_per_second": 5.0158701470118195e+10,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 2.8800000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 2.8800000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 7.2253440000000000e+06,
      "input_width": 1.4000000000000000e+01,
      "num_iterations": 4.8590000000000000e+03,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 2.8800000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 7.2253440000000000e+06,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 5.0158701470118195e+10,
      "predicted_flops_count": 7.2253440000000000e+06
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__13782369319766857365<CUDNN_ACTIVATION_RELU>/input[0]:128/input[1]:384/input[2]:12/input[3]:12/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 4965,
      "real_time": 1.4099678879182631e+05,
      "cpu_time": 1.4643798046319257e+05,
      "time_unit": "ns",
      "items_per_second": 5.0198930490892921e+10,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 3.8400000000000000e+02,
      "input[2]": 1.2000000000000000e+01,
      "input[3]": 1.2000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 3.8400000000000000e+02,
      "input_height": 1.2000000000000000e+01,
      "input_size": 7.0778880000000000e+06,
      "input_width": 1.2000000000000000e+01,
      "num_iterations": 4.9650000000000000e+03,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 3.8400000000000000e+02,
      "output_height": 1.2000000000000000e+01,
      "output_size": 7.0778880000000000e+06,
      "output_width": 1.2000000000000000e+01,
      "predicted_flops": 5.0198930490892921e+10,
      "predicted_flops_count": 7.0778880000000000e+06
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__13782369319766857365<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:128/input[1]:384/input[2]:12/input[3]:12/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 4954,
      "real_time": 1.4126197188266591e+05,
      "cpu_time": 1.4673521174835649e+05,
      "time_unit": "ns",
      "items_per_second": 5.0104694884756310e+10,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 3.8400000000000000e+02,
      "input[2]": 1.2000000000000000e+01,
      "input[3]": 1.2000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 3.8400000000000000e+02,
      "input_height": 1.2000000000000000e+01,
      "input_size": 7.0778880000000000e+06,
      "input_width": 1.2000000000000000e+01,
      "num_iterations": 4.9540000000000000e+03,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 3.8400000000000000e+02,
      "output_height": 1.2000000000000000e+01,
      "output_size": 7.0778880000000000e+06,
      "output_width": 1.2000000000000000e+01,
      "predicted_flops": 5.0104694884756310e+10,
      "predicted_flops_count": 7.0778880000000000e+06
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__14974818703643426192<CUDNN_ACTIVATION_RELU>/input[0]:1/input[1]:96/input[2]:13/input[3]:13/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 134558,
      "real_time": 5.1982907957380548e+03,
      "cpu_time": 1.0310527720362204e+04,
      "time_unit": "ns",
      "items_per_second": 3.1210258597502160e+09,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 9.6000000000000000e+01,
      "input[2]": 1.3000000000000000e+01,
      "input[3]": 1.3000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 9.6000000000000000e+01,
      "input_height": 1.3000000000000000e+01,
      "input_size": 1.6224000000000000e+04,
      "input_width": 1.3000000000000000e+01,
      "num_iterations": 1.3455800000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 9.6000000000000000e+01,
      "output_height": 1.3000000000000000e+01,
      "output_size": 1.6224000000000000e+04,
      "output_width": 1.3000000000000000e+01,
      "predicted_flops": 3.1210258597502160e+09,
      "predicted_flops_count": 1.6224000000000000e+04
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__14974818703643426192<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1/input[1]:96/input[2]:13/input[3]:13/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 134662,
      "real_time": 5.2278216957005125e+03,
      "cpu_time": 1.0345745555513517e+04,
      "time_unit": "ns",
      "items_per_second": 3.1033958203553519e+09,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 9.6000000000000000e+01,
      "input[2]": 1.3000000000000000e+01,
      "input[3]": 1.3000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 9.6000000000000000e+01,
      "input_height": 1.3000000000000000e+01,
      "input_size": 1.6224000000000000e+04,
      "input_width": 1.3000000000000000e+01,
      "num_iterations": 1.3466200000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 9.6000000000000000e+01,
      "output_height": 1.3000000000000000e+01,
      "output_size": 1.6224000000000000e+04,
      "output_width": 1.3000000000000000e+01,
      "predicted_flops": 3.1033958203553519e+09,
      "predicted_flops_count": 1.6224000000000000e+04
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__3246023937145201288<CUDNN_ACTIVATION_RELU>/input[0]:1/input[1]:640/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 118338,
      "real_time": 6.2680863554558191e+03,
      "cpu_time": 1.1640513461467875e+04,
      "time_unit": "ns",
      "items_per_second": 2.0012487525928146e+10,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 6.4000000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 6.4000000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 1.2544000000000000e+05,
      "input_width": 1.4000000000000000e+01,
      "num_iterations": 1.1833800000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 6.4000000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 1.2544000000000000e+05,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 2.0012487525928146e+10,
      "predicted_flops_count": 1.2544000000000000e+05
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__3246023937145201288<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1/input[1]:640/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 103945,
      "real_time": 6.6889854705424495e+03,
      "cpu_time": 1.2250280744554177e+04,
      "time_unit": "ns",
      "items_per_second": 1.8753217592178047e+10,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 6.4000000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 6.4000000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 1.2544000000000000e+05,
      "input_width": 1.4000000000000000e+01,
      "num_iterations": 1.0394500000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 6.4000000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 1.2544000000000000e+05,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 1.8753217592178047e+10,
      "predicted_flops_count": 1.2544000000000000e+05
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__2835781425470952885<CUDNN_ACTIVATION_RELU>/input[0]:1/input[1]:16/input[2]:13/input[3]:13/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 120130,
      "real_time": 5.1778322551796491e+03,
      "cpu_time": 1.0367038916183628e+04,
      "time_unit": "ns",
      "items_per_second": 5.2222626511221009e+08,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 1.6000000000000000e+01,
      "input[2]": 1.3000000000000000e+01,
      "input[3]": 1.3000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 1.6000000000000000e+01,
      "input_height": 1.3000000000000000e+01,
      "input_size": 2.7040000000000000e+03,
      "input_width": 1.3000000000000000e+01,
      "num_iterations": 1.2013000000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 1.6000000000000000e+01,
      "output_height": 1.3000000000000000e+01,
      "output_size": 2.7040000000000000e+03,
      "output_width": 1.3000000000000000e+01,
      "predicted_flops": 5.2222626511221009e+08,
      "predicted_flops_count": 2.7040000000000000e+03
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__2835781425470952885<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1/input[1]:16/input[2]:13/input[3]:13/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 135783,
      "real_time": 5.0704939161251295e+03,
      "cpu_time": 1.0227228415902864e+04,
      "time_unit": "ns",
      "items_per_second": 5.3328138140561974e+08,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 1.6000000000000000e+01,
      "input[2]": 1.3000000000000000e+01,
      "input[3]": 1.3000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 1.6000000000000000e+01,
      "input_height": 1.3000000000000000e+01,
      "input_size": 2.7040000000000000e+03,
      "input_width": 1.3000000000000000e+01,
      "num_iterations": 1.3578300000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 1.6000000000000000e+01,
      "output_height": 1.3000000000000000e+01,
      "output_size": 2.7040000000000000e+03,
      "output_width": 1.3000000000000000e+01,
      "predicted_flops": 5.3328138140561974e+08,
      "predicted_flops_count": 2.7040000000000000e+03
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__6935698784193640648<CUDNN_ACTIVATION_RELU>/input[0]:128/input[1]:32/input[2]:112/input[3]:112/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 660,
      "real_time": 1.0595291152695252e+06,
      "cpu_time": 1.0812723742429682e+06,
      "time_unit": "ns",
      "items_per_second": 4.8493451722588860e+10,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 3.2000000000000000e+01,
      "input[2]": 1.1200000000000000e+02,
      "input[3]": 1.1200000000000000e+02,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 3.2000000000000000e+01,
      "input_height": 1.1200000000000000e+02,
      "input_size": 5.1380224000000000e+07,
      "input_width": 1.1200000000000000e+02,
      "num_iterations": 6.6000000000000000e+02,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 3.2000000000000000e+01,
      "output_height": 1.1200000000000000e+02,
      "output_size": 5.1380224000000000e+07,
      "output_width": 1.1200000000000000e+02,
      "predicted_flops": 4.8493451722588860e+10,
      "predicted_flops_count": 5.1380224000000000e+07
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__6935698784193640648<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:128/input[1]:32/input[2]:112/input[3]:112/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 661,
      "real_time": 1.0591473715005051e+06,
      "cpu_time": 1.0809943857784653e+06,
      "time_unit": "ns",
      "items_per_second": 4.8510930001373749e+10,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 3.2000000000000000e+01,
      "input[2]": 1.1200000000000000e+02,
      "input[3]": 1.1200000000000000e+02,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 3.2000000000000000e+01,
      "input_height": 1.1200000000000000e+02,
      "input_size": 5.1380224000000000e+07,
      "input_width": 1.1200000000000000e+02,
      "num_iterations": 6.6100000000000000e+02,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 3.2000000000000000e+01,
      "output_height": 1.1200000000000000e+02,
      "output_size": 5.1380224000000000e+07,
      "output_width": 1.1200000000000000e+02,
      "predicted_flops": 4.8510930001373749e+10,
      "predicted_flops_count": 5.1380224000000000e+07
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__6649550724734871123<CUDNN_ACTIVATION_RELU>/input[0]:128/input[1]:96/input[2]:112/input[3]:112/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 194,
      "real_time": 3.6045979377189553e+06,
      "cpu_time": 3.8020671752572227e+06,
      "time_unit": "ns",
      "items_per_second": 4.2762237193516945e+10,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 9.6000000000000000e+01,
      "input[2]": 1.1200000000000000e+02,
      "input[3]": 1.1200000000000000e+02,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 9.6000000000000000e+01,
      "input_height": 1.1200000000000000e+02,
      "input_size": 1.5414067200000000e+08,
      "input_width": 1.1200000000000000e+02,
      "num_iterations": 1.9400000000000000e+02,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 9.6000000000000000e+01,
      "output_height": 1.1200000000000000e+02,
      "output_size": 1.5414067200000000e+08,
      "output_width": 1.1200000000000000e+02,
      "predicted_flops": 4.2762237193516945e+10,
      "predicted_flops_count": 1.5414067200000000e+08
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__6649550724734871123<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:128/input[1]:96/input[2]:112/input[3]:112/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 195,
      "real_time": 3.5997740219896422e+06,
      "cpu_time": 3.7957133692311971e+06,
      "time_unit": "ns",
      "items_per_second": 4.2819541187422768e+10,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 9.6000000000000000e+01,
      "input[2]": 1.1200000000000000e+02,
      "input[3]": 1.1200000000000000e+02,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 9.6000000000000000e+01,
      "input_height": 1.1200000000000000e+02,
      "input_size": 1.5414067200000000e+08,
      "input_width": 1.1200000000000000e+02,
      "num_iterations": 1.9500000000000000e+02,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 9.6000000000000000e+01,
      "output_height": 1.1200000000000000e+02,
      "output_size": 1.5414067200000000e+08,
      "output_width": 1.1200000000000000e+02,
      "predicted_flops": 4.2819541187422768e+10,
      "predicted_flops_count": 1.5414067200000000e+08
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__8530913494105235961<CUDNN_ACTIVATION_RELU>/input[0]:1/input[1]:48/input[2]:13/input[3]:13/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 138196,
      "real_time": 5.0982925956813069e+03,
      "cpu_time": 1.0241213066959748e+04,
      "time_unit": "ns",
      "items_per_second": 1.5911209189663930e+09,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 4.8000000000000000e+01,
      "input[2]": 1.3000000000000000e+01,
      "input[3]": 1.3000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 4.8000000000000000e+01,
      "input_height": 1.3000000000000000e+01,
      "input_size": 8.1120000000000000e+03,
      "input_width": 1.3000000000000000e+01,
      "num_iterations": 1.3819600000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 4.8000000000000000e+01,
      "output_height": 1.3000000000000000e+01,
      "output_size": 8.1120000000000000e+03,
      "output_width": 1.3000000000000000e+01,
      "predicted_flops": 1.5911209189663930e+09,
      "predicted_flops_count": 8.1120000000000000e+03
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__8530913494105235961<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1/input[1]:48/input[2]:13/input[3]:13/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 136865,
      "real_time": 5.1169525283519097e+03,
      "cpu_time": 1.0274301808328286e+04,
      "time_unit": "ns",
      "items_per_second": 1.5853185963819656e+09,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 4.8000000000000000e+01,
      "input[2]": 1.3000000000000000e+01,
      "input[3]": 1.3000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 4.8000000000000000e+01,
      "input_height": 1.3000000000000000e+01,
      "input_size": 8.1120000000000000e+03,
      "input_width": 1.3000000000000000e+01,
      "num_iterations": 1.3686500000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 4.8000000000000000e+01,
      "output_height": 1.3000000000000000e+01,
      "output_size": 8.1120000000000000e+03,
      "output_width": 1.3000000000000000e+01,
      "predicted_flops": 1.5853185963819656e+09,
      "predicted_flops_count": 8.1120000000000000e+03
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__5021995321031533874<CUDNN_ACTIVATION_RELU>/input[0]:1/input[1]:128/input[2]:27/input[3]:27/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 123588,
      "real_time": 5.6455321999819416e+03,
      "cpu_time": 1.0773079036786437e+04,
      "time_unit": "ns",
      "items_per_second": 1.6528468299286022e+10,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 1.2800000000000000e+02,
      "input[2]": 2.7000000000000000e+01,
      "input[3]": 2.7000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 1.2800000000000000e+02,
      "input_height": 2.7000000000000000e+01,
      "input_size": 9.3312000000000000e+04,
      "input_width": 2.7000000000000000e+01,
      "num_iterations": 1.2358800000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 2.7000000000000000e+01,
      "output_size": 9.3312000000000000e+04,
      "output_width": 2.7000000000000000e+01,
      "predicted_flops": 1.6528468299286022e+10,
      "predicted_flops_count": 9.3312000000000000e+04
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__5021995321031533874<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1/input[1]:128/input[2]:27/input[3]:27/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 123507,
      "real_time": 5.6712619190568530e+03,
      "cpu_time": 1.0780309609986032e+04,
      "time_unit": "ns",
      "items_per_second": 1.6453480959228569e+10,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 1.2800000000000000e+02,
      "input[2]": 2.7000000000000000e+01,
      "input[3]": 2.7000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 1.2800000000000000e+02,
      "input_height": 2.7000000000000000e+01,
      "input_size": 9.3312000000000000e+04,
      "input_width": 2.7000000000000000e+01,
      "num_iterations": 1.2350700000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 2.7000000000000000e+01,
      "output_size": 9.3312000000000000e+04,
      "output_width": 2.7000000000000000e+01,
      "predicted_flops": 1.6453480959228569e+10,
      "predicted_flops_count": 9.3312000000000000e+04
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__10528096359655546081<CUDNN_ACTIVATION_RELU>/input[0]:1/input[1]:672/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 117551,
      "real_time": 5.9422580105969273e+03,
      "cpu_time": 1.1124473420016357e+04,
      "time_unit": "ns",
      "items_per_second": 2.2165311530585815e+10,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 6.7200000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 6.7200000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 1.3171200000000000e+05,
      "input_width": 1.4000000000000000e+01,
      "num_iterations": 1.1755100000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 6.7200000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 1.3171200000000000e+05,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 2.2165311530585815e+10,
      "predicted_flops_count": 1.3171200000000000e+05
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__10528096359655546081<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1/input[1]:672/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 117622,
      "real_time": 5.9867388367178692e+03,
      "cpu_time": 1.1184689819919729e+04,
      "time_unit": "ns",
      "items_per_second": 2.2000625648171574e+10,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 6.7200000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 6.7200000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 1.3171200000000000e+05,
      "input_width": 1.4000000000000000e+01,
      "num_iterations": 1.1762200000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 6.7200000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 1.3171200000000000e+05,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 2.2000625648171574e+10,
      "predicted_flops_count": 1.3171200000000000e+05
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__13812236619334176983<CUDNN_ACTIVATION_RELU>/input[0]:128/input[1]:256/input[2]:12/input[3]:12/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 7346,
      "real_time": 9.5266006080078558e+04,
      "cpu_time": 1.0054006016855052e+05,
      "time_unit": "ns",
      "items_per_second": 4.9530700342718819e+10,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 1.2000000000000000e+01,
      "input[3]": 1.2000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 1.2000000000000000e+01,
      "input_size": 4.7185920000000000e+06,
      "input_width": 1.2000000000000000e+01,
      "num_iterations": 7.3460000000000000e+03,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 1.2000000000000000e+01,
      "output_size": 4.7185920000000000e+06,
      "output_width": 1.2000000000000000e+01,
      "predicted_flops": 4.9530700342718819e+10,
      "predicted_flops_count": 4.7185920000000000e+06
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__13812236619334176983<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:128/input[1]:256/input[2]:12/input[3]:12/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 7333,
      "real_time": 9.5468609497825149e+04,
      "cpu_time": 1.0076391981430969e+05,
      "time_unit": "ns",
      "items_per_second": 4.9425586324345634e+10,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 1.2000000000000000e+01,
      "input[3]": 1.2000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 1.2000000000000000e+01,
      "input_size": 4.7185920000000000e+06,
      "input_width": 1.2000000000000000e+01,
      "num_iterations": 7.3330000000000000e+03,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 1.2000000000000000e+01,
      "output_size": 4.7185920000000000e+06,
      "output_width": 1.2000000000000000e+01,
      "predicted_flops": 4.9425586324345634e+10,
      "predicted_flops_count": 4.7185920000000000e+06
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__9092731666121438591<CUDNN_ACTIVATION_RELU>/input[0]:128/input[1]:320/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 4402,
      "real_time": 1.5896314471237140e+05,
      "cpu_time": 1.6448190935932053e+05,
      "time_unit": "ns",
      "items_per_second": 5.0503278697248894e+10,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 3.2000000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 3.2000000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 8.0281600000000000e+06,
      "input_width": 1.4000000000000000e+01,
      "num_iterations": 4.4020000000000000e+03,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 3.2000000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 8.0281600000000000e+06,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 5.0503278697248894e+10,
      "predicted_flops_count": 8.0281600000000000e+06
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__9092731666121438591<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:128/input[1]:320/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 4397,
      "real_time": 1.5920013564706891e+05,
      "cpu_time": 1.6474567273168781e+05,
      "time_unit": "ns",
      "items_per_second": 5.0428097736032364e+10,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 3.2000000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 3.2000000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 8.0281600000000000e+06,
      "input_width": 1.4000000000000000e+01,
      "num_iterations": 4.3970000000000000e+03,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 3.2000000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 8.0281600000000000e+06,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 5.0428097736032364e+10,
      "predicted_flops_count": 8.0281600000000000e+06
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__12802031666541440495<CUDNN_ACTIVATION_RELU>/input[0]:128/input[1]:96/input[2]:56/input[3]:56/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 904,
      "real_time": 7.7356198164881661e+05,
      "cpu_time": 7.8759190818654804e+05,
      "time_unit": "ns",
      "items_per_second": 4.9815229954636368e+10,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 9.6000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 9.6000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 3.8535168000000000e+07,
      "input_width": 5.6000000000000000e+01,
      "num_iterations": 9.0400000000000000e+02,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 9.6000000000000000e+01,
      "output_height": 5.6000000000000000e+01,
      "output_size": 3.8535168000000000e+07,
      "output_width": 5.6000000000000000e+01,
      "predicted_flops": 4.9815229954636368e+10,
      "predicted_flops_count": 3.8535168000000000e+07
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__12802031666541440495<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:128/input[1]:96/input[2]:56/input[3]:56/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 906,
      "real_time": 7.7394490053406428e+05,
      "cpu_time": 7.8795985430497967e+05,
      "time_unit": "ns",
      "items_per_second": 4.9790583248766968e+10,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 9.6000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 9.6000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 3.8535168000000000e+07,
      "input_width": 5.6000000000000000e+01,
      "num_iterations": 9.0600000000000000e+02,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 9.6000000000000000e+01,
      "output_height": 5.6000000000000000e+01,
      "output_size": 3.8535168000000000e+07,
      "output_width": 5.6000000000000000e+01,
      "predicted_flops": 4.9790583248766968e+10,
      "predicted_flops_count": 3.8535168000000000e+07
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__15025665147266655593<CUDNN_ACTIVATION_RELU>/input[0]:1/input[1]:832/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 113979,
      "real_time": 6.2027288858916500e+03,
      "cpu_time": 1.1437823467488060e+04,
      "time_unit": "ns",
      "items_per_second": 2.6290363967207020e+10,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 8.3200000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 8.3200000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 1.6307200000000000e+05,
      "input_width": 1.4000000000000000e+01,
      "num_iterations": 1.1397900000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 8.3200000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 1.6307200000000000e+05,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 2.6290363967207020e+10,
      "predicted_flops_count": 1.6307200000000000e+05
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__15025665147266655593<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1/input[1]:832/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 101621,
      "real_time": 6.1553113956206234e+03,
      "cpu_time": 1.1319861898655812e+04,
      "time_unit": "ns",
      "items_per_second": 2.6492891995037384e+10,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 8.3200000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 8.3200000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 1.6307200000000000e+05,
      "input_width": 1.4000000000000000e+01,
      "num_iterations": 1.0162100000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 8.3200000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 1.6307200000000000e+05,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 2.6492891995037384e+10,
      "predicted_flops_count": 1.6307200000000000e+05
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__9445731292345734694<CUDNN_ACTIVATION_RELU>/input[0]:1/input[1]:352/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 124610,
      "real_time": 5.6262248097703668e+03,
      "cpu_time": 1.0749832052000766e+04,
      "time_unit": "ns",
      "items_per_second": 1.2262574342957315e+10,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 3.5200000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 3.5200000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 6.8992000000000000e+04,
      "input_width": 1.4000000000000000e+01,
      "num_iterations": 1.2461000000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 3.5200000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 6.8992000000000000e+04,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 1.2262574342957315e+10,
      "predicted_flops_count": 6.8992000000000000e+04
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__9445731292345734694<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1/input[1]:352/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 124488,
      "real_time": 5.6224276200907834e+03,
      "cpu_time": 1.0759329879208744e+04,
      "time_unit": "ns",
      "items_per_second": 1.2270856053970156e+10,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 3.5200000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 3.5200000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 6.8992000000000000e+04,
      "input_width": 1.4000000000000000e+01,
      "num_iterations": 1.2448800000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 3.5200000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 6.8992000000000000e+04,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 1.2270856053970156e+10,
      "predicted_flops_count": 6.8992000000000000e+04
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__14740440911401069196<CUDNN_ACTIVATION_RELU>/input[0]:1/input[1]:384/input[2]:28/input[3]:28/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 100006,
      "real_time": 6.9742075212472200e+03,
      "cpu_time": 1.2138411305281921e+04,
      "time_unit": "ns",
      "items_per_second": 4.3167055050028282e+10,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 3.8400000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 3.8400000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 3.0105600000000000e+05,
      "input_width": 2.8000000000000000e+01,
      "num_iterations": 1.0000600000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 3.8400000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 3.0105600000000000e+05,
      "output_width": 2.8000000000000000e+01,
      "predicted_flops": 4.3167055050028282e+10,
      "predicted_flops_count": 3.0105600000000000e+05
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__14740440911401069196<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1/input[1]:384/input[2]:28/input[3]:28/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 99642,
      "real_time": 7.0100631235194642e+03,
      "cpu_time": 1.2191538427571746e+04,
      "time_unit": "ns",
      "items_per_second": 4.2946260924516777e+10,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 3.8400000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 3.8400000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 3.0105600000000000e+05,
      "input_width": 2.8000000000000000e+01,
      "num_iterations": 9.9642000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 3.8400000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 3.0105600000000000e+05,
      "output_width": 2.8000000000000000e+01,
      "predicted_flops": 4.2946260924516777e+10,
      "predicted_flops_count": 3.0105600000000000e+05
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__3544833755246448921<CUDNN_ACTIVATION_RELU>/input[0]:1/input[1]:704/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 116604,
      "real_time": 6.0110432182558852e+03,
      "cpu_time": 1.1176257864212530e+04,
      "time_unit": "ns",
      "items_per_second": 2.2955083666830849e+10,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 7.0400000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 7.0400000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 1.3798400000000000e+05,
      "input_width": 1.4000000000000000e+01,
      "num_iterations": 1.1660400000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 7.0400000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 1.3798400000000000e+05,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 2.2955083666830849e+10,
      "predicted_flops_count": 1.3798400000000000e+05
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__3544833755246448921<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1/input[1]:704/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 116490,
      "real_time": 6.4686724333467055e+03,
      "cpu_time": 1.1870053832903313e+04,
      "time_unit": "ns",
      "items_per_second": 2.1331115684367870e+10,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 7.0400000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 7.0400000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 1.3798400000000000e+05,
      "input_width": 1.4000000000000000e+01,
      "num_iterations": 1.1649000000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 7.0400000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 1.3798400000000000e+05,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 2.1331115684367870e+10,
      "predicted_flops_count": 1.3798400000000000e+05
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__17207803664042782686<CUDNN_ACTIVATION_RELU>/input[0]:1/input[1]:112/input[2]:13/input[3]:13/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 117288,
      "real_time": 5.9464096894371005e+03,
      "cpu_time": 1.1503781853216591e+04,
      "time_unit": "ns",
      "items_per_second": 3.1830971945344996e+09,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 1.1200000000000000e+02,
      "input[2]": 1.3000000000000000e+01,
      "input[3]": 1.3000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 1.1200000000000000e+02,
      "input_height": 1.3000000000000000e+01,
      "input_size": 1.8928000000000000e+04,
      "input_width": 1.3000000000000000e+01,
      "num_iterations": 1.1728800000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 1.1200000000000000e+02,
      "output_height": 1.3000000000000000e+01,
      "output_size": 1.8928000000000000e+04,
      "output_width": 1.3000000000000000e+01,
      "predicted_flops": 3.1830971945344996e+09,
      "predicted_flops_count": 1.8928000000000000e+04
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__17207803664042782686<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1/input[1]:112/input[2]:13/input[3]:13/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 132942,
      "real_time": 5.2704056638333559e+03,
      "cpu_time": 1.0400559612468060e+04,
      "time_unit": "ns",
      "items_per_second": 3.5913744040402737e+09,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 1.1200000000000000e+02,
      "input[2]": 1.3000000000000000e+01,
      "input[3]": 1.3000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 1.1200000000000000e+02,
      "input_height": 1.3000000000000000e+01,
      "input_size": 1.8928000000000000e+04,
      "input_width": 1.3000000000000000e+01,
      "num_iterations": 1.3294200000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 1.1200000000000000e+02,
      "output_height": 1.3000000000000000e+01,
      "output_size": 1.8928000000000000e+04,
      "output_width": 1.3000000000000000e+01,
      "predicted_flops": 3.5913744040402737e+09,
      "predicted_flops_count": 1.8928000000000000e+04
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__11873764108174407600<CUDNN_ACTIVATION_RELU>/input[0]:1/input[1]:416/input[2]:28/input[3]:28/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 99248,
      "real_time": 7.0574751565850320e+03,
      "cpu_time": 1.2201747027699354e+04,
      "time_unit": "ns",
      "items_per_second": 4.6212560832848106e+10,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 4.1600000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 4.1600000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 3.2614400000000000e+05,
      "input_width": 2.8000000000000000e+01,
      "num_iterations": 9.9248000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 4.1600000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 3.2614400000000000e+05,
      "output_width": 2.8000000000000000e+01,
      "predicted_flops": 4.6212560832848106e+10,
      "predicted_flops_count": 3.2614400000000000e+05
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__11873764108174407600<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1/input[1]:416/input[2]:28/input[3]:28/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 98654,
      "real_time": 7.1271805588348934e+03,
      "cpu_time": 1.2286918472643289e+04,
      "time_unit": "ns",
      "items_per_second": 4.5760591766643265e+10,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 4.1600000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 4.1600000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 3.2614400000000000e+05,
      "input_width": 2.8000000000000000e+01,
      "num_iterations": 9.8654000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 4.1600000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 3.2614400000000000e+05,
      "output_width": 2.8000000000000000e+01,
      "predicted_flops": 4.5760591766643265e+10,
      "predicted_flops_count": 3.2614400000000000e+05
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__6598087145846086276<CUDNN_ACTIVATION_RELU>/input[0]:1/input[1]:384/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 123618,
      "real_time": 5.6370258192344982e+03,
      "cpu_time": 1.0759122020979652e+04,
      "time_unit": "ns",
      "items_per_second": 1.3351721708136644e+10,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 3.8400000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 3.8400000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 7.5264000000000000e+04,
      "input_width": 1.4000000000000000e+01,
      "num_iterations": 1.2361800000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 3.8400000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 7.5264000000000000e+04,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 1.3351721708136644e+10,
      "predicted_flops_count": 7.5264000000000000e+04
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__6598087145846086276<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1/input[1]:384/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 123671,
      "real_time": 5.7781788283857104e+03,
      "cpu_time": 1.0950992932861533e+04,
      "time_unit": "ns",
      "items_per_second": 1.3025557400587933e+10,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 3.8400000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 3.8400000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 7.5264000000000000e+04,
      "input_width": 1.4000000000000000e+01,
      "num_iterations": 1.2367100000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 3.8400000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 7.5264000000000000e+04,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 1.3025557400587933e+10,
      "predicted_flops_count": 7.5264000000000000e+04
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__8085962806674819134<CUDNN_ACTIVATION_RELU>/input[0]:1/input[1]:736/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 102738,
      "real_time": 6.0736597099593382e+03,
      "cpu_time": 1.1251417060782227e+04,
      "time_unit": "ns",
      "items_per_second": 2.3751083677515701e+10,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 7.3600000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 7.3600000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 1.4425600000000000e+05,
      "input_width": 1.4000000000000000e+01,
      "num_iterations": 1.0273800000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 7.3600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 1.4425600000000000e+05,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 2.3751083677515701e+10,
      "predicted_flops_count": 1.4425600000000000e+05
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__8085962806674819134<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1/input[1]:736/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 115755,
      "real_time": 6.0201928859142599e+03,
      "cpu_time": 1.1182616664569137e+04,
      "time_unit": "ns",
      "items_per_second": 2.3962022934102795e+10,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 7.3600000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 7.3600000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 1.4425600000000000e+05,
      "input_width": 1.4000000000000000e+01,
      "num_iterations": 1.1575500000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 7.3600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 1.4425600000000000e+05,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 2.3962022934102795e+10,
      "predicted_flops_count": 1.4425600000000000e+05
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__1603106815824656010<CUDNN_ACTIVATION_RELU>/input[0]:1/input[1]:4096/input[2]:-1/input[3]:-1/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 137356,
      "real_time": 5.0201580347233539e+03,
      "cpu_time": 1.0163894929917078e+04,
      "time_unit": "ns",
      "items_per_second": 8.1591056928264976e+08,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 4.0960000000000000e+03,
      "input[2]": -1.0000000000000000e+00,
      "input[3]": -1.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 4.0960000000000000e+03,
      "input_height": 1.0000000000000000e+00,
      "input_size": 4.0960000000000000e+03,
      "input_width": 1.0000000000000000e+00,
      "num_iterations": 1.3735600000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 4.0960000000000000e+03,
      "output_height": 1.0000000000000000e+00,
      "output_size": 4.0960000000000000e+03,
      "output_width": 1.0000000000000000e+00,
      "predicted_flops": 8.1591056928264976e+08,
      "predicted_flops_count": 4.0960000000000000e+03
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__1603106815824656010<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1/input[1]:4096/input[2]:-1/input[3]:-1/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 138346,
      "real_time": 5.0473723213278017e+03,
      "cpu_time": 1.0192620335963309e+04,
      "time_unit": "ns",
      "items_per_second": 8.1151136457523584e+08,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 4.0960000000000000e+03,
      "input[2]": -1.0000000000000000e+00,
      "input[3]": -1.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 4.0960000000000000e+03,
      "input_height": 1.0000000000000000e+00,
      "input_size": 4.0960000000000000e+03,
      "input_width": 1.0000000000000000e+00,
      "num_iterations": 1.3834600000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 4.0960000000000000e+03,
      "output_height": 1.0000000000000000e+00,
      "output_size": 4.0960000000000000e+03,
      "output_width": 1.0000000000000000e+00,
      "predicted_flops": 8.1151136457523584e+08,
      "predicted_flops_count": 4.0960000000000000e+03
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__5442124813259541838<CUDNN_ACTIVATION_RELU>/input[0]:1/input[1]:768/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 115856,
      "real_time": 6.0491534630657516e+03,
      "cpu_time": 1.1245763326825681e+04,
      "time_unit": "ns",
      "items_per_second": 2.4884143032422157e+10,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 7.6800000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 7.6800000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 1.5052800000000000e+05,
      "input_width": 1.4000000000000000e+01,
      "num_iterations": 1.1585600000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 7.6800000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 1.5052800000000000e+05,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 2.4884143032422157e+10,
      "predicted_flops_count": 1.5052800000000000e+05
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__5442124813259541838<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1/input[1]:768/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 115694,
      "real_time": 6.0798188639812224e+03,
      "cpu_time": 1.1260784077030989e+04,
      "time_unit": "ns",
      "items_per_second": 2.4758632348699677e+10,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 7.6800000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 7.6800000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 1.5052800000000000e+05,
      "input_width": 1.4000000000000000e+01,
      "num_iterations": 1.1569400000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 7.6800000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 1.5052800000000000e+05,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 2.4758632348699677e+10,
      "predicted_flops_count": 1.5052800000000000e+05
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__11476792763544506720<CUDNN_ACTIVATION_RELU>/input[0]:1/input[1]:416/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 123915,
      "real_time": 6.2863536036245487e+03,
      "cpu_time": 1.1676658160912688e+04,
      "time_unit": "ns",
      "items_per_second": 1.2970317156990412e+10,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 4.1600000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 4.1600000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 8.1536000000000000e+04,
      "input_width": 1.4000000000000000e+01,
      "num_iterations": 1.2391500000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 4.1600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 8.1536000000000000e+04,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 1.2970317156990412e+10,
      "predicted_flops_count": 8.1536000000000000e+04
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__11476792763544506720<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1/input[1]:416/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 108563,
      "real_time": 6.2241947111889631e+03,
      "cpu_time": 1.1574124618839232e+04,
      "time_unit": "ns",
      "items_per_second": 1.3099847254686024e+10,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 4.1600000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 4.1600000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 8.1536000000000000e+04,
      "input_width": 1.4000000000000000e+01,
      "num_iterations": 1.0856300000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 4.1600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 8.1536000000000000e+04,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 1.3099847254686024e+10,
      "predicted_flops_count": 8.1536000000000000e+04
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__14488049760001578203<CUDNN_ACTIVATION_RELU>/input[0]:128/input[1]:144/input[2]:28/input[3]:28/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 2477,
      "real_time": 2.8263654681435850e+05,
      "cpu_time": 2.8895937949115731e+05,
      "time_unit": "ns",
      "items_per_second": 5.1128164998037247e+10,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 1.4400000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 1.4400000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 1.4450688000000000e+07,
      "input_width": 2.8000000000000000e+01,
      "num_iterations": 2.4770000000000000e+03,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 1.4400000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 1.4450688000000000e+07,
      "output_width": 2.8000000000000000e+01,
      "predicted_flops": 5.1128164998037247e+10,
      "predicted_flops_count": 1.4450688000000000e+07
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__14488049760001578203<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:128/input[1]:144/input[2]:28/input[3]:28/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 2474,
      "real_time": 2.8289390818035969e+05,
      "cpu_time": 2.8923771988741861e+05,
      "time_unit": "ns",
      "items_per_second": 5.1081651396985649e+10,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 1.4400000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 1.4400000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 1.4450688000000000e+07,
      "input_width": 2.8000000000000000e+01,
      "num_iterations": 2.4740000000000000e+03,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 1.4400000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 1.4450688000000000e+07,
      "output_width": 2.8000000000000000e+01,
      "predicted_flops": 5.1081651396985649e+10,
      "predicted_flops_count": 1.4450688000000000e+07
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__11887735352365997151<CUDNN_ACTIVATION_RELU>/input[0]:128/input[1]:144/input[2]:56/input[3]:56/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 580,
      "real_time": 1.2062765238405175e+06,
      "cpu_time": 1.2330159086190930e+06,
      "time_unit": "ns",
      "items_per_second": 4.7918326235819328e+10,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 1.4400000000000000e+02,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 1.4400000000000000e+02,
      "input_height": 5.6000000000000000e+01,
      "input_size": 5.7802752000000000e+07,
      "input_width": 5.6000000000000000e+01,
      "num_iterations": 5.8000000000000000e+02,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 1.4400000000000000e+02,
      "output_height": 5.6000000000000000e+01,
      "output_size": 5.7802752000000000e+07,
      "output_width": 5.6000000000000000e+01,
      "predicted_flops": 4.7918326235819328e+10,
      "predicted_flops_count": 5.7802752000000000e+07
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__11887735352365997151<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:128/input[1]:144/input[2]:56/input[3]:56/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 580,
      "real_time": 1.2062594176125552e+06,
      "cpu_time": 1.2330977741366520e+06,
      "time_unit": "ns",
      "items_per_second": 4.7919005776057678e+10,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 1.4400000000000000e+02,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 1.4400000000000000e+02,
      "input_height": 5.6000000000000000e+01,
      "input_size": 5.7802752000000000e+07,
      "input_width": 5.6000000000000000e+01,
      "num_iterations": 5.8000000000000000e+02,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 1.4400000000000000e+02,
      "output_height": 5.6000000000000000e+01,
      "output_size": 5.7802752000000000e+07,
      "output_width": 5.6000000000000000e+01,
      "predicted_flops": 4.7919005776057678e+10,
      "predicted_flops_count": 5.7802752000000000e+07
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__18294223596520119380<CUDNN_ACTIVATION_RELU>/input[0]:128/input[1]:32/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 34013,
      "real_time": 2.0583155735524088e+04,
      "cpu_time": 2.5729224384891040e+04,
      "time_unit": "ns",
      "items_per_second": 3.9003543009414955e+10,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 3.2000000000000000e+01,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 3.2000000000000000e+01,
      "input_height": 1.4000000000000000e+01,
      "input_size": 8.0281600000000000e+05,
      "input_width": 1.4000000000000000e+01,
      "num_iterations": 3.4013000000000000e+04,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 3.2000000000000000e+01,
      "output_height": 1.4000000000000000e+01,
      "output_size": 8.0281600000000000e+05,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 3.9003543009414955e+10,
      "predicted_flops_count": 8.0281600000000000e+05
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__18294223596520119380<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:128/input[1]:32/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 33897,
      "real_time": 2.0993123305671677e+04,
      "cpu_time": 2.6347525326843646e+04,
      "time_unit": "ns",
      "items_per_second": 3.8241856074036606e+10,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 3.2000000000000000e+01,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 3.2000000000000000e+01,
      "input_height": 1.4000000000000000e+01,
      "input_size": 8.0281600000000000e+05,
      "input_width": 1.4000000000000000e+01,
      "num_iterations": 3.3897000000000000e+04,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 3.2000000000000000e+01,
      "output_height": 1.4000000000000000e+01,
      "output_size": 8.0281600000000000e+05,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 3.8241856074036606e+10,
      "predicted_flops_count": 8.0281600000000000e+05
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__8096921656341651302<CUDNN_ACTIVATION_RELU>/input[0]:128/input[1]:256/input[2]:26/input[3]:26/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 1616,
      "real_time": 4.3326562400120607e+05,
      "cpu_time": 4.4118571843900537e+05,
      "time_unit": "ns",
      "items_per_second": 5.1126068566054382e+10,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 2.6000000000000000e+01,
      "input[3]": 2.6000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 2.6000000000000000e+01,
      "input_size": 2.2151168000000000e+07,
      "input_width": 2.6000000000000000e+01,
      "num_iterations": 1.6160000000000000e+03,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 2.6000000000000000e+01,
      "output_size": 2.2151168000000000e+07,
      "output_width": 2.6000000000000000e+01,
      "predicted_flops": 5.1126068566054382e+10,
      "predicted_flops_count": 2.2151168000000000e+07
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__8096921656341651302<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:128/input[1]:256/input[2]:26/input[3]:26/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 1614,
      "real_time": 4.3360912071539793e+05,
      "cpu_time": 4.4151451424987748e+05,
      "time_unit": "ns",
      "items_per_second": 5.1085567488648506e+10,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 2.6000000000000000e+01,
      "input[3]": 2.6000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 2.6000000000000000e+01,
      "input_size": 2.2151168000000000e+07,
      "input_width": 2.6000000000000000e+01,
      "num_iterations": 1.6140000000000000e+03,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 2.6000000000000000e+01,
      "output_size": 2.2151168000000000e+07,
      "output_width": 2.6000000000000000e+01,
      "predicted_flops": 5.1085567488648506e+10,
      "predicted_flops_count": 2.2151168000000000e+07
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__18246384279302888895<CUDNN_ACTIVATION_RELU>/input[0]:1/input[1]:800/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 114784,
      "real_time": 6.0491349627787813e+03,
      "cpu_time": 1.1205733368709307e+04,
      "time_unit": "ns",
      "items_per_second": 2.5921061600512054e+10,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 8.0000000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 8.0000000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 1.5680000000000000e+05,
      "input_width": 1.4000000000000000e+01,
      "num_iterations": 1.1478400000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 8.0000000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 1.5680000000000000e+05,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 2.5921061600512054e+10,
      "predicted_flops_count": 1.5680000000000000e+05
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__18246384279302888895<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1/input[1]:800/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 115083,
      "real_time": 6.0715000099757644e+03,
      "cpu_time": 1.1231203088201972e+04,
      "time_unit": "ns",
      "items_per_second": 2.5825578480172955e+10,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 8.0000000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 8.0000000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 1.5680000000000000e+05,
      "input_width": 1.4000000000000000e+01,
      "num_iterations": 1.1508300000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 8.0000000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 1.5680000000000000e+05,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 2.5825578480172955e+10,
      "predicted_flops_count": 1.5680000000000000e+05
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__2320220655716854409<CUDNN_ACTIVATION_RELU>/input[0]:1/input[1]:448/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 123727,
      "real_time": 5.6494404728927921e+03,
      "cpu_time": 1.0785050878142118e+04,
      "time_unit": "ns",
      "items_per_second": 1.5542778160301241e+10,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 4.4800000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 4.4800000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 8.7808000000000000e+04,
      "input_width": 1.4000000000000000e+01,
      "num_iterations": 1.2372700000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 4.4800000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 8.7808000000000000e+04,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 1.5542778160301241e+10,
      "predicted_flops_count": 8.7808000000000000e+04
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__2320220655716854409<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1/input[1]:448/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 123716,
      "real_time": 5.6532786819684634e+03,
      "cpu_time": 1.0775266901659372e+04,
      "time_unit": "ns",
      "items_per_second": 1.5532225623348429e+10,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 4.4800000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 4.4800000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 8.7808000000000000e+04,
      "input_width": 1.4000000000000000e+01,
      "num_iterations": 1.2371600000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 4.4800000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 8.7808000000000000e+04,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 1.5532225623348429e+10,
      "predicted_flops_count": 8.7808000000000000e+04
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__2206057058500228769<CUDNN_ACTIVATION_RELU>/input[0]:1/input[1]:480/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 123646,
      "real_time": 6.2994181684412670e+03,
      "cpu_time": 1.1663550976251398e+04,
      "time_unit": "ns",
      "items_per_second": 1.4934712617003361e+10,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 4.8000000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 4.8000000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 9.4080000000000000e+04,
      "input_width": 1.4000000000000000e+01,
      "num_iterations": 1.2364600000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 4.8000000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 9.4080000000000000e+04,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 1.4934712617003361e+10,
      "predicted_flops_count": 9.4080000000000000e+04
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__2206057058500228769<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1/input[1]:480/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 108203,
      "real_time": 6.2748444541984081e+03,
      "cpu_time": 1.1602846603096556e+04,
      "time_unit": "ns",
      "items_per_second": 1.4993200339341070e+10,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 4.8000000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 4.8000000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 9.4080000000000000e+04,
      "input_width": 1.4000000000000000e+01,
      "num_iterations": 1.0820300000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 4.8000000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 9.4080000000000000e+04,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 1.4993200339341070e+10,
      "predicted_flops_count": 9.4080000000000000e+04
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__14060889412066880601<CUDNN_ACTIVATION_RELU>/input[0]:128/input[1]:128/input[2]:400/input[3]:400/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD failed to cudnnSetTensor4dDescriptor",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__14060889412066880601<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:128/input[1]:128/input[2]:400/input[3]:400/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD failed to cudnnSetTensor4dDescriptor",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__13236108144488237476<CUDNN_ACTIVATION_RELU>/input[0]:128/input[1]:32/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 110537,
      "real_time": 6.3262761490757730e+03,
      "cpu_time": 1.1450823905061490e+04,
      "time_unit": "ns",
      "items_per_second": 3.1725456693717285e+10,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 3.2000000000000000e+01,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 3.2000000000000000e+01,
      "input_height": 7.0000000000000000e+00,
      "input_size": 2.0070400000000000e+05,
      "input_width": 7.0000000000000000e+00,
      "num_iterations": 1.1053700000000000e+05,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 3.2000000000000000e+01,
      "output_height": 7.0000000000000000e+00,
      "output_size": 2.0070400000000000e+05,
      "output_width": 7.0000000000000000e+00,
      "predicted_flops": 3.1725456693717285e+10,
      "predicted_flops_count": 2.0070400000000000e+05
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__13236108144488237476<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:128/input[1]:32/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 110433,
      "real_time": 6.3495495954347380e+03,
      "cpu_time": 1.1496221781308150e+04,
      "time_unit": "ns",
      "items_per_second": 3.1609171167716232e+10,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 3.2000000000000000e+01,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 3.2000000000000000e+01,
      "input_height": 7.0000000000000000e+00,
      "input_size": 2.0070400000000000e+05,
      "input_width": 7.0000000000000000e+00,
      "num_iterations": 1.1043300000000000e+05,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 3.2000000000000000e+01,
      "output_height": 7.0000000000000000e+00,
      "output_size": 2.0070400000000000e+05,
      "output_width": 7.0000000000000000e+00,
      "predicted_flops": 3.1609171167716232e+10,
      "predicted_flops_count": 2.0070400000000000e+05
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__16474615529544097758<CUDNN_ACTIVATION_RELU>/input[0]:1/input[1]:512/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 132537,
      "real_time": 5.2912661501851535e+03,
      "cpu_time": 1.0444356549558026e+04,
      "time_unit": "ns",
      "items_per_second": 4.7413982377586718e+09,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 2.5088000000000000e+04,
      "input_width": 7.0000000000000000e+00,
      "num_iterations": 1.3253700000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 2.5088000000000000e+04,
      "output_width": 7.0000000000000000e+00,
      "predicted_flops": 4.7413982377586718e+09,
      "predicted_flops_count": 2.5088000000000000e+04
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__16474615529544097758<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1/input[1]:512/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 131404,
      "real_time": 5.2674231969269858e+03,
      "cpu_time": 1.0440783065926702e+04,
      "time_unit": "ns",
      "items_per_second": 4.7628601428182831e+09,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 2.5088000000000000e+04,
      "input_width": 7.0000000000000000e+00,
      "num_iterations": 1.3140400000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 2.5088000000000000e+04,
      "output_width": 7.0000000000000000e+00,
      "predicted_flops": 4.7628601428182831e+09,
      "predicted_flops_count": 2.5088000000000000e+04
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__4596287659301054462<CUDNN_ACTIVATION_RELU>/input[0]:1/input[1]:576/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 130948,
      "real_time": 5.5521410026240655e+03,
      "cpu_time": 1.0875879104732740e+04,
      "time_unit": "ns",
      "items_per_second": 5.0834443841863365e+09,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 5.7600000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 5.7600000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 2.8224000000000000e+04,
      "input_width": 7.0000000000000000e+00,
      "num_iterations": 1.3094800000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 5.7600000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 2.8224000000000000e+04,
      "output_width": 7.0000000000000000e+00,
      "predicted_flops": 5.0834443841863365e+09,
      "predicted_flops_count": 2.8224000000000000e+04
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__4596287659301054462<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1/input[1]:576/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 131428,
      "real_time": 5.2867380287851875e+03,
      "cpu_time": 1.0488180821511096e+04,
      "time_unit": "ns",
      "items_per_second": 5.3386416815673857e+09,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 5.7600000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 5.7600000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 2.8224000000000000e+04,
      "input_width": 7.0000000000000000e+00,
      "num_iterations": 1.3142800000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 5.7600000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 2.8224000000000000e+04,
      "output_width": 7.0000000000000000e+00,
      "predicted_flops": 5.3386416815673857e+09,
      "predicted_flops_count": 2.8224000000000000e+04
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__1911803411335583173<CUDNN_ACTIVATION_RELU>/input[0]:1/input[1]:448/input[2]:28/input[3]:28/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 97113,
      "real_time": 7.2112951229914634e+03,
      "cpu_time": 1.2336020718128906e+04,
      "time_unit": "ns",
      "items_per_second": 4.8705814144283470e+10,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 4.4800000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 4.4800000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 3.5123200000000000e+05,
      "input_width": 2.8000000000000000e+01,
      "num_iterations": 9.7113000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 4.4800000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 3.5123200000000000e+05,
      "output_width": 2.8000000000000000e+01,
      "predicted_flops": 4.8705814144283470e+10,
      "predicted_flops_count": 3.5123200000000000e+05
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__1911803411335583173<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1/input[1]:448/input[2]:28/input[3]:28/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 96756,
      "real_time": 7.2685833160728307e+03,
      "cpu_time": 1.2409956839930082e+04,
      "time_unit": "ns",
      "items_per_second": 4.8321933549737228e+10,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 4.4800000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 4.4800000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 3.5123200000000000e+05,
      "input_width": 2.8000000000000000e+01,
      "num_iterations": 9.6756000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 4.4800000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 3.5123200000000000e+05,
      "output_width": 2.8000000000000000e+01,
      "predicted_flops": 4.8321933549737228e+10,
      "predicted_flops_count": 3.5123200000000000e+05
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__6323109827671691149<CUDNN_ACTIVATION_RELU>/input[0]:1/input[1]:896/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 112980,
      "real_time": 6.2167894054510662e+03,
      "cpu_time": 1.1317715533776700e+04,
      "time_unit": "ns",
      "items_per_second": 2.8248664792475460e+10,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 8.9600000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 8.9600000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 1.7561600000000000e+05,
      "input_width": 1.4000000000000000e+01,
      "num_iterations": 1.1298000000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 8.9600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 1.7561600000000000e+05,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 2.8248664792475460e+10,
      "predicted_flops_count": 1.7561600000000000e+05
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__6323109827671691149<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1/input[1]:896/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 112483,
      "real_time": 6.2050561514287056e+03,
      "cpu_time": 1.1296245477070348e+04,
      "time_unit": "ns",
      "items_per_second": 2.8302080708740189e+10,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 8.9600000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 8.9600000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 1.7561600000000000e+05,
      "input_width": 1.4000000000000000e+01,
      "num_iterations": 1.1248300000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 8.9600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 1.7561600000000000e+05,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 2.8302080708740189e+10,
      "predicted_flops_count": 1.7561600000000000e+05
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__6719237062006914636<CUDNN_ACTIVATION_RELU>/input[0]:1/input[1]:288/input[2]:13/input[3]:13/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 126684,
      "real_time": 5.5484270183517619e+03,
      "cpu_time": 1.0696284076846472e+04,
      "time_unit": "ns",
      "items_per_second": 8.7722159521994953e+09,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 2.8800000000000000e+02,
      "input[2]": 1.3000000000000000e+01,
      "input[3]": 1.3000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 2.8800000000000000e+02,
      "input_height": 1.3000000000000000e+01,
      "input_size": 4.8672000000000000e+04,
      "input_width": 1.3000000000000000e+01,
      "num_iterations": 1.2668400000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 2.8800000000000000e+02,
      "output_height": 1.3000000000000000e+01,
      "output_size": 4.8672000000000000e+04,
      "output_width": 1.3000000000000000e+01,
      "predicted_flops": 8.7722159521994953e+09,
      "predicted_flops_count": 4.8672000000000000e+04
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__6719237062006914636<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1/input[1]:288/input[2]:13/input[3]:13/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 113889,
      "real_time": 6.2404866760231207e+03,
      "cpu_time": 1.1747873947329686e+04,
      "time_unit": "ns",
      "items_per_second": 7.7993917024140234e+09,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 2.8800000000000000e+02,
      "input[2]": 1.3000000000000000e+01,
      "input[3]": 1.3000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 2.8800000000000000e+02,
      "input_height": 1.3000000000000000e+01,
      "input_size": 4.8672000000000000e+04,
      "input_width": 1.3000000000000000e+01,
      "num_iterations": 1.1388900000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 2.8800000000000000e+02,
      "output_height": 1.3000000000000000e+01,
      "output_size": 4.8672000000000000e+04,
      "output_width": 1.3000000000000000e+01,
      "predicted_flops": 7.7993917024140234e+09,
      "predicted_flops_count": 4.8672000000000000e+04
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__2588722912333944632<CUDNN_ACTIVATION_RELU>/input[0]:1/input[1]:224/input[2]:13/input[3]:13/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 113545,
      "real_time": 5.7843636379021009e+03,
      "cpu_time": 1.1143005636540523e+04,
      "time_unit": "ns",
      "items_per_second": 6.5445401378205519e+09,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 2.2400000000000000e+02,
      "input[2]": 1.3000000000000000e+01,
      "input[3]": 1.3000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 2.2400000000000000e+02,
      "input_height": 1.3000000000000000e+01,
      "input_size": 3.7856000000000000e+04,
      "input_width": 1.3000000000000000e+01,
      "num_iterations": 1.1354500000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 2.2400000000000000e+02,
      "output_height": 1.3000000000000000e+01,
      "output_size": 3.7856000000000000e+04,
      "output_width": 1.3000000000000000e+01,
      "predicted_flops": 6.5445401378205519e+09,
      "predicted_flops_count": 3.7856000000000000e+04
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__2588722912333944632<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1/input[1]:224/input[2]:13/input[3]:13/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 130915,
      "real_time": 5.3565250004996842e+03,
      "cpu_time": 1.0542737890983282e+04,
      "time_unit": "ns",
      "items_per_second": 7.0672684242990742e+09,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 2.2400000000000000e+02,
      "input[2]": 1.3000000000000000e+01,
      "input[3]": 1.3000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 2.2400000000000000e+02,
      "input_height": 1.3000000000000000e+01,
      "input_size": 3.7856000000000000e+04,
      "input_width": 1.3000000000000000e+01,
      "num_iterations": 1.3091500000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 2.2400000000000000e+02,
      "output_height": 1.3000000000000000e+01,
      "output_size": 3.7856000000000000e+04,
      "output_width": 1.3000000000000000e+01,
      "predicted_flops": 7.0672684242990742e+09,
      "predicted_flops_count": 3.7856000000000000e+04
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__4704244164941136179<CUDNN_ACTIVATION_RELU>/input[0]:128/input[1]:384/input[2]:28/input[3]:28/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 906,
      "real_time": 7.7324333818111301e+05,
      "cpu_time": 7.8725948565055465e+05,
      "time_unit": "ns",
      "items_per_second": 4.9835758159450317e+10,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 3.8400000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 3.8400000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 3.8535168000000000e+07,
      "input_width": 2.8000000000000000e+01,
      "num_iterations": 9.0600000000000000e+02,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 3.8400000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 3.8535168000000000e+07,
      "output_width": 2.8000000000000000e+01,
      "predicted_flops": 4.9835758159450317e+10,
      "predicted_flops_count": 3.8535168000000000e+07
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__4704244164941136179<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:128/input[1]:384/input[2]:28/input[3]:28/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 905,
      "real_time": 7.7373029732335743e+05,
      "cpu_time": 7.8779238232137181e+05,
      "time_unit": "ns",
      "items_per_second": 4.9804393253448334e+10,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 3.8400000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 3.8400000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 3.8535168000000000e+07,
      "input_width": 2.8000000000000000e+01,
      "num_iterations": 9.0500000000000000e+02,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 3.8400000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 3.8535168000000000e+07,
      "output_width": 2.8000000000000000e+01,
      "predicted_flops": 4.9804393253448334e+10,
      "predicted_flops_count": 3.8535168000000000e+07
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__9306013828847496653<CUDNN_ACTIVATION_RELU>/input[0]:1/input[1]:480/input[2]:28/input[3]:28/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 85574,
      "real_time": 8.1608091227927698e+03,
      "cpu_time": 1.3363184448492537e+04,
      "time_unit": "ns",
      "items_per_second": 4.6113074615230904e+10,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 4.8000000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 4.8000000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 3.7632000000000000e+05,
      "input_width": 2.8000000000000000e+01,
      "num_iterations": 8.5574000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 4.8000000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 3.7632000000000000e+05,
      "output_width": 2.8000000000000000e+01,
      "predicted_flops": 4.6113074615230904e+10,
      "predicted_flops_count": 3.7632000000000000e+05
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__9306013828847496653<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1/input[1]:480/input[2]:28/input[3]:28/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 85510,
      "real_time": 8.1773123035528261e+03,
      "cpu_time": 1.3398845164291995e+04,
      "time_unit": "ns",
      "items_per_second": 4.6020010735862305e+10,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 4.8000000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 4.8000000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 3.7632000000000000e+05,
      "input_width": 2.8000000000000000e+01,
      "num_iterations": 8.5510000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 4.8000000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 3.7632000000000000e+05,
      "output_width": 2.8000000000000000e+01,
      "predicted_flops": 4.6020010735862305e+10,
      "predicted_flops_count": 3.7632000000000000e+05
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__6123726645612438266<CUDNN_ACTIVATION_RELU>/input[0]:1/input[1]:24/input[2]:13/input[3]:13/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 137354,
      "real_time": 5.3010306054408893e+03,
      "cpu_time": 1.0513836153349544e+04,
      "time_unit": "ns",
      "items_per_second": 7.6513423556487095e+08,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 2.4000000000000000e+01,
      "input[2]": 1.3000000000000000e+01,
      "input[3]": 1.3000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 2.4000000000000000e+01,
      "input_height": 1.3000000000000000e+01,
      "input_size": 4.0560000000000000e+03,
      "input_width": 1.3000000000000000e+01,
      "num_iterations": 1.3735400000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 2.4000000000000000e+01,
      "output_height": 1.3000000000000000e+01,
      "output_size": 4.0560000000000000e+03,
      "output_width": 1.3000000000000000e+01,
      "predicted_flops": 7.6513423556487095e+08,
      "predicted_flops_count": 4.0560000000000000e+03
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__6123726645612438266<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1/input[1]:24/input[2]:13/input[3]:13/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 137328,
      "real_time": 5.0981048264739738e+03,
      "cpu_time": 1.0252696179913764e+04,
      "time_unit": "ns",
      "items_per_second": 7.9558976091224682e+08,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 2.4000000000000000e+01,
      "input[2]": 1.3000000000000000e+01,
      "input[3]": 1.3000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 2.4000000000000000e+01,
      "input_height": 1.3000000000000000e+01,
      "input_size": 4.0560000000000000e+03,
      "input_width": 1.3000000000000000e+01,
      "num_iterations": 1.3732800000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 2.4000000000000000e+01,
      "output_height": 1.3000000000000000e+01,
      "output_size": 4.0560000000000000e+03,
      "output_width": 1.3000000000000000e+01,
      "predicted_flops": 7.9558976091224682e+08,
      "predicted_flops_count": 4.0560000000000000e+03
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__12990107224996438020<CUDNN_ACTIVATION_RELU>/input[0]:1/input[1]:144/input[2]:13/input[3]:13/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 132429,
      "real_time": 5.3040326672914443e+03,
      "cpu_time": 1.0506421569258027e+04,
      "time_unit": "ns",
      "items_per_second": 4.5882070353890581e+09,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 1.4400000000000000e+02,
      "input[2]": 1.3000000000000000e+01,
      "input[3]": 1.3000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 1.4400000000000000e+02,
      "input_height": 1.3000000000000000e+01,
      "input_size": 2.4336000000000000e+04,
      "input_width": 1.3000000000000000e+01,
      "num_iterations": 1.3242900000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 1.4400000000000000e+02,
      "output_height": 1.3000000000000000e+01,
      "output_size": 2.4336000000000000e+04,
      "output_width": 1.3000000000000000e+01,
      "predicted_flops": 4.5882070353890581e+09,
      "predicted_flops_count": 2.4336000000000000e+04
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__12990107224996438020<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1/input[1]:144/input[2]:13/input[3]:13/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 131758,
      "real_time": 5.2627713055104914e+03,
      "cpu_time": 1.0441554364870311e+04,
      "time_unit": "ns",
      "items_per_second": 4.6241796550267153e+09,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 1.4400000000000000e+02,
      "input[2]": 1.3000000000000000e+01,
      "input[3]": 1.3000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 1.4400000000000000e+02,
      "input_height": 1.3000000000000000e+01,
      "input_size": 2.4336000000000000e+04,
      "input_width": 1.3000000000000000e+01,
      "num_iterations": 1.3175800000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 1.4400000000000000e+02,
      "output_height": 1.3000000000000000e+01,
      "output_size": 2.4336000000000000e+04,
      "output_width": 1.3000000000000000e+01,
      "predicted_flops": 4.6241796550267153e+09,
      "predicted_flops_count": 2.4336000000000000e+04
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__3006029908054728870<CUDNN_ACTIVATION_RELU>/input[0]:1/input[1]:736/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 130050,
      "real_time": 5.3156615916160390e+03,
      "cpu_time": 1.0487154317496781e+04,
      "time_unit": "ns",
      "items_per_second": 6.7844800460738163e+09,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 7.3600000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 7.3600000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 3.6064000000000000e+04,
      "input_width": 7.0000000000000000e+00,
      "num_iterations": 1.3005000000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 7.3600000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 3.6064000000000000e+04,
      "output_width": 7.0000000000000000e+00,
      "predicted_flops": 6.7844800460738163e+09,
      "predicted_flops_count": 3.6064000000000000e+04
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__3006029908054728870<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1/input[1]:736/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 130851,
      "real_time": 5.3827948936052344e+03,
      "cpu_time": 1.0530198447049284e+04,
      "time_unit": "ns",
      "items_per_second": 6.6998651653705158e+09,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 7.3600000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 7.3600000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 3.6064000000000000e+04,
      "input_width": 7.0000000000000000e+00,
      "num_iterations": 1.3085100000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 7.3600000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 3.6064000000000000e+04,
      "output_width": 7.0000000000000000e+00,
      "predicted_flops": 6.6998651653705158e+09,
      "predicted_flops_count": 3.6064000000000000e+04
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__1854157221896980618<CUDNN_ACTIVATION_RELU>/input[0]:1/input[1]:512/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 122604,
      "real_time": 6.4081373025049716e+03,
      "cpu_time": 1.1800600274018667e+04,
      "time_unit": "ns",
      "items_per_second": 1.5660088924869308e+10,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 1.0035200000000000e+05,
      "input_width": 1.4000000000000000e+01,
      "num_iterations": 1.2260400000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 1.0035200000000000e+05,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 1.5660088924869308e+10,
      "predicted_flops_count": 1.0035200000000000e+05
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__1854157221896980618<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1/input[1]:512/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 107272,
      "real_time": 6.2980568460938894e+03,
      "cpu_time": 1.1630326636974563e+04,
      "time_unit": "ns",
      "items_per_second": 1.5933803465467163e+10,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 1.0035200000000000e+05,
      "input_width": 1.4000000000000000e+01,
      "num_iterations": 1.0727200000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 1.0035200000000000e+05,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 1.5933803465467163e+10,
      "predicted_flops_count": 1.0035200000000000e+05
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__13409702507013341771<CUDNN_ACTIVATION_RELU>/input[0]:1/input[1]:608/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 131772,
      "real_time": 5.3193785465250985e+03,
      "cpu_time": 1.0485559436042358e+04,
      "time_unit": "ns",
      "items_per_second": 5.6006542379770508e+09,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 6.0800000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 6.0800000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 2.9792000000000000e+04,
      "input_width": 7.0000000000000000e+00,
      "num_iterations": 1.3177200000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 6.0800000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 2.9792000000000000e+04,
      "output_width": 7.0000000000000000e+00,
      "predicted_flops": 5.6006542379770508e+09,
      "predicted_flops_count": 2.9792000000000000e+04
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__13409702507013341771<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1/input[1]:608/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 131174,
      "real_time": 5.3461162580246109e+03,
      "cpu_time": 1.0518314140203045e+04,
      "time_unit": "ns",
      "items_per_second": 5.5726434970959902e+09,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 6.0800000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 6.0800000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 2.9792000000000000e+04,
      "input_width": 7.0000000000000000e+00,
      "num_iterations": 1.3117400000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 6.0800000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 2.9792000000000000e+04,
      "output_width": 7.0000000000000000e+00,
      "predicted_flops": 5.5726434970959902e+09,
      "predicted_flops_count": 2.9792000000000000e+04
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__3782035135739875651<CUDNN_ACTIVATION_RELU>/input[0]:1/input[1]:544/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 120928,
      "real_time": 5.7908394015189397e+03,
      "cpu_time": 1.0975314029909228e+04,
      "time_unit": "ns",
      "items_per_second": 1.8412529273740952e+10,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 5.4400000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 5.4400000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 1.0662400000000000e+05,
      "input_width": 1.4000000000000000e+01,
      "num_iterations": 1.2092800000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 5.4400000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 1.0662400000000000e+05,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 1.8412529273740952e+10,
      "predicted_flops_count": 1.0662400000000000e+05
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__3782035135739875651<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1/input[1]:544/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 120677,
      "real_time": 5.7776023192139282e+03,
      "cpu_time": 1.0908453491524315e+04,
      "time_unit": "ns",
      "items_per_second": 1.8454714275749378e+10,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 5.4400000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 5.4400000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 1.0662400000000000e+05,
      "input_width": 1.4000000000000000e+01,
      "num_iterations": 1.2067700000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 5.4400000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 1.0662400000000000e+05,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 1.8454714275749378e+10,
      "predicted_flops_count": 1.0662400000000000e+05
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__9542155896868387401<CUDNN_ACTIVATION_RELU>/input[0]:128/input[1]:64/input[2]:199/input[3]:199/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 86,
      "real_time": 8.1423193021395868e+06,
      "cpu_time": 9.1253203837218955e+06,
      "time_unit": "ns",
      "items_per_second": 3.9842627138775215e+10,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 1.9900000000000000e+02,
      "input[3]": 1.9900000000000000e+02,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 1.9900000000000000e+02,
      "input_size": 3.2441139200000000e+08,
      "input_width": 1.9900000000000000e+02,
      "num_iterations": 8.6000000000000000e+01,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 1.9900000000000000e+02,
      "output_size": 3.2441139200000000e+08,
      "output_width": 1.9900000000000000e+02,
      "predicted_flops": 3.9842627138775215e+10,
      "predicted_flops_count": 3.2441139200000000e+08
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__9542155896868387401<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:128/input[1]:64/input[2]:199/input[3]:199/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 86,
      "real_time": 8.1323329792466275e+06,
      "cpu_time": 9.1147360116315465e+06,
      "time_unit": "ns",
      "items_per_second": 3.9891552993204323e+10,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 1.9900000000000000e+02,
      "input[3]": 1.9900000000000000e+02,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 1.9900000000000000e+02,
      "input_size": 3.2441139200000000e+08,
      "input_width": 1.9900000000000000e+02,
      "num_iterations": 8.6000000000000000e+01,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 1.9900000000000000e+02,
      "output_size": 3.2441139200000000e+08,
      "output_width": 1.9900000000000000e+02,
      "predicted_flops": 3.9891552993204323e+10,
      "predicted_flops_count": 3.2441139200000000e+08
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__12845871009045495745<CUDNN_ACTIVATION_RELU>/input[0]:1/input[1]:704/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 130815,
      "real_time": 5.3519895287107993e+03,
      "cpu_time": 1.0508675044799089e+04,
      "time_unit": "ns",
      "items_per_second": 6.4454535673035002e+09,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 7.0400000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 7.0400000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 3.4496000000000000e+04,
      "input_width": 7.0000000000000000e+00,
      "num_iterations": 1.3081500000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 7.0400000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 3.4496000000000000e+04,
      "output_width": 7.0000000000000000e+00,
      "predicted_flops": 6.4454535673035002e+09,
      "predicted_flops_count": 3.4496000000000000e+04
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__12845871009045495745<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1/input[1]:704/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 130934,
      "real_time": 5.3243892492058239e+03,
      "cpu_time": 1.0487561794524239e+04,
      "time_unit": "ns",
      "items_per_second": 6.4788651590687809e+09,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 7.0400000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 7.0400000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 3.4496000000000000e+04,
      "input_width": 7.0000000000000000e+00,
      "num_iterations": 1.3093400000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 7.0400000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 3.4496000000000000e+04,
      "output_width": 7.0000000000000000e+00,
      "predicted_flops": 6.4788651590687809e+09,
      "predicted_flops_count": 3.4496000000000000e+04
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__16102228065260051246<CUDNN_ACTIVATION_RELU>/input[0]:128/input[1]:48/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 100456,
      "real_time": 7.0433855726719730e+03,
      "cpu_time": 1.2225434548543815e+04,
      "time_unit": "ns",
      "items_per_second": 4.2743080993334236e+10,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 4.8000000000000000e+01,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 4.8000000000000000e+01,
      "input_height": 7.0000000000000000e+00,
      "input_size": 3.0105600000000000e+05,
      "input_width": 7.0000000000000000e+00,
      "num_iterations": 1.0045600000000000e+05,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 4.8000000000000000e+01,
      "output_height": 7.0000000000000000e+00,
      "output_size": 3.0105600000000000e+05,
      "output_width": 7.0000000000000000e+00,
      "predicted_flops": 4.2743080993334236e+10,
      "predicted_flops_count": 3.0105600000000000e+05
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__16102228065260051246<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:128/input[1]:48/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 90198,
      "real_time": 7.7663235059191311e+03,
      "cpu_time": 1.3215616211003759e+04,
      "time_unit": "ns",
      "items_per_second": 3.8764287860343323e+10,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 4.8000000000000000e+01,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 4.8000000000000000e+01,
      "input_height": 7.0000000000000000e+00,
      "input_size": 3.0105600000000000e+05,
      "input_width": 7.0000000000000000e+00,
      "num_iterations": 9.0198000000000000e+04,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 4.8000000000000000e+01,
      "output_height": 7.0000000000000000e+00,
      "output_size": 3.0105600000000000e+05,
      "output_width": 7.0000000000000000e+00,
      "predicted_flops": 3.8764287860343323e+10,
      "predicted_flops_count": 3.0105600000000000e+05
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__5291900785675511683<CUDNN_ACTIVATION_RELU>/input[0]:128/input[1]:384/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 13452,
      "real_time": 5.2008373131954933e+04,
      "cpu_time": 5.7530582441086430e+04,
      "time_unit": "ns",
      "items_per_second": 4.6308850959235329e+10,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 3.8400000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 3.8400000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 2.4084480000000000e+06,
      "input_width": 7.0000000000000000e+00,
      "num_iterations": 1.3452000000000000e+04,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 3.8400000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 2.4084480000000000e+06,
      "output_width": 7.0000000000000000e+00,
      "predicted_flops": 4.6308850959235329e+10,
      "predicted_flops_count": 2.4084480000000000e+06
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__5291900785675511683<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:128/input[1]:384/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 13423,
      "real_time": 5.1362139360137342e+04,
      "cpu_time": 5.6575568948660570e+04,
      "time_unit": "ns",
      "items_per_second": 4.6891504715421181e+10,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 3.8400000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 3.8400000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 2.4084480000000000e+06,
      "input_width": 7.0000000000000000e+00,
      "num_iterations": 1.3423000000000000e+04,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 3.8400000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 2.4084480000000000e+06,
      "output_width": 7.0000000000000000e+00,
      "predicted_flops": 4.6891504715421181e+10,
      "predicted_flops_count": 2.4084480000000000e+06
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__14852377515649857131<CUDNN_ACTIVATION_RELU>/input[0]:128/input[1]:384/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 3687,
      "real_time": 1.8975669235678893e+05,
      "cpu_time": 1.9542775806891563e+05,
      "time_unit": "ns",
      "items_per_second": 5.0769181736610992e+10,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 3.8400000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 3.8400000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 9.6337920000000000e+06,
      "input_width": 1.4000000000000000e+01,
      "num_iterations": 3.6870000000000000e+03,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 3.8400000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 9.6337920000000000e+06,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 5.0769181736610992e+10,
      "predicted_flops_count": 9.6337920000000000e+06
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__14852377515649857131<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:128/input[1]:384/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 3682,
      "real_time": 1.9020325410924575e+05,
      "cpu_time": 1.9589867191756782e+05,
      "time_unit": "ns",
      "items_per_second": 5.0649985170425659e+10,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 3.8400000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 3.8400000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 9.6337920000000000e+06,
      "input_width": 1.4000000000000000e+01,
      "num_iterations": 3.6820000000000000e+03,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 3.8400000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 9.6337920000000000e+06,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 5.0649985170425659e+10,
      "predicted_flops_count": 9.6337920000000000e+06
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__8678841859161628557<CUDNN_ACTIVATION_RELU>/input[0]:1/input[1]:128/input[2]:28/input[3]:28/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 122512,
      "real_time": 5.6729878722387348e+03,
      "cpu_time": 1.0784355532589101e+04,
      "time_unit": "ns",
      "items_per_second": 1.7689443774607971e+10,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 1.2800000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 1.2800000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 1.0035200000000000e+05,
      "input_width": 2.8000000000000000e+01,
      "num_iterations": 1.2251200000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 1.0035200000000000e+05,
      "output_width": 2.8000000000000000e+01,
      "predicted_flops": 1.7689443774607971e+10,
      "predicted_flops_count": 1.0035200000000000e+05
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__8678841859161628557<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1/input[1]:128/input[2]:28/input[3]:28/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 122727,
      "real_time": 5.6954013600069929e+03,
      "cpu_time": 1.0780473864838257e+04,
      "time_unit": "ns",
      "items_per_second": 1.7619829342435802e+10,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 1.2800000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 1.2800000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 1.0035200000000000e+05,
      "input_width": 2.8000000000000000e+01,
      "num_iterations": 1.2272700000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 1.0035200000000000e+05,
      "output_width": 2.8000000000000000e+01,
      "predicted_flops": 1.7619829342435802e+10,
      "predicted_flops_count": 1.0035200000000000e+05
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__1114247392826806057<CUDNN_ACTIVATION_RELU>/input[0]:1/input[1]:128/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 131565,
      "real_time": 5.3759501284427788e+03,
      "cpu_time": 1.0577416326671037e+04,
      "time_unit": "ns",
      "items_per_second": 4.6667099583505812e+09,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 1.2800000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 1.2800000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 2.5088000000000000e+04,
      "input_width": 1.4000000000000000e+01,
      "num_iterations": 1.3156500000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 2.5088000000000000e+04,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 4.6667099583505812e+09,
      "predicted_flops_count": 2.5088000000000000e+04
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__1114247392826806057<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1/input[1]:128/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 115765,
      "real_time": 5.3854060803817365e+03,
      "cpu_time": 1.0598562691661131e+04,
      "time_unit": "ns",
      "items_per_second": 4.6585159272189322e+09,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 1.2800000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 1.2800000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 2.5088000000000000e+04,
      "input_width": 1.4000000000000000e+01,
      "num_iterations": 1.1576500000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 2.5088000000000000e+04,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 4.6585159272189322e+09,
      "predicted_flops_count": 2.5088000000000000e+04
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__15288896826146077873<CUDNN_ACTIVATION_RELU>/input[0]:128/input[1]:576/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 2476,
      "real_time": 2.8258918519427109e+05,
      "cpu_time": 2.8890843255316257e+05,
      "time_unit": "ns",
      "items_per_second": 5.1136734019264084e+10,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 5.7600000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 5.7600000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 1.4450688000000000e+07,
      "input_width": 1.4000000000000000e+01,
      "num_iterations": 2.4760000000000000e+03,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 5.7600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 1.4450688000000000e+07,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 5.1136734019264084e+10,
      "predicted_flops_count": 1.4450688000000000e+07
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__15288896826146077873<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:128/input[1]:576/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 2475,
      "real_time": 2.8288362386655249e+05,
      "cpu_time": 2.8921899919143674e+05,
      "time_unit": "ns",
      "items_per_second": 5.1083508484807045e+10,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 5.7600000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 5.7600000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 1.4450688000000000e+07,
      "input_width": 1.4000000000000000e+01,
      "num_iterations": 2.4750000000000000e+03,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 5.7600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 1.4450688000000000e+07,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 5.1083508484807045e+10,
      "predicted_flops_count": 1.4450688000000000e+07
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__14053627354337777324<CUDNN_ACTIVATION_RELU>/input[0]:1/input[1]:960/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 112215,
      "real_time": 6.2404163732401530e+03,
      "cpu_time": 1.1325560673552567e+04,
      "time_unit": "ns",
      "items_per_second": 3.0151834228058643e+10,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 9.6000000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 9.6000000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 1.8816000000000000e+05,
      "input_width": 1.4000000000000000e+01,
      "num_iterations": 1.1221500000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 9.6000000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 1.8816000000000000e+05,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 3.0151834228058643e+10,
      "predicted_flops_count": 1.8816000000000000e+05
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__14053627354337777324<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1/input[1]:960/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 111701,
      "real_time": 6.2471253351475661e+03,
      "cpu_time": 1.1345277768491478e+04,
      "time_unit": "ns",
      "items_per_second": 3.0119453333419537e+10,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 9.6000000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 9.6000000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 1.8816000000000000e+05,
      "input_width": 1.4000000000000000e+01,
      "num_iterations": 1.1170100000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 9.6000000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 1.8816000000000000e+05,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 3.0119453333419537e+10,
      "predicted_flops_count": 1.8816000000000000e+05
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__7214324892851242403<CUDNN_ACTIVATION_RELU>/input[0]:1/input[1]:864/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 114815,
      "real_time": 6.1348870760325772e+03,
      "cpu_time": 1.1260324313123971e+04,
      "time_unit": "ns",
      "items_per_second": 2.7603442068491100e+10,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 8.6400000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 8.6400000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 1.6934400000000000e+05,
      "input_width": 1.4000000000000000e+01,
      "num_iterations": 1.1481500000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 8.6400000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 1.6934400000000000e+05,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 2.7603442068491100e+10,
      "predicted_flops_count": 1.6934400000000000e+05
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__7214324892851242403<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1/input[1]:864/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 113899,
      "real_time": 6.2581764153218564e+03,
      "cpu_time": 1.1419626335629151e+04,
      "time_unit": "ns",
      "items_per_second": 2.7059639863362770e+10,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 8.6400000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 8.6400000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 1.6934400000000000e+05,
      "input_width": 1.4000000000000000e+01,
      "num_iterations": 1.1389900000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 8.6400000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 1.6934400000000000e+05,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 2.7059639863362770e+10,
      "predicted_flops_count": 1.6934400000000000e+05
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__12520849883310571022<CUDNN_ACTIVATION_RELU>/input[0]:1/input[1]:928/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 99547,
      "real_time": 7.0182332944432283e+03,
      "cpu_time": 1.2458676313645068e+04,
      "time_unit": "ns",
      "items_per_second": 2.5916493848104485e+10,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 9.2800000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 9.2800000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 1.8188800000000000e+05,
      "input_width": 1.4000000000000000e+01,
      "num_iterations": 9.9547000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 9.2800000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 1.8188800000000000e+05,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 2.5916493848104485e+10,
      "predicted_flops_count": 1.8188800000000000e+05
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__12520849883310571022<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1/input[1]:928/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 99643,
      "real_time": 6.6437553717619867e+03,
      "cpu_time": 1.1918467237981817e+04,
      "time_unit": "ns",
      "items_per_second": 2.7377287365678787e+10,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 9.2800000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 9.2800000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 1.8188800000000000e+05,
      "input_width": 1.4000000000000000e+01,
      "num_iterations": 9.9643000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 9.2800000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 1.8188800000000000e+05,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 2.7377287365678787e+10,
      "predicted_flops_count": 1.8188800000000000e+05
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__11670589493566310871<CUDNN_ACTIVATION_RELU>/input[0]:1/input[1]:544/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 131296,
      "real_time": 5.2967277429211063e+03,
      "cpu_time": 1.0478820961784009e+04,
      "time_unit": "ns",
      "items_per_second": 5.0325410883398390e+09,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 5.4400000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 5.4400000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 2.6656000000000000e+04,
      "input_width": 7.0000000000000000e+00,
      "num_iterations": 1.3129600000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 5.4400000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 2.6656000000000000e+04,
      "output_width": 7.0000000000000000e+00,
      "predicted_flops": 5.0325410883398390e+09,
      "predicted_flops_count": 2.6656000000000000e+04
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__11670589493566310871<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1/input[1]:544/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 130925,
      "real_time": 5.3164984363211688e+03,
      "cpu_time": 1.0493117616917601e+04,
      "time_unit": "ns",
      "items_per_second": 5.0138263594496651e+09,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 5.4400000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 5.4400000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 2.6656000000000000e+04,
      "input_width": 7.0000000000000000e+00,
      "num_iterations": 1.3092500000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 5.4400000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 2.6656000000000000e+04,
      "output_width": 7.0000000000000000e+00,
      "predicted_flops": 5.0138263594496651e+09,
      "predicted_flops_count": 2.6656000000000000e+04
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__14632120628782387106<CUDNN_ACTIVATION_RELU>/input[0]:1/input[1]:928/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 126350,
      "real_time": 5.5218716324639981e+03,
      "cpu_time": 1.0680817570258876e+04,
      "time_unit": "ns",
      "items_per_second": 8.2348890062316141e+09,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 9.2800000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 9.2800000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 4.5472000000000000e+04,
      "input_width": 7.0000000000000000e+00,
      "num_iterations": 1.2635000000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 9.2800000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 4.5472000000000000e+04,
      "output_width": 7.0000000000000000e+00,
      "predicted_flops": 8.2348890062316141e+09,
      "predicted_flops_count": 4.5472000000000000e+04
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__14632120628782387106<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1/input[1]:928/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 126792,
      "real_time": 5.4922710601013778e+03,
      "cpu_time": 1.0663873635535643e+04,
      "time_unit": "ns",
      "items_per_second": 8.2792709067714262e+09,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 9.2800000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 9.2800000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 4.5472000000000000e+04,
      "input_width": 7.0000000000000000e+00,
      "num_iterations": 1.2679200000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 9.2800000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 4.5472000000000000e+04,
      "output_width": 7.0000000000000000e+00,
      "predicted_flops": 8.2792709067714262e+09,
      "predicted_flops_count": 4.5472000000000000e+04
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__7535005013359104634<CUDNN_ACTIVATION_RELU>/input[0]:1/input[1]:1024/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 110494,
      "real_time": 6.3116674091010855e+03,
      "cpu_time": 1.1429571117027615e+04,
      "time_unit": "ns",
      "items_per_second": 3.1798887202230518e+10,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 1.0240000000000000e+03,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 1.0240000000000000e+03,
      "input_height": 1.4000000000000000e+01,
      "input_size": 2.0070400000000000e+05,
      "input_width": 1.4000000000000000e+01,
      "num_iterations": 1.1049400000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 1.0240000000000000e+03,
      "output_height": 1.4000000000000000e+01,
      "output_size": 2.0070400000000000e+05,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 3.1798887202230518e+10,
      "predicted_flops_count": 2.0070400000000000e+05
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__7535005013359104634<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1/input[1]:1024/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 110807,
      "real_time": 6.3044898116699933e+03,
      "cpu_time": 1.1438408909305683e+04,
      "time_unit": "ns",
      "items_per_second": 3.1835089911396912e+10,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 1.0240000000000000e+03,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 1.0240000000000000e+03,
      "input_height": 1.4000000000000000e+01,
      "input_size": 2.0070400000000000e+05,
      "input_width": 1.4000000000000000e+01,
      "num_iterations": 1.1080700000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 1.0240000000000000e+03,
      "output_height": 1.4000000000000000e+01,
      "output_size": 2.0070400000000000e+05,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 3.1835089911396912e+10,
      "predicted_flops_count": 2.0070400000000000e+05
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__14208199326932404465<CUDNN_ACTIVATION_RELU>/input[0]:128/input[1]:576/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 9431,
      "real_time": 7.4198200742762943e+04,
      "cpu_time": 7.9429435690731756e+04,
      "time_unit": "ns",
      "items_per_second": 4.8689482545873848e+10,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 5.7600000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 5.7600000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 3.6126720000000000e+06,
      "input_width": 7.0000000000000000e+00,
      "num_iterations": 9.4310000000000000e+03,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 5.7600000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 3.6126720000000000e+06,
      "output_width": 7.0000000000000000e+00,
      "predicted_flops": 4.8689482545873848e+10,
      "predicted_flops_count": 3.6126720000000000e+06
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__14208199326932404465<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:128/input[1]:576/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 9411,
      "real_time": 7.4334445862668945e+04,
      "cpu_time": 7.9584830835716813e+04,
      "time_unit": "ns",
      "items_per_second": 4.8600241221604347e+10,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 5.7600000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 5.7600000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 3.6126720000000000e+06,
      "input_width": 7.0000000000000000e+00,
      "num_iterations": 9.4110000000000000e+03,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 5.7600000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 3.6126720000000000e+06,
      "output_width": 7.0000000000000000e+00,
      "predicted_flops": 4.8600241221604347e+10,
      "predicted_flops_count": 3.6126720000000000e+06
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__8091235345273135317<CUDNN_ACTIVATION_RELU>/input[0]:1/input[1]:672/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 131975,
      "real_time": 5.3217598931328921e+03,
      "cpu_time": 1.0503239060511991e+04,
      "time_unit": "ns",
      "items_per_second": 6.1874268402243643e+09,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 6.7200000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 6.7200000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 3.2928000000000000e+04,
      "input_width": 7.0000000000000000e+00,
      "num_iterations": 1.3197500000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 6.7200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 3.2928000000000000e+04,
      "output_width": 7.0000000000000000e+00,
      "predicted_flops": 6.1874268402243643e+09,
      "predicted_flops_count": 3.2928000000000000e+04
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__8091235345273135317<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1/input[1]:672/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 131423,
      "real_time": 5.2641391340318796e+03,
      "cpu_time": 1.0441712866072876e+04,
      "time_unit": "ns",
      "items_per_second": 6.2551538174827785e+09,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 6.7200000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 6.7200000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 3.2928000000000000e+04,
      "input_width": 7.0000000000000000e+00,
      "num_iterations": 1.3142300000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 6.7200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 3.2928000000000000e+04,
      "output_width": 7.0000000000000000e+00,
      "predicted_flops": 6.2551538174827785e+09,
      "predicted_flops_count": 3.2928000000000000e+04
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__11338305390499976235<CUDNN_ACTIVATION_RELU>/input[0]:128/input[1]:960/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 5808,
      "real_time": 1.2051223984474070e+05,
      "cpu_time": 1.2593640340910123e+05,
      "time_unit": "ns",
      "items_per_second": 4.9962725842264465e+10,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 9.6000000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 9.6000000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 6.0211200000000000e+06,
      "input_width": 7.0000000000000000e+00,
      "num_iterations": 5.8080000000000000e+03,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 9.6000000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 6.0211200000000000e+06,
      "output_width": 7.0000000000000000e+00,
      "predicted_flops": 4.9962725842264465e+10,
      "predicted_flops_count": 6.0211200000000000e+06
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__11338305390499976235<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:128/input[1]:960/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 5797,
      "real_time": 1.2080536238969333e+05,
      "cpu_time": 1.2619310332902131e+05,
      "time_unit": "ns",
      "items_per_second": 4.9841496113203163e+10,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 9.6000000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 9.6000000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 6.0211200000000000e+06,
      "input_width": 7.0000000000000000e+00,
      "num_iterations": 5.7970000000000000e+03,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 9.6000000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 6.0211200000000000e+06,
      "output_width": 7.0000000000000000e+00,
      "predicted_flops": 4.9841496113203163e+10,
      "predicted_flops_count": 6.0211200000000000e+06
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__10537112639109253411<CUDNN_ACTIVATION_RELU>/input[0]:128/input[1]:64/input[2]:64/input[3]:64/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 1050,
      "real_time": 6.6647554864175618e+05,
      "cpu_time": 6.7821580190406204e+05,
      "time_unit": "ns",
      "items_per_second": 5.0346081065362793e+10,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 6.4000000000000000e+01,
      "input[3]": 6.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 6.4000000000000000e+01,
      "input_size": 3.3554432000000000e+07,
      "input_width": 6.4000000000000000e+01,
      "num_iterations": 1.0500000000000000e+03,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 6.4000000000000000e+01,
      "output_size": 3.3554432000000000e+07,
      "output_width": 6.4000000000000000e+01,
      "predicted_flops": 5.0346081065362793e+10,
      "predicted_flops_count": 3.3554432000000000e+07
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__10537112639109253411<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:128/input[1]:64/input[2]:64/input[3]:64/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 1050,
      "real_time": 6.6700016880141839e+05,
      "cpu_time": 6.7878634952362080e+05,
      "time_unit": "ns",
      "items_per_second": 5.0306482021281082e+10,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 6.4000000000000000e+01,
      "input[3]": 6.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 6.4000000000000000e+01,
      "input_size": 3.3554432000000000e+07,
      "input_width": 6.4000000000000000e+01,
      "num_iterations": 1.0500000000000000e+03,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 6.4000000000000000e+01,
      "output_size": 3.3554432000000000e+07,
      "output_width": 6.4000000000000000e+01,
      "predicted_flops": 5.0306482021281082e+10,
      "predicted_flops_count": 3.3554432000000000e+07
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__10352455638451390380<CUDNN_ACTIVATION_RELU>/input[0]:1/input[1]:640/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 131134,
      "real_time": 5.3148514175009350e+03,
      "cpu_time": 1.0516052739920535e+04,
      "time_unit": "ns",
      "items_per_second": 5.9004471689907751e+09,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 6.4000000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 6.4000000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 3.1360000000000000e+04,
      "input_width": 7.0000000000000000e+00,
      "num_iterations": 1.3113400000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 6.4000000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 3.1360000000000000e+04,
      "output_width": 7.0000000000000000e+00,
      "predicted_flops": 5.9004471689907751e+09,
      "predicted_flops_count": 3.1360000000000000e+04
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__10352455638451390380<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1/input[1]:640/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 130557,
      "real_time": 5.3128039228625403e+03,
      "cpu_time": 1.0498057507478623e+04,
      "time_unit": "ns",
      "items_per_second": 5.9027211347004166e+09,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 6.4000000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 6.4000000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 3.1360000000000000e+04,
      "input_width": 7.0000000000000000e+00,
      "num_iterations": 1.3055700000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 6.4000000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 3.1360000000000000e+04,
      "output_width": 7.0000000000000000e+00,
      "predicted_flops": 5.9027211347004166e+09,
      "predicted_flops_count": 3.1360000000000000e+04
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__16631141030050079572<CUDNN_ACTIVATION_RELU>/input[0]:1/input[1]:960/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 126807,
      "real_time": 5.5348076413949057e+03,
      "cpu_time": 1.0691008335481532e+04,
      "time_unit": "ns",
      "items_per_second": 8.4989403512756538e+09,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 9.6000000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 9.6000000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 4.7040000000000000e+04,
      "input_width": 7.0000000000000000e+00,
      "num_iterations": 1.2680700000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 9.6000000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 4.7040000000000000e+04,
      "output_width": 7.0000000000000000e+00,
      "predicted_flops": 8.4989403512756538e+09,
      "predicted_flops_count": 4.7040000000000000e+04
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__16631141030050079572<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1/input[1]:960/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 126474,
      "real_time": 5.4830628901557238e+03,
      "cpu_time": 1.0652404209460556e+04,
      "time_unit": "ns",
      "items_per_second": 8.5791465358632822e+09,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 9.6000000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 9.6000000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 4.7040000000000000e+04,
      "input_width": 7.0000000000000000e+00,
      "num_iterations": 1.2647400000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 9.6000000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 4.7040000000000000e+04,
      "output_width": 7.0000000000000000e+00,
      "predicted_flops": 8.5791465358632822e+09,
      "predicted_flops_count": 4.7040000000000000e+04
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__15785643385107570281<CUDNN_ACTIVATION_RELU>/input[0]:1/input[1]:896/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 126921,
      "real_time": 5.5272996620721970e+03,
      "cpu_time": 1.0687923306636219e+04,
      "time_unit": "ns",
      "items_per_second": 7.9431191873429737e+09,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 8.9600000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 8.9600000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 4.3904000000000000e+04,
      "input_width": 7.0000000000000000e+00,
      "num_iterations": 1.2692100000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 8.9600000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 4.3904000000000000e+04,
      "output_width": 7.0000000000000000e+00,
      "predicted_flops": 7.9431191873429737e+09,
      "predicted_flops_count": 4.3904000000000000e+04
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__15785643385107570281<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1/input[1]:896/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 126501,
      "real_time": 5.7569204459488983e+03,
      "cpu_time": 1.1017038063008589e+04,
      "time_unit": "ns",
      "items_per_second": 7.6262995836419649e+09,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 8.9600000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 8.9600000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 4.3904000000000000e+04,
      "input_width": 7.0000000000000000e+00,
      "num_iterations": 1.2650100000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 8.9600000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 4.3904000000000000e+04,
      "output_width": 7.0000000000000000e+00,
      "predicted_flops": 7.6262995836419649e+09,
      "predicted_flops_count": 4.3904000000000000e+04
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__10361111861848887604<CUDNN_ACTIVATION_RELU>/input[0]:128/input[1]:1280/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 4402,
      "real_time": 1.5896403870971318e+05,
      "cpu_time": 1.6448958337131070e+05,
      "time_unit": "ns",
      "items_per_second": 5.0502994672023605e+10,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 1.2800000000000000e+03,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 1.2800000000000000e+03,
      "input_height": 7.0000000000000000e+00,
      "input_size": 8.0281600000000000e+06,
      "input_width": 7.0000000000000000e+00,
      "num_iterations": 4.4020000000000000e+03,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 1.2800000000000000e+03,
      "output_height": 7.0000000000000000e+00,
      "output_size": 8.0281600000000000e+06,
      "output_width": 7.0000000000000000e+00,
      "predicted_flops": 5.0502994672023605e+10,
      "predicted_flops_count": 8.0281600000000000e+06
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__10361111861848887604<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:128/input[1]:1280/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 4394,
      "real_time": 1.5925665645836081e+05,
      "cpu_time": 1.6480392148455384e+05,
      "time_unit": "ns",
      "items_per_second": 5.0410200606585266e+10,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 1.2800000000000000e+03,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 1.2800000000000000e+03,
      "input_height": 7.0000000000000000e+00,
      "input_size": 8.0281600000000000e+06,
      "input_width": 7.0000000000000000e+00,
      "num_iterations": 4.3940000000000000e+03,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 1.2800000000000000e+03,
      "output_height": 7.0000000000000000e+00,
      "output_size": 8.0281600000000000e+06,
      "output_width": 7.0000000000000000e+00,
      "predicted_flops": 5.0410200606585266e+10,
      "predicted_flops_count": 8.0281600000000000e+06
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__13396873099139726196<CUDNN_ACTIVATION_RELU>/input[0]:1/input[1]:992/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 126432,
      "real_time": 5.5189744384349506e+03,
      "cpu_time": 1.0678149202840663e+04,
      "time_unit": "ns",
      "items_per_second": 8.8074334357279739e+09,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 9.9200000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 9.9200000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 4.8608000000000000e+04,
      "input_width": 7.0000000000000000e+00,
      "num_iterations": 1.2643200000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 9.9200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 4.8608000000000000e+04,
      "output_width": 7.0000000000000000e+00,
      "predicted_flops": 8.8074334357279739e+09,
      "predicted_flops_count": 4.8608000000000000e+04
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__13396873099139726196<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1/input[1]:992/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 126809,
      "real_time": 5.5317562658732077e+03,
      "cpu_time": 1.0684708482792090e+04,
      "time_unit": "ns",
      "items_per_second": 8.7870827389621181e+09,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 9.9200000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 9.9200000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 4.8608000000000000e+04,
      "input_width": 7.0000000000000000e+00,
      "num_iterations": 1.2680900000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 9.9200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 4.8608000000000000e+04,
      "output_width": 7.0000000000000000e+00,
      "predicted_flops": 8.7870827389621181e+09,
      "predicted_flops_count": 4.8608000000000000e+04
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__13427562355699918080<CUDNN_ACTIVATION_RELU>/input[0]:1/input[1]:320/input[2]:13/input[3]:13/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 126444,
      "real_time": 5.5295824875417939e+03,
      "cpu_time": 1.0690375138466692e+04,
      "time_unit": "ns",
      "items_per_second": 9.7801235666242065e+09,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 3.2000000000000000e+02,
      "input[2]": 1.3000000000000000e+01,
      "input[3]": 1.3000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 3.2000000000000000e+02,
      "input_height": 1.3000000000000000e+01,
      "input_size": 5.4080000000000000e+04,
      "input_width": 1.3000000000000000e+01,
      "num_iterations": 1.2644400000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 3.2000000000000000e+02,
      "output_height": 1.3000000000000000e+01,
      "output_size": 5.4080000000000000e+04,
      "output_width": 1.3000000000000000e+01,
      "predicted_flops": 9.7801235666242065e+09,
      "predicted_flops_count": 5.4080000000000000e+04
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__13427562355699918080<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1/input[1]:320/input[2]:13/input[3]:13/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 126796,
      "real_time": 5.5392553720653195e+03,
      "cpu_time": 1.0696379254813228e+04,
      "time_unit": "ns",
      "items_per_second": 9.7630450967701435e+09,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 3.2000000000000000e+02,
      "input[2]": 1.3000000000000000e+01,
      "input[3]": 1.3000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 3.2000000000000000e+02,
      "input_height": 1.3000000000000000e+01,
      "input_size": 5.4080000000000000e+04,
      "input_width": 1.3000000000000000e+01,
      "num_iterations": 1.2679600000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 3.2000000000000000e+02,
      "output_height": 1.3000000000000000e+01,
      "output_size": 5.4080000000000000e+04,
      "output_width": 1.3000000000000000e+01,
      "predicted_flops": 9.7630450967701435e+09,
      "predicted_flops_count": 5.4080000000000000e+04
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__13500622049652464134<CUDNN_ACTIVATION_RELU>/input[0]:128/input[1]:128/input[2]:32/input[3]:32/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 2138,
      "real_time": 3.2739207684944523e+05,
      "cpu_time": 3.3413158512645104e+05,
      "time_unit": "ns",
      "items_per_second": 5.1245027556715080e+10,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 1.2800000000000000e+02,
      "input[2]": 3.2000000000000000e+01,
      "input[3]": 3.2000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 1.2800000000000000e+02,
      "input_height": 3.2000000000000000e+01,
      "input_size": 1.6777216000000000e+07,
      "input_width": 3.2000000000000000e+01,
      "num_iterations": 2.1380000000000000e+03,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 3.2000000000000000e+01,
      "output_size": 1.6777216000000000e+07,
      "output_width": 3.2000000000000000e+01,
      "predicted_flops": 5.1245027556715080e+10,
      "predicted_flops_count": 1.6777216000000000e+07
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__13500622049652464134<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:128/input[1]:128/input[2]:32/input[3]:32/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 2135,
      "real_time": 3.2758404687810387e+05,
      "cpu_time": 3.3434374566744611e+05,
      "time_unit": "ns",
      "items_per_second": 5.1214997066822708e+10,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 1.2800000000000000e+02,
      "input[2]": 3.2000000000000000e+01,
      "input[3]": 3.2000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 1.2800000000000000e+02,
      "input_height": 3.2000000000000000e+01,
      "input_size": 1.6777216000000000e+07,
      "input_width": 3.2000000000000000e+01,
      "num_iterations": 2.1350000000000000e+03,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 3.2000000000000000e+01,
      "output_size": 1.6777216000000000e+07,
      "output_width": 3.2000000000000000e+01,
      "predicted_flops": 5.1214997066822708e+10,
      "predicted_flops_count": 1.6777216000000000e+07
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__11437836186997684138<CUDNN_ACTIVATION_RELU>/input[0]:1/input[1]:1024/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 126961,
      "real_time": 5.5140137826710488e+03,
      "cpu_time": 1.0678264734810178e+04,
      "time_unit": "ns",
      "items_per_second": 9.0997233553693085e+09,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 1.0240000000000000e+03,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 1.0240000000000000e+03,
      "input_height": 7.0000000000000000e+00,
      "input_size": 5.0176000000000000e+04,
      "input_width": 7.0000000000000000e+00,
      "num_iterations": 1.2696100000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 1.0240000000000000e+03,
      "output_height": 7.0000000000000000e+00,
      "output_size": 5.0176000000000000e+04,
      "output_width": 7.0000000000000000e+00,
      "predicted_flops": 9.0997233553693085e+09,
      "predicted_flops_count": 5.0176000000000000e+04
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__11437836186997684138<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1/input[1]:1024/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 126386,
      "real_time": 5.5229871661510870e+03,
      "cpu_time": 1.0681041816344123e+04,
      "time_unit": "ns",
      "items_per_second": 9.0849387279976501e+09,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 1.0240000000000000e+03,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 1.0240000000000000e+03,
      "input_height": 7.0000000000000000e+00,
      "input_size": 5.0176000000000000e+04,
      "input_width": 7.0000000000000000e+00,
      "num_iterations": 1.2638600000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 1.0240000000000000e+03,
      "output_height": 7.0000000000000000e+00,
      "output_size": 5.0176000000000000e+04,
      "output_width": 7.0000000000000000e+00,
      "predicted_flops": 9.0849387279976501e+09,
      "predicted_flops_count": 5.0176000000000000e+04
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__7131927949494240285<CUDNN_ACTIVATION_RELU>/input[0]:1/input[1]:128/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 137358,
      "real_time": 5.0687013746314433e+03,
      "cpu_time": 1.0215028684223809e+04,
      "time_unit": "ns",
      "items_per_second": 1.2373978138445868e+09,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 1.2800000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 1.2800000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 6.2720000000000000e+03,
      "input_width": 7.0000000000000000e+00,
      "num_iterations": 1.3735800000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 6.2720000000000000e+03,
      "output_width": 7.0000000000000000e+00,
      "predicted_flops": 1.2373978138445868e+09,
      "predicted_flops_count": 6.2720000000000000e+03
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__7131927949494240285<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1/input[1]:128/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 137220,
      "real_time": 5.0574420877822940e+03,
      "cpu_time": 1.0200450568474518e+04,
      "time_unit": "ns",
      "items_per_second": 1.2401526089941437e+09,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 1.2800000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 1.2800000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 6.2720000000000000e+03,
      "input_width": 7.0000000000000000e+00,
      "num_iterations": 1.3722000000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 6.2720000000000000e+03,
      "output_width": 7.0000000000000000e+00,
      "predicted_flops": 1.2401526089941437e+09,
      "predicted_flops_count": 6.2720000000000000e+03
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__10544100885689436639<CUDNN_ACTIVATION_RELU>/input[0]:1/input[1]:32/input[2]:13/input[3]:13/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 136514,
      "real_time": 5.2093329393445720e+03,
      "cpu_time": 1.0406939617870456e+04,
      "time_unit": "ns",
      "items_per_second": 1.0381367562735248e+09,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 3.2000000000000000e+01,
      "input[2]": 1.3000000000000000e+01,
      "input[3]": 1.3000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 3.2000000000000000e+01,
      "input_height": 1.3000000000000000e+01,
      "input_size": 5.4080000000000000e+03,
      "input_width": 1.3000000000000000e+01,
      "num_iterations": 1.3651400000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 3.2000000000000000e+01,
      "output_height": 1.3000000000000000e+01,
      "output_size": 5.4080000000000000e+03,
      "output_width": 1.3000000000000000e+01,
      "predicted_flops": 1.0381367562735248e+09,
      "predicted_flops_count": 5.4080000000000000e+03
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__10544100885689436639<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1/input[1]:32/input[2]:13/input[3]:13/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 119992,
      "real_time": 5.0841805127635625e+03,
      "cpu_time": 1.0233690979389132e+04,
      "time_unit": "ns",
      "items_per_second": 1.0636915794833614e+09,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 3.2000000000000000e+01,
      "input[2]": 1.3000000000000000e+01,
      "input[3]": 1.3000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 3.2000000000000000e+01,
      "input_height": 1.3000000000000000e+01,
      "input_size": 5.4080000000000000e+03,
      "input_width": 1.3000000000000000e+01,
      "num_iterations": 1.1999200000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 3.2000000000000000e+01,
      "output_height": 1.3000000000000000e+01,
      "output_size": 5.4080000000000000e+03,
      "output_width": 1.3000000000000000e+01,
      "predicted_flops": 1.0636915794833614e+09,
      "predicted_flops_count": 5.4080000000000000e+03
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__688985642208744754<CUDNN_ACTIVATION_RELU>/input[0]:128/input[1]:16/input[2]:28/input[3]:28/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 19525,
      "real_time": 3.5881064591852402e+04,
      "cpu_time": 4.1039481946132633e+04,
      "time_unit": "ns",
      "items_per_second": 4.4748728006375671e+10,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 1.6000000000000000e+01,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 1.6000000000000000e+01,
      "input_height": 2.8000000000000000e+01,
      "input_size": 1.6056320000000000e+06,
      "input_width": 2.8000000000000000e+01,
      "num_iterations": 1.9525000000000000e+04,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 1.6000000000000000e+01,
      "output_height": 2.8000000000000000e+01,
      "output_size": 1.6056320000000000e+06,
      "output_width": 2.8000000000000000e+01,
      "predicted_flops": 4.4748728006375671e+10,
      "predicted_flops_count": 1.6056320000000000e+06
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__688985642208744754<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:128/input[1]:16/input[2]:28/input[3]:28/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 19460,
      "real_time": 3.5944779188728622e+04,
      "cpu_time": 4.1127478571500804e+04,
      "time_unit": "ns",
      "items_per_second": 4.4669407803831657e+10,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 1.6000000000000000e+01,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 1.6000000000000000e+01,
      "input_height": 2.8000000000000000e+01,
      "input_size": 1.6056320000000000e+06,
      "input_width": 2.8000000000000000e+01,
      "num_iterations": 1.9460000000000000e+04,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 1.6000000000000000e+01,
      "output_height": 2.8000000000000000e+01,
      "output_size": 1.6056320000000000e+06,
      "output_width": 2.8000000000000000e+01,
      "predicted_flops": 4.4669407803831657e+10,
      "predicted_flops_count": 1.6056320000000000e+06
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__15564522690150313013<CUDNN_ACTIVATION_RELU>/input[0]:128/input[1]:256/input[2]:199/input[3]:199/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 20,
      "real_time": 3.5253458097577095e+07,
      "cpu_time": 5.3436440750002131e+07,
      "time_unit": "ns",
      "items_per_second": 3.6809029185400246e+10,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 1.9900000000000000e+02,
      "input[3]": 1.9900000000000000e+02,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 1.9900000000000000e+02,
      "input_size": 1.2976455680000000e+09,
      "input_width": 1.9900000000000000e+02,
      "num_iterations": 2.0000000000000000e+01,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 1.9900000000000000e+02,
      "output_size": 1.2976455680000000e+09,
      "output_width": 1.9900000000000000e+02,
      "predicted_flops": 3.6809029185400246e+10,
      "predicted_flops_count": 1.2976455680000000e+09
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__15564522690150313013<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:128/input[1]:256/input[2]:199/input[3]:199/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 20,
      "real_time": 3.5284887999296188e+07,
      "cpu_time": 5.3434706350000739e+07,
      "time_unit": "ns",
      "items_per_second": 3.6776241659769005e+10,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 1.9900000000000000e+02,
      "input[3]": 1.9900000000000000e+02,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 1.9900000000000000e+02,
      "input_size": 1.2976455680000000e+09,
      "input_width": 1.9900000000000000e+02,
      "num_iterations": 2.0000000000000000e+01,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 1.9900000000000000e+02,
      "output_size": 1.2976455680000000e+09,
      "output_width": 1.9900000000000000e+02,
      "predicted_flops": 3.6776241659769005e+10,
      "predicted_flops_count": 1.2976455680000000e+09
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__18338656442900607191<CUDNN_ACTIVATION_RELU>/input[0]:1/input[1]:800/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 127960,
      "real_time": 5.4302529515693768e+03,
      "cpu_time": 1.0630988934061919e+04,
      "time_unit": "ns",
      "items_per_second": 7.2188165725633383e+09,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 8.0000000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 8.0000000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 3.9200000000000000e+04,
      "input_width": 7.0000000000000000e+00,
      "num_iterations": 1.2796000000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 8.0000000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 3.9200000000000000e+04,
      "output_width": 7.0000000000000000e+00,
      "predicted_flops": 7.2188165725633383e+09,
      "predicted_flops_count": 3.9200000000000000e+04
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__18338656442900607191<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1/input[1]:800/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 128181,
      "real_time": 5.4702612103646261e+03,
      "cpu_time": 1.0648564241249902e+04,
      "time_unit": "ns",
      "items_per_second": 7.1660197735579586e+09,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 8.0000000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 8.0000000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 3.9200000000000000e+04,
      "input_width": 7.0000000000000000e+00,
      "num_iterations": 1.2818100000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 8.0000000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 3.9200000000000000e+04,
      "output_width": 7.0000000000000000e+00,
      "predicted_flops": 7.1660197735579586e+09,
      "predicted_flops_count": 3.9200000000000000e+04
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__8337023137083059825<CUDNN_ACTIVATION_RELU>/input[0]:128/input[1]:64/input[2]:28/input[3]:28/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 5457,
      "real_time": 1.2829548316883648e+05,
      "cpu_time": 1.3367750210714029e+05,
      "time_unit": "ns",
      "items_per_second": 5.0060437369786217e+10,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 2.8000000000000000e+01,
      "input_size": 6.4225280000000000e+06,
      "input_width": 2.8000000000000000e+01,
      "num_iterations": 5.4570000000000000e+03,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 2.8000000000000000e+01,
      "output_size": 6.4225280000000000e+06,
      "output_width": 2.8000000000000000e+01,
      "predicted_flops": 5.0060437369786217e+10,
      "predicted_flops_count": 6.4225280000000000e+06
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__8337023137083059825<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:128/input[1]:64/input[2]:28/input[3]:28/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 5445,
      "real_time": 1.2851543906268802e+05,
      "cpu_time": 1.3392850688735637e+05,
      "time_unit": "ns",
      "items_per_second": 4.9974758261279259e+10,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 2.8000000000000000e+01,
      "input_size": 6.4225280000000000e+06,
      "input_width": 2.8000000000000000e+01,
      "num_iterations": 5.4450000000000000e+03,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 2.8000000000000000e+01,
      "output_size": 6.4225280000000000e+06,
      "output_width": 2.8000000000000000e+01,
      "predicted_flops": 4.9974758261279259e+10,
      "predicted_flops_count": 6.4225280000000000e+06
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__17308865387622888974<CUDNN_ACTIVATION_RELU>/input[0]:1/input[1]:256/input[2]:13/input[3]:13/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 128406,
      "real_time": 6.1061822310121788e+03,
      "cpu_time": 1.1570562372466962e+04,
      "time_unit": "ns",
      "items_per_second": 7.0852782251191397e+09,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 1.3000000000000000e+01,
      "input[3]": 1.3000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 1.3000000000000000e+01,
      "input_size": 4.3264000000000000e+04,
      "input_width": 1.3000000000000000e+01,
      "num_iterations": 1.2840600000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 1.3000000000000000e+01,
      "output_size": 4.3264000000000000e+04,
      "output_width": 1.3000000000000000e+01,
      "predicted_flops": 7.0852782251191397e+09,
      "predicted_flops_count": 4.3264000000000000e+04
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__17308865387622888974<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1/input[1]:256/input[2]:13/input[3]:13/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 112558,
      "real_time": 5.9293065109215995e+03,
      "cpu_time": 1.1326961362157586e+04,
      "time_unit": "ns",
      "items_per_second": 7.2966374600990925e+09,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 1.3000000000000000e+01,
      "input[3]": 1.3000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 1.3000000000000000e+01,
      "input_size": 4.3264000000000000e+04,
      "input_width": 1.3000000000000000e+01,
      "num_iterations": 1.1255800000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 1.3000000000000000e+01,
      "output_size": 4.3264000000000000e+04,
      "output_width": 1.3000000000000000e+01,
      "predicted_flops": 7.2966374600990925e+09,
      "predicted_flops_count": 4.3264000000000000e+04
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__16368529060455175510<CUDNN_ACTIVATION_RELU>/input[0]:128/input[1]:64/input[2]:400/input[3]:400/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 20,
      "real_time": 3.5886003449559212e+07,
      "cpu_time": 5.4341645450006127e+07,
      "time_unit": "ns",
      "items_per_second": 3.6524546452834373e+10,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 4.0000000000000000e+02,
      "input[3]": 4.0000000000000000e+02,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 4.0000000000000000e+02,
      "input_size": 1.3107200000000000e+09,
      "input_width": 4.0000000000000000e+02,
      "num_iterations": 2.0000000000000000e+01,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 4.0000000000000000e+02,
      "output_size": 1.3107200000000000e+09,
      "output_width": 4.0000000000000000e+02,
      "predicted_flops": 3.6524546452834373e+10,
      "predicted_flops_count": 1.3107200000000000e+09
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__16368529060455175510<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:128/input[1]:64/input[2]:400/input[3]:400/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 20,
      "real_time": 3.5849507153034210e+07,
      "cpu_time": 5.4285836499994382e+07,
      "time_unit": "ns",
      "items_per_second": 3.6561729967578201e+10,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 4.0000000000000000e+02,
      "input[3]": 4.0000000000000000e+02,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 4.0000000000000000e+02,
      "input_size": 1.3107200000000000e+09,
      "input_width": 4.0000000000000000e+02,
      "num_iterations": 2.0000000000000000e+01,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 4.0000000000000000e+02,
      "output_size": 1.3107200000000000e+09,
      "output_width": 4.0000000000000000e+02,
      "predicted_flops": 3.6561729967578201e+10,
      "predicted_flops_count": 1.3107200000000000e+09
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__5491702308704442244<CUDNN_ACTIVATION_RELU>/input[0]:1/input[1]:992/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 110166,
      "real_time": 6.2878742519572334e+03,
      "cpu_time": 1.1420860483410652e+04,
      "time_unit": "ns",
      "items_per_second": 3.0921737968834049e+10,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 9.9200000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 9.9200000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 1.9443200000000000e+05,
      "input_width": 1.4000000000000000e+01,
      "num_iterations": 1.1016600000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 9.9200000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 1.9443200000000000e+05,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 3.0921737968834049e+10,
      "predicted_flops_count": 1.9443200000000000e+05
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__5491702308704442244<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1/input[1]:992/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 110864,
      "real_time": 6.3162984797495728e+03,
      "cpu_time": 1.1426268473175660e+04,
      "time_unit": "ns",
      "items_per_second": 3.0782585817209324e+10,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 9.9200000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 9.9200000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 1.9443200000000000e+05,
      "input_width": 1.4000000000000000e+01,
      "num_iterations": 1.1086400000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 9.9200000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 1.9443200000000000e+05,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 3.0782585817209324e+10,
      "predicted_flops_count": 1.9443200000000000e+05
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__14170837469975180193<CUDNN_ACTIVATION_RELU>/input[0]:1/input[1]:832/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 128642,
      "real_time": 5.4947257689557500e+03,
      "cpu_time": 1.0678828516249207e+04,
      "time_unit": "ns",
      "items_per_second": 7.4194785534761620e+09,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 8.3200000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 8.3200000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 4.0768000000000000e+04,
      "input_width": 7.0000000000000000e+00,
      "num_iterations": 1.2864200000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 8.3200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 4.0768000000000000e+04,
      "output_width": 7.0000000000000000e+00,
      "predicted_flops": 7.4194785534761620e+09,
      "predicted_flops_count": 4.0768000000000000e+04
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__14170837469975180193<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1/input[1]:832/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 127630,
      "real_time": 5.5112893250663628e+03,
      "cpu_time": 1.0683708626460566e+04,
      "time_unit": "ns",
      "items_per_second": 7.3971801506735630e+09,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 8.3200000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 8.3200000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 4.0768000000000000e+04,
      "input_width": 7.0000000000000000e+00,
      "num_iterations": 1.2763000000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 8.3200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 4.0768000000000000e+04,
      "output_width": 7.0000000000000000e+00,
      "predicted_flops": 7.3971801506735630e+09,
      "predicted_flops_count": 4.0768000000000000e+04
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__158707808943489313<CUDNN_ACTIVATION_RELU>/input[0]:128/input[1]:256/input[2]:13/input[3]:13/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 6294,
      "real_time": 1.1114248763280084e+05,
      "cpu_time": 1.1648604893544094e+05,
      "time_unit": "ns",
      "items_per_second": 4.9826057684583115e+10,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 1.3000000000000000e+01,
      "input[3]": 1.3000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 1.3000000000000000e+01,
      "input_size": 5.5377920000000000e+06,
      "input_width": 1.3000000000000000e+01,
      "num_iterations": 6.2940000000000000e+03,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 1.3000000000000000e+01,
      "output_size": 5.5377920000000000e+06,
      "output_width": 1.3000000000000000e+01,
      "predicted_flops": 4.9826057684583115e+10,
      "predicted_flops_count": 5.5377920000000000e+06
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__158707808943489313<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:128/input[1]:256/input[2]:13/input[3]:13/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 6280,
      "real_time": 1.1141922548133360e+05,
      "cpu_time": 1.1680043120964689e+05,
      "time_unit": "ns",
      "items_per_second": 4.9702302058523666e+10,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 1.3000000000000000e+01,
      "input[3]": 1.3000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 1.3000000000000000e+01,
      "input_size": 5.5377920000000000e+06,
      "input_width": 1.3000000000000000e+01,
      "num_iterations": 6.2800000000000000e+03,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 1.3000000000000000e+01,
      "output_size": 5.5377920000000000e+06,
      "output_width": 1.3000000000000000e+01,
      "predicted_flops": 4.9702302058523666e+10,
      "predicted_flops_count": 5.5377920000000000e+06
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__14567914788867635507<CUDNN_ACTIVATION_RELU>/input[0]:128/input[1]:192/input[2]:56/input[3]:56/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 421,
      "real_time": 1.6647462573813854e+06,
      "cpu_time": 1.7109842612813788e+06,
      "time_unit": "ns",
      "items_per_second": 4.6295545437194847e+10,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 1.9200000000000000e+02,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 1.9200000000000000e+02,
      "input_height": 5.6000000000000000e+01,
      "input_size": 7.7070336000000000e+07,
      "input_width": 5.6000000000000000e+01,
      "num_iterations": 4.2100000000000000e+02,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 1.9200000000000000e+02,
      "output_height": 5.6000000000000000e+01,
      "output_size": 7.7070336000000000e+07,
      "output_width": 5.6000000000000000e+01,
      "predicted_flops": 4.6295545437194847e+10,
      "predicted_flops_count": 7.7070336000000000e+07
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__14567914788867635507<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:128/input[1]:192/input[2]:56/input[3]:56/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 421,
      "real_time": 1.6624394479603672e+06,
      "cpu_time": 1.7085469382420240e+06,
      "time_unit": "ns",
      "items_per_second": 4.6359785371164604e+10,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 1.9200000000000000e+02,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 1.9200000000000000e+02,
      "input_height": 5.6000000000000000e+01,
      "input_size": 7.7070336000000000e+07,
      "input_width": 5.6000000000000000e+01,
      "num_iterations": 4.2100000000000000e+02,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 1.9200000000000000e+02,
      "output_height": 5.6000000000000000e+01,
      "output_size": 7.7070336000000000e+07,
      "output_width": 5.6000000000000000e+01,
      "predicted_flops": 4.6359785371164604e+10,
      "predicted_flops_count": 7.7070336000000000e+07
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__3460075133082350086<CUDNN_ACTIVATION_RELU>/input[0]:1/input[1]:256/input[2]:6/input[3]:6/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 137602,
      "real_time": 5.0852541928096916e+03,
      "cpu_time": 1.0226963612345959e+04,
      "time_unit": "ns",
      "items_per_second": 1.8122987859743545e+09,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 6.0000000000000000e+00,
      "input[3]": 6.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 6.0000000000000000e+00,
      "input_size": 9.2160000000000000e+03,
      "input_width": 6.0000000000000000e+00,
      "num_iterations": 1.3760200000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 6.0000000000000000e+00,
      "output_size": 9.2160000000000000e+03,
      "output_width": 6.0000000000000000e+00,
      "predicted_flops": 1.8122987859743545e+09,
      "predicted_flops_count": 9.2160000000000000e+03
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__3460075133082350086<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1/input[1]:256/input[2]:6/input[3]:6/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 136813,
      "real_time": 5.0545058383604528e+03,
      "cpu_time": 1.0203853420411524e+04,
      "time_unit": "ns",
      "items_per_second": 1.8233236432445047e+09,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 6.0000000000000000e+00,
      "input[3]": 6.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 6.0000000000000000e+00,
      "input_size": 9.2160000000000000e+03,
      "input_width": 6.0000000000000000e+00,
      "num_iterations": 1.3681300000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 6.0000000000000000e+00,
      "output_size": 9.2160000000000000e+03,
      "output_width": 6.0000000000000000e+00,
      "predicted_flops": 1.8233236432445047e+09,
      "predicted_flops_count": 9.2160000000000000e+03
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__14244930242321980192<CUDNN_ACTIVATION_RELU>/input[0]:1/input[1]:160/input[2]:6/input[3]:6/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 137146,
      "real_time": 5.0862003087721296e+03,
      "cpu_time": 1.0232187777938110e+04,
      "time_unit": "ns",
      "items_per_second": 1.1324760430818608e+09,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 1.6000000000000000e+02,
      "input[2]": 6.0000000000000000e+00,
      "input[3]": 6.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 1.6000000000000000e+02,
      "input_height": 6.0000000000000000e+00,
      "input_size": 5.7600000000000000e+03,
      "input_width": 6.0000000000000000e+00,
      "num_iterations": 1.3714600000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 1.6000000000000000e+02,
      "output_height": 6.0000000000000000e+00,
      "output_size": 5.7600000000000000e+03,
      "output_width": 6.0000000000000000e+00,
      "predicted_flops": 1.1324760430818608e+09,
      "predicted_flops_count": 5.7600000000000000e+03
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__14244930242321980192<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1/input[1]:160/input[2]:6/input[3]:6/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 137567,
      "real_time": 5.6840752917429827e+03,
      "cpu_time": 1.1084072190185383e+04,
      "time_unit": "ns",
      "items_per_second": 1.0133574423912557e+09,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 1.6000000000000000e+02,
      "input[2]": 6.0000000000000000e+00,
      "input[3]": 6.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 1.6000000000000000e+02,
      "input_height": 6.0000000000000000e+00,
      "input_size": 5.7600000000000000e+03,
      "input_width": 6.0000000000000000e+00,
      "num_iterations": 1.3756700000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 1.6000000000000000e+02,
      "output_height": 6.0000000000000000e+00,
      "output_size": 5.7600000000000000e+03,
      "output_width": 6.0000000000000000e+00,
      "predicted_flops": 1.0133574423912557e+09,
      "predicted_flops_count": 5.7600000000000000e+03
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__16783576863349565363<CUDNN_ACTIVATION_RELU>/input[0]:1/input[1]:864/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 112655,
      "real_time": 5.9595257224741199e+03,
      "cpu_time": 1.1331546473743279e+04,
      "time_unit": "ns",
      "items_per_second": 7.1039210117586412e+09,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 8.6400000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 8.6400000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 4.2336000000000000e+04,
      "input_width": 7.0000000000000000e+00,
      "num_iterations": 1.1265500000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 8.6400000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 4.2336000000000000e+04,
      "output_width": 7.0000000000000000e+00,
      "predicted_flops": 7.1039210117586412e+09,
      "predicted_flops_count": 4.2336000000000000e+04
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__16783576863349565363<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1/input[1]:864/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 126622,
      "real_time": 5.4756583849321296e+03,
      "cpu_time": 1.0648568692632085e+04,
      "time_unit": "ns",
      "items_per_second": 7.7316729831977558e+09,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 8.6400000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 8.6400000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 4.2336000000000000e+04,
      "input_width": 7.0000000000000000e+00,
      "num_iterations": 1.2662200000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 8.6400000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 4.2336000000000000e+04,
      "output_width": 7.0000000000000000e+00,
      "predicted_flops": 7.7316729831977558e+09,
      "predicted_flops_count": 4.2336000000000000e+04
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__6116020220632206068<CUDNN_ACTIVATION_RELU>/input[0]:1/input[1]:320/input[2]:6/input[3]:6/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 137072,
      "real_time": 5.0874807658857972e+03,
      "cpu_time": 1.0217398097341103e+04,
      "time_unit": "ns",
      "items_per_second": 2.2643820252348843e+09,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 3.2000000000000000e+02,
      "input[2]": 6.0000000000000000e+00,
      "input[3]": 6.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 3.2000000000000000e+02,
      "input_height": 6.0000000000000000e+00,
      "input_size": 1.1520000000000000e+04,
      "input_width": 6.0000000000000000e+00,
      "num_iterations": 1.3707200000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 3.2000000000000000e+02,
      "output_height": 6.0000000000000000e+00,
      "output_size": 1.1520000000000000e+04,
      "output_width": 6.0000000000000000e+00,
      "predicted_flops": 2.2643820252348843e+09,
      "predicted_flops_count": 1.1520000000000000e+04
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__6116020220632206068<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1/input[1]:320/input[2]:6/input[3]:6/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 136823,
      "real_time": 5.1181810936460724e+03,
      "cpu_time": 1.0270242795470263e+04,
      "time_unit": "ns",
      "items_per_second": 2.2507996081462255e+09,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 3.2000000000000000e+02,
      "input[2]": 6.0000000000000000e+00,
      "input[3]": 6.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 3.2000000000000000e+02,
      "input_height": 6.0000000000000000e+00,
      "input_size": 1.1520000000000000e+04,
      "input_width": 6.0000000000000000e+00,
      "num_iterations": 1.3682300000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 3.2000000000000000e+02,
      "output_height": 6.0000000000000000e+00,
      "output_size": 1.1520000000000000e+04,
      "output_width": 6.0000000000000000e+00,
      "predicted_flops": 2.2507996081462255e+09,
      "predicted_flops_count": 1.1520000000000000e+04
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__16190918981699667463<CUDNN_ACTIVATION_RELU>/input[0]:128/input[1]:128/input[2]:100/input[3]:100/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 182,
      "real_time": 3.8467945497749108e+06,
      "cpu_time": 4.0705198186804405e+06,
      "time_unit": "ns",
      "items_per_second": 4.2591305015129242e+10,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 1.2800000000000000e+02,
      "input[2]": 1.0000000000000000e+02,
      "input[3]": 1.0000000000000000e+02,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 1.2800000000000000e+02,
      "input_height": 1.0000000000000000e+02,
      "input_size": 1.6384000000000000e+08,
      "input_width": 1.0000000000000000e+02,
      "num_iterations": 1.8200000000000000e+02,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 1.0000000000000000e+02,
      "output_size": 1.6384000000000000e+08,
      "output_width": 1.0000000000000000e+02,
      "predicted_flops": 4.2591305015129242e+10,
      "predicted_flops_count": 1.6384000000000000e+08
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__16190918981699667463<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:128/input[1]:128/input[2]:100/input[3]:100/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 182,
      "real_time": 3.8410630345774386e+06,
      "cpu_time": 4.0647378461520541e+06,
      "time_unit": "ns",
      "items_per_second": 4.2654858440255798e+10,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 1.2800000000000000e+02,
      "input[2]": 1.0000000000000000e+02,
      "input[3]": 1.0000000000000000e+02,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 1.2800000000000000e+02,
      "input_height": 1.0000000000000000e+02,
      "input_size": 1.6384000000000000e+08,
      "input_width": 1.0000000000000000e+02,
      "num_iterations": 1.8200000000000000e+02,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 1.0000000000000000e+02,
      "output_size": 1.6384000000000000e+08,
      "output_width": 1.0000000000000000e+02,
      "predicted_flops": 4.2654858440255798e+10,
      "predicted_flops_count": 1.6384000000000000e+08
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__16182859776298916712<CUDNN_ACTIVATION_RELU>/input[0]:1/input[1]:160/input[2]:13/input[3]:13/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 130690,
      "real_time": 5.3171223354181875e+03,
      "cpu_time": 1.0509378299791240e+04,
      "time_unit": "ns",
      "items_per_second": 5.0854575641192808e+09,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 1.6000000000000000e+02,
      "input[2]": 1.3000000000000000e+01,
      "input[3]": 1.3000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 1.6000000000000000e+02,
      "input_height": 1.3000000000000000e+01,
      "input_size": 2.7040000000000000e+04,
      "input_width": 1.3000000000000000e+01,
      "num_iterations": 1.3069000000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 1.6000000000000000e+02,
      "output_height": 1.3000000000000000e+01,
      "output_size": 2.7040000000000000e+04,
      "output_width": 1.3000000000000000e+01,
      "predicted_flops": 5.0854575641192808e+09,
      "predicted_flops_count": 2.7040000000000000e+04
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__16182859776298916712<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1/input[1]:160/input[2]:13/input[3]:13/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 132246,
      "real_time": 5.3017512042751077e+03,
      "cpu_time": 1.0483285241177373e+04,
      "time_unit": "ns",
      "items_per_second": 5.1002016047445021e+09,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 1.6000000000000000e+02,
      "input[2]": 1.3000000000000000e+01,
      "input[3]": 1.3000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 1.6000000000000000e+02,
      "input_height": 1.3000000000000000e+01,
      "input_size": 2.7040000000000000e+04,
      "input_width": 1.3000000000000000e+01,
      "num_iterations": 1.3224600000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 1.6000000000000000e+02,
      "output_height": 1.3000000000000000e+01,
      "output_size": 2.7040000000000000e+04,
      "output_width": 1.3000000000000000e+01,
      "predicted_flops": 5.1002016047445021e+09,
      "predicted_flops_count": 2.7040000000000000e+04
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__17209248717076149071<CUDNN_ACTIVATION_RELU>/input[0]:128/input[1]:160/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 8529,
      "real_time": 8.1989198783048138e+04,
      "cpu_time": 8.7248335678334115e+04,
      "time_unit": "ns",
      "items_per_second": 4.8958644060197113e+10,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 1.6000000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 1.6000000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 4.0140800000000000e+06,
      "input_width": 1.4000000000000000e+01,
      "num_iterations": 8.5290000000000000e+03,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 1.6000000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 4.0140800000000000e+06,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 4.8958644060197113e+10,
      "predicted_flops_count": 4.0140800000000000e+06
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__17209248717076149071<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:128/input[1]:160/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 8523,
      "real_time": 8.2145609434400772e+04,
      "cpu_time": 8.7440831163087394e+04,
      "time_unit": "ns",
      "items_per_second": 4.8865423576965904e+10,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 1.6000000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 1.6000000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 4.0140800000000000e+06,
      "input_width": 1.4000000000000000e+01,
      "num_iterations": 8.5230000000000000e+03,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 1.6000000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 4.0140800000000000e+06,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 4.8865423576965904e+10,
      "predicted_flops_count": 4.0140800000000000e+06
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__6030931145330442278<CUDNN_ACTIVATION_RELU>/input[0]:1/input[1]:768/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 130999,
      "real_time": 5.3402168737456932e+03,
      "cpu_time": 1.0514220024503122e+04,
      "time_unit": "ns",
      "items_per_second": 7.0469048148609104e+09,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 7.6800000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 7.6800000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 3.7632000000000000e+04,
      "input_width": 7.0000000000000000e+00,
      "num_iterations": 1.3099900000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 7.6800000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 3.7632000000000000e+04,
      "output_width": 7.0000000000000000e+00,
      "predicted_flops": 7.0469048148609104e+09,
      "predicted_flops_count": 3.7632000000000000e+04
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__6030931145330442278<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1/input[1]:768/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 130686,
      "real_time": 6.1335488397099989e+03,
      "cpu_time": 1.1663445877928258e+04,
      "time_unit": "ns",
      "items_per_second": 6.1354365936343107e+09,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 7.6800000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 7.6800000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 3.7632000000000000e+04,
      "input_width": 7.0000000000000000e+00,
      "num_iterations": 1.3068600000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 7.6800000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 3.7632000000000000e+04,
      "output_width": 7.0000000000000000e+00,
      "predicted_flops": 6.1354365936343107e+09,
      "predicted_flops_count": 3.7632000000000000e+04
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__16840264435767396395<CUDNN_ACTIVATION_RELU>/input[0]:128/input[1]:96/input[2]:28/input[3]:28/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 3670,
      "real_time": 1.9031084437311528e+05,
      "cpu_time": 1.9628555776676250e+05,
      "time_unit": "ns",
      "items_per_second": 5.0621350726143593e+10,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 9.6000000000000000e+01,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 9.6000000000000000e+01,
      "input_height": 2.8000000000000000e+01,
      "input_size": 9.6337920000000000e+06,
      "input_width": 2.8000000000000000e+01,
      "num_iterations": 3.6700000000000000e+03,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 9.6000000000000000e+01,
      "output_height": 2.8000000000000000e+01,
      "output_size": 9.6337920000000000e+06,
      "output_width": 2.8000000000000000e+01,
      "predicted_flops": 5.0621350726143593e+10,
      "predicted_flops_count": 9.6337920000000000e+06
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__16840264435767396395<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:128/input[1]:96/input[2]:28/input[3]:28/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 3680,
      "real_time": 1.9021823418765765e+05,
      "cpu_time": 1.9592622445543381e+05,
      "time_unit": "ns",
      "items_per_second": 5.0645996379589417e+10,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 9.6000000000000000e+01,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 9.6000000000000000e+01,
      "input_height": 2.8000000000000000e+01,
      "input_size": 9.6337920000000000e+06,
      "input_width": 2.8000000000000000e+01,
      "num_iterations": 3.6800000000000000e+03,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 9.6000000000000000e+01,
      "output_height": 2.8000000000000000e+01,
      "output_size": 9.6337920000000000e+06,
      "output_width": 2.8000000000000000e+01,
      "predicted_flops": 5.0645996379589417e+10,
      "predicted_flops_count": 9.6337920000000000e+06
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__15589547768943294586<CUDNN_ACTIVATION_RELU>/input[0]:128/input[1]:128/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 10486,
      "real_time": 6.6720433648957536e+04,
      "cpu_time": 7.1943798016134897e+04,
      "time_unit": "ns",
      "items_per_second": 4.8130142811956589e+10,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 1.2800000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 1.2800000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 3.2112640000000000e+06,
      "input_width": 1.4000000000000000e+01,
      "num_iterations": 1.0486000000000000e+04,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 3.2112640000000000e+06,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 4.8130142811956589e+10,
      "predicted_flops_count": 3.2112640000000000e+06
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__15589547768943294586<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:128/input[1]:128/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 10470,
      "real_time": 6.6842217719374283e+04,
      "cpu_time": 7.2071955874618652e+04,
      "time_unit": "ns",
      "items_per_second": 4.8042451456083450e+10,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 1.2800000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 1.2800000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 3.2112640000000000e+06,
      "input_width": 1.4000000000000000e+01,
      "num_iterations": 1.0470000000000000e+04,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 3.2112640000000000e+06,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 4.8042451456083450e+10,
      "predicted_flops_count": 3.2112640000000000e+06
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__3554457459958890736<CUDNN_ACTIVATION_RELU>/input[0]:128/input[1]:256/input[2]:100/input[3]:100/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 85,
      "real_time": 8.2202488118234798e+06,
      "cpu_time": 9.2233845882286485e+06,
      "time_unit": "ns",
      "items_per_second": 3.9862540356282898e+10,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 1.0000000000000000e+02,
      "input[3]": 1.0000000000000000e+02,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 1.0000000000000000e+02,
      "input_size": 3.2768000000000000e+08,
      "input_width": 1.0000000000000000e+02,
      "num_iterations": 8.5000000000000000e+01,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 1.0000000000000000e+02,
      "output_size": 3.2768000000000000e+08,
      "output_width": 1.0000000000000000e+02,
      "predicted_flops": 3.9862540356282898e+10,
      "predicted_flops_count": 3.2768000000000000e+08
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__3554457459958890736<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:128/input[1]:256/input[2]:100/input[3]:100/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 86,
      "real_time": 8.2158113418276915e+06,
      "cpu_time": 9.2066895930191427e+06,
      "time_unit": "ns",
      "items_per_second": 3.9884070649448990e+10,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 1.0000000000000000e+02,
      "input[3]": 1.0000000000000000e+02,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 1.0000000000000000e+02,
      "input_size": 3.2768000000000000e+08,
      "input_width": 1.0000000000000000e+02,
      "num_iterations": 8.6000000000000000e+01,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 1.0000000000000000e+02,
      "output_size": 3.2768000000000000e+08,
      "output_width": 1.0000000000000000e+02,
      "predicted_flops": 3.9884070649448990e+10,
      "predicted_flops_count": 3.2768000000000000e+08
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__12714539637107237701<CUDNN_ACTIVATION_RELU>/input[0]:128/input[1]:256/input[2]:8/input[3]:8/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 15444,
      "real_time": 4.5320107732064047e+04,
      "cpu_time": 5.0497444508545246e+04,
      "time_unit": "ns",
      "items_per_second": 4.6274205974939941e+10,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 8.0000000000000000e+00,
      "input[3]": 8.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 8.0000000000000000e+00,
      "input_size": 2.0971520000000000e+06,
      "input_width": 8.0000000000000000e+00,
      "num_iterations": 1.5444000000000000e+04,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 8.0000000000000000e+00,
      "output_size": 2.0971520000000000e+06,
      "output_width": 8.0000000000000000e+00,
      "predicted_flops": 4.6274205974939941e+10,
      "predicted_flops_count": 2.0971520000000000e+06
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__12714539637107237701<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:128/input[1]:256/input[2]:8/input[3]:8/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 15414,
      "real_time": 4.5407865045930499e+04,
      "cpu_time": 5.0585495588144171e+04,
      "time_unit": "ns",
      "items_per_second": 4.6184774331026360e+10,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 8.0000000000000000e+00,
      "input[3]": 8.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 8.0000000000000000e+00,
      "input_size": 2.0971520000000000e+06,
      "input_width": 8.0000000000000000e+00,
      "num_iterations": 1.5414000000000000e+04,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 8.0000000000000000e+00,
      "output_size": 2.0971520000000000e+06,
      "output_width": 8.0000000000000000e+00,
      "predicted_flops": 4.6184774331026360e+10,
      "predicted_flops_count": 2.0971520000000000e+06
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__11346742453623308887<CUDNN_ACTIVATION_RELU>/input[0]:128/input[1]:224/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 6210,
      "real_time": 1.1268638236156288e+05,
      "cpu_time": 1.1803094315677733e+05,
      "time_unit": "ns",
      "items_per_second": 4.9870373706458374e+10,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 2.2400000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 2.2400000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 5.6197120000000000e+06,
      "input_width": 1.4000000000000000e+01,
      "num_iterations": 6.2100000000000000e+03,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 2.2400000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 5.6197120000000000e+06,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 4.9870373706458374e+10,
      "predicted_flops_count": 5.6197120000000000e+06
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__11346742453623308887<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:128/input[1]:224/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 6196,
      "real_time": 1.1293558733583412e+05,
      "cpu_time": 1.1830783683059009e+05,
      "time_unit": "ns",
      "items_per_second": 4.9760329162576393e+10,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 2.2400000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 2.2400000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 5.6197120000000000e+06,
      "input_width": 1.4000000000000000e+01,
      "num_iterations": 6.1960000000000000e+03,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 2.2400000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 5.6197120000000000e+06,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 4.9760329162576393e+10,
      "predicted_flops_count": 5.6197120000000000e+06
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__3740040012013082923<CUDNN_ACTIVATION_RELU>/input[0]:128/input[1]:96/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 13647,
      "real_time": 5.1257791684143813e+04,
      "cpu_time": 5.6448000293722667e+04,
      "time_unit": "ns",
      "items_per_second": 4.6986963754527763e+10,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 9.6000000000000000e+01,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 9.6000000000000000e+01,
      "input_height": 1.4000000000000000e+01,
      "input_size": 2.4084480000000000e+06,
      "input_width": 1.4000000000000000e+01,
      "num_iterations": 1.3647000000000000e+04,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 9.6000000000000000e+01,
      "output_height": 1.4000000000000000e+01,
      "output_size": 2.4084480000000000e+06,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 4.6986963754527763e+10,
      "predicted_flops_count": 2.4084480000000000e+06
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__3740040012013082923<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:128/input[1]:96/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 13627,
      "real_time": 5.1327531210307214e+04,
      "cpu_time": 5.6530476994777848e+04,
      "time_unit": "ns",
      "items_per_second": 4.6923121825823433e+10,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 9.6000000000000000e+01,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 9.6000000000000000e+01,
      "input_height": 1.4000000000000000e+01,
      "input_size": 2.4084480000000000e+06,
      "input_width": 1.4000000000000000e+01,
      "num_iterations": 1.3627000000000000e+04,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 9.6000000000000000e+01,
      "output_height": 1.4000000000000000e+01,
      "output_size": 2.4084480000000000e+06,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 4.6923121825823433e+10,
      "predicted_flops_count": 2.4084480000000000e+06
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__6698331834156115781<CUDNN_ACTIVATION_RELU>/input[0]:128/input[1]:64/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 19505,
      "real_time": 3.5883141042476280e+04,
      "cpu_time": 4.1048816610894435e+04,
      "time_unit": "ns",
      "items_per_second": 4.4746138530608299e+10,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 1.4000000000000000e+01,
      "input_size": 1.6056320000000000e+06,
      "input_width": 1.4000000000000000e+01,
      "num_iterations": 1.9505000000000000e+04,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 1.4000000000000000e+01,
      "output_size": 1.6056320000000000e+06,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 4.4746138530608299e+10,
      "predicted_flops_count": 1.6056320000000000e+06
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__6698331834156115781<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:128/input[1]:64/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 19487,
      "real_time": 3.5911067393716039e+04,
      "cpu_time": 4.1085226817702765e+04,
      "time_unit": "ns",
      "items_per_second": 4.4711341559314499e+10,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 1.4000000000000000e+01,
      "input_size": 1.6056320000000000e+06,
      "input_width": 1.4000000000000000e+01,
      "num_iterations": 1.9487000000000000e+04,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 1.4000000000000000e+01,
      "output_size": 1.6056320000000000e+06,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 4.4711341559314499e+10,
      "predicted_flops_count": 1.6056320000000000e+06
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__10240466360025027105<CUDNN_ACTIVATION_RELU>/input[0]:128/input[1]:352/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 14793,
      "real_time": 4.7322068712526532e+04,
      "cpu_time": 5.2535791455550505e+04,
      "time_unit": "ns",
      "items_per_second": 4.6653581723395638e+10,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 3.5200000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 3.5200000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 2.2077440000000000e+06,
      "input_width": 7.0000000000000000e+00,
      "num_iterations": 1.4793000000000000e+04,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 3.5200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 2.2077440000000000e+06,
      "output_width": 7.0000000000000000e+00,
      "predicted_flops": 4.6653581723395638e+10,
      "predicted_flops_count": 2.2077440000000000e+06
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__10240466360025027105<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:128/input[1]:352/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 14762,
      "real_time": 4.7438831767706091e+04,
      "cpu_time": 5.2633573567046202e+04,
      "time_unit": "ns",
      "items_per_second": 4.6538751434914513e+10,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 3.5200000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 3.5200000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 2.2077440000000000e+06,
      "input_width": 7.0000000000000000e+00,
      "num_iterations": 1.4762000000000000e+04,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 3.5200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 2.2077440000000000e+06,
      "output_width": 7.0000000000000000e+00,
      "predicted_flops": 4.6538751434914513e+10,
      "predicted_flops_count": 2.2077440000000000e+06
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__13390799428213926816<CUDNN_ACTIVATION_RELU>/input[0]:128/input[1]:1024/input[2]:100/input[3]:100/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 20,
      "real_time": 3.5844098962843418e+07,
      "cpu_time": 5.4336737149998270e+07,
      "time_unit": "ns",
      "items_per_second": 3.6567246434586456e+10,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 1.0240000000000000e+03,
      "input[2]": 1.0000000000000000e+02,
      "input[3]": 1.0000000000000000e+02,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 1.0240000000000000e+03,
      "input_height": 1.0000000000000000e+02,
      "input_size": 1.3107200000000000e+09,
      "input_width": 1.0000000000000000e+02,
      "num_iterations": 2.0000000000000000e+01,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 1.0240000000000000e+03,
      "output_height": 1.0000000000000000e+02,
      "output_size": 1.3107200000000000e+09,
      "output_width": 1.0000000000000000e+02,
      "predicted_flops": 3.6567246434586456e+10,
      "predicted_flops_count": 1.3107200000000000e+09
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__13390799428213926816<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:128/input[1]:1024/input[2]:100/input[3]:100/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 20,
      "real_time": 3.5809788852930069e+07,
      "cpu_time": 5.4294988700013384e+07,
      "time_unit": "ns",
      "items_per_second": 3.6602282280498642e+10,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 1.0240000000000000e+03,
      "input[2]": 1.0000000000000000e+02,
      "input[3]": 1.0000000000000000e+02,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 1.0240000000000000e+03,
      "input_height": 1.0000000000000000e+02,
      "input_size": 1.3107200000000000e+09,
      "input_width": 1.0000000000000000e+02,
      "num_iterations": 2.0000000000000000e+01,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 1.0240000000000000e+03,
      "output_height": 1.0000000000000000e+02,
      "output_size": 1.3107200000000000e+09,
      "output_width": 1.0000000000000000e+02,
      "predicted_flops": 3.6602282280498642e+10,
      "predicted_flops_count": 1.3107200000000000e+09
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__5485937294812110399<CUDNN_ACTIVATION_RELU>/input[0]:128/input[1]:160/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 28317,
      "real_time": 2.4313286445748479e+04,
      "cpu_time": 2.9475257795797708e+04,
      "time_unit": "ns",
      "items_per_second": 4.1274551765727234e+10,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 1.6000000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 1.6000000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 1.0035200000000000e+06,
      "input_width": 7.0000000000000000e+00,
      "num_iterations": 2.8317000000000000e+04,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 1.6000000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 1.0035200000000000e+06,
      "output_width": 7.0000000000000000e+00,
      "predicted_flops": 4.1274551765727234e+10,
      "predicted_flops_count": 1.0035200000000000e+06
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__5485937294812110399<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:128/input[1]:160/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 28716,
      "real_time": 2.4372630323245296e+04,
      "cpu_time": 2.9547127942668754e+04,
      "time_unit": "ns",
      "items_per_second": 4.1174054120982452e+10,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 1.6000000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 1.6000000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 1.0035200000000000e+06,
      "input_width": 7.0000000000000000e+00,
      "num_iterations": 2.8716000000000000e+04,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 1.6000000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 1.0035200000000000e+06,
      "output_width": 7.0000000000000000e+00,
      "predicted_flops": 4.1174054120982452e+10,
      "predicted_flops_count": 1.0035200000000000e+06
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__3311159043309202149<CUDNN_ACTIVATION_RELU>/input[0]:128/input[1]:256/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 19506,
      "real_time": 3.5864500864970818e+04,
      "cpu_time": 4.1040597867677046e+04,
      "time_unit": "ns",
      "items_per_second": 4.4769394841020508e+10,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 1.6056320000000000e+06,
      "input_width": 7.0000000000000000e+00,
      "num_iterations": 1.9506000000000000e+04,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 1.6056320000000000e+06,
      "output_width": 7.0000000000000000e+00,
      "predicted_flops": 4.4769394841020508e+10,
      "predicted_flops_count": 1.6056320000000000e+06
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__3311159043309202149<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:128/input[1]:256/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 19487,
      "real_time": 3.5934406888104219e+04,
      "cpu_time": 4.1116990763455549e+04,
      "time_unit": "ns",
      "items_per_second": 4.4682301422137321e+10,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 1.6056320000000000e+06,
      "input_width": 7.0000000000000000e+00,
      "num_iterations": 1.9487000000000000e+04,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 1.6056320000000000e+06,
      "output_width": 7.0000000000000000e+00,
      "predicted_flops": 4.4682301422137321e+10,
      "predicted_flops_count": 1.6056320000000000e+06
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__14409018036447111975<CUDNN_ACTIVATION_RELU>/input[0]:128/input[1]:192/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 7185,
      "real_time": 9.7422223125116812e+04,
      "cpu_time": 1.0271869157965519e+05,
      "time_unit": "ns",
      "items_per_second": 4.9443503191400040e+10,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 1.9200000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 1.9200000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 4.8168960000000000e+06,
      "input_width": 1.4000000000000000e+01,
      "num_iterations": 7.1850000000000000e+03,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 1.9200000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 4.8168960000000000e+06,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 4.9443503191400040e+10,
      "predicted_flops_count": 4.8168960000000000e+06
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__14409018036447111975<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:128/input[1]:192/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 7171,
      "real_time": 9.7647339726141465e+04,
      "cpu_time": 1.0294978106305785e+05,
      "time_unit": "ns",
      "items_per_second": 4.9329515924441040e+10,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 1.9200000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 1.9200000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 4.8168960000000000e+06,
      "input_width": 1.4000000000000000e+01,
      "num_iterations": 7.1710000000000000e+03,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 1.9200000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 4.8168960000000000e+06,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 4.9329515924441040e+10,
      "predicted_flops_count": 4.8168960000000000e+06
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__7982439705678190339<CUDNN_ACTIVATION_RELU>/input[0]:128/input[1]:224/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 21973,
      "real_time": 3.1890774422001494e+04,
      "cpu_time": 3.7050373959439392e+04,
      "time_unit": "ns",
      "items_per_second": 4.4054370753403160e+10,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 2.2400000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 2.2400000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 1.4049280000000000e+06,
      "input_width": 7.0000000000000000e+00,
      "num_iterations": 2.1973000000000000e+04,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 2.2400000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 1.4049280000000000e+06,
      "output_width": 7.0000000000000000e+00,
      "predicted_flops": 4.4054370753403160e+10,
      "predicted_flops_count": 1.4049280000000000e+06
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__7982439705678190339<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:128/input[1]:224/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 21908,
      "real_time": 3.1944817335563053e+04,
      "cpu_time": 3.7134368449744936e+04,
      "time_unit": "ns",
      "items_per_second": 4.3979841400938065e+10,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 2.2400000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 2.2400000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 1.4049280000000000e+06,
      "input_width": 7.0000000000000000e+00,
      "num_iterations": 2.1908000000000000e+04,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 2.2400000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 1.4049280000000000e+06,
      "output_width": 7.0000000000000000e+00,
      "predicted_flops": 4.3979841400938065e+10,
      "predicted_flops_count": 1.4049280000000000e+06
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__16112820294470647347<CUDNN_ACTIVATION_RELU>/input[0]:128/input[1]:192/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 24933,
      "real_time": 2.8078333725210643e+04,
      "cpu_time": 3.3235780972808570e+04,
      "time_unit": "ns",
      "items_per_second": 4.2888015071876068e+10,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 1.9200000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 1.9200000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 1.2042240000000000e+06,
      "input_width": 7.0000000000000000e+00,
      "num_iterations": 2.4933000000000000e+04,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 1.9200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 1.2042240000000000e+06,
      "output_width": 7.0000000000000000e+00,
      "predicted_flops": 4.2888015071876068e+10,
      "predicted_flops_count": 1.2042240000000000e+06
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__16112820294470647347<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:128/input[1]:192/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 24853,
      "real_time": 2.8113285927228604e+04,
      "cpu_time": 3.3294834104812719e+04,
      "time_unit": "ns",
      "items_per_second": 4.2834693999027374e+10,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 1.9200000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 1.9200000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 1.2042240000000000e+06,
      "input_width": 7.0000000000000000e+00,
      "num_iterations": 2.4853000000000000e+04,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 1.9200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 1.2042240000000000e+06,
      "output_width": 7.0000000000000000e+00,
      "predicted_flops": 4.2834693999027374e+10,
      "predicted_flops_count": 1.2042240000000000e+06
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__2469186169906215506<CUDNN_ACTIVATION_RELU>/input[0]:128/input[1]:128/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 34063,
      "real_time": 2.0525225261634314e+04,
      "cpu_time": 2.5669807532965962e+04,
      "time_unit": "ns",
      "items_per_second": 3.9113626757637650e+10,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 1.2800000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 1.2800000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 8.0281600000000000e+05,
      "input_width": 7.0000000000000000e+00,
      "num_iterations": 3.4063000000000000e+04,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 8.0281600000000000e+05,
      "output_width": 7.0000000000000000e+00,
      "predicted_flops": 3.9113626757637650e+10,
      "predicted_flops_count": 8.0281600000000000e+05
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__2469186169906215506<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:128/input[1]:128/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 33962,
      "real_time": 2.0615429365785225e+04,
      "cpu_time": 2.5785130763655263e+04,
      "time_unit": "ns",
      "items_per_second": 3.8942482630626572e+10,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 1.2800000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 1.2800000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 8.0281600000000000e+05,
      "input_width": 7.0000000000000000e+00,
      "num_iterations": 3.3962000000000000e+04,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 8.0281600000000000e+05,
      "output_width": 7.0000000000000000e+00,
      "predicted_flops": 3.8942482630626572e+10,
      "predicted_flops_count": 8.0281600000000000e+05
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__11162441852474213005<CUDNN_ACTIVATION_RELU>/input[0]:1/input[1]:192/input[2]:55/input[3]:55/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 43233,
      "real_time": 1.6212413729558293e+04,
      "cpu_time": 2.1376388175980133e+04,
      "time_unit": "ns",
      "items_per_second": 3.5824400344600868e+10,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 1.9200000000000000e+02,
      "input[2]": 5.5000000000000000e+01,
      "input[3]": 5.5000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 1.9200000000000000e+02,
      "input_height": 5.5000000000000000e+01,
      "input_size": 5.8080000000000000e+05,
      "input_width": 5.5000000000000000e+01,
      "num_iterations": 4.3233000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 1.9200000000000000e+02,
      "output_height": 5.5000000000000000e+01,
      "output_size": 5.8080000000000000e+05,
      "output_width": 5.5000000000000000e+01,
      "predicted_flops": 3.5824400344600868e+10,
      "predicted_flops_count": 5.8080000000000000e+05
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__11162441852474213005<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:1/input[1]:192/input[2]:55/input[3]:55/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 43134,
      "real_time": 1.6202113656992642e+04,
      "cpu_time": 2.1373633908258256e+04,
      "time_unit": "ns",
      "items_per_second": 3.5847174775825226e+10,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 1.9200000000000000e+02,
      "input[2]": 5.5000000000000000e+01,
      "input[3]": 5.5000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 1.9200000000000000e+02,
      "input_height": 5.5000000000000000e+01,
      "input_size": 5.8080000000000000e+05,
      "input_width": 5.5000000000000000e+01,
      "num_iterations": 4.3134000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 1.9200000000000000e+02,
      "output_height": 5.5000000000000000e+01,
      "output_size": 5.8080000000000000e+05,
      "output_width": 5.5000000000000000e+01,
      "predicted_flops": 3.5847174775825226e+10,
      "predicted_flops_count": 5.8080000000000000e+05
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__13811507302503856802<CUDNN_ACTIVATION_RELU>/input[0]:128/input[1]:16/input[2]:416/input[3]:416/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 78,
      "real_time": 8.9341702345663160e+06,
      "cpu_time": 1.0125867358978597e+07,
      "time_unit": "ns",
      "items_per_second": 3.9670017326147835e+10,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 1.6000000000000000e+01,
      "input[2]": 4.1600000000000000e+02,
      "input[3]": 4.1600000000000000e+02,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 1.6000000000000000e+01,
      "input_height": 4.1600000000000000e+02,
      "input_size": 3.5441868800000000e+08,
      "input_width": 4.1600000000000000e+02,
      "num_iterations": 7.8000000000000000e+01,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 1.6000000000000000e+01,
      "output_height": 4.1600000000000000e+02,
      "output_size": 3.5441868800000000e+08,
      "output_width": 4.1600000000000000e+02,
      "predicted_flops": 3.9670017326147835e+10,
      "predicted_flops_count": 3.5441868800000000e+08
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__248974903914619304<CUDNN_ACTIVATION_RELU>/input[0]:128/input[1]:512/input[2]:100/input[3]:100/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 41,
      "real_time": 1.7248746098541632e+07,
      "cpu_time": 2.1600932878050670e+07,
      "time_unit": "ns",
      "items_per_second": 3.7994645886486214e+10,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 1.0000000000000000e+02,
      "input[3]": 1.0000000000000000e+02,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 1.0000000000000000e+02,
      "input_size": 6.5536000000000000e+08,
      "input_width": 1.0000000000000000e+02,
      "num_iterations": 4.1000000000000000e+01,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 1.0000000000000000e+02,
      "output_size": 6.5536000000000000e+08,
      "output_width": 1.0000000000000000e+02,
      "predicted_flops": 3.7994645886486214e+10,
      "predicted_flops_count": 6.5536000000000000e+08
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__248974903914619304<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:128/input[1]:512/input[2]:100/input[3]:100/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 41,
      "real_time": 1.7254075535186905e+07,
      "cpu_time": 2.1596919073167887e+07,
      "time_unit": "ns",
      "items_per_second": 3.7982910105122635e+10,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 1.0000000000000000e+02,
      "input[3]": 1.0000000000000000e+02,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 1.0000000000000000e+02,
      "input_size": 6.5536000000000000e+08,
      "input_width": 1.0000000000000000e+02,
      "num_iterations": 4.1000000000000000e+01,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 1.0000000000000000e+02,
      "output_size": 6.5536000000000000e+08,
      "output_width": 1.0000000000000000e+02,
      "predicted_flops": 3.7982910105122635e+10,
      "predicted_flops_count": 6.5536000000000000e+08
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__6951535212333613489<CUDNN_ACTIVATION_RELU>/input[0]:128/input[1]:24/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 41866,
      "real_time": 1.6670658282641540e+04,
      "cpu_time": 2.1811915038342235e+04,
      "time_unit": "ns",
      "items_per_second": 3.6118069832128586e+10,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 2.4000000000000000e+01,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 2.4000000000000000e+01,
      "input_height": 1.4000000000000000e+01,
      "input_size": 6.0211200000000000e+05,
      "input_width": 1.4000000000000000e+01,
      "num_iterations": 4.1866000000000000e+04,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 2.4000000000000000e+01,
      "output_height": 1.4000000000000000e+01,
      "output_size": 6.0211200000000000e+05,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 3.6118069832128586e+10,
      "predicted_flops_count": 6.0211200000000000e+05
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__6951535212333613489<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:128/input[1]:24/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 41861,
      "real_time": 1.6723060888622829e+04,
      "cpu_time": 2.1900077064489084e+04,
      "time_unit": "ns",
      "items_per_second": 3.6004891927986336e+10,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 2.4000000000000000e+01,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 2.4000000000000000e+01,
      "input_height": 1.4000000000000000e+01,
      "input_size": 6.0211200000000000e+05,
      "input_width": 1.4000000000000000e+01,
      "num_iterations": 4.1861000000000000e+04,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 2.4000000000000000e+01,
      "output_height": 1.4000000000000000e+01,
      "output_size": 6.0211200000000000e+05,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 3.6004891927986336e+10,
      "predicted_flops_count": 6.0211200000000000e+05
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__3553234332425407226<CUDNN_ACTIVATION_RELU>/input[0]:128/input[1]:256/input[2]:16/input[3]:16/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 4218,
      "real_time": 1.6588157348195906e+05,
      "cpu_time": 1.7142961332351266e+05,
      "time_unit": "ns",
      "items_per_second": 5.0569860316114777e+10,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 1.6000000000000000e+01,
      "input[3]": 1.6000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 1.6000000000000000e+01,
      "input_size": 8.3886080000000000e+06,
      "input_width": 1.6000000000000000e+01,
      "num_iterations": 4.2180000000000000e+03,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 1.6000000000000000e+01,
      "output_size": 8.3886080000000000e+06,
      "output_width": 1.6000000000000000e+01,
      "predicted_flops": 5.0569860316114777e+10,
      "predicted_flops_count": 8.3886080000000000e+06
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__3553234332425407226<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:128/input[1]:256/input[2]:16/input[3]:16/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 4213,
      "real_time": 1.6616687712870489e+05,
      "cpu_time": 1.7172985402329327e+05,
      "time_unit": "ns",
      "items_per_second": 5.0483033351481880e+10,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 1.6000000000000000e+01,
      "input[3]": 1.6000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 1.6000000000000000e+01,
      "input_size": 8.3886080000000000e+06,
      "input_width": 1.6000000000000000e+01,
      "num_iterations": 4.2130000000000000e+03,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 1.6000000000000000e+01,
      "output_size": 8.3886080000000000e+06,
      "output_width": 1.6000000000000000e+01,
      "predicted_flops": 5.0483033351481880e+10,
      "predicted_flops_count": 8.3886080000000000e+06
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__905413646176338360<CUDNN_ACTIVATION_RELU>/input[0]:128/input[1]:32/input[2]:28/input[3]:28/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 10486,
      "real_time": 6.6777045522922301e+04,
      "cpu_time": 7.2015891188645444e+04,
      "time_unit": "ns",
      "items_per_second": 4.8089339305939819e+10,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 3.2000000000000000e+01,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 3.2000000000000000e+01,
      "input_height": 2.8000000000000000e+01,
      "input_size": 3.2112640000000000e+06,
      "input_width": 2.8000000000000000e+01,
      "num_iterations": 1.0486000000000000e+04,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 3.2000000000000000e+01,
      "output_height": 2.8000000000000000e+01,
      "output_size": 3.2112640000000000e+06,
      "output_width": 2.8000000000000000e+01,
      "predicted_flops": 4.8089339305939819e+10,
      "predicted_flops_count": 3.2112640000000000e+06
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__905413646176338360<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:128/input[1]:32/input[2]:28/input[3]:28/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 10353,
      "real_time": 6.7587841607778988e+04,
      "cpu_time": 7.3149220323170957e+04,
      "time_unit": "ns",
      "items_per_second": 4.7512450813792534e+10,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 3.2000000000000000e+01,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 3.2000000000000000e+01,
      "input_height": 2.8000000000000000e+01,
      "input_size": 3.2112640000000000e+06,
      "input_width": 2.8000000000000000e+01,
      "num_iterations": 1.0353000000000000e+04,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 3.2000000000000000e+01,
      "output_height": 2.8000000000000000e+01,
      "output_size": 3.2112640000000000e+06,
      "output_width": 2.8000000000000000e+01,
      "predicted_flops": 4.7512450813792534e+10,
      "predicted_flops_count": 3.2112640000000000e+06
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__16209224632504742210<CUDNN_ACTIVATION_RELU>/input[0]:128/input[1]:32/input[2]:208/input[3]:208/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 167,
      "real_time": 4.1896944620205970e+06,
      "cpu_time": 4.4544164011912178e+06,
      "time_unit": "ns",
      "items_per_second": 4.2296483814367661e+10,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 3.2000000000000000e+01,
      "input[2]": 2.0800000000000000e+02,
      "input[3]": 2.0800000000000000e+02,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 3.2000000000000000e+01,
      "input_height": 2.0800000000000000e+02,
      "input_size": 1.7720934400000000e+08,
      "input_width": 2.0800000000000000e+02,
      "num_iterations": 1.6700000000000000e+02,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 3.2000000000000000e+01,
      "output_height": 2.0800000000000000e+02,
      "output_size": 1.7720934400000000e+08,
      "output_width": 2.0800000000000000e+02,
      "predicted_flops": 4.2296483814367661e+10,
      "predicted_flops_count": 1.7720934400000000e+08
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__1604481517759940826<CUDNN_ACTIVATION_RELU>/input[0]:128/input[1]:1024/input[2]:12/input[3]:12/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 1902,
      "real_time": 3.6804016248507134e+05,
      "cpu_time": 3.7517789326915407e+05,
      "time_unit": "ns",
      "items_per_second": 5.1283446547129471e+10,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 1.0240000000000000e+03,
      "input[2]": 1.2000000000000000e+01,
      "input[3]": 1.2000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 1.0240000000000000e+03,
      "input_height": 1.2000000000000000e+01,
      "input_size": 1.8874368000000000e+07,
      "input_width": 1.2000000000000000e+01,
      "num_iterations": 1.9020000000000000e+03,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 1.0240000000000000e+03,
      "output_height": 1.2000000000000000e+01,
      "output_size": 1.8874368000000000e+07,
      "output_width": 1.2000000000000000e+01,
      "predicted_flops": 5.1283446547129471e+10,
      "predicted_flops_count": 1.8874368000000000e+07
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__11404165245588578937<CUDNN_ACTIVATION_RELU>/input[0]:128/input[1]:128/input[2]:52/input[3]:52/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 776,
      "real_time": 9.0227707161042432e+05,
      "cpu_time": 9.1952932603063120e+05,
      "time_unit": "ns",
      "items_per_second": 4.9100589379853371e+10,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 1.2800000000000000e+02,
      "input[2]": 5.2000000000000000e+01,
      "input[3]": 5.2000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 1.2800000000000000e+02,
      "input_height": 5.2000000000000000e+01,
      "input_size": 4.4302336000000000e+07,
      "input_width": 5.2000000000000000e+01,
      "num_iterations": 7.7600000000000000e+02,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 5.2000000000000000e+01,
      "output_size": 4.4302336000000000e+07,
      "output_width": 5.2000000000000000e+01,
      "predicted_flops": 4.9100589379853371e+10,
      "predicted_flops_count": 4.4302336000000000e+07
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__9620316750620623884<CUDNN_ACTIVATION_RELU>/input[0]:128/input[1]:512/input[2]:13/input[3]:13/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 3216,
      "real_time": 2.1761565362998116e+05,
      "cpu_time": 2.2347077829663397e+05,
      "time_unit": "ns",
      "items_per_second": 5.0895162251664894e+10,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 1.3000000000000000e+01,
      "input[3]": 1.3000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 1.3000000000000000e+01,
      "input_size": 1.1075584000000000e+07,
      "input_width": 1.3000000000000000e+01,
      "num_iterations": 3.2160000000000000e+03,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 1.3000000000000000e+01,
      "output_size": 1.1075584000000000e+07,
      "output_width": 1.3000000000000000e+01,
      "predicted_flops": 5.0895162251664894e+10,
      "predicted_flops_count": 1.1075584000000000e+07
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__7523049824865877230<CUDNN_ACTIVATION_RELU>/input[0]:128/input[1]:64/input[2]:104/input[3]:104/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 360,
      "real_time": 1.9446696937342898e+06,
      "cpu_time": 2.0059201000009351e+06,
      "time_unit": "ns",
      "items_per_second": 4.5562838915772453e+10,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 1.0400000000000000e+02,
      "input[3]": 1.0400000000000000e+02,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 1.0400000000000000e+02,
      "input_size": 8.8604672000000000e+07,
      "input_width": 1.0400000000000000e+02,
      "num_iterations": 3.6000000000000000e+02,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 1.0400000000000000e+02,
      "output_size": 8.8604672000000000e+07,
      "output_width": 1.0400000000000000e+02,
      "predicted_flops": 4.5562838915772453e+10,
      "predicted_flops_count": 8.8604672000000000e+07
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__13641513767584415507<CUDNN_ACTIVATION_RELU>/input[0]:128/input[1]:2048/input[2]:100/input[3]:100/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD failed to cudnnSetTensor4dDescriptor",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__13641513767584415507<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:128/input[1]:2048/input[2]:100/input[3]:100/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD failed to cudnnSetTensor4dDescriptor",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__11705896087681706035<CUDNN_ACTIVATION_RELU>/input[0]:128/input[1]:320/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 16116,
      "real_time": 4.3419993027975099e+04,
      "cpu_time": 4.8593334016084766e+04,
      "time_unit": "ns",
      "items_per_second": 4.6223867394609734e+10,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 3.2000000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 3.2000000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 2.0070400000000000e+06,
      "input_width": 7.0000000000000000e+00,
      "num_iterations": 1.6116000000000000e+04,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 3.2000000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 2.0070400000000000e+06,
      "output_width": 7.0000000000000000e+00,
      "predicted_flops": 4.6223867394609734e+10,
      "predicted_flops_count": 2.0070400000000000e+06
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__11705896087681706035<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:128/input[1]:320/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 16085,
      "real_time": 4.3518334816330913e+04,
      "cpu_time": 4.8714664718560656e+04,
      "time_unit": "ns",
      "items_per_second": 4.6119411702463120e+10,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 3.2000000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 3.2000000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 2.0070400000000000e+06,
      "input_width": 7.0000000000000000e+00,
      "num_iterations": 1.6085000000000000e+04,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 3.2000000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 2.0070400000000000e+06,
      "output_width": 7.0000000000000000e+00,
      "predicted_flops": 4.6119411702463120e+10,
      "predicted_flops_count": 2.0070400000000000e+06
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__1481627139142729746<CUDNN_ACTIVATION_RELU>/input[0]:128/input[1]:128/input[2]:56/input[3]:56/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 661,
      "real_time": 1.0593284808068271e+06,
      "cpu_time": 1.0811359515900719e+06,
      "time_unit": "ns",
      "items_per_second": 4.8502636274696167e+10,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 1.2800000000000000e+02,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 1.2800000000000000e+02,
      "input_height": 5.6000000000000000e+01,
      "input_size": 5.1380224000000000e+07,
      "input_width": 5.6000000000000000e+01,
      "num_iterations": 6.6100000000000000e+02,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 5.6000000000000000e+01,
      "output_size": 5.1380224000000000e+07,
      "output_width": 5.6000000000000000e+01,
      "predicted_flops": 4.8502636274696167e+10,
      "predicted_flops_count": 5.1380224000000000e+07
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__1481627139142729746<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:128/input[1]:128/input[2]:56/input[3]:56/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 662,
      "real_time": 1.0590256405276812e+06,
      "cpu_time": 1.0807466299080218e+06,
      "time_unit": "ns",
      "items_per_second": 4.8516506148424088e+10,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 1.2800000000000000e+02,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 1.2800000000000000e+02,
      "input_height": 5.6000000000000000e+01,
      "input_size": 5.1380224000000000e+07,
      "input_width": 5.6000000000000000e+01,
      "num_iterations": 6.6200000000000000e+02,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 5.6000000000000000e+01,
      "output_size": 5.1380224000000000e+07,
      "output_width": 5.6000000000000000e+01,
      "predicted_flops": 4.8516506148424088e+10,
      "predicted_flops_count": 5.1380224000000000e+07
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__8242555014862608825<CUDNN_ACTIVATION_RELU>/input[0]:128/input[1]:256/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 5456,
      "real_time": 1.2829612959678579e+05,
      "cpu_time": 1.3368166037319781e+05,
      "time_unit": "ns",
      "items_per_second": 5.0060185137189865e+10,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 6.4225280000000000e+06,
      "input_width": 1.4000000000000000e+01,
      "num_iterations": 5.4560000000000000e+03,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 6.4225280000000000e+06,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 5.0060185137189865e+10,
      "predicted_flops_count": 6.4225280000000000e+06
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__8242555014862608825<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:128/input[1]:256/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 5445,
      "real_time": 1.2854699246821408e+05,
      "cpu_time": 1.3394869311387927e+05,
      "time_unit": "ns",
      "items_per_second": 4.9962491355743729e+10,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 6.4225280000000000e+06,
      "input_width": 1.4000000000000000e+01,
      "num_iterations": 5.4450000000000000e+03,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 6.4225280000000000e+06,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 4.9962491355743729e+10,
      "predicted_flops_count": 6.4225280000000000e+06
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__6387969106677877641<CUDNN_ACTIVATION_RELU>/input[0]:128/input[1]:1024/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 1389,
      "real_time": 5.0500942340665119e+05,
      "cpu_time": 5.1391996904201125e+05,
      "time_unit": "ns",
      "items_per_second": 5.0870559655504539e+10,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 1.0240000000000000e+03,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 1.0240000000000000e+03,
      "input_height": 1.4000000000000000e+01,
      "input_size": 2.5690112000000000e+07,
      "input_width": 1.4000000000000000e+01,
      "num_iterations": 1.3890000000000000e+03,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 1.0240000000000000e+03,
      "output_height": 1.4000000000000000e+01,
      "output_size": 2.5690112000000000e+07,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 5.0870559655504539e+10,
      "predicted_flops_count": 2.5690112000000000e+07
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__6387969106677877641<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:128/input[1]:1024/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 1386,
      "real_time": 5.0529471164653922e+05,
      "cpu_time": 5.1423952813818865e+05,
      "time_unit": "ns",
      "items_per_second": 5.0841838253732994e+10,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 1.0240000000000000e+03,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 1.0240000000000000e+03,
      "input_height": 1.4000000000000000e+01,
      "input_size": 2.5690112000000000e+07,
      "input_width": 1.4000000000000000e+01,
      "num_iterations": 1.3860000000000000e+03,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 1.0240000000000000e+03,
      "output_height": 1.4000000000000000e+01,
      "output_size": 2.5690112000000000e+07,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 5.0841838253732994e+10,
      "predicted_flops_count": 2.5690112000000000e+07
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__6799485797667927710<CUDNN_ACTIVATION_RELU>/input[0]:128/input[1]:128/input[2]:28/input[3]:28/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 2781,
      "real_time": 2.5168015062842477e+05,
      "cpu_time": 2.5776506400483416e+05,
      "time_unit": "ns",
      "items_per_second": 5.1037223110074211e+10,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 1.2800000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 1.2800000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 1.2845056000000000e+07,
      "input_width": 2.8000000000000000e+01,
      "num_iterations": 2.7810000000000000e+03,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 1.2845056000000000e+07,
      "output_width": 2.8000000000000000e+01,
      "predicted_flops": 5.1037223110074211e+10,
      "predicted_flops_count": 1.2845056000000000e+07
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__6799485797667927710<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:128/input[1]:128/input[2]:28/input[3]:28/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 2779,
      "real_time": 2.5195054471634861e+05,
      "cpu_time": 2.5804127132009802e+05,
      "time_unit": "ns",
      "items_per_second": 5.0982449807605072e+10,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 1.2800000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 1.2800000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 1.2845056000000000e+07,
      "input_width": 2.8000000000000000e+01,
      "num_iterations": 2.7790000000000000e+03,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 1.2845056000000000e+07,
      "output_width": 2.8000000000000000e+01,
      "predicted_flops": 5.0982449807605072e+10,
      "predicted_flops_count": 1.2845056000000000e+07
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__16061700958344977745<CUDNN_ACTIVATION_RELU>/input[0]:128/input[1]:512/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 10485,
      "real_time": 6.6717296264761229e+04,
      "cpu_time": 7.1930489269997910e+04,
      "time_unit": "ns",
      "items_per_second": 4.8132406134331421e+10,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 3.2112640000000000e+06,
      "input_width": 7.0000000000000000e+00,
      "num_iterations": 1.0485000000000000e+04,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 3.2112640000000000e+06,
      "output_width": 7.0000000000000000e+00,
      "predicted_flops": 4.8132406134331421e+10,
      "predicted_flops_count": 3.2112640000000000e+06
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__16061700958344977745<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:128/input[1]:512/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 10425,
      "real_time": 6.6855892107561813e+04,
      "cpu_time": 7.2081982637709501e+04,
      "time_unit": "ns",
      "items_per_second": 4.8032625080127922e+10,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 3.2112640000000000e+06,
      "input_width": 7.0000000000000000e+00,
      "num_iterations": 1.0425000000000000e+04,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 3.2112640000000000e+06,
      "output_width": 7.0000000000000000e+00,
      "predicted_flops": 4.8032625080127922e+10,
      "predicted_flops_count": 3.2112640000000000e+06
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__5319246877271560707<CUDNN_ACTIVATION_RELU>/input[0]:128/input[1]:64/input[2]:224/input[3]:224/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 66,
      "real_time": 1.0502500854658358e+07,
      "cpu_time": 1.2153299090906937e+07,
      "time_unit": "ns",
      "items_per_second": 3.9137515691577728e+10,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 2.2400000000000000e+02,
      "input[3]": 2.2400000000000000e+02,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 2.2400000000000000e+02,
      "input_size": 4.1104179200000000e+08,
      "input_width": 2.2400000000000000e+02,
      "num_iterations": 6.6000000000000000e+01,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 2.2400000000000000e+02,
      "output_size": 4.1104179200000000e+08,
      "output_width": 2.2400000000000000e+02,
      "predicted_flops": 3.9137515691577728e+10,
      "predicted_flops_count": 4.1104179200000000e+08
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__5319246877271560707<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:128/input[1]:64/input[2]:224/input[3]:224/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 67,
      "real_time": 1.0495191912597684e+07,
      "cpu_time": 1.2117565104482148e+07,
      "time_unit": "ns",
      "items_per_second": 3.9164771394662590e+10,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 2.2400000000000000e+02,
      "input[3]": 2.2400000000000000e+02,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 2.2400000000000000e+02,
      "input_size": 4.1104179200000000e+08,
      "input_width": 2.2400000000000000e+02,
      "num_iterations": 6.7000000000000000e+01,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 2.2400000000000000e+02,
      "output_size": 4.1104179200000000e+08,
      "output_width": 2.2400000000000000e+02,
      "predicted_flops": 3.9164771394662590e+10,
      "predicted_flops_count": 4.1104179200000000e+08
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__206422828309295546<CUDNN_ACTIVATION_RELU>/input[0]:128/input[1]:2048/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 2781,
      "real_time": 2.5173020482140986e+05,
      "cpu_time": 2.5782700179846765e+05,
      "time_unit": "ns",
      "items_per_second": 5.1027074836382591e+10,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 2.0480000000000000e+03,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 2.0480000000000000e+03,
      "input_height": 7.0000000000000000e+00,
      "input_size": 1.2845056000000000e+07,
      "input_width": 7.0000000000000000e+00,
      "num_iterations": 2.7810000000000000e+03,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 2.0480000000000000e+03,
      "output_height": 7.0000000000000000e+00,
      "output_size": 1.2845056000000000e+07,
      "output_width": 7.0000000000000000e+00,
      "predicted_flops": 5.1027074836382591e+10,
      "predicted_flops_count": 1.2845056000000000e+07
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__206422828309295546<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:128/input[1]:2048/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 2778,
      "real_time": 2.5195503116713045e+05,
      "cpu_time": 2.5805914507027616e+05,
      "time_unit": "ns",
      "items_per_second": 5.0981541985876968e+10,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 2.0480000000000000e+03,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 2.0480000000000000e+03,
      "input_height": 7.0000000000000000e+00,
      "input_size": 1.2845056000000000e+07,
      "input_width": 7.0000000000000000e+00,
      "num_iterations": 2.7780000000000000e+03,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 2.0480000000000000e+03,
      "output_height": 7.0000000000000000e+00,
      "output_size": 1.2845056000000000e+07,
      "output_width": 7.0000000000000000e+00,
      "predicted_flops": 5.0981541985876968e+10,
      "predicted_flops_count": 1.2845056000000000e+07
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__9583543823496601561<CUDNN_ACTIVATION_RELU>/input[0]:128/input[1]:64/input[2]:112/input[3]:112/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 305,
      "real_time": 2.2914891573982160e+06,
      "cpu_time": 2.3745871606568797e+06,
      "time_unit": "ns",
      "items_per_second": 4.4844396347340973e+10,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 1.1200000000000000e+02,
      "input[3]": 1.1200000000000000e+02,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 1.1200000000000000e+02,
      "input_size": 1.0276044800000000e+08,
      "input_width": 1.1200000000000000e+02,
      "num_iterations": 3.0500000000000000e+02,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 1.1200000000000000e+02,
      "output_size": 1.0276044800000000e+08,
      "output_width": 1.1200000000000000e+02,
      "predicted_flops": 4.4844396347340973e+10,
      "predicted_flops_count": 1.0276044800000000e+08
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__9583543823496601561<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:128/input[1]:64/input[2]:112/input[3]:112/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 306,
      "real_time": 2.2851926787433769e+06,
      "cpu_time": 2.3677779901951011e+06,
      "time_unit": "ns",
      "items_per_second": 4.4967957825117737e+10,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 1.1200000000000000e+02,
      "input[3]": 1.1200000000000000e+02,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 1.1200000000000000e+02,
      "input_size": 1.0276044800000000e+08,
      "input_width": 1.1200000000000000e+02,
      "num_iterations": 3.0600000000000000e+02,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 1.1200000000000000e+02,
      "output_size": 1.0276044800000000e+08,
      "output_width": 1.1200000000000000e+02,
      "predicted_flops": 4.4967957825117737e+10,
      "predicted_flops_count": 1.0276044800000000e+08
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__17023923929730144393<CUDNN_ACTIVATION_RELU>/input[0]:128/input[1]:256/input[2]:28/input[3]:28/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 1386,
      "real_time": 5.0487511231554579e+05,
      "cpu_time": 5.1380391269900562e+05,
      "time_unit": "ns",
      "items_per_second": 5.0884092666353775e+10,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 2.5690112000000000e+07,
      "input_width": 2.8000000000000000e+01,
      "num_iterations": 1.3860000000000000e+03,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 2.5690112000000000e+07,
      "output_width": 2.8000000000000000e+01,
      "predicted_flops": 5.0884092666353775e+10,
      "predicted_flops_count": 2.5690112000000000e+07
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__17023923929730144393<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:128/input[1]:256/input[2]:28/input[3]:28/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 1385,
      "real_time": 5.0543998216786538e+05,
      "cpu_time": 5.1439339711197343e+05,
      "time_unit": "ns",
      "items_per_second": 5.0827225598207359e+10,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 2.5690112000000000e+07,
      "input_width": 2.8000000000000000e+01,
      "num_iterations": 1.3850000000000000e+03,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 2.5690112000000000e+07,
      "output_width": 2.8000000000000000e+01,
      "predicted_flops": 5.0827225598207359e+10,
      "predicted_flops_count": 2.5690112000000000e+07
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__13496529203017699962<CUDNN_ACTIVATION_RELU>/input[0]:128/input[1]:128/input[2]:112/input[3]:112/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 142,
      "real_time": 4.9454134259320479e+06,
      "cpu_time": 5.3107877042244058e+06,
      "time_unit": "ns",
      "items_per_second": 4.1557879655180916e+10,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 1.2800000000000000e+02,
      "input[2]": 1.1200000000000000e+02,
      "input[3]": 1.1200000000000000e+02,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 1.2800000000000000e+02,
      "input_height": 1.1200000000000000e+02,
      "input_size": 2.0552089600000000e+08,
      "input_width": 1.1200000000000000e+02,
      "num_iterations": 1.4200000000000000e+02,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 1.1200000000000000e+02,
      "output_size": 2.0552089600000000e+08,
      "output_width": 1.1200000000000000e+02,
      "predicted_flops": 4.1557879655180916e+10,
      "predicted_flops_count": 2.0552089600000000e+08
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__13496529203017699962<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:128/input[1]:128/input[2]:112/input[3]:112/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 142,
      "real_time": 4.9378249046563264e+06,
      "cpu_time": 5.3027041197176110e+06,
      "time_unit": "ns",
      "items_per_second": 4.1621746410285950e+10,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 1.2800000000000000e+02,
      "input[2]": 1.1200000000000000e+02,
      "input[3]": 1.1200000000000000e+02,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 1.2800000000000000e+02,
      "input_height": 1.1200000000000000e+02,
      "input_size": 2.0552089600000000e+08,
      "input_width": 1.1200000000000000e+02,
      "num_iterations": 1.4200000000000000e+02,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 1.1200000000000000e+02,
      "output_size": 2.0552089600000000e+08,
      "output_width": 1.1200000000000000e+02,
      "predicted_flops": 4.1621746410285950e+10,
      "predicted_flops_count": 2.0552089600000000e+08
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__17872007209646640521<CUDNN_ACTIVATION_RELU>/input[0]:128/input[1]:512/input[2]:28/input[3]:28/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 661,
      "real_time": 1.0594479116553415e+06,
      "cpu_time": 1.0811921694397985e+06,
      "time_unit": "ns",
      "items_per_second": 4.8497168605222527e+10,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 5.1380224000000000e+07,
      "input_width": 2.8000000000000000e+01,
      "num_iterations": 6.6100000000000000e+02,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 5.1380224000000000e+07,
      "output_width": 2.8000000000000000e+01,
      "predicted_flops": 4.8497168605222527e+10,
      "predicted_flops_count": 5.1380224000000000e+07
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__17872007209646640521<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:128/input[1]:512/input[2]:28/input[3]:28/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 661,
      "real_time": 1.0590376247864629e+06,
      "cpu_time": 1.0807988714099526e+06,
      "time_unit": "ns",
      "items_per_second": 4.8515957126981171e+10,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 5.1380224000000000e+07,
      "input_width": 2.8000000000000000e+01,
      "num_iterations": 6.6100000000000000e+02,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 5.1380224000000000e+07,
      "output_width": 2.8000000000000000e+01,
      "predicted_flops": 4.8515957126981171e+10,
      "predicted_flops_count": 5.1380224000000000e+07
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__9242866265924482173<CUDNN_ACTIVATION_RELU>/input[0]:128/input[1]:64/input[2]:56/input[3]:56/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 1385,
      "real_time": 5.0491573808492842e+05,
      "cpu_time": 5.1384605343051982e+05,
      "time_unit": "ns",
      "items_per_second": 5.0879998507154556e+10,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 2.5690112000000000e+07,
      "input_width": 5.6000000000000000e+01,
      "num_iterations": 1.3850000000000000e+03,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 5.6000000000000000e+01,
      "output_size": 2.5690112000000000e+07,
      "output_width": 5.6000000000000000e+01,
      "predicted_flops": 5.0879998507154556e+10,
      "predicted_flops_count": 2.5690112000000000e+07
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__9242866265924482173<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:128/input[1]:64/input[2]:56/input[3]:56/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 1384,
      "real_time": 5.0529612146177993e+05,
      "cpu_time": 5.1422021676230372e+05,
      "time_unit": "ns",
      "items_per_second": 5.0841696401073944e+10,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 2.5690112000000000e+07,
      "input_width": 5.6000000000000000e+01,
      "num_iterations": 1.3840000000000000e+03,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 5.6000000000000000e+01,
      "output_size": 2.5690112000000000e+07,
      "output_width": 5.6000000000000000e+01,
      "predicted_flops": 5.0841696401073944e+10,
      "predicted_flops_count": 2.5690112000000000e+07
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__3352989603140871193<CUDNN_ACTIVATION_RELU>/input[0]:128/input[1]:256/input[2]:56/input[3]:56/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 305,
      "real_time": 2.2903470200349074e+06,
      "cpu_time": 2.3730824229486361e+06,
      "time_unit": "ns",
      "items_per_second": 4.4866759098555214e+10,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 5.6000000000000000e+01,
      "input_size": 1.0276044800000000e+08,
      "input_width": 5.6000000000000000e+01,
      "num_iterations": 3.0500000000000000e+02,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 5.6000000000000000e+01,
      "output_size": 1.0276044800000000e+08,
      "output_width": 5.6000000000000000e+01,
      "predicted_flops": 4.4866759098555214e+10,
      "predicted_flops_count": 1.0276044800000000e+08
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__3352989603140871193<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:128/input[1]:256/input[2]:56/input[3]:56/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 306,
      "real_time": 2.2878279716226887e+06,
      "cpu_time": 2.3703925098022879e+06,
      "time_unit": "ns",
      "items_per_second": 4.4916160338364540e+10,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 5.6000000000000000e+01,
      "input_size": 1.0276044800000000e+08,
      "input_width": 5.6000000000000000e+01,
      "num_iterations": 3.0600000000000000e+02,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 5.6000000000000000e+01,
      "output_size": 1.0276044800000000e+08,
      "output_width": 5.6000000000000000e+01,
      "predicted_flops": 4.4916160338364540e+10,
      "predicted_flops_count": 1.0276044800000000e+08
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__12060485571192749417<CUDNN_ACTIVATION_RELU>/input[0]:128/input[1]:512/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 2781,
      "real_time": 2.5158540450548235e+05,
      "cpu_time": 2.5767167817437940e+05,
      "time_unit": "ns",
      "items_per_second": 5.1056443537526802e+10,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 1.2845056000000000e+07,
      "input_width": 1.4000000000000000e+01,
      "num_iterations": 2.7810000000000000e+03,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 1.2845056000000000e+07,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 5.1056443537526802e+10,
      "predicted_flops_count": 1.2845056000000000e+07
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__12060485571192749417<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:128/input[1]:512/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 2778,
      "real_time": 2.5194930606233352e+05,
      "cpu_time": 2.5804745464595992e+05,
      "time_unit": "ns",
      "items_per_second": 5.0982700451741150e+10,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 1.2845056000000000e+07,
      "input_width": 1.4000000000000000e+01,
      "num_iterations": 2.7780000000000000e+03,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 1.2845056000000000e+07,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 5.0982700451741150e+10,
      "predicted_flops_count": 1.2845056000000000e+07
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__11751377051572972149<CUDNN_ACTIVATION_RELU>/input[0]:128/input[1]:4096/input[2]:-1/input[3]:-1/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 47006,
      "real_time": 1.4910777292841849e+04,
      "cpu_time": 2.0093193698400733e+04,
      "time_unit": "ns",
      "items_per_second": 3.5161681359944443e+10,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 1.0148130340695654e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 4.0960000000000000e+03,
      "input[2]": -1.0000000000000000e+00,
      "input[3]": -1.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 4.0960000000000000e+03,
      "input_height": 1.0000000000000000e+00,
      "input_size": 5.2428800000000000e+05,
      "input_width": 1.0000000000000000e+00,
      "num_iterations": 4.7006000000000000e+04,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 4.0960000000000000e+03,
      "output_height": 1.0000000000000000e+00,
      "output_size": 5.2428800000000000e+05,
      "output_width": 1.0000000000000000e+00,
      "predicted_flops": 3.5161681359944443e+10,
      "predicted_flops_count": 5.2428800000000000e+05
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_FLOAT32__BatchSize_128__11751377051572972149<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:128/input[1]:4096/input[2]:-1/input[3]:-1/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 46811,
      "real_time": 1.4952539451273879e+04,
      "cpu_time": 2.0090128559388144e+04,
      "time_unit": "ns",
      "items_per_second": 3.5063475452347557e+10,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 1.4930345010129449e+19,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = float; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 1.0150096267486517e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 4.0960000000000000e+03,
      "input[2]": -1.0000000000000000e+00,
      "input[3]": -1.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 4.0960000000000000e+03,
      "input_height": 1.0000000000000000e+00,
      "input_size": 5.2428800000000000e+05,
      "input_width": 1.0000000000000000e+00,
      "num_iterations": 4.6811000000000000e+04,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 4.0960000000000000e+03,
      "output_height": 1.0000000000000000e+00,
      "output_size": 5.2428800000000000e+05,
      "output_width": 1.0000000000000000e+00,
      "predicted_flops": 3.5063475452347557e+10,
      "predicted_flops_count": 5.2428800000000000e+05
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_128__14635279133322201344<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:1/input[1]:112/input[2]:28/input[3]:28/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 92253,
      "real_time": 7.6055983837491412e+03,
      "cpu_time": 1.2715644380575963e+04,
      "time_unit": "ns",
      "items_per_second": 1.1545179691267828e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = false]": 1.4627515035010154e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 1.1200000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 1.1200000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 8.7808000000000000e+04,
      "input_width": 2.8000000000000000e+01,
      "is_training": 0.0000000000000000e+00,
      "num_iterations": 9.2253000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 1.1200000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 8.7808000000000000e+04,
      "output_width": 2.8000000000000000e+01,
      "predicted_flops": 1.1545179691267828e+10,
      "predicted_flops_count": 8.7808000000000000e+04
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_128__2608648416314068011<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:1/input[1]:112/input[2]:28/input[3]:28/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 40208,
      "real_time": 1.7422845027637326e+04,
      "cpu_time": 2.2624413325693746e+04,
      "time_unit": "ns",
      "items_per_second": 5.0398198377310286e+09,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = true]": 9.0033003156525926e+18,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 1.1200000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 1.1200000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 8.7808000000000000e+04,
      "input_width": 2.8000000000000000e+01,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 4.0208000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 1.1200000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 8.7808000000000000e+04,
      "output_width": 2.8000000000000000e+01,
      "predicted_flops": 5.0398198377310286e+09,
      "predicted_flops_count": 8.7808000000000000e+04
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_128__12759236022740069797<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:1/input[1]:136/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 112899,
      "real_time": 6.1948691397827342e+03,
      "cpu_time": 1.1686306769645840e+04,
      "time_unit": "ns",
      "items_per_second": 4.3029157514915447e+09,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = false]": 1.4627515035010154e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 1.3600000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 1.3600000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 2.6656000000000000e+04,
      "input_width": 1.4000000000000000e+01,
      "is_training": 0.0000000000000000e+00,
      "num_iterations": 1.1289900000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 1.3600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 2.6656000000000000e+04,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 4.3029157514915447e+09,
      "predicted_flops_count": 2.6656000000000000e+04
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_128__6789416899669682318<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:1/input[1]:136/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 70091,
      "real_time": 9.7310422748838519e+03,
      "cpu_time": 1.5107206360573447e+04,
      "time_unit": "ns",
      "items_per_second": 2.7392749149595242e+09,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = true]": 9.0033003156525926e+18,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 1.3600000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 1.3600000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 2.6656000000000000e+04,
      "input_width": 1.4000000000000000e+01,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 7.0091000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 1.3600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 2.6656000000000000e+04,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 2.7392749149595242e+09,
      "predicted_flops_count": 2.6656000000000000e+04
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_128__249465507809891955<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:128/input[1]:112/input[2]:56/input[3]:56/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 420,
      "real_time": 1.6662955394990388e+06,
      "cpu_time": 1.7115007761931557e+06,
      "time_unit": "ns",
      "items_per_second": 2.6980625545883804e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = false]": 1.4627515035010154e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 1.1200000000000000e+02,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 1.1200000000000000e+02,
      "input_height": 5.6000000000000000e+01,
      "input_size": 4.4957696000000000e+07,
      "input_width": 5.6000000000000000e+01,
      "is_training": 0.0000000000000000e+00,
      "num_iterations": 4.2000000000000000e+02,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 1.1200000000000000e+02,
      "output_height": 5.6000000000000000e+01,
      "output_size": 4.4957696000000000e+07,
      "output_width": 5.6000000000000000e+01,
      "predicted_flops": 2.6980625545883804e+10,
      "predicted_flops_count": 4.4957696000000000e+07
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_128__17032460631051785048<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:128/input[1]:112/input[2]:56/input[3]:56/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 275,
      "real_time": 2.5314563605934381e+06,
      "cpu_time": 2.6288099490896207e+06,
      "time_unit": "ns",
      "items_per_second": 1.7759617230557655e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = true]": 9.0033003156525926e+18,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 1.1200000000000000e+02,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 1.1200000000000000e+02,
      "input_height": 5.6000000000000000e+01,
      "input_size": 4.4957696000000000e+07,
      "input_width": 5.6000000000000000e+01,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 2.7500000000000000e+02,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 1.1200000000000000e+02,
      "output_height": 5.6000000000000000e+01,
      "output_size": 4.4957696000000000e+07,
      "output_width": 5.6000000000000000e+01,
      "predicted_flops": 1.7759617230557655e+10,
      "predicted_flops_count": 4.4957696000000000e+07
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_128__1206941806307629707<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:128/input[1]:24/input[2]:112/input[3]:112/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 488,
      "real_time": 1.4367453860344184e+06,
      "cpu_time": 1.4715274446711449e+06,
      "time_unit": "ns",
      "items_per_second": 2.6821153124675400e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = false]": 1.4627515035010154e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 2.4000000000000000e+01,
      "input[2]": 1.1200000000000000e+02,
      "input[3]": 1.1200000000000000e+02,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 2.4000000000000000e+01,
      "input_height": 1.1200000000000000e+02,
      "input_size": 3.8535168000000000e+07,
      "input_width": 1.1200000000000000e+02,
      "is_training": 0.0000000000000000e+00,
      "num_iterations": 4.8800000000000000e+02,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 2.4000000000000000e+01,
      "output_height": 1.1200000000000000e+02,
      "output_size": 3.8535168000000000e+07,
      "output_width": 1.1200000000000000e+02,
      "predicted_flops": 2.6821153124675400e+10,
      "predicted_flops_count": 3.8535168000000000e+07
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_128__18417145293194305440<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:128/input[1]:24/input[2]:112/input[3]:112/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 321,
      "real_time": 2.1855817082108832e+06,
      "cpu_time": 2.2590265576299545e+06,
      "time_unit": "ns",
      "items_per_second": 1.7631538484802238e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = true]": 9.0033003156525926e+18,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 2.4000000000000000e+01,
      "input[2]": 1.1200000000000000e+02,
      "input[3]": 1.1200000000000000e+02,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 2.4000000000000000e+01,
      "input_height": 1.1200000000000000e+02,
      "input_size": 3.8535168000000000e+07,
      "input_width": 1.1200000000000000e+02,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 3.2100000000000000e+02,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 2.4000000000000000e+01,
      "output_height": 1.1200000000000000e+02,
      "output_size": 3.8535168000000000e+07,
      "output_width": 1.1200000000000000e+02,
      "predicted_flops": 1.7631538484802238e+10,
      "predicted_flops_count": 3.8535168000000000e+07
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_128__1431259546713732813<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:1/input[1]:136/input[2]:28/input[3]:28/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 85375,
      "real_time": 8.2140975956485709e+03,
      "cpu_time": 1.3319672960566324e+04,
      "time_unit": "ns",
      "items_per_second": 1.2980610317618359e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = false]": 1.4627515035010154e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 1.3600000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 1.3600000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 1.0662400000000000e+05,
      "input_width": 2.8000000000000000e+01,
      "is_training": 0.0000000000000000e+00,
      "num_iterations": 8.5375000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 1.3600000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 1.0662400000000000e+05,
      "output_width": 2.8000000000000000e+01,
      "predicted_flops": 1.2980610317618359e+10,
      "predicted_flops_count": 1.0662400000000000e+05
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_128__18227732094930416614<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:1/input[1]:136/input[2]:28/input[3]:28/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 32097,
      "real_time": 2.2081088678296885e+04,
      "cpu_time": 2.7263346730156318e+04,
      "time_unit": "ns",
      "items_per_second": 4.8287474206287146e+09,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = true]": 9.0033003156525926e+18,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 1.3600000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 1.3600000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 1.0662400000000000e+05,
      "input_width": 2.8000000000000000e+01,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 3.2097000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 1.3600000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 1.0662400000000000e+05,
      "output_width": 2.8000000000000000e+01,
      "predicted_flops": 4.8287474206287146e+09,
      "predicted_flops_count": 1.0662400000000000e+05
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_128__2839155807307719424<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:1/input[1]:272/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 109928,
      "real_time": 6.3869491497465751e+03,
      "cpu_time": 1.1529089849987544e+04,
      "time_unit": "ns",
      "items_per_second": 8.3470212068488665e+09,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = false]": 1.4627515035010154e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 2.7200000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 2.7200000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 5.3312000000000000e+04,
      "input_width": 1.4000000000000000e+01,
      "is_training": 0.0000000000000000e+00,
      "num_iterations": 1.0992800000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 2.7200000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 5.3312000000000000e+04,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 8.3470212068488665e+09,
      "predicted_flops_count": 5.3312000000000000e+04
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_128__14433902765975676459<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:1/input[1]:272/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 56312,
      "real_time": 1.2473113283928973e+04,
      "cpu_time": 1.7636486716699859e+04,
      "time_unit": "ns",
      "items_per_second": 4.2741534359901977e+09,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = true]": 9.0033003156525926e+18,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 2.7200000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 2.7200000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 5.3312000000000000e+04,
      "input_width": 1.4000000000000000e+01,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 5.6312000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 2.7200000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 5.3312000000000000e+04,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 4.2741534359901977e+09,
      "predicted_flops_count": 5.3312000000000000e+04
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_128__9587979371344587824<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:1/input[1]:272/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 131623,
      "real_time": 5.2802632809891247e+03,
      "cpu_time": 1.0474350941565359e+04,
      "time_unit": "ns",
      "items_per_second": 2.5241165621391773e+09,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = false]": 1.4627515035010154e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 2.7200000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 2.7200000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 1.3328000000000000e+04,
      "input_width": 7.0000000000000000e+00,
      "is_training": 0.0000000000000000e+00,
      "num_iterations": 1.3162300000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 2.7200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 1.3328000000000000e+04,
      "output_width": 7.0000000000000000e+00,
      "predicted_flops": 2.5241165621391773e+09,
      "predicted_flops_count": 1.3328000000000000e+04
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_128__7648918996176480539<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:1/input[1]:272/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 80167,
      "real_time": 8.7208928270020406e+03,
      "cpu_time": 1.3868931804951604e+04,
      "time_unit": "ns",
      "items_per_second": 1.5282838884034002e+09,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = true]": 9.0033003156525926e+18,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 2.7200000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 2.7200000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 1.3328000000000000e+04,
      "input_width": 7.0000000000000000e+00,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 8.0167000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 2.7200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 1.3328000000000000e+04,
      "output_width": 7.0000000000000000e+00,
      "predicted_flops": 1.5282838884034002e+09,
      "predicted_flops_count": 1.3328000000000000e+04
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_128__8517350207404045870<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:1/input[1]:192/input[2]:28/input[3]:28/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 47687,
      "real_time": 1.4658988908550446e+04,
      "cpu_time": 1.9774518673578819e+04,
      "time_unit": "ns",
      "items_per_second": 1.0268648195251616e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = false]": 1.4627515035010154e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 1.9200000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 1.9200000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 1.5052800000000000e+05,
      "input_width": 2.8000000000000000e+01,
      "is_training": 0.0000000000000000e+00,
      "num_iterations": 4.7687000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 1.9200000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 1.5052800000000000e+05,
      "output_width": 2.8000000000000000e+01,
      "predicted_flops": 1.0268648195251616e+10,
      "predicted_flops_count": 1.5052800000000000e+05
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_128__11032279626896945925<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:1/input[1]:192/input[2]:28/input[3]:28/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 23169,
      "real_time": 3.0021693289991556e+04,
      "cpu_time": 3.5196852691091306e+04,
      "time_unit": "ns",
      "items_per_second": 5.0139743466829062e+09,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = true]": 9.0033003156525926e+18,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 1.9200000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 1.9200000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 1.5052800000000000e+05,
      "input_width": 2.8000000000000000e+01,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 2.3169000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 1.9200000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 1.5052800000000000e+05,
      "output_width": 2.8000000000000000e+01,
      "predicted_flops": 5.0139743466829062e+09,
      "predicted_flops_count": 1.5052800000000000e+05
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_128__17623692984078297832<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:1/input[1]:512/input[2]:28/input[3]:28/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 24301,
      "real_time": 2.8811195969016575e+04,
      "cpu_time": 3.3956432451727109e+04,
      "time_unit": "ns",
      "items_per_second": 1.3932361587199373e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = false]": 1.4627515035010154e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 4.0140800000000000e+05,
      "input_width": 2.8000000000000000e+01,
      "is_training": 0.0000000000000000e+00,
      "num_iterations": 2.4301000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 4.0140800000000000e+05,
      "output_width": 2.8000000000000000e+01,
      "predicted_flops": 1.3932361587199373e+10,
      "predicted_flops_count": 4.0140800000000000e+05
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_128__1998151657196990403<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:1/input[1]:512/input[2]:28/input[3]:28/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 10050,
      "real_time": 6.9618588479974802e+04,
      "cpu_time": 7.4846810844935782e+04,
      "time_unit": "ns",
      "items_per_second": 5.7658164114525480e+09,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = true]": 9.0033003156525926e+18,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 4.0140800000000000e+05,
      "input_width": 2.8000000000000000e+01,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 1.0050000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 4.0140800000000000e+05,
      "output_width": 2.8000000000000000e+01,
      "predicted_flops": 5.7658164114525480e+09,
      "predicted_flops_count": 4.0140800000000000e+05
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_128__572067854669450898<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:1/input[1]:224/input[2]:28/input[3]:28/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 43801,
      "real_time": 1.5978796144375961e+04,
      "cpu_time": 2.1094478436353744e+04,
      "time_unit": "ns",
      "items_per_second": 1.0990565147288107e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = false]": 1.4627515035010154e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 2.2400000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 2.2400000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 1.7561600000000000e+05,
      "input_width": 2.8000000000000000e+01,
      "is_training": 0.0000000000000000e+00,
      "num_iterations": 4.3801000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 2.2400000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 1.7561600000000000e+05,
      "output_width": 2.8000000000000000e+01,
      "predicted_flops": 1.0990565147288107e+10,
      "predicted_flops_count": 1.7561600000000000e+05
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_128__16778538178518469561<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:1/input[1]:224/input[2]:28/input[3]:28/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 20032,
      "real_time": 3.5012162379244459e+04,
      "cpu_time": 4.0211548322812050e+04,
      "time_unit": "ns",
      "items_per_second": 5.0158570069955702e+09,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = true]": 9.0033003156525926e+18,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 2.2400000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 2.2400000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 1.7561600000000000e+05,
      "input_width": 2.8000000000000000e+01,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 2.0032000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 2.2400000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 1.7561600000000000e+05,
      "output_width": 2.8000000000000000e+01,
      "predicted_flops": 5.0158570069955702e+09,
      "predicted_flops_count": 1.7561600000000000e+05
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_128__15084625692151911196<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:1/input[1]:64/input[2]:112/input[3]:112/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 13755,
      "real_time": 5.0907229079460536e+04,
      "cpu_time": 5.6051603271464723e+04,
      "time_unit": "ns",
      "items_per_second": 1.5770176741438694e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = false]": 1.4627515035010154e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 1.1200000000000000e+02,
      "input[3]": 1.1200000000000000e+02,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 1.1200000000000000e+02,
      "input_size": 8.0281600000000000e+05,
      "input_width": 1.1200000000000000e+02,
      "is_training": 0.0000000000000000e+00,
      "num_iterations": 1.3755000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 1.1200000000000000e+02,
      "output_size": 8.0281600000000000e+05,
      "output_width": 1.1200000000000000e+02,
      "predicted_flops": 1.5770176741438694e+10,
      "predicted_flops_count": 8.0281600000000000e+05
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_128__4503151131087623735<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:1/input[1]:64/input[2]:112/input[3]:112/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 5434,
      "real_time": 1.2873325767576555e+05,
      "cpu_time": 1.3415084983431618e+05,
      "time_unit": "ns",
      "items_per_second": 6.2362750270952921e+09,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = true]": 9.0033003156525926e+18,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 1.1200000000000000e+02,
      "input[3]": 1.1200000000000000e+02,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 1.1200000000000000e+02,
      "input_size": 8.0281600000000000e+05,
      "input_width": 1.1200000000000000e+02,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 5.4340000000000000e+03,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 1.1200000000000000e+02,
      "output_size": 8.0281600000000000e+05,
      "output_width": 1.1200000000000000e+02,
      "predicted_flops": 6.2362750270952921e+09,
      "predicted_flops_count": 8.0281600000000000e+05
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_128__4539858465689264992<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:1/input[1]:64/input[2]:56/input[3]:56/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 40174,
      "real_time": 1.7386105416705304e+04,
      "cpu_time": 2.2485127097039760e+04,
      "time_unit": "ns",
      "items_per_second": 1.1543930925850428e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = false]": 1.4627515035010154e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 2.0070400000000000e+05,
      "input_width": 5.6000000000000000e+01,
      "is_training": 0.0000000000000000e+00,
      "num_iterations": 4.0174000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 5.6000000000000000e+01,
      "output_size": 2.0070400000000000e+05,
      "output_width": 5.6000000000000000e+01,
      "predicted_flops": 1.1543930925850428e+10,
      "predicted_flops_count": 2.0070400000000000e+05
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_128__14999768548625557067<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:1/input[1]:64/input[2]:56/input[3]:56/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 17823,
      "real_time": 3.9249047529687145e+04,
      "cpu_time": 4.4460704876414893e+04,
      "time_unit": "ns",
      "items_per_second": 5.1136017975516930e+09,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = true]": 9.0033003156525926e+18,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 2.0070400000000000e+05,
      "input_width": 5.6000000000000000e+01,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 1.7823000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 5.6000000000000000e+01,
      "output_size": 2.0070400000000000e+05,
      "output_width": 5.6000000000000000e+01,
      "predicted_flops": 5.1136017975516930e+09,
      "predicted_flops_count": 2.0070400000000000e+05
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_128__5688711566377727730<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:1/input[1]:96/input[2]:56/input[3]:56/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 30273,
      "real_time": 2.3108581362752888e+04,
      "cpu_time": 2.8232436098384420e+04,
      "time_unit": "ns",
      "items_per_second": 1.3027887574494347e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = false]": 1.4627515035010154e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 9.6000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 9.6000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 3.0105600000000000e+05,
      "input_width": 5.6000000000000000e+01,
      "is_training": 0.0000000000000000e+00,
      "num_iterations": 3.0273000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 9.6000000000000000e+01,
      "output_height": 5.6000000000000000e+01,
      "output_size": 3.0105600000000000e+05,
      "output_width": 5.6000000000000000e+01,
      "predicted_flops": 1.3027887574494347e+10,
      "predicted_flops_count": 3.0105600000000000e+05
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_128__11663036859479225305<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:1/input[1]:96/input[2]:56/input[3]:56/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 12790,
      "real_time": 5.4664959872220767e+04,
      "cpu_time": 5.9894732838844677e+04,
      "time_unit": "ns",
      "items_per_second": 5.5072938991214447e+09,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = true]": 9.0033003156525926e+18,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 9.6000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 9.6000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 3.0105600000000000e+05,
      "input_width": 5.6000000000000000e+01,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 1.2790000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 9.6000000000000000e+01,
      "output_height": 5.6000000000000000e+01,
      "output_size": 3.0105600000000000e+05,
      "output_width": 5.6000000000000000e+01,
      "predicted_flops": 5.5072938991214447e+09,
      "predicted_flops_count": 3.0105600000000000e+05
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_128__16976950614874946274<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:1/input[1]:160/input[2]:56/input[3]:56/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 20522,
      "real_time": 3.4071600982822696e+04,
      "cpu_time": 3.9195636049245928e+04,
      "time_unit": "ns",
      "items_per_second": 1.4726634074312031e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = false]": 1.4627515035010154e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 1.6000000000000000e+02,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 1.6000000000000000e+02,
      "input_height": 5.6000000000000000e+01,
      "input_size": 5.0176000000000000e+05,
      "input_width": 5.6000000000000000e+01,
      "is_training": 0.0000000000000000e+00,
      "num_iterations": 2.0522000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 1.6000000000000000e+02,
      "output_height": 5.6000000000000000e+01,
      "output_size": 5.0176000000000000e+05,
      "output_width": 5.6000000000000000e+01,
      "predicted_flops": 1.4726634074312031e+10,
      "predicted_flops_count": 5.0176000000000000e+05
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_128__338629375898042313<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:1/input[1]:160/input[2]:56/input[3]:56/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 8295,
      "real_time": 8.4342469375196291e+04,
      "cpu_time": 8.9616163953790252e+04,
      "time_unit": "ns",
      "items_per_second": 5.9490788415018740e+09,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = true]": 9.0033003156525926e+18,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 1.6000000000000000e+02,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 1.6000000000000000e+02,
      "input_height": 5.6000000000000000e+01,
      "input_size": 5.0176000000000000e+05,
      "input_width": 5.6000000000000000e+01,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 8.2950000000000000e+03,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 1.6000000000000000e+02,
      "output_height": 5.6000000000000000e+01,
      "output_size": 5.0176000000000000e+05,
      "output_width": 5.6000000000000000e+01,
      "predicted_flops": 5.9490788415018740e+09,
      "predicted_flops_count": 5.0176000000000000e+05
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_128__11981179330518706970<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:1/input[1]:192/input[2]:56/input[3]:56/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 17583,
      "real_time": 3.9793403971936001e+04,
      "cpu_time": 4.4958931240530073e+04,
      "time_unit": "ns",
      "items_per_second": 1.5130949853514290e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = false]": 1.4627515035010154e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 1.9200000000000000e+02,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 1.9200000000000000e+02,
      "input_height": 5.6000000000000000e+01,
      "input_size": 6.0211200000000000e+05,
      "input_width": 5.6000000000000000e+01,
      "is_training": 0.0000000000000000e+00,
      "num_iterations": 1.7583000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 1.9200000000000000e+02,
      "output_height": 5.6000000000000000e+01,
      "output_size": 6.0211200000000000e+05,
      "output_width": 5.6000000000000000e+01,
      "predicted_flops": 1.5130949853514290e+10,
      "predicted_flops_count": 6.0211200000000000e+05
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_128__5290744546806967857<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:1/input[1]:192/input[2]:56/input[3]:56/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 7037,
      "real_time": 9.9537828979068843e+04,
      "cpu_time": 1.0484889540919222e+05,
      "time_unit": "ns",
      "items_per_second": 6.0490770813035736e+09,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = true]": 9.0033003156525926e+18,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 1.9200000000000000e+02,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 1.9200000000000000e+02,
      "input_height": 5.6000000000000000e+01,
      "input_size": 6.0211200000000000e+05,
      "input_width": 5.6000000000000000e+01,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 7.0370000000000000e+03,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 1.9200000000000000e+02,
      "output_height": 5.6000000000000000e+01,
      "output_size": 6.0211200000000000e+05,
      "output_width": 5.6000000000000000e+01,
      "predicted_flops": 6.0490770813035736e+09,
      "predicted_flops_count": 6.0211200000000000e+05
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_128__755123416777754502<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:1/input[1]:224/input[2]:56/input[3]:56/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 15393,
      "real_time": 4.5483431702627633e+04,
      "cpu_time": 5.0680489832955682e+04,
      "time_unit": "ns",
      "items_per_second": 1.5444393127430132e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = false]": 1.4627515035010154e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 2.2400000000000000e+02,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 2.2400000000000000e+02,
      "input_height": 5.6000000000000000e+01,
      "input_size": 7.0246400000000000e+05,
      "input_width": 5.6000000000000000e+01,
      "is_training": 0.0000000000000000e+00,
      "num_iterations": 1.5393000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 2.2400000000000000e+02,
      "output_height": 5.6000000000000000e+01,
      "output_size": 7.0246400000000000e+05,
      "output_width": 5.6000000000000000e+01,
      "predicted_flops": 1.5444393127430132e+10,
      "predicted_flops_count": 7.0246400000000000e+05
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_128__16524709247713034925<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:1/input[1]:224/input[2]:56/input[3]:56/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 6135,
      "real_time": 1.1411864568120529e+05,
      "cpu_time": 1.1948325069207529e+05,
      "time_unit": "ns",
      "items_per_second": 6.1555585049822569e+09,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = true]": 9.0033003156525926e+18,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 2.2400000000000000e+02,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 2.2400000000000000e+02,
      "input_height": 5.6000000000000000e+01,
      "input_size": 7.0246400000000000e+05,
      "input_width": 5.6000000000000000e+01,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 6.1350000000000000e+03,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 2.2400000000000000e+02,
      "output_height": 5.6000000000000000e+01,
      "output_size": 7.0246400000000000e+05,
      "output_width": 5.6000000000000000e+01,
      "predicted_flops": 6.1555585049822569e+09,
      "predicted_flops_count": 7.0246400000000000e+05
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_128__7133708088482491164<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:1/input[1]:256/input[2]:28/input[3]:28/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 40256,
      "real_time": 1.7387086416552727e+04,
      "cpu_time": 2.2480529809455227e+04,
      "time_unit": "ns",
      "items_per_second": 1.1543279603702162e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = false]": 1.4627515035010154e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 2.0070400000000000e+05,
      "input_width": 2.8000000000000000e+01,
      "is_training": 0.0000000000000000e+00,
      "num_iterations": 4.0256000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 2.0070400000000000e+05,
      "output_width": 2.8000000000000000e+01,
      "predicted_flops": 1.1543279603702162e+10,
      "predicted_flops_count": 2.0070400000000000e+05
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_128__10099663599737122359<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:1/input[1]:256/input[2]:28/input[3]:28/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 17825,
      "real_time": 3.9276361867846193e+04,
      "cpu_time": 4.4466946030442967e+04,
      "time_unit": "ns",
      "items_per_second": 5.1100455962625046e+09,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = true]": 9.0033003156525926e+18,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 2.0070400000000000e+05,
      "input_width": 2.8000000000000000e+01,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 1.7825000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 2.0070400000000000e+05,
      "output_width": 2.8000000000000000e+01,
      "predicted_flops": 5.1100455962625046e+09,
      "predicted_flops_count": 2.0070400000000000e+05
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_128__15548626810074999671<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:1/input[1]:128/input[2]:56/input[3]:56/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 24276,
      "real_time": 2.8833650737886557e+04,
      "cpu_time": 3.3988177129906566e+04,
      "time_unit": "ns",
      "items_per_second": 1.3921511488399971e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = false]": 1.4627515035010154e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 1.2800000000000000e+02,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 1.2800000000000000e+02,
      "input_height": 5.6000000000000000e+01,
      "input_size": 4.0140800000000000e+05,
      "input_width": 5.6000000000000000e+01,
      "is_training": 0.0000000000000000e+00,
      "num_iterations": 2.4276000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 5.6000000000000000e+01,
      "output_size": 4.0140800000000000e+05,
      "output_width": 5.6000000000000000e+01,
      "predicted_flops": 1.3921511488399971e+10,
      "predicted_flops_count": 4.0140800000000000e+05
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_128__4102465390292037212<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:1/input[1]:128/input[2]:56/input[3]:56/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 10051,
      "real_time": 6.9648077834879892e+04,
      "cpu_time": 7.4876079692808999e+04,
      "time_unit": "ns",
      "items_per_second": 5.7633751350848351e+09,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = true]": 9.0033003156525926e+18,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 1.2800000000000000e+02,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 1.2800000000000000e+02,
      "input_height": 5.6000000000000000e+01,
      "input_size": 4.0140800000000000e+05,
      "input_width": 5.6000000000000000e+01,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 1.0051000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 5.6000000000000000e+01,
      "output_size": 4.0140800000000000e+05,
      "output_width": 5.6000000000000000e+01,
      "predicted_flops": 5.7633751350848351e+09,
      "predicted_flops_count": 4.0140800000000000e+05
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_128__6929638820680760088<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:1/input[1]:256/input[2]:56/input[3]:56/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 13744,
      "real_time": 5.0954394043578221e+04,
      "cpu_time": 5.6110008876453940e+04,
      "time_unit": "ns",
      "items_per_second": 1.5755579377774561e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = false]": 1.4627515035010154e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 5.6000000000000000e+01,
      "input_size": 8.0281600000000000e+05,
      "input_width": 5.6000000000000000e+01,
      "is_training": 0.0000000000000000e+00,
      "num_iterations": 1.3744000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 5.6000000000000000e+01,
      "output_size": 8.0281600000000000e+05,
      "output_width": 5.6000000000000000e+01,
      "predicted_flops": 1.5755579377774561e+10,
      "predicted_flops_count": 8.0281600000000000e+05
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_128__10304859334353141299<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:1/input[1]:256/input[2]:56/input[3]:56/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 5434,
      "real_time": 1.2876049941808415e+05,
      "cpu_time": 1.3416595767328539e+05,
      "time_unit": "ns",
      "items_per_second": 6.2349556240323658e+09,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = true]": 9.0033003156525926e+18,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 5.6000000000000000e+01,
      "input_size": 8.0281600000000000e+05,
      "input_width": 5.6000000000000000e+01,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 5.4340000000000000e+03,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 5.6000000000000000e+01,
      "output_size": 8.0281600000000000e+05,
      "output_width": 5.6000000000000000e+01,
      "predicted_flops": 6.2349556240323658e+09,
      "predicted_flops_count": 8.0281600000000000e+05
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_128__14813349769926507190<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:1/input[1]:288/input[2]:28/input[3]:28/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 37170,
      "real_time": 1.8803643163309636e+04,
      "cpu_time": 2.3966054156278267e+04,
      "time_unit": "ns",
      "items_per_second": 1.2007885814413544e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = false]": 1.4627515035010154e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 2.8800000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 2.8800000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 2.2579200000000000e+05,
      "input_width": 2.8000000000000000e+01,
      "is_training": 0.0000000000000000e+00,
      "num_iterations": 3.7170000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 2.8800000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 2.2579200000000000e+05,
      "output_width": 2.8000000000000000e+01,
      "predicted_flops": 1.2007885814413544e+10,
      "predicted_flops_count": 2.2579200000000000e+05
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_128__2502492986983006109<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:1/input[1]:288/input[2]:28/input[3]:28/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 16202,
      "real_time": 4.3235007994360836e+04,
      "cpu_time": 4.8427773237993140e+04,
      "time_unit": "ns",
      "items_per_second": 5.2224345611188555e+09,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = true]": 9.0033003156525926e+18,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 2.8800000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 2.8800000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 2.2579200000000000e+05,
      "input_width": 2.8000000000000000e+01,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 1.6202000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 2.8800000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 2.2579200000000000e+05,
      "output_width": 2.8000000000000000e+01,
      "predicted_flops": 5.2224345611188555e+09,
      "predicted_flops_count": 2.2579200000000000e+05
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_128__6305378961443721110<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:1/input[1]:160/input[2]:28/input[3]:28/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 70716,
      "real_time": 9.8747234206966350e+03,
      "cpu_time": 1.4976108546945261e+04,
      "time_unit": "ns",
      "items_per_second": 1.2703140600078756e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = false]": 1.4627515035010154e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 1.6000000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 1.6000000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 1.2544000000000000e+05,
      "input_width": 2.8000000000000000e+01,
      "is_training": 0.0000000000000000e+00,
      "num_iterations": 7.0716000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 1.6000000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 1.2544000000000000e+05,
      "output_width": 2.8000000000000000e+01,
      "predicted_flops": 1.2703140600078756e+10,
      "predicted_flops_count": 1.2544000000000000e+05
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_128__13305893892726540989<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:1/input[1]:160/input[2]:28/input[3]:28/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 28062,
      "real_time": 2.4997517933853349e+04,
      "cpu_time": 3.0146138835345620e+04,
      "time_unit": "ns",
      "items_per_second": 5.0180982100675116e+09,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = true]": 9.0033003156525926e+18,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 1.6000000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 1.6000000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 1.2544000000000000e+05,
      "input_width": 2.8000000000000000e+01,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 2.8062000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 1.6000000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 1.2544000000000000e+05,
      "output_width": 2.8000000000000000e+01,
      "predicted_flops": 5.0180982100675116e+09,
      "predicted_flops_count": 1.2544000000000000e+05
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_128__1409096752283171396<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:1/input[1]:256/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 111627,
      "real_time": 6.3511071972577411e+03,
      "cpu_time": 1.1521914348601542e+04,
      "time_unit": "ns",
      "items_per_second": 7.9003547636016636e+09,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = false]": 1.4627515035010154e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 5.0176000000000000e+04,
      "input_width": 1.4000000000000000e+01,
      "is_training": 0.0000000000000000e+00,
      "num_iterations": 1.1162700000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 5.0176000000000000e+04,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 7.9003547636016636e+09,
      "predicted_flops_count": 5.0176000000000000e+04
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_128__18205569748784971631<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:1/input[1]:256/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 54425,
      "real_time": 1.2344745766219699e+04,
      "cpu_time": 1.7545619494300598e+04,
      "time_unit": "ns",
      "items_per_second": 4.0645632522706275e+09,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = true]": 9.0033003156525926e+18,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 5.0176000000000000e+04,
      "input_width": 1.4000000000000000e+01,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 5.4425000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 5.0176000000000000e+04,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 4.0645632522706275e+09,
      "predicted_flops_count": 5.0176000000000000e+04
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_128__13062329519576575002<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:1/input[1]:288/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 108390,
      "real_time": 6.4373938785089640e+03,
      "cpu_time": 1.1560176483117604e+04,
      "time_unit": "ns",
      "items_per_second": 8.7687659113806705e+09,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = false]": 1.4627515035010154e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 2.8800000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 2.8800000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 5.6448000000000000e+04,
      "input_width": 1.4000000000000000e+01,
      "is_training": 0.0000000000000000e+00,
      "num_iterations": 1.0839000000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 2.8800000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 5.6448000000000000e+04,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 8.7687659113806705e+09,
      "predicted_flops_count": 5.6448000000000000e+04
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_128__6516572599821510961<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:1/input[1]:288/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 55195,
      "real_time": 1.2658884679966777e+04,
      "cpu_time": 1.7799210671707500e+04,
      "time_unit": "ns",
      "items_per_second": 4.4591606154159346e+09,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = true]": 9.0033003156525926e+18,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 2.8800000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 2.8800000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 5.6448000000000000e+04,
      "input_width": 1.4000000000000000e+01,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 5.5195000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 2.8800000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 5.6448000000000000e+04,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 4.4591606154159346e+09,
      "predicted_flops_count": 5.6448000000000000e+04
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_128__65304553759942324<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:1/input[1]:768/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 47615,
      "real_time": 1.4692460519541290e+04,
      "cpu_time": 1.9834029444270727e+04,
      "time_unit": "ns",
      "items_per_second": 1.0245254686905199e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = false]": 1.4627515035010154e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 7.6800000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 7.6800000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 1.5052800000000000e+05,
      "input_width": 1.4000000000000000e+01,
      "is_training": 0.0000000000000000e+00,
      "num_iterations": 4.7615000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 7.6800000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 1.5052800000000000e+05,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 1.0245254686905199e+10,
      "predicted_flops_count": 1.5052800000000000e+05
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_128__17276143625608225695<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:1/input[1]:768/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 23156,
      "real_time": 3.0024681457895724e+04,
      "cpu_time": 3.5182358309011128e+04,
      "time_unit": "ns",
      "items_per_second": 5.0134753373183584e+09,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = true]": 9.0033003156525926e+18,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 7.6800000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 7.6800000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 1.5052800000000000e+05,
      "input_width": 1.4000000000000000e+01,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 2.3156000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 7.6800000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 1.5052800000000000e+05,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 5.0134753373183584e+09,
      "predicted_flops_count": 1.5052800000000000e+05
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_128__6878402469592448704<CUDNN_BATCHNORM_SPATIAL>/input[0]:128/input[1]:32/input[2]:112/input[3]:112/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 713,
      "real_time": 9.8129139013384667e+05,
      "cpu_time": 1.0001881248223482e+06,
      "time_unit": "ns",
      "items_per_second": 5.2359803129416855e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 1.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)1; bool is_training = false]": 7.0429798546002954e+18,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 3.2000000000000000e+01,
      "input[2]": 1.1200000000000000e+02,
      "input[3]": 1.1200000000000000e+02,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 3.2000000000000000e+01,
      "input_height": 1.1200000000000000e+02,
      "input_size": 5.1380224000000000e+07,
      "input_width": 1.1200000000000000e+02,
      "is_training": 0.0000000000000000e+00,
      "num_iterations": 7.1300000000000000e+02,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 3.2000000000000000e+01,
      "output_height": 1.1200000000000000e+02,
      "output_size": 5.1380224000000000e+07,
      "output_width": 1.1200000000000000e+02,
      "predicted_flops": 5.2359803129416855e+10,
      "predicted_flops_count": 5.1380224000000000e+07
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_128__6878402469592448704<CUDNN_BATCHNORM_SPATIAL_PERSISTENT>/input[0]:128/input[1]:32/input[2]:112/input[3]:112/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/BATCHNORM_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_128__16691266168801636191<CUDNN_BATCHNORM_SPATIAL>/input[0]:128/input[1]:32/input[2]:112/input[3]:112/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 428,
      "real_time": 1.6349154477177414e+06,
      "cpu_time": 1.6781693130808244e+06,
      "time_unit": "ns",
      "items_per_second": 3.1426838661121082e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 1.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)1; bool is_training = true]": 1.2389518253260638e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 3.2000000000000000e+01,
      "input[2]": 1.1200000000000000e+02,
      "input[3]": 1.1200000000000000e+02,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 3.2000000000000000e+01,
      "input_height": 1.1200000000000000e+02,
      "input_size": 5.1380224000000000e+07,
      "input_width": 1.1200000000000000e+02,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 4.2800000000000000e+02,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 3.2000000000000000e+01,
      "output_height": 1.1200000000000000e+02,
      "output_size": 5.1380224000000000e+07,
      "output_width": 1.1200000000000000e+02,
      "predicted_flops": 3.1426838661121082e+10,
      "predicted_flops_count": 5.1380224000000000e+07
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_128__16691266168801636191<CUDNN_BATCHNORM_SPATIAL_PERSISTENT>/input[0]:128/input[1]:32/input[2]:112/input[3]:112/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 428,
      "real_time": 1.6346117416309698e+06,
      "cpu_time": 1.6779439556058545e+06,
      "time_unit": "ns",
      "items_per_second": 3.1432677675944168e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 2.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)2; bool is_training = true]": 8.6489340726076344e+18,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 3.2000000000000000e+01,
      "input[2]": 1.1200000000000000e+02,
      "input[3]": 1.1200000000000000e+02,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 3.2000000000000000e+01,
      "input_height": 1.1200000000000000e+02,
      "input_size": 5.1380224000000000e+07,
      "input_width": 1.1200000000000000e+02,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 4.2800000000000000e+02,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 3.2000000000000000e+01,
      "output_height": 1.1200000000000000e+02,
      "output_size": 5.1380224000000000e+07,
      "output_width": 1.1200000000000000e+02,
      "predicted_flops": 3.1432677675944168e+10,
      "predicted_flops_count": 5.1380224000000000e+07
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_128__15482928056355911880<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:1/input[1]:576/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 81348,
      "real_time": 8.5618000619396207e+03,
      "cpu_time": 1.3688243423116037e+04,
      "time_unit": "ns",
      "items_per_second": 1.3186012191742790e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = false]": 1.4627515035010154e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 5.7600000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 5.7600000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 1.1289600000000000e+05,
      "input_width": 1.4000000000000000e+01,
      "is_training": 0.0000000000000000e+00,
      "num_iterations": 8.1348000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 5.7600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 1.1289600000000000e+05,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 1.3186012191742790e+10,
      "predicted_flops_count": 1.1289600000000000e+05
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_128__4176906360909708771<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:1/input[1]:576/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 30522,
      "real_time": 2.2643531132892618e+04,
      "cpu_time": 2.7794055369884423e+04,
      "time_unit": "ns",
      "items_per_second": 4.9857948098918266e+09,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = true]": 9.0033003156525926e+18,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 5.7600000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 5.7600000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 1.1289600000000000e+05,
      "input_width": 1.4000000000000000e+01,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 3.0522000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 5.7600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 1.1289600000000000e+05,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 4.9857948098918266e+09,
      "predicted_flops_count": 1.1289600000000000e+05
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_128__10330511206834743764<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:1/input[1]:352/input[2]:28/input[3]:28/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 32073,
      "real_time": 2.1831721351246517e+04,
      "cpu_time": 2.6937085211735906e+04,
      "time_unit": "ns",
      "items_per_second": 1.2640689002942188e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = false]": 1.4627515035010154e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 3.5200000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 3.5200000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 2.7596800000000000e+05,
      "input_width": 2.8000000000000000e+01,
      "is_training": 0.0000000000000000e+00,
      "num_iterations": 3.2073000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 3.5200000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 2.7596800000000000e+05,
      "output_width": 2.8000000000000000e+01,
      "predicted_flops": 1.2640689002942188e+10,
      "predicted_flops_count": 2.7596800000000000e+05
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_128__6950296711617178879<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:1/input[1]:352/input[2]:28/input[3]:28/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 13819,
      "real_time": 5.0685881770808279e+04,
      "cpu_time": 5.5866400317899795e+04,
      "time_unit": "ns",
      "items_per_second": 5.4446719748878746e+09,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = true]": 9.0033003156525926e+18,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 3.5200000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 3.5200000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 2.7596800000000000e+05,
      "input_width": 2.8000000000000000e+01,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 1.3819000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 3.5200000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 2.7596800000000000e+05,
      "output_width": 2.8000000000000000e+01,
      "predicted_flops": 5.4446719748878746e+09,
      "predicted_flops_count": 2.7596800000000000e+05
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_128__6633600494606252393<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:1/input[1]:608/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 78310,
      "real_time": 8.9286798073126301e+03,
      "cpu_time": 1.4063861946182338e+04,
      "time_unit": "ns",
      "items_per_second": 1.3346653992721392e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = false]": 1.4627515035010154e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 6.0800000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 6.0800000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 1.1916800000000000e+05,
      "input_width": 1.4000000000000000e+01,
      "is_training": 0.0000000000000000e+00,
      "num_iterations": 7.8310000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 6.0800000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 1.1916800000000000e+05,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 1.3346653992721392e+10,
      "predicted_flops_count": 1.1916800000000000e+05
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_128__12909141436180347970<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:1/input[1]:608/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 29252,
      "real_time": 2.3800235344416353e+04,
      "cpu_time": 2.9004168637880768e+04,
      "time_unit": "ns",
      "items_per_second": 5.0070093121141081e+09,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = true]": 9.0033003156525926e+18,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 6.0800000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 6.0800000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 1.1916800000000000e+05,
      "input_width": 1.4000000000000000e+01,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 2.9252000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 6.0800000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 1.1916800000000000e+05,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 5.0070093121141081e+09,
      "predicted_flops_count": 1.1916800000000000e+05
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_128__7166213206480855131<CUDNN_BATCHNORM_SPATIAL>/input[0]:128/input[1]:96/input[2]:112/input[3]:112/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 240,
      "real_time": 2.9224279035891718e+06,
      "cpu_time": 3.0493362666703663e+06,
      "time_unit": "ns",
      "items_per_second": 5.2744046075762062e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 1.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)1; bool is_training = false]": 7.0429798546002954e+18,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 9.6000000000000000e+01,
      "input[2]": 1.1200000000000000e+02,
      "input[3]": 1.1200000000000000e+02,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 9.6000000000000000e+01,
      "input_height": 1.1200000000000000e+02,
      "input_size": 1.5414067200000000e+08,
      "input_width": 1.1200000000000000e+02,
      "is_training": 0.0000000000000000e+00,
      "num_iterations": 2.4000000000000000e+02,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 9.6000000000000000e+01,
      "output_height": 1.1200000000000000e+02,
      "output_size": 1.5414067200000000e+08,
      "output_width": 1.1200000000000000e+02,
      "predicted_flops": 5.2744046075762062e+10,
      "predicted_flops_count": 1.5414067200000000e+08
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_128__7166213206480855131<CUDNN_BATCHNORM_SPATIAL_PERSISTENT>/input[0]:128/input[1]:96/input[2]:112/input[3]:112/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/BATCHNORM_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_128__15826832501605773764<CUDNN_BATCHNORM_SPATIAL>/input[0]:128/input[1]:96/input[2]:112/input[3]:112/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 159,
      "real_time": 4.4166868839576934e+06,
      "cpu_time": 4.6992797484318661e+06,
      "time_unit": "ns",
      "items_per_second": 3.4899615039470047e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 1.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)1; bool is_training = true]": 1.2389518253260638e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 9.6000000000000000e+01,
      "input[2]": 1.1200000000000000e+02,
      "input[3]": 1.1200000000000000e+02,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 9.6000000000000000e+01,
      "input_height": 1.1200000000000000e+02,
      "input_size": 1.5414067200000000e+08,
      "input_width": 1.1200000000000000e+02,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 1.5900000000000000e+02,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 9.6000000000000000e+01,
      "output_height": 1.1200000000000000e+02,
      "output_size": 1.5414067200000000e+08,
      "output_width": 1.1200000000000000e+02,
      "predicted_flops": 3.4899615039470047e+10,
      "predicted_flops_count": 1.5414067200000000e+08
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_128__15826832501605773764<CUDNN_BATCHNORM_SPATIAL_PERSISTENT>/input[0]:128/input[1]:96/input[2]:112/input[3]:112/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 158,
      "real_time": 4.4166480597768780e+06,
      "cpu_time": 4.7013923354397835e+06,
      "time_unit": "ns",
      "items_per_second": 3.4899921821660141e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 2.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)2; bool is_training = true]": 8.6489340726076344e+18,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 9.6000000000000000e+01,
      "input[2]": 1.1200000000000000e+02,
      "input[3]": 1.1200000000000000e+02,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 9.6000000000000000e+01,
      "input_height": 1.1200000000000000e+02,
      "input_size": 1.5414067200000000e+08,
      "input_width": 1.1200000000000000e+02,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 1.5800000000000000e+02,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 9.6000000000000000e+01,
      "output_height": 1.1200000000000000e+02,
      "output_size": 1.5414067200000000e+08,
      "output_width": 1.1200000000000000e+02,
      "predicted_flops": 3.4899921821660141e+10,
      "predicted_flops_count": 1.5414067200000000e+08
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_128__14446341555250806236<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:1/input[1]:352/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 98407,
      "real_time": 7.1299865140359843e+03,
      "cpu_time": 1.2265212220662188e+04,
      "time_unit": "ns",
      "items_per_second": 9.6763156373694935e+09,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = false]": 1.4627515035010154e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 3.5200000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 3.5200000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 6.8992000000000000e+04,
      "input_width": 1.4000000000000000e+01,
      "is_training": 0.0000000000000000e+00,
      "num_iterations": 9.8407000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 3.5200000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 6.8992000000000000e+04,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 9.6763156373694935e+09,
      "predicted_flops_count": 6.8992000000000000e+04
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_128__2833472421772818679<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:1/input[1]:352/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 51965,
      "real_time": 1.3472501362240695e+04,
      "cpu_time": 1.8612082651698573e+04,
      "time_unit": "ns",
      "items_per_second": 5.1209495657104559e+09,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = true]": 9.0033003156525926e+18,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 3.5200000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 3.5200000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 6.8992000000000000e+04,
      "input_width": 1.4000000000000000e+01,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 5.1965000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 3.5200000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 6.8992000000000000e+04,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 5.1209495657104559e+09,
      "predicted_flops_count": 6.8992000000000000e+04
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_128__7377595585551616370<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:1/input[1]:640/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 70593,
      "real_time": 9.9586745809715321e+03,
      "cpu_time": 1.5081297862384670e+04,
      "time_unit": "ns",
      "items_per_second": 1.2596053719807615e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = false]": 1.4627515035010154e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 6.4000000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 6.4000000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 1.2544000000000000e+05,
      "input_width": 1.4000000000000000e+01,
      "is_training": 0.0000000000000000e+00,
      "num_iterations": 7.0593000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 6.4000000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 1.2544000000000000e+05,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 1.2596053719807615e+10,
      "predicted_flops_count": 1.2544000000000000e+05
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_128__9893088029757213785<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:1/input[1]:640/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 27415,
      "real_time": 2.5512455955188339e+04,
      "cpu_time": 3.1002774429695080e+04,
      "time_unit": "ns",
      "items_per_second": 4.9168139758998747e+09,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = true]": 9.0033003156525926e+18,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 6.4000000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 6.4000000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 1.2544000000000000e+05,
      "input_width": 1.4000000000000000e+01,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 2.7415000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 6.4000000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 1.2544000000000000e+05,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 4.9168139758998747e+09,
      "predicted_flops_count": 1.2544000000000000e+05
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_128__17809761402038097230<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:1/input[1]:320/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 94586,
      "real_time": 7.2874697556484070e+03,
      "cpu_time": 1.2643924354433413e+04,
      "time_unit": "ns",
      "items_per_second": 8.6065537289381790e+09,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = false]": 1.4627515035010154e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 3.2000000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 3.2000000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 6.2720000000000000e+04,
      "input_width": 1.4000000000000000e+01,
      "is_training": 0.0000000000000000e+00,
      "num_iterations": 9.4586000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 3.2000000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 6.2720000000000000e+04,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 8.6065537289381790e+09,
      "predicted_flops_count": 6.2720000000000000e+04
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_128__1729884321187352677<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:1/input[1]:320/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 53112,
      "real_time": 1.3260538128845305e+04,
      "cpu_time": 1.8423041986957880e+04,
      "time_unit": "ns",
      "items_per_second": 4.7298231331628094e+09,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = true]": 9.0033003156525926e+18,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 3.2000000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 3.2000000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 6.2720000000000000e+04,
      "input_width": 1.4000000000000000e+01,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 5.3112000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 3.2000000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 6.2720000000000000e+04,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 4.7298231331628094e+09,
      "predicted_flops_count": 6.2720000000000000e+04
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_128__13446777369765777870<CUDNN_BATCHNORM_SPATIAL>/input[0]:128/input[1]:16/input[2]:112/input[3]:112/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 1411,
      "real_time": 4.9616775197728747e+05,
      "cpu_time": 5.0482264138946164e+05,
      "time_unit": "ns",
      "items_per_second": 5.1777069141680107e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 1.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)1; bool is_training = false]": 7.0429798546002954e+18,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 1.6000000000000000e+01,
      "input[2]": 1.1200000000000000e+02,
      "input[3]": 1.1200000000000000e+02,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 1.6000000000000000e+01,
      "input_height": 1.1200000000000000e+02,
      "input_size": 2.5690112000000000e+07,
      "input_width": 1.1200000000000000e+02,
      "is_training": 0.0000000000000000e+00,
      "num_iterations": 1.4110000000000000e+03,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 1.6000000000000000e+01,
      "output_height": 1.1200000000000000e+02,
      "output_size": 2.5690112000000000e+07,
      "output_width": 1.1200000000000000e+02,
      "predicted_flops": 5.1777069141680107e+10,
      "predicted_flops_count": 2.5690112000000000e+07
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_128__13446777369765777870<CUDNN_BATCHNORM_SPATIAL_PERSISTENT>/input[0]:128/input[1]:16/input[2]:112/input[3]:112/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/BATCHNORM_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_128__165287904316620881<CUDNN_BATCHNORM_SPATIAL>/input[0]:128/input[1]:16/input[2]:112/input[3]:112/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 624,
      "real_time": 1.1208016773870883e+06,
      "cpu_time": 1.1439122019223482e+06,
      "time_unit": "ns",
      "items_per_second": 2.2921193390690720e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 1.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)1; bool is_training = true]": 1.2389518253260638e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 1.6000000000000000e+01,
      "input[2]": 1.1200000000000000e+02,
      "input[3]": 1.1200000000000000e+02,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 1.6000000000000000e+01,
      "input_height": 1.1200000000000000e+02,
      "input_size": 2.5690112000000000e+07,
      "input_width": 1.1200000000000000e+02,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 6.2400000000000000e+02,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 1.6000000000000000e+01,
      "output_height": 1.1200000000000000e+02,
      "output_size": 2.5690112000000000e+07,
      "output_width": 1.1200000000000000e+02,
      "predicted_flops": 2.2921193390690720e+10,
      "predicted_flops_count": 2.5690112000000000e+07
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_128__165287904316620881<CUDNN_BATCHNORM_SPATIAL_PERSISTENT>/input[0]:128/input[1]:16/input[2]:112/input[3]:112/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 625,
      "real_time": 1.1207524197176099e+06,
      "cpu_time": 1.1438159984023513e+06,
      "time_unit": "ns",
      "items_per_second": 2.2922200789424129e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 2.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)2; bool is_training = true]": 8.6489340726076344e+18,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 1.6000000000000000e+01,
      "input[2]": 1.1200000000000000e+02,
      "input[3]": 1.1200000000000000e+02,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 1.6000000000000000e+01,
      "input_height": 1.1200000000000000e+02,
      "input_size": 2.5690112000000000e+07,
      "input_width": 1.1200000000000000e+02,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 6.2500000000000000e+02,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 1.6000000000000000e+01,
      "output_height": 1.1200000000000000e+02,
      "output_size": 2.5690112000000000e+07,
      "output_width": 1.1200000000000000e+02,
      "predicted_flops": 2.2922200789424129e+10,
      "predicted_flops_count": 2.5690112000000000e+07
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_128__10276510862693067751<CUDNN_BATCHNORM_SPATIAL>/input[0]:128/input[1]:96/input[2]:56/input[3]:56/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 965,
      "real_time": 7.2511850157752633e+05,
      "cpu_time": 7.3777207875515788e+05,
      "time_unit": "ns",
      "items_per_second": 5.3143269570649612e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 1.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)1; bool is_training = false]": 7.0429798546002954e+18,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 9.6000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 9.6000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 3.8535168000000000e+07,
      "input_width": 5.6000000000000000e+01,
      "is_training": 0.0000000000000000e+00,
      "num_iterations": 9.6500000000000000e+02,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 9.6000000000000000e+01,
      "output_height": 5.6000000000000000e+01,
      "output_size": 3.8535168000000000e+07,
      "output_width": 5.6000000000000000e+01,
      "predicted_flops": 5.3143269570649612e+10,
      "predicted_flops_count": 3.8535168000000000e+07
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_128__10276510862693067751<CUDNN_BATCHNORM_SPATIAL_PERSISTENT>/input[0]:128/input[1]:96/input[2]:56/input[3]:56/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/BATCHNORM_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_128__3911997026276211320<CUDNN_BATCHNORM_SPATIAL>/input[0]:128/input[1]:96/input[2]:56/input[3]:56/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 634,
      "real_time": 1.1038000218728881e+06,
      "cpu_time": 1.1263582965305315e+06,
      "time_unit": "ns",
      "items_per_second": 3.4911367309646286e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 1.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)1; bool is_training = true]": 1.2389518253260638e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 9.6000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 9.6000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 3.8535168000000000e+07,
      "input_width": 5.6000000000000000e+01,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 6.3400000000000000e+02,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 9.6000000000000000e+01,
      "output_height": 5.6000000000000000e+01,
      "output_size": 3.8535168000000000e+07,
      "output_width": 5.6000000000000000e+01,
      "predicted_flops": 3.4911367309646286e+10,
      "predicted_flops_count": 3.8535168000000000e+07
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_128__3911997026276211320<CUDNN_BATCHNORM_SPATIAL_PERSISTENT>/input[0]:128/input[1]:96/input[2]:56/input[3]:56/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 703,
      "real_time": 9.9543610304212500e+05,
      "cpu_time": 1.0147502389765647e+06,
      "time_unit": "ns",
      "items_per_second": 3.8711844871040672e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 2.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)2; bool is_training = true]": 8.6489340726076344e+18,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 9.6000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 9.6000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 3.8535168000000000e+07,
      "input_width": 5.6000000000000000e+01,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 7.0300000000000000e+02,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 9.6000000000000000e+01,
      "output_height": 5.6000000000000000e+01,
      "output_size": 3.8535168000000000e+07,
      "output_width": 5.6000000000000000e+01,
      "predicted_flops": 3.8711844871040672e+10,
      "predicted_flops_count": 3.8535168000000000e+07
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_128__1224786440798679422<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:1/input[1]:384/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 96515,
      "real_time": 7.2374011013598329e+03,
      "cpu_time": 1.2362007636019413e+04,
      "time_unit": "ns",
      "items_per_second": 1.0399313088486788e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = false]": 1.4627515035010154e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 3.8400000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 3.8400000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 7.5264000000000000e+04,
      "input_width": 1.4000000000000000e+01,
      "is_training": 0.0000000000000000e+00,
      "num_iterations": 9.6515000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 3.8400000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 7.5264000000000000e+04,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 1.0399313088486788e+10,
      "predicted_flops_count": 7.5264000000000000e+04
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_128__18435032050711360597<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:1/input[1]:384/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 45292,
      "real_time": 1.5387135229200008e+04,
      "cpu_time": 2.0544480504440500e+04,
      "time_unit": "ns",
      "items_per_second": 4.8913588448337202e+09,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = true]": 9.0033003156525926e+18,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 3.8400000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 3.8400000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 7.5264000000000000e+04,
      "input_width": 1.4000000000000000e+01,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 4.5292000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 3.8400000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 7.5264000000000000e+04,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 4.8913588448337202e+09,
      "predicted_flops_count": 7.5264000000000000e+04
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_128__3418271484845960793<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:1/input[1]:864/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 44308,
      "real_time": 1.5787086419615947e+04,
      "cpu_time": 2.0941508553924639e+04,
      "time_unit": "ns",
      "items_per_second": 1.0726741812826515e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = false]": 1.4627515035010154e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 8.6400000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 8.6400000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 1.6934400000000000e+05,
      "input_width": 1.4000000000000000e+01,
      "is_training": 0.0000000000000000e+00,
      "num_iterations": 4.4308000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 8.6400000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 1.6934400000000000e+05,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 1.0726741812826515e+10,
      "predicted_flops_count": 1.6934400000000000e+05
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_128__13860127966153239410<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:1/input[1]:864/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 21091,
      "real_time": 3.3211899864242601e+04,
      "cpu_time": 3.8383946944553521e+04,
      "time_unit": "ns",
      "items_per_second": 5.0988952963309174e+09,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = true]": 9.0033003156525926e+18,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 8.6400000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 8.6400000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 1.6934400000000000e+05,
      "input_width": 1.4000000000000000e+01,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 2.1091000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 8.6400000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 1.6934400000000000e+05,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 5.0988952963309174e+09,
      "predicted_flops_count": 1.6934400000000000e+05
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_128__15669433027751393051<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:1/input[1]:672/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 63316,
      "real_time": 1.1070609117764099e+04,
      "cpu_time": 1.6185670715115737e+04,
      "time_unit": "ns",
      "items_per_second": 1.1897448333592823e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = false]": 1.4627515035010154e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 6.7200000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 6.7200000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 1.3171200000000000e+05,
      "input_width": 1.4000000000000000e+01,
      "is_training": 0.0000000000000000e+00,
      "num_iterations": 6.3316000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 6.7200000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 1.3171200000000000e+05,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 1.1897448333592823e+10,
      "predicted_flops_count": 1.3171200000000000e+05
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_128__3917060119975129648<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:1/input[1]:672/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 27044,
      "real_time": 2.5870594676799206e+04,
      "cpu_time": 3.1072013607511322e+04,
      "time_unit": "ns",
      "items_per_second": 5.0911856354859724e+09,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = true]": 9.0033003156525926e+18,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 6.7200000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 6.7200000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 1.3171200000000000e+05,
      "input_width": 1.4000000000000000e+01,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 2.7044000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 6.7200000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 1.3171200000000000e+05,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 5.0911856354859724e+09,
      "predicted_flops_count": 1.3171200000000000e+05
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_128__9799513258356179318<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:1/input[1]:384/input[2]:28/input[3]:28/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 30308,
      "real_time": 2.3080441446192650e+04,
      "cpu_time": 2.8198912498377853e+04,
      "time_unit": "ns",
      "items_per_second": 1.3043771311820477e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = false]": 1.4627515035010154e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 3.8400000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 3.8400000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 3.0105600000000000e+05,
      "input_width": 2.8000000000000000e+01,
      "is_training": 0.0000000000000000e+00,
      "num_iterations": 3.0308000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 3.8400000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 3.0105600000000000e+05,
      "output_width": 2.8000000000000000e+01,
      "predicted_flops": 1.3043771311820477e+10,
      "predicted_flops_count": 3.0105600000000000e+05
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_128__7554768987635008605<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:1/input[1]:384/input[2]:28/input[3]:28/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 12791,
      "real_time": 5.4679566939972116e+04,
      "cpu_time": 5.9871720350294374e+04,
      "time_unit": "ns",
      "items_per_second": 5.5058226838281822e+09,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = true]": 9.0033003156525926e+18,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 3.8400000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 3.8400000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 3.0105600000000000e+05,
      "input_width": 2.8000000000000000e+01,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 1.2791000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 3.8400000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 3.0105600000000000e+05,
      "output_width": 2.8000000000000000e+01,
      "predicted_flops": 5.5058226838281822e+09,
      "predicted_flops_count": 3.0105600000000000e+05
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_128__11235266512668642963<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:1/input[1]:832/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 45402,
      "real_time": 1.5379358121609859e+04,
      "cpu_time": 2.0492375974512408e+04,
      "time_unit": "ns",
      "items_per_second": 1.0603303383049784e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = false]": 1.4627515035010154e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 8.3200000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 8.3200000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 1.6307200000000000e+05,
      "input_width": 1.4000000000000000e+01,
      "is_training": 0.0000000000000000e+00,
      "num_iterations": 4.5402000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 8.3200000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 1.6307200000000000e+05,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 1.0603303383049784e+10,
      "predicted_flops_count": 1.6307200000000000e+05
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_128__8413458993106029496<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:1/input[1]:832/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 21601,
      "real_time": 3.2268124716314793e+04,
      "cpu_time": 3.7458786398686643e+04,
      "time_unit": "ns",
      "items_per_second": 5.0536559354981871e+09,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = true]": 9.0033003156525926e+18,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 8.3200000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 8.3200000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 1.6307200000000000e+05,
      "input_width": 1.4000000000000000e+01,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 2.1601000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 8.3200000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 1.6307200000000000e+05,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 5.0536559354981871e+09,
      "predicted_flops_count": 1.6307200000000000e+05
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_128__8817918391201856227<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:1/input[1]:704/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 57256,
      "real_time": 1.2239197501629838e+04,
      "cpu_time": 1.7358881270026872e+04,
      "time_unit": "ns",
      "items_per_second": 1.1273941774501579e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = false]": 1.4627515035010154e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 7.0400000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 7.0400000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 1.3798400000000000e+05,
      "input_width": 1.4000000000000000e+01,
      "is_training": 0.0000000000000000e+00,
      "num_iterations": 5.7256000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 7.0400000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 1.3798400000000000e+05,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 1.1273941774501579e+10,
      "predicted_flops_count": 1.3798400000000000e+05
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_128__10769999190985162696<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:1/input[1]:704/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 26301,
      "real_time": 2.6668427263855450e+04,
      "cpu_time": 3.1827667350796899e+04,
      "time_unit": "ns",
      "items_per_second": 5.1740583962749844e+09,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = true]": 9.0033003156525926e+18,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 7.0400000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 7.0400000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 1.3798400000000000e+05,
      "input_width": 1.4000000000000000e+01,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 2.6301000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 7.0400000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 1.3798400000000000e+05,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 5.1740583962749844e+09,
      "predicted_flops_count": 1.3798400000000000e+05
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_128__15288471399323613850<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:1/input[1]:416/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 94844,
      "real_time": 7.3682436778137608e+03,
      "cpu_time": 1.2477999093407845e+04,
      "time_unit": "ns",
      "items_per_second": 1.1065866380818806e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = false]": 1.4627515035010154e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 4.1600000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 4.1600000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 8.1536000000000000e+04,
      "input_width": 1.4000000000000000e+01,
      "is_training": 0.0000000000000000e+00,
      "num_iterations": 9.4844000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 4.1600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 8.1536000000000000e+04,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 1.1065866380818806e+10,
      "predicted_flops_count": 8.1536000000000000e+04
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_128__4252168260955766705<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:1/input[1]:416/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 42660,
      "real_time": 1.6397108001109347e+04,
      "cpu_time": 2.1550362658119993e+04,
      "time_unit": "ns",
      "items_per_second": 4.9725841895097399e+09,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = true]": 9.0033003156525926e+18,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 4.1600000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 4.1600000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 8.1536000000000000e+04,
      "input_width": 1.4000000000000000e+01,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 4.2660000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 4.1600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 8.1536000000000000e+04,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 4.9725841895097399e+09,
      "predicted_flops_count": 8.1536000000000000e+04
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_128__4276539337276957636<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:1/input[1]:736/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 50832,
      "real_time": 1.3782560398515625e+04,
      "cpu_time": 1.8925494000147504e+04,
      "time_unit": "ns",
      "items_per_second": 1.0466560336317213e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = false]": 1.4627515035010154e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 7.3600000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 7.3600000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 1.4425600000000000e+05,
      "input_width": 1.4000000000000000e+01,
      "is_training": 0.0000000000000000e+00,
      "num_iterations": 5.0832000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 7.3600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 1.4425600000000000e+05,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 1.0466560336317213e+10,
      "predicted_flops_count": 1.4425600000000000e+05
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_128__15307843864798357231<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:1/input[1]:736/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 24007,
      "real_time": 2.8642399664539655e+04,
      "cpu_time": 3.3833272795328288e+04,
      "time_unit": "ns",
      "items_per_second": 5.0364495185294914e+09,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = true]": 9.0033003156525926e+18,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 7.3600000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 7.3600000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 1.4425600000000000e+05,
      "input_width": 1.4000000000000000e+01,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 2.4007000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 7.3600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 1.4425600000000000e+05,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 5.0364495185294914e+09,
      "predicted_flops_count": 1.4425600000000000e+05
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_128__17268586585507208266<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:1/input[1]:416/input[2]:28/input[3]:28/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 28531,
      "real_time": 2.4545229391413191e+04,
      "cpu_time": 2.9724323507900950e+04,
      "time_unit": "ns",
      "items_per_second": 1.3287470033345745e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = false]": 1.4627515035010154e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 4.1600000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 4.1600000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 3.2614400000000000e+05,
      "input_width": 2.8000000000000000e+01,
      "is_training": 0.0000000000000000e+00,
      "num_iterations": 2.8531000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 4.1600000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 3.2614400000000000e+05,
      "output_width": 2.8000000000000000e+01,
      "predicted_flops": 1.3287470033345745e+10,
      "predicted_flops_count": 3.2614400000000000e+05
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_128__40368830570682721<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:1/input[1]:416/input[2]:28/input[3]:28/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 11861,
      "real_time": 5.8998887235339760e+04,
      "cpu_time": 6.4221946800091748e+04,
      "time_unit": "ns",
      "items_per_second": 5.5279686665792389e+09,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = true]": 9.0033003156525926e+18,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 4.1600000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 4.1600000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 3.2614400000000000e+05,
      "input_width": 2.8000000000000000e+01,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 1.1861000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 4.1600000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 3.2614400000000000e+05,
      "output_width": 2.8000000000000000e+01,
      "predicted_flops": 5.5279686665792389e+09,
      "predicted_flops_count": 3.2614400000000000e+05
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_128__2066729369142305911<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:1/input[1]:896/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 43782,
      "real_time": 1.6005156863509372e+04,
      "cpu_time": 2.1118594307920743e+04,
      "time_unit": "ns",
      "items_per_second": 1.0972463531450420e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = false]": 1.4627515035010154e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 8.9600000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 8.9600000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 1.7561600000000000e+05,
      "input_width": 1.4000000000000000e+01,
      "is_training": 0.0000000000000000e+00,
      "num_iterations": 4.3782000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 8.9600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 1.7561600000000000e+05,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 1.0972463531450420e+10,
      "predicted_flops_count": 1.7561600000000000e+05
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_128__17548078397715538268<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:1/input[1]:896/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 20035,
      "real_time": 3.5007878030522021e+04,
      "cpu_time": 4.0191603443610918e+04,
      "time_unit": "ns",
      "items_per_second": 5.0164708596986990e+09,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = true]": 9.0033003156525926e+18,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 8.9600000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 8.9600000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 1.7561600000000000e+05,
      "input_width": 1.4000000000000000e+01,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 2.0035000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 8.9600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 1.7561600000000000e+05,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 5.0164708596986990e+09,
      "predicted_flops_count": 1.7561600000000000e+05
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_128__5932182551825187565<CUDNN_BATCHNORM_SPATIAL>/input[0]:128/input[1]:24/input[2]:56/input[3]:56/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 3701,
      "real_time": 1.8929241289795088e+05,
      "cpu_time": 1.9494189786386659e+05,
      "time_unit": "ns",
      "items_per_second": 5.0893703833727646e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 1.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)1; bool is_training = false]": 7.0429798546002954e+18,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 2.4000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 2.4000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 9.6337920000000000e+06,
      "input_width": 5.6000000000000000e+01,
      "is_training": 0.0000000000000000e+00,
      "num_iterations": 3.7010000000000000e+03,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 2.4000000000000000e+01,
      "output_height": 5.6000000000000000e+01,
      "output_size": 9.6337920000000000e+06,
      "output_width": 5.6000000000000000e+01,
      "predicted_flops": 5.0893703833727646e+10,
      "predicted_flops_count": 9.6337920000000000e+06
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_128__5932182551825187565<CUDNN_BATCHNORM_SPATIAL_PERSISTENT>/input[0]:128/input[1]:24/input[2]:56/input[3]:56/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/BATCHNORM_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_128__16898891353589486450<CUDNN_BATCHNORM_SPATIAL>/input[0]:128/input[1]:24/input[2]:56/input[3]:56/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 2142,
      "real_time": 3.2688536744333897e+05,
      "cpu_time": 3.3351436741293164e+05,
      "time_unit": "ns",
      "items_per_second": 2.9471469082108376e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 1.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)1; bool is_training = true]": 1.2389518253260638e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 2.4000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 2.4000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 9.6337920000000000e+06,
      "input_width": 5.6000000000000000e+01,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 2.1420000000000000e+03,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 2.4000000000000000e+01,
      "output_height": 5.6000000000000000e+01,
      "output_size": 9.6337920000000000e+06,
      "output_width": 5.6000000000000000e+01,
      "predicted_flops": 2.9471469082108376e+10,
      "predicted_flops_count": 9.6337920000000000e+06
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_128__16898891353589486450<CUDNN_BATCHNORM_SPATIAL_PERSISTENT>/input[0]:128/input[1]:24/input[2]:56/input[3]:56/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 2740,
      "real_time": 2.5534352119187792e+05,
      "cpu_time": 2.6142843868672696e+05,
      "time_unit": "ns",
      "items_per_second": 3.7728750488878418e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 2.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)2; bool is_training = true]": 8.6489340726076344e+18,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 2.4000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 2.4000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 9.6337920000000000e+06,
      "input_width": 5.6000000000000000e+01,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 2.7400000000000000e+03,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 2.4000000000000000e+01,
      "output_height": 5.6000000000000000e+01,
      "output_size": 9.6337920000000000e+06,
      "output_width": 5.6000000000000000e+01,
      "predicted_flops": 3.7728750488878418e+10,
      "predicted_flops_count": 9.6337920000000000e+06
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_128__11226853231070190167<CUDNN_BATCHNORM_SPATIAL>/input[0]:128/input[1]:144/input[2]:56/input[3]:56/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 631,
      "real_time": 1.1084482901052183e+06,
      "cpu_time": 1.1311817860550932e+06,
      "time_unit": "ns",
      "items_per_second": 5.2147450193200378e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 1.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)1; bool is_training = false]": 7.0429798546002954e+18,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 1.4400000000000000e+02,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 1.4400000000000000e+02,
      "input_height": 5.6000000000000000e+01,
      "input_size": 5.7802752000000000e+07,
      "input_width": 5.6000000000000000e+01,
      "is_training": 0.0000000000000000e+00,
      "num_iterations": 6.3100000000000000e+02,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 1.4400000000000000e+02,
      "output_height": 5.6000000000000000e+01,
      "output_size": 5.7802752000000000e+07,
      "output_width": 5.6000000000000000e+01,
      "predicted_flops": 5.2147450193200378e+10,
      "predicted_flops_count": 5.7802752000000000e+07
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_128__11226853231070190167<CUDNN_BATCHNORM_SPATIAL_PERSISTENT>/input[0]:128/input[1]:144/input[2]:56/input[3]:56/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/BATCHNORM_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_128__2529474022634294216<CUDNN_BATCHNORM_SPATIAL>/input[0]:128/input[1]:144/input[2]:56/input[3]:56/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 394,
      "real_time": 1.7772584823834791e+06,
      "cpu_time": 1.8273925939112196e+06,
      "time_unit": "ns",
      "items_per_second": 3.2523548247456276e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 1.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)1; bool is_training = true]": 1.2389518253260638e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 1.4400000000000000e+02,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 1.4400000000000000e+02,
      "input_height": 5.6000000000000000e+01,
      "input_size": 5.7802752000000000e+07,
      "input_width": 5.6000000000000000e+01,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 3.9400000000000000e+02,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 1.4400000000000000e+02,
      "output_height": 5.6000000000000000e+01,
      "output_size": 5.7802752000000000e+07,
      "output_width": 5.6000000000000000e+01,
      "predicted_flops": 3.2523548247456276e+10,
      "predicted_flops_count": 5.7802752000000000e+07
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_128__2529474022634294216<CUDNN_BATCHNORM_SPATIAL_PERSISTENT>/input[0]:128/input[1]:144/input[2]:56/input[3]:56/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 475,
      "real_time": 1.4738883411413745e+06,
      "cpu_time": 1.5101549157878635e+06,
      "time_unit": "ns",
      "items_per_second": 3.9217863651216438e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 2.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)2; bool is_training = true]": 8.6489340726076344e+18,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 1.4400000000000000e+02,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 1.4400000000000000e+02,
      "input_height": 5.6000000000000000e+01,
      "input_size": 5.7802752000000000e+07,
      "input_width": 5.6000000000000000e+01,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 4.7500000000000000e+02,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 1.4400000000000000e+02,
      "output_height": 5.6000000000000000e+01,
      "output_size": 5.7802752000000000e+07,
      "output_width": 5.6000000000000000e+01,
      "predicted_flops": 3.9217863651216438e+10,
      "predicted_flops_count": 5.7802752000000000e+07
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_128__13138794921079207493<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:1/input[1]:800/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 46688,
      "real_time": 1.5019034824936227e+04,
      "cpu_time": 2.0137782877713191e+04,
      "time_unit": "ns",
      "items_per_second": 1.0440084987329790e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = false]": 1.4627515035010154e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 8.0000000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 8.0000000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 1.5680000000000000e+05,
      "input_width": 1.4000000000000000e+01,
      "is_training": 0.0000000000000000e+00,
      "num_iterations": 4.6688000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 8.0000000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 1.5680000000000000e+05,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 1.0440084987329790e+10,
      "predicted_flops_count": 1.5680000000000000e+05
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_128__6448964876952122222<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:1/input[1]:800/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 22402,
      "real_time": 3.1391413749553623e+04,
      "cpu_time": 3.6595998170187471e+04,
      "time_unit": "ns",
      "items_per_second": 4.9949964423704767e+09,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = true]": 9.0033003156525926e+18,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 8.0000000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 8.0000000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 1.5680000000000000e+05,
      "input_width": 1.4000000000000000e+01,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 2.2402000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 8.0000000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 1.5680000000000000e+05,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 4.9949964423704767e+09,
      "predicted_flops_count": 1.5680000000000000e+05
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_128__7736438617458458995<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:1/input[1]:448/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 92535,
      "real_time": 7.5785091917762156e+03,
      "cpu_time": 1.2697923910083709e+04,
      "time_unit": "ns",
      "items_per_second": 1.1586447647946966e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = false]": 1.4627515035010154e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 4.4800000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 4.4800000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 8.7808000000000000e+04,
      "input_width": 1.4000000000000000e+01,
      "is_training": 0.0000000000000000e+00,
      "num_iterations": 9.2535000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 4.4800000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 8.7808000000000000e+04,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 1.1586447647946966e+10,
      "predicted_flops_count": 8.7808000000000000e+04
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_128__9544370967328556120<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:1/input[1]:448/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 40221,
      "real_time": 1.7335820147304552e+04,
      "cpu_time": 2.2460297680355725e+04,
      "time_unit": "ns",
      "items_per_second": 5.0651194609706869e+09,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = true]": 9.0033003156525926e+18,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 4.4800000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 4.4800000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 8.7808000000000000e+04,
      "input_width": 1.4000000000000000e+01,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 4.0221000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 4.4800000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 8.7808000000000000e+04,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 5.0651194609706869e+09,
      "predicted_flops_count": 8.7808000000000000e+04
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_128__6193347507491773787<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:1/input[1]:480/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 90546,
      "real_time": 7.8426254842414801e+03,
      "cpu_time": 1.3008358701613513e+04,
      "time_unit": "ns",
      "items_per_second": 1.1995982746981726e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = false]": 1.4627515035010154e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 4.8000000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 4.8000000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 9.4080000000000000e+04,
      "input_width": 1.4000000000000000e+01,
      "is_training": 0.0000000000000000e+00,
      "num_iterations": 9.0546000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 4.8000000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 9.4080000000000000e+04,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 1.1995982746981726e+10,
      "predicted_flops_count": 9.4080000000000000e+04
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_128__13464077901289445488<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:1/input[1]:480/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 37370,
      "real_time": 1.8357199425927622e+04,
      "cpu_time": 2.3516911238528286e+04,
      "time_unit": "ns",
      "items_per_second": 5.1249647518194885e+09,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = true]": 9.0033003156525926e+18,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 4.8000000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 4.8000000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 9.4080000000000000e+04,
      "input_width": 1.4000000000000000e+01,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 3.7370000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 4.8000000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 9.4080000000000000e+04,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 5.1249647518194885e+09,
      "predicted_flops_count": 9.4080000000000000e+04
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_128__12125660515354148524<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:128/input[1]:64/input[2]:400/input[3]:400/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 14,
      "real_time": 4.8681417214018956e+07,
      "cpu_time": 8.3299721714273080e+07,
      "time_unit": "ns",
      "items_per_second": 2.6924442117978180e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = false]": 1.4627515035010154e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 4.0000000000000000e+02,
      "input[3]": 4.0000000000000000e+02,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 4.0000000000000000e+02,
      "input_size": 1.3107200000000000e+09,
      "input_width": 4.0000000000000000e+02,
      "is_training": 0.0000000000000000e+00,
      "num_iterations": 1.4000000000000000e+01,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 4.0000000000000000e+02,
      "output_size": 1.3107200000000000e+09,
      "output_width": 4.0000000000000000e+02,
      "predicted_flops": 2.6924442117978180e+10,
      "predicted_flops_count": 1.3107200000000000e+09
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_128__5147558041171508103<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:128/input[1]:64/input[2]:400/input[3]:400/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 9,
      "real_time": 8.1923695902029678e+07,
      "cpu_time": 1.7304718700001508e+08,
      "time_unit": "ns",
      "items_per_second": 1.5999278176700603e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = true]": 9.0033003156525926e+18,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 4.0000000000000000e+02,
      "input[3]": 4.0000000000000000e+02,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 4.0000000000000000e+02,
      "input_size": 1.3107200000000000e+09,
      "input_width": 4.0000000000000000e+02,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 9.0000000000000000e+00,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 4.0000000000000000e+02,
      "output_size": 1.3107200000000000e+09,
      "output_width": 4.0000000000000000e+02,
      "predicted_flops": 1.5999278176700603e+10,
      "predicted_flops_count": 1.3107200000000000e+09
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_128__16904277444093157933<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:1/input[1]:544/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 113293,
      "real_time": 5.7024351510265560e+03,
      "cpu_time": 1.0819359060395302e+04,
      "time_unit": "ns",
      "items_per_second": 4.6744941930994816e+09,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = false]": 1.4627515035010154e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 5.4400000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 5.4400000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 2.6656000000000000e+04,
      "input_width": 7.0000000000000000e+00,
      "is_training": 0.0000000000000000e+00,
      "num_iterations": 1.1329300000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 5.4400000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 2.6656000000000000e+04,
      "output_width": 7.0000000000000000e+00,
      "predicted_flops": 4.6744941930994816e+09,
      "predicted_flops_count": 2.6656000000000000e+04
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_128__410177179444340486<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:1/input[1]:544/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 74335,
      "real_time": 9.4279408913884763e+03,
      "cpu_time": 1.4627022681196444e+04,
      "time_unit": "ns",
      "items_per_second": 2.8273405939941468e+09,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = true]": 9.0033003156525926e+18,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 5.4400000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 5.4400000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 2.6656000000000000e+04,
      "input_width": 7.0000000000000000e+00,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 7.4335000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 5.4400000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 2.6656000000000000e+04,
      "output_width": 7.0000000000000000e+00,
      "predicted_flops": 2.8273405939941468e+09,
      "predicted_flops_count": 2.6656000000000000e+04
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_128__9821257763164194723<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:128/input[1]:128/input[2]:400/input[3]:400/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD failed to cudnnSetTensor4dDescriptor",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_128__7450412676701831816<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:128/input[1]:128/input[2]:400/input[3]:400/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD failed to cudnnSetTensor4dDescriptor",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_128__5901503973176032831<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:1/input[1]:448/input[2]:28/input[3]:28/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 26958,
      "real_time": 2.5923147263187875e+04,
      "cpu_time": 3.1080994398587813e+04,
      "time_unit": "ns",
      "items_per_second": 1.3548972138069302e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = false]": 1.4627515035010154e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 4.4800000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 4.4800000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 3.5123200000000000e+05,
      "input_width": 2.8000000000000000e+01,
      "is_training": 0.0000000000000000e+00,
      "num_iterations": 2.6958000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 4.4800000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 3.5123200000000000e+05,
      "output_width": 2.8000000000000000e+01,
      "predicted_flops": 1.3548972138069302e+10,
      "predicted_flops_count": 3.5123200000000000e+05
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_128__13749324348628728596<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:1/input[1]:448/input[2]:28/input[3]:28/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 11219,
      "real_time": 6.2413613859362493e+04,
      "cpu_time": 6.7625006239741968e+04,
      "time_unit": "ns",
      "items_per_second": 5.6274901945501223e+09,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = true]": 9.0033003156525926e+18,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 4.4800000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 4.4800000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 3.5123200000000000e+05,
      "input_width": 2.8000000000000000e+01,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 1.1219000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 4.4800000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 3.5123200000000000e+05,
      "output_width": 2.8000000000000000e+01,
      "predicted_flops": 5.6274901945501223e+09,
      "predicted_flops_count": 3.5123200000000000e+05
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_128__17399262348674148785<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:1/input[1]:608/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 121851,
      "real_time": 5.7183762022277115e+03,
      "cpu_time": 1.0796971867046819e+04,
      "time_unit": "ns",
      "items_per_second": 5.2098705902549591e+09,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = false]": 1.4627515035010154e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 6.0800000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 6.0800000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 2.9792000000000000e+04,
      "input_width": 7.0000000000000000e+00,
      "is_training": 0.0000000000000000e+00,
      "num_iterations": 1.2185100000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 6.0800000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 2.9792000000000000e+04,
      "output_width": 7.0000000000000000e+00,
      "predicted_flops": 5.2098705902549591e+09,
      "predicted_flops_count": 2.9792000000000000e+04
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_128__2188656882801929370<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:1/input[1]:608/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 71718,
      "real_time": 9.7614811722781142e+03,
      "cpu_time": 1.4906191193085473e+04,
      "time_unit": "ns",
      "items_per_second": 3.0519958471678538e+09,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = true]": 9.0033003156525926e+18,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 6.0800000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 6.0800000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 2.9792000000000000e+04,
      "input_width": 7.0000000000000000e+00,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 7.1718000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 6.0800000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 2.9792000000000000e+04,
      "output_width": 7.0000000000000000e+00,
      "predicted_flops": 3.0519958471678538e+09,
      "predicted_flops_count": 2.9792000000000000e+04
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_128__8017254434804693755<CUDNN_BATCHNORM_SPATIAL>/input[0]:128/input[1]:192/input[2]:28/input[3]:28/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 1911,
      "real_time": 3.6620583907544636e+05,
      "cpu_time": 3.7324254264701752e+05,
      "time_unit": "ns",
      "items_per_second": 5.2614081874403046e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 1.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)1; bool is_training = false]": 7.0429798546002954e+18,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 1.9200000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 1.9200000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 1.9267584000000000e+07,
      "input_width": 2.8000000000000000e+01,
      "is_training": 0.0000000000000000e+00,
      "num_iterations": 1.9110000000000000e+03,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 1.9200000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 1.9267584000000000e+07,
      "output_width": 2.8000000000000000e+01,
      "predicted_flops": 5.2614081874403046e+10,
      "predicted_flops_count": 1.9267584000000000e+07
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_128__8017254434804693755<CUDNN_BATCHNORM_SPATIAL_PERSISTENT>/input[0]:128/input[1]:192/input[2]:28/input[3]:28/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/BATCHNORM_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_128__15534242024825154404<CUDNN_BATCHNORM_SPATIAL>/input[0]:128/input[1]:192/input[2]:28/input[3]:28/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 1172,
      "real_time": 5.9621619107718207e+05,
      "cpu_time": 6.0645917662327515e+05,
      "time_unit": "ns",
      "items_per_second": 3.2316438715274254e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 1.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)1; bool is_training = true]": 1.2389518253260638e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 1.9200000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 1.9200000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 1.9267584000000000e+07,
      "input_width": 2.8000000000000000e+01,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 1.1720000000000000e+03,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 1.9200000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 1.9267584000000000e+07,
      "output_width": 2.8000000000000000e+01,
      "predicted_flops": 3.2316438715274254e+10,
      "predicted_flops_count": 1.9267584000000000e+07
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_128__15534242024825154404<CUDNN_BATCHNORM_SPATIAL_PERSISTENT>/input[0]:128/input[1]:192/input[2]:28/input[3]:28/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 1372,
      "real_time": 5.0936107150056341e+05,
      "cpu_time": 5.1822373469316447e+05,
      "time_unit": "ns",
      "items_per_second": 3.7826966130800377e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 2.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)2; bool is_training = true]": 8.6489340726076344e+18,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 1.9200000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 1.9200000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 1.9267584000000000e+07,
      "input_width": 2.8000000000000000e+01,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 1.3720000000000000e+03,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 1.9200000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 1.9267584000000000e+07,
      "output_width": 2.8000000000000000e+01,
      "predicted_flops": 3.7826966130800377e+10,
      "predicted_flops_count": 1.9267584000000000e+07
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_128__14576981906394236471<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:1/input[1]:480/input[2]:28/input[3]:28/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 25576,
      "real_time": 2.7333941979710784e+04,
      "cpu_time": 3.2437539060160034e+04,
      "time_unit": "ns",
      "items_per_second": 1.3767498309586365e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = false]": 1.4627515035010154e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 4.8000000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 4.8000000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 3.7632000000000000e+05,
      "input_width": 2.8000000000000000e+01,
      "is_training": 0.0000000000000000e+00,
      "num_iterations": 2.5576000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 4.8000000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 3.7632000000000000e+05,
      "output_width": 2.8000000000000000e+01,
      "predicted_flops": 1.3767498309586365e+10,
      "predicted_flops_count": 3.7632000000000000e+05
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_128__2693967258241106716<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:1/input[1]:480/input[2]:28/input[3]:28/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 10641,
      "real_time": 6.5782667722406579e+04,
      "cpu_time": 7.1010961281723241e+04,
      "time_unit": "ns",
      "items_per_second": 5.7206558053865547e+09,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = true]": 9.0033003156525926e+18,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 4.8000000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 4.8000000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 3.7632000000000000e+05,
      "input_width": 2.8000000000000000e+01,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 1.0641000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 4.8000000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 3.7632000000000000e+05,
      "output_width": 2.8000000000000000e+01,
      "predicted_flops": 5.7206558053865547e+09,
      "predicted_flops_count": 3.7632000000000000e+05
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_128__16621857322922710516<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:1/input[1]:928/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 42703,
      "real_time": 1.6350974577361034e+04,
      "cpu_time": 2.1491730932232924e+04,
      "time_unit": "ns",
      "items_per_second": 1.1123985248673527e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = false]": 1.4627515035010154e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 9.2800000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 9.2800000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 1.8188800000000000e+05,
      "input_width": 1.4000000000000000e+01,
      "is_training": 0.0000000000000000e+00,
      "num_iterations": 4.2703000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 9.2800000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 1.8188800000000000e+05,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 1.1123985248673527e+10,
      "predicted_flops_count": 1.8188800000000000e+05
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_128__686095351364112607<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:1/input[1]:928/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 19319,
      "real_time": 3.6240953530221421e+04,
      "cpu_time": 4.1435670065959428e+04,
      "time_unit": "ns",
      "items_per_second": 5.0188524937215891e+09,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = true]": 9.0033003156525926e+18,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 9.2800000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 9.2800000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 1.8188800000000000e+05,
      "input_width": 1.4000000000000000e+01,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 1.9319000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 9.2800000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 1.8188800000000000e+05,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 5.0188524937215891e+09,
      "predicted_flops_count": 1.8188800000000000e+05
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_128__3683730341301957751<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:1/input[1]:128/input[2]:28/input[3]:28/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 87928,
      "real_time": 7.9457100677219778e+03,
      "cpu_time": 1.3049790897141980e+04,
      "time_unit": "ns",
      "items_per_second": 1.2629708250702728e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = false]": 1.4627515035010154e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 1.2800000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 1.2800000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 1.0035200000000000e+05,
      "input_width": 2.8000000000000000e+01,
      "is_training": 0.0000000000000000e+00,
      "num_iterations": 8.7928000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 1.0035200000000000e+05,
      "output_width": 2.8000000000000000e+01,
      "predicted_flops": 1.2629708250702728e+10,
      "predicted_flops_count": 1.0035200000000000e+05
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_128__15867885760678195548<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:1/input[1]:128/input[2]:28/input[3]:28/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 35749,
      "real_time": 1.9468815547890827e+04,
      "cpu_time": 2.4628256929995016e+04,
      "time_unit": "ns",
      "items_per_second": 5.1544994996304102e+09,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = true]": 9.0033003156525926e+18,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 1.2800000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 1.2800000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 1.0035200000000000e+05,
      "input_width": 2.8000000000000000e+01,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 3.5749000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 1.0035200000000000e+05,
      "output_width": 2.8000000000000000e+01,
      "predicted_flops": 5.1544994996304102e+09,
      "predicted_flops_count": 1.0035200000000000e+05
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_128__9156435283693894329<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:1/input[1]:544/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 85539,
      "real_time": 8.1757917079172657e+03,
      "cpu_time": 1.3289503711504420e+04,
      "time_unit": "ns",
      "items_per_second": 1.3041428134323376e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = false]": 1.4627515035010154e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 5.4400000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 5.4400000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 1.0662400000000000e+05,
      "input_width": 1.4000000000000000e+01,
      "is_training": 0.0000000000000000e+00,
      "num_iterations": 8.5539000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 5.4400000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 1.0662400000000000e+05,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 1.3041428134323376e+10,
      "predicted_flops_count": 1.0662400000000000e+05
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_128__10392903167057543058<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:1/input[1]:544/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 31720,
      "real_time": 2.1781420387639868e+04,
      "cpu_time": 2.6971726734101383e+04,
      "time_unit": "ns",
      "items_per_second": 4.8951812187833757e+09,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = true]": 9.0033003156525926e+18,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 5.4400000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 5.4400000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 1.0662400000000000e+05,
      "input_width": 1.4000000000000000e+01,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 3.1720000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 5.4400000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 1.0662400000000000e+05,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 4.8951812187833757e+09,
      "predicted_flops_count": 1.0662400000000000e+05
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_128__5968685270233129840<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:1/input[1]:512/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 88039,
      "real_time": 7.9573762831599470e+03,
      "cpu_time": 1.3065548245800792e+04,
      "time_unit": "ns",
      "items_per_second": 1.2611191984520470e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = false]": 1.4627515035010154e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 1.0035200000000000e+05,
      "input_width": 1.4000000000000000e+01,
      "is_training": 0.0000000000000000e+00,
      "num_iterations": 8.8039000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 1.0035200000000000e+05,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 1.2611191984520470e+10,
      "predicted_flops_count": 1.0035200000000000e+05
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_128__13689874812997494363<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:1/input[1]:512/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 35770,
      "real_time": 1.9484036867630963e+04,
      "cpu_time": 2.4680873329513572e+04,
      "time_unit": "ns",
      "items_per_second": 5.1504727014100370e+09,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = true]": 9.0033003156525926e+18,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 1.0035200000000000e+05,
      "input_width": 1.4000000000000000e+01,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 3.5770000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 1.0035200000000000e+05,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 5.1504727014100370e+09,
      "predicted_flops_count": 1.0035200000000000e+05
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_128__9828769825327627606<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:1/input[1]:960/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 42084,
      "real_time": 1.6652428945375832e+04,
      "cpu_time": 2.1821434987202410e+04,
      "time_unit": "ns",
      "items_per_second": 1.1299252536504572e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = false]": 1.4627515035010154e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 9.6000000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 9.6000000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 1.8816000000000000e+05,
      "input_width": 1.4000000000000000e+01,
      "is_training": 0.0000000000000000e+00,
      "num_iterations": 4.2084000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 9.6000000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 1.8816000000000000e+05,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 1.1299252536504572e+10,
      "predicted_flops_count": 1.8816000000000000e+05
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_128__7444447064784205949<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:1/input[1]:960/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 18658,
      "real_time": 3.7503343243240692e+04,
      "cpu_time": 4.2703863061892989e+04,
      "time_unit": "ns",
      "items_per_second": 5.0171527050168381e+09,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = true]": 9.0033003156525926e+18,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 9.6000000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 9.6000000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 1.8816000000000000e+05,
      "input_width": 1.4000000000000000e+01,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 1.8658000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 9.6000000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 1.8816000000000000e+05,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 5.0171527050168381e+09,
      "predicted_flops_count": 1.8816000000000000e+05
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_128__847297196735432346<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:1/input[1]:320/input[2]:28/input[3]:28/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 34338,
      "real_time": 2.0378663757189006e+04,
      "cpu_time": 2.5529664395042506e+04,
      "time_unit": "ns",
      "items_per_second": 1.2310915131101112e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = false]": 1.4627515035010154e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 3.2000000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 3.2000000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 2.5088000000000000e+05,
      "input_width": 2.8000000000000000e+01,
      "is_training": 0.0000000000000000e+00,
      "num_iterations": 3.4338000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 3.2000000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 2.5088000000000000e+05,
      "output_width": 2.8000000000000000e+01,
      "predicted_flops": 1.2310915131101112e+10,
      "predicted_flops_count": 2.5088000000000000e+05
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_128__16495286249914614705<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:1/input[1]:320/input[2]:28/input[3]:28/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 14719,
      "real_time": 4.7522272085239310e+04,
      "cpu_time": 5.2748685440368718e+04,
      "time_unit": "ns",
      "items_per_second": 5.2792088633726072e+09,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = true]": 9.0033003156525926e+18,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 3.2000000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 3.2000000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 2.5088000000000000e+05,
      "input_width": 2.8000000000000000e+01,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 1.4719000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 3.2000000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 2.5088000000000000e+05,
      "output_width": 2.8000000000000000e+01,
      "predicted_flops": 5.2792088633726072e+09,
      "predicted_flops_count": 2.5088000000000000e+05
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_128__8405694704743189508<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:1/input[1]:576/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 122378,
      "real_time": 5.8918566611731330e+03,
      "cpu_time": 1.1138538609846259e+04,
      "time_unit": "ns",
      "items_per_second": 4.7903405705698700e+09,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = false]": 1.4627515035010154e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 5.7600000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 5.7600000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 2.8224000000000000e+04,
      "input_width": 7.0000000000000000e+00,
      "is_training": 0.0000000000000000e+00,
      "num_iterations": 1.2237800000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 5.7600000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 2.8224000000000000e+04,
      "output_width": 7.0000000000000000e+00,
      "predicted_flops": 4.7903405705698700e+09,
      "predicted_flops_count": 2.8224000000000000e+04
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_128__11208955831952066863<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:1/input[1]:576/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 68498,
      "real_time": 1.0180593668938254e+04,
      "cpu_time": 1.5688712268861595e+04,
      "time_unit": "ns",
      "items_per_second": 2.7723334137294483e+09,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = true]": 9.0033003156525926e+18,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 5.7600000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 5.7600000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 2.8224000000000000e+04,
      "input_width": 7.0000000000000000e+00,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 6.8498000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 5.7600000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 2.8224000000000000e+04,
      "output_width": 7.0000000000000000e+00,
      "predicted_flops": 2.7723334137294483e+09,
      "predicted_flops_count": 2.8224000000000000e+04
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_128__9114343306464528187<CUDNN_BATCHNORM_SPATIAL>/input[0]:128/input[1]:384/input[2]:28/input[3]:28/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 942,
      "real_time": 7.4290581252188631e+05,
      "cpu_time": 7.5602611889582244e+05,
      "time_unit": "ns",
      "items_per_second": 5.1870866199293251e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 1.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)1; bool is_training = false]": 7.0429798546002954e+18,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 3.8400000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 3.8400000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 3.8535168000000000e+07,
      "input_width": 2.8000000000000000e+01,
      "is_training": 0.0000000000000000e+00,
      "num_iterations": 9.4200000000000000e+02,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 3.8400000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 3.8535168000000000e+07,
      "output_width": 2.8000000000000000e+01,
      "predicted_flops": 5.1870866199293251e+10,
      "predicted_flops_count": 3.8535168000000000e+07
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_128__9114343306464528187<CUDNN_BATCHNORM_SPATIAL_PERSISTENT>/input[0]:128/input[1]:384/input[2]:28/input[3]:28/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/BATCHNORM_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_128__14315555965436925604<CUDNN_BATCHNORM_SPATIAL>/input[0]:128/input[1]:384/input[2]:28/input[3]:28/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 604,
      "real_time": 1.1617086719049276e+06,
      "cpu_time": 1.1860366407284313e+06,
      "time_unit": "ns",
      "items_per_second": 3.3171111597894360e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 1.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)1; bool is_training = true]": 1.2389518253260638e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 3.8400000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 3.8400000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 3.8535168000000000e+07,
      "input_width": 2.8000000000000000e+01,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 6.0400000000000000e+02,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 3.8400000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 3.8535168000000000e+07,
      "output_width": 2.8000000000000000e+01,
      "predicted_flops": 3.3171111597894360e+10,
      "predicted_flops_count": 3.8535168000000000e+07
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_128__14315555965436925604<CUDNN_BATCHNORM_SPATIAL_PERSISTENT>/input[0]:128/input[1]:384/input[2]:28/input[3]:28/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 713,
      "real_time": 9.8233590456676704e+05,
      "cpu_time": 1.0013087461411960e+06,
      "time_unit": "ns",
      "items_per_second": 3.9228096846358177e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 2.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)2; bool is_training = true]": 8.6489340726076344e+18,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 3.8400000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 3.8400000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 3.8535168000000000e+07,
      "input_width": 2.8000000000000000e+01,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 7.1300000000000000e+02,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 3.8400000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 3.8535168000000000e+07,
      "output_width": 2.8000000000000000e+01,
      "predicted_flops": 3.9228096846358177e+10,
      "predicted_flops_count": 3.8535168000000000e+07
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_128__14916697881833509299<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:128/input[1]:64/input[2]:199/input[3]:199/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 58,
      "real_time": 1.1986062348145863e+07,
      "cpu_time": 1.4060747655170463e+07,
      "time_unit": "ns",
      "items_per_second": 2.7065718713717815e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = false]": 1.4627515035010154e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 1.9900000000000000e+02,
      "input[3]": 1.9900000000000000e+02,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 1.9900000000000000e+02,
      "input_size": 3.2441139200000000e+08,
      "input_width": 1.9900000000000000e+02,
      "is_training": 0.0000000000000000e+00,
      "num_iterations": 5.8000000000000000e+01,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 1.9900000000000000e+02,
      "output_size": 3.2441139200000000e+08,
      "output_width": 1.9900000000000000e+02,
      "predicted_flops": 2.7065718713717815e+10,
      "predicted_flops_count": 3.2441139200000000e+08
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_128__2318213118344320152<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:128/input[1]:64/input[2]:199/input[3]:199/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 38,
      "real_time": 1.8457950239903048e+07,
      "cpu_time": 2.3324060894735437e+07,
      "time_unit": "ns",
      "items_per_second": 1.7575699781586582e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = true]": 9.0033003156525926e+18,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 1.9900000000000000e+02,
      "input[3]": 1.9900000000000000e+02,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 1.9900000000000000e+02,
      "input_size": 3.2441139200000000e+08,
      "input_width": 1.9900000000000000e+02,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 3.8000000000000000e+01,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 1.9900000000000000e+02,
      "output_size": 3.2441139200000000e+08,
      "output_width": 1.9900000000000000e+02,
      "predicted_flops": 1.7575699781586582e+10,
      "predicted_flops_count": 3.2441139200000000e+08
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_128__7122968153930484572<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:1/input[1]:736/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 121741,
      "real_time": 5.8501207918320097e+03,
      "cpu_time": 1.0970270574298964e+04,
      "time_unit": "ns",
      "items_per_second": 6.1646590358190346e+09,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = false]": 1.4627515035010154e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 7.3600000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 7.3600000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 3.6064000000000000e+04,
      "input_width": 7.0000000000000000e+00,
      "is_training": 0.0000000000000000e+00,
      "num_iterations": 1.2174100000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 7.3600000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 3.6064000000000000e+04,
      "output_width": 7.0000000000000000e+00,
      "predicted_flops": 6.1646590358190346e+09,
      "predicted_flops_count": 3.6064000000000000e+04
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_128__10227937474716372599<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:1/input[1]:736/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 60226,
      "real_time": 1.1615052680412617e+04,
      "cpu_time": 1.6632691578559610e+04,
      "time_unit": "ns",
      "items_per_second": 3.1049364124553285e+09,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = true]": 9.0033003156525926e+18,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 7.3600000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 7.3600000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 3.6064000000000000e+04,
      "input_width": 7.0000000000000000e+00,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 6.0226000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 7.3600000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 3.6064000000000000e+04,
      "output_width": 7.0000000000000000e+00,
      "predicted_flops": 3.1049364124553285e+09,
      "predicted_flops_count": 3.6064000000000000e+04
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_128__4906908824640152787<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:1/input[1]:128/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 123092,
      "real_time": 5.6417368580635784e+03,
      "cpu_time": 1.0719215984772834e+04,
      "time_unit": "ns",
      "items_per_second": 4.4468575247607327e+09,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = false]": 1.4627515035010154e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 1.2800000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 1.2800000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 2.5088000000000000e+04,
      "input_width": 1.4000000000000000e+01,
      "is_training": 0.0000000000000000e+00,
      "num_iterations": 1.2309200000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 2.5088000000000000e+04,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 4.4468575247607327e+09,
      "predicted_flops_count": 2.5088000000000000e+04
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_128__12335892292500300280<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:1/input[1]:128/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 74537,
      "real_time": 9.3929593320136992e+03,
      "cpu_time": 1.4557018272707575e+04,
      "time_unit": "ns",
      "items_per_second": 2.6709367211346736e+09,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = true]": 9.0033003156525926e+18,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 1.2800000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 1.2800000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 2.5088000000000000e+04,
      "input_width": 1.4000000000000000e+01,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 7.4537000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 2.5088000000000000e+04,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 2.6709367211346736e+09,
      "predicted_flops_count": 2.5088000000000000e+04
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_128__14178741234798799958<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:1/input[1]:640/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 122139,
      "real_time": 5.7222945189848824e+03,
      "cpu_time": 1.0832778948634745e+04,
      "time_unit": "ns",
      "items_per_second": 5.4803191090491390e+09,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = false]": 1.4627515035010154e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 6.4000000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 6.4000000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 3.1360000000000000e+04,
      "input_width": 7.0000000000000000e+00,
      "is_training": 0.0000000000000000e+00,
      "num_iterations": 1.2213900000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 6.4000000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 3.1360000000000000e+04,
      "output_width": 7.0000000000000000e+00,
      "predicted_flops": 5.4803191090491390e+09,
      "predicted_flops_count": 3.1360000000000000e+04
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_128__3164958765901408637<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:1/input[1]:640/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 71110,
      "real_time": 1.0265810187420777e+04,
      "cpu_time": 1.5748297890817557e+04,
      "time_unit": "ns",
      "items_per_second": 3.0548002960766811e+09,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = true]": 9.0033003156525926e+18,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 6.4000000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 6.4000000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 3.1360000000000000e+04,
      "input_width": 7.0000000000000000e+00,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 7.1110000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 6.4000000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 3.1360000000000000e+04,
      "output_width": 7.0000000000000000e+00,
      "predicted_flops": 3.0548002960766811e+09,
      "predicted_flops_count": 3.1360000000000000e+04
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_128__10623436706895202255<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:128/input[1]:256/input[2]:199/input[3]:199/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 15,
      "real_time": 4.7856153796116509e+07,
      "cpu_time": 7.9767224733344242e+07,
      "time_unit": "ns",
      "items_per_second": 2.7115542413383480e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = false]": 1.4627515035010154e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 1.9900000000000000e+02,
      "input[3]": 1.9900000000000000e+02,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 1.9900000000000000e+02,
      "input_size": 1.2976455680000000e+09,
      "input_width": 1.9900000000000000e+02,
      "is_training": 0.0000000000000000e+00,
      "num_iterations": 1.5000000000000000e+01,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 1.9900000000000000e+02,
      "output_size": 1.2976455680000000e+09,
      "output_width": 1.9900000000000000e+02,
      "predicted_flops": 2.7115542413383480e+10,
      "predicted_flops_count": 1.2976455680000000e+09
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_128__8955183950373307108<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:128/input[1]:256/input[2]:199/input[3]:199/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 9,
      "real_time": 8.0957847336928055e+07,
      "cpu_time": 1.7098840022222501e+08,
      "time_unit": "ns",
      "items_per_second": 1.6028657019491833e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = true]": 9.0033003156525926e+18,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 1.9900000000000000e+02,
      "input[3]": 1.9900000000000000e+02,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 1.9900000000000000e+02,
      "input_size": 1.2976455680000000e+09,
      "input_width": 1.9900000000000000e+02,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 9.0000000000000000e+00,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 1.9900000000000000e+02,
      "output_size": 1.2976455680000000e+09,
      "output_width": 1.9900000000000000e+02,
      "predicted_flops": 1.6028657019491833e+10,
      "predicted_flops_count": 1.2976455680000000e+09
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_128__16940678669688044217<CUDNN_BATCHNORM_SPATIAL>/input[0]:128/input[1]:576/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 2374,
      "real_time": 2.9438183740851970e+05,
      "cpu_time": 3.0075164111166442e+05,
      "time_unit": "ns",
      "items_per_second": 4.9088245821179810e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 1.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)1; bool is_training = false]": 7.0429798546002954e+18,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 5.7600000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 5.7600000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 1.4450688000000000e+07,
      "input_width": 1.4000000000000000e+01,
      "is_training": 0.0000000000000000e+00,
      "num_iterations": 2.3740000000000000e+03,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 5.7600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 1.4450688000000000e+07,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 4.9088245821179810e+10,
      "predicted_flops_count": 1.4450688000000000e+07
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_128__16940678669688044217<CUDNN_BATCHNORM_SPATIAL_PERSISTENT>/input[0]:128/input[1]:576/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/BATCHNORM_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_128__6038999178143230758<CUDNN_BATCHNORM_SPATIAL>/input[0]:128/input[1]:576/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 1535,
      "real_time": 4.5597955043403379e+05,
      "cpu_time": 4.6407840912034397e+05,
      "time_unit": "ns",
      "items_per_second": 3.1691526486757591e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 1.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)1; bool is_training = true]": 1.2389518253260638e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 5.7600000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 5.7600000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 1.4450688000000000e+07,
      "input_width": 1.4000000000000000e+01,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 1.5350000000000000e+03,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 5.7600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 1.4450688000000000e+07,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 3.1691526486757591e+10,
      "predicted_flops_count": 1.4450688000000000e+07
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_128__6038999178143230758<CUDNN_BATCHNORM_SPATIAL_PERSISTENT>/input[0]:128/input[1]:576/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 1625,
      "real_time": 4.3076474171203491e+05,
      "cpu_time": 4.3861279015541537e+05,
      "time_unit": "ns",
      "items_per_second": 3.3546589589870026e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 2.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)2; bool is_training = true]": 8.6489340726076344e+18,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 5.7600000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 5.7600000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 1.4450688000000000e+07,
      "input_width": 1.4000000000000000e+01,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 1.6250000000000000e+03,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 5.7600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 1.4450688000000000e+07,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 3.3546589589870026e+10,
      "predicted_flops_count": 1.4450688000000000e+07
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_128__529242968985074814<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:1/input[1]:992/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 41119,
      "real_time": 1.7049668820949384e+04,
      "cpu_time": 2.2212625428620682e+04,
      "time_unit": "ns",
      "items_per_second": 1.1403857872071754e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = false]": 1.4627515035010154e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 9.9200000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 9.9200000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 1.9443200000000000e+05,
      "input_width": 1.4000000000000000e+01,
      "is_training": 0.0000000000000000e+00,
      "num_iterations": 4.1119000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 9.9200000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 1.9443200000000000e+05,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 1.1403857872071754e+10,
      "predicted_flops_count": 1.9443200000000000e+05
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_128__16749182303429212501<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:1/input[1]:992/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 18162,
      "real_time": 3.8542145553458846e+04,
      "cpu_time": 4.3733639632753948e+04,
      "time_unit": "ns",
      "items_per_second": 5.0446594814063568e+09,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = true]": 9.0033003156525926e+18,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 9.9200000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 9.9200000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 1.9443200000000000e+05,
      "input_width": 1.4000000000000000e+01,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 1.8162000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 9.9200000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 1.9443200000000000e+05,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 5.0446594814063568e+09,
      "predicted_flops_count": 1.9443200000000000e+05
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_128__18021674889009843961<CUDNN_BATCHNORM_SPATIAL>/input[0]:128/input[1]:576/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 5100,
      "real_time": 1.3725687387883299e+05,
      "cpu_time": 1.4267239235243111e+05,
      "time_unit": "ns",
      "items_per_second": 2.6320517857555016e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 1.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)1; bool is_training = false]": 7.0429798546002954e+18,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 5.7600000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 5.7600000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 3.6126720000000000e+06,
      "input_width": 7.0000000000000000e+00,
      "is_training": 0.0000000000000000e+00,
      "num_iterations": 5.1000000000000000e+03,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 5.7600000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 3.6126720000000000e+06,
      "output_width": 7.0000000000000000e+00,
      "predicted_flops": 2.6320517857555016e+10,
      "predicted_flops_count": 3.6126720000000000e+06
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_128__18021674889009843961<CUDNN_BATCHNORM_SPATIAL_PERSISTENT>/input[0]:128/input[1]:576/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/BATCHNORM_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_128__4813905358400708454<CUDNN_BATCHNORM_SPATIAL>/input[0]:128/input[1]:576/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 6220,
      "real_time": 1.1249612888988141e+05,
      "cpu_time": 1.1783966736333273e+05,
      "time_unit": "ns",
      "items_per_second": 3.2113745029718491e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 1.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)1; bool is_training = true]": 1.2389518253260638e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 5.7600000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 5.7600000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 3.6126720000000000e+06,
      "input_width": 7.0000000000000000e+00,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 6.2200000000000000e+03,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 5.7600000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 3.6126720000000000e+06,
      "output_width": 7.0000000000000000e+00,
      "predicted_flops": 3.2113745029718491e+10,
      "predicted_flops_count": 3.6126720000000000e+06
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_128__4813905358400708454<CUDNN_BATCHNORM_SPATIAL_PERSISTENT>/input[0]:128/input[1]:576/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 6226,
      "real_time": 1.1248424567770299e+05,
      "cpu_time": 1.1781241117837442e+05,
      "time_unit": "ns",
      "items_per_second": 3.2117137633222500e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 2.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)2; bool is_training = true]": 8.6489340726076344e+18,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 5.7600000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 5.7600000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 3.6126720000000000e+06,
      "input_width": 7.0000000000000000e+00,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 6.2260000000000000e+03,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 5.7600000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 3.6126720000000000e+06,
      "output_width": 7.0000000000000000e+00,
      "predicted_flops": 3.2117137633222500e+10,
      "predicted_flops_count": 3.6126720000000000e+06
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_128__17377787318148837475<CUDNN_BATCHNORM_SPATIAL>/input[0]:128/input[1]:384/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 3528,
      "real_time": 1.9878431543920486e+05,
      "cpu_time": 2.0456619075895473e+05,
      "time_unit": "ns",
      "items_per_second": 4.8463541898235672e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 1.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)1; bool is_training = false]": 7.0429798546002954e+18,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 3.8400000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 3.8400000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 9.6337920000000000e+06,
      "input_width": 1.4000000000000000e+01,
      "is_training": 0.0000000000000000e+00,
      "num_iterations": 3.5280000000000000e+03,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 3.8400000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 9.6337920000000000e+06,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 4.8463541898235672e+10,
      "predicted_flops_count": 9.6337920000000000e+06
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_128__17377787318148837475<CUDNN_BATCHNORM_SPATIAL_PERSISTENT>/input[0]:128/input[1]:384/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/BATCHNORM_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_128__5331692143958041084<CUDNN_BATCHNORM_SPATIAL>/input[0]:128/input[1]:384/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 2187,
      "real_time": 3.1969163081737317e+05,
      "cpu_time": 3.2627277914855652e+05,
      "time_unit": "ns",
      "items_per_second": 3.0134639356584824e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 1.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)1; bool is_training = true]": 1.2389518253260638e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 3.8400000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 3.8400000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 9.6337920000000000e+06,
      "input_width": 1.4000000000000000e+01,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 2.1870000000000000e+03,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 3.8400000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 9.6337920000000000e+06,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 3.0134639356584824e+10,
      "predicted_flops_count": 9.6337920000000000e+06
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_128__5331692143958041084<CUDNN_BATCHNORM_SPATIAL_PERSISTENT>/input[0]:128/input[1]:384/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 2382,
      "real_time": 2.9352388248327689e+05,
      "cpu_time": 2.9992085474420292e+05,
      "time_unit": "ns",
      "items_per_second": 3.2821152127370327e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 2.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)2; bool is_training = true]": 8.6489340726076344e+18,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 3.8400000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 3.8400000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 9.6337920000000000e+06,
      "input_width": 1.4000000000000000e+01,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 2.3820000000000000e+03,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 3.8400000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 9.6337920000000000e+06,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 3.2821152127370327e+10,
      "predicted_flops_count": 9.6337920000000000e+06
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_128__15408246865298578512<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:1/input[1]:1024/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 111394,
      "real_time": 6.2916816605160147e+03,
      "cpu_time": 1.1416799360819703e+04,
      "time_unit": "ns",
      "items_per_second": 7.9749743720957422e+09,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = false]": 1.4627515035010154e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 1.0240000000000000e+03,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 1.0240000000000000e+03,
      "input_height": 7.0000000000000000e+00,
      "input_size": 5.0176000000000000e+04,
      "input_width": 7.0000000000000000e+00,
      "is_training": 0.0000000000000000e+00,
      "num_iterations": 1.1139400000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 1.0240000000000000e+03,
      "output_height": 7.0000000000000000e+00,
      "output_size": 5.0176000000000000e+04,
      "output_width": 7.0000000000000000e+00,
      "predicted_flops": 7.9749743720957422e+09,
      "predicted_flops_count": 5.0176000000000000e+04
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_128__4250313784913533307<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:1/input[1]:1024/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 57072,
      "real_time": 1.2287088951086220e+04,
      "cpu_time": 1.7473603781487669e+04,
      "time_unit": "ns",
      "items_per_second": 4.0836360996283236e+09,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = true]": 9.0033003156525926e+18,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 1.0240000000000000e+03,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 1.0240000000000000e+03,
      "input_height": 7.0000000000000000e+00,
      "input_size": 5.0176000000000000e+04,
      "input_width": 7.0000000000000000e+00,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 5.7072000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 1.0240000000000000e+03,
      "output_height": 7.0000000000000000e+00,
      "output_size": 5.0176000000000000e+04,
      "output_width": 7.0000000000000000e+00,
      "predicted_flops": 4.0836360996283236e+09,
      "predicted_flops_count": 5.0176000000000000e+04
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_128__9250940892129420376<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:1/input[1]:928/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 113712,
      "real_time": 6.1363287192159460e+03,
      "cpu_time": 1.1170881657357504e+04,
      "time_unit": "ns",
      "items_per_second": 7.4102940179205513e+09,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = false]": 1.4627515035010154e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 9.2800000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 9.2800000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 4.5472000000000000e+04,
      "input_width": 7.0000000000000000e+00,
      "is_training": 0.0000000000000000e+00,
      "num_iterations": 1.1371200000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 9.2800000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 4.5472000000000000e+04,
      "output_width": 7.0000000000000000e+00,
      "predicted_flops": 7.4102940179205513e+09,
      "predicted_flops_count": 4.5472000000000000e+04
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_128__8018873022373962099<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:1/input[1]:928/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 57877,
      "real_time": 1.2087643597555500e+04,
      "cpu_time": 1.7276868565756333e+04,
      "time_unit": "ns",
      "items_per_second": 3.7618581018715563e+09,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = true]": 9.0033003156525926e+18,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 9.2800000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 9.2800000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 4.5472000000000000e+04,
      "input_width": 7.0000000000000000e+00,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 5.7877000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 9.2800000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 4.5472000000000000e+04,
      "output_width": 7.0000000000000000e+00,
      "predicted_flops": 3.7618581018715563e+09,
      "predicted_flops_count": 4.5472000000000000e+04
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_128__4262545065456962351<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:1/input[1]:672/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 120396,
      "real_time": 5.7613417250540651e+03,
      "cpu_time": 1.0864616532154221e+04,
      "time_unit": "ns",
      "items_per_second": 5.7153353457246971e+09,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = false]": 1.4627515035010154e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 6.7200000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 6.7200000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 3.2928000000000000e+04,
      "input_width": 7.0000000000000000e+00,
      "is_training": 0.0000000000000000e+00,
      "num_iterations": 1.2039600000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 6.7200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 3.2928000000000000e+04,
      "output_width": 7.0000000000000000e+00,
      "predicted_flops": 5.7153353457246971e+09,
      "predicted_flops_count": 3.2928000000000000e+04
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_128__15280336516152970756<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:1/input[1]:672/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 71057,
      "real_time": 1.0308707448155172e+04,
      "cpu_time": 1.5827038096089464e+04,
      "time_unit": "ns",
      "items_per_second": 3.1941928865090389e+09,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = true]": 9.0033003156525926e+18,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 6.7200000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 6.7200000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 3.2928000000000000e+04,
      "input_width": 7.0000000000000000e+00,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 7.1057000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 6.7200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 3.2928000000000000e+04,
      "output_width": 7.0000000000000000e+00,
      "predicted_flops": 3.1941928865090389e+09,
      "predicted_flops_count": 3.2928000000000000e+04
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_128__12512093971862784174<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:1/input[1]:960/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 104161,
      "real_time": 6.6806738376446301e+03,
      "cpu_time": 1.2118381687840987e+04,
      "time_unit": "ns",
      "items_per_second": 7.0412058937732315e+09,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = false]": 1.4627515035010154e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 9.6000000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 9.6000000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 4.7040000000000000e+04,
      "input_width": 7.0000000000000000e+00,
      "is_training": 0.0000000000000000e+00,
      "num_iterations": 1.0416100000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 9.6000000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 4.7040000000000000e+04,
      "output_width": 7.0000000000000000e+00,
      "predicted_flops": 7.0412058937732315e+09,
      "predicted_flops_count": 4.7040000000000000e+04
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_128__4794873527157280133<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:1/input[1]:960/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 57577,
      "real_time": 1.2160913778122191e+04,
      "cpu_time": 1.7347690518732536e+04,
      "time_unit": "ns",
      "items_per_second": 3.8681303772275910e+09,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = true]": 9.0033003156525926e+18,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 9.6000000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 9.6000000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 4.7040000000000000e+04,
      "input_width": 7.0000000000000000e+00,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 5.7577000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 9.6000000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 4.7040000000000000e+04,
      "output_width": 7.0000000000000000e+00,
      "predicted_flops": 3.8681303772275910e+09,
      "predicted_flops_count": 4.7040000000000000e+04
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_128__17954723705592091707<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:1/input[1]:704/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 122102,
      "real_time": 5.7666399778479790e+03,
      "cpu_time": 1.0858534241721825e+04,
      "time_unit": "ns",
      "items_per_second": 5.9819930032936401e+09,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = false]": 1.4627515035010154e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 7.0400000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 7.0400000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 3.4496000000000000e+04,
      "input_width": 7.0000000000000000e+00,
      "is_training": 0.0000000000000000e+00,
      "num_iterations": 1.2210200000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 7.0400000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 3.4496000000000000e+04,
      "output_width": 7.0000000000000000e+00,
      "predicted_flops": 5.9819930032936401e+09,
      "predicted_flops_count": 3.4496000000000000e+04
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_128__1586055592551141648<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:1/input[1]:704/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 70248,
      "real_time": 9.9395027317339100e+03,
      "cpu_time": 1.5129314001907238e+04,
      "time_unit": "ns",
      "items_per_second": 3.4705961586855259e+09,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = true]": 9.0033003156525926e+18,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 7.0400000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 7.0400000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 3.4496000000000000e+04,
      "input_width": 7.0000000000000000e+00,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 7.0248000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 7.0400000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 3.4496000000000000e+04,
      "output_width": 7.0000000000000000e+00,
      "predicted_flops": 3.4705961586855259e+09,
      "predicted_flops_count": 3.4496000000000000e+04
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_128__12753740602899994428<CUDNN_BATCHNORM_SPATIAL>/input[0]:128/input[1]:1280/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 2336,
      "real_time": 2.9969629039977957e+05,
      "cpu_time": 3.0611479452169314e+05,
      "time_unit": "ns",
      "items_per_second": 2.6787652223825809e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 1.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)1; bool is_training = false]": 7.0429798546002954e+18,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 1.2800000000000000e+03,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 1.2800000000000000e+03,
      "input_height": 7.0000000000000000e+00,
      "input_size": 8.0281600000000000e+06,
      "input_width": 7.0000000000000000e+00,
      "is_training": 0.0000000000000000e+00,
      "num_iterations": 2.3360000000000000e+03,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 1.2800000000000000e+03,
      "output_height": 7.0000000000000000e+00,
      "output_size": 8.0281600000000000e+06,
      "output_width": 7.0000000000000000e+00,
      "predicted_flops": 2.6787652223825809e+10,
      "predicted_flops_count": 8.0281600000000000e+06
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_128__12753740602899994428<CUDNN_BATCHNORM_SPATIAL_PERSISTENT>/input[0]:128/input[1]:1280/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/BATCHNORM_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_128__588237890413397667<CUDNN_BATCHNORM_SPATIAL>/input[0]:128/input[1]:1280/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 3044,
      "real_time": 2.2990686885922909e+05,
      "cpu_time": 2.3583398390213132e+05,
      "time_unit": "ns",
      "items_per_second": 3.4919182884072960e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 1.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)1; bool is_training = true]": 1.2389518253260638e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 1.2800000000000000e+03,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 1.2800000000000000e+03,
      "input_height": 7.0000000000000000e+00,
      "input_size": 8.0281600000000000e+06,
      "input_width": 7.0000000000000000e+00,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 3.0440000000000000e+03,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 1.2800000000000000e+03,
      "output_height": 7.0000000000000000e+00,
      "output_size": 8.0281600000000000e+06,
      "output_width": 7.0000000000000000e+00,
      "predicted_flops": 3.4919182884072960e+10,
      "predicted_flops_count": 8.0281600000000000e+06
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_128__588237890413397667<CUDNN_BATCHNORM_SPATIAL_PERSISTENT>/input[0]:128/input[1]:1280/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 3044,
      "real_time": 2.2985211979751854e+05,
      "cpu_time": 2.3572223751602400e+05,
      "time_unit": "ns",
      "items_per_second": 3.4927500373162407e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 2.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)2; bool is_training = true]": 8.6489340726076344e+18,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 1.2800000000000000e+03,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 1.2800000000000000e+03,
      "input_height": 7.0000000000000000e+00,
      "input_size": 8.0281600000000000e+06,
      "input_width": 7.0000000000000000e+00,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 3.0440000000000000e+03,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 1.2800000000000000e+03,
      "output_height": 7.0000000000000000e+00,
      "output_size": 8.0281600000000000e+06,
      "output_width": 7.0000000000000000e+00,
      "predicted_flops": 3.4927500373162407e+10,
      "predicted_flops_count": 8.0281600000000000e+06
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_128__17475387745110757518<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:1/input[1]:992/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 111709,
      "real_time": 6.2549949875384318e+03,
      "cpu_time": 1.1374006543795575e+04,
      "time_unit": "ns",
      "items_per_second": 7.7710693768483763e+09,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = false]": 1.4627515035010154e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 9.9200000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 9.9200000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 4.8608000000000000e+04,
      "input_width": 7.0000000000000000e+00,
      "is_training": 0.0000000000000000e+00,
      "num_iterations": 1.1170900000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 9.9200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 4.8608000000000000e+04,
      "output_width": 7.0000000000000000e+00,
      "predicted_flops": 7.7710693768483763e+09,
      "predicted_flops_count": 4.8608000000000000e+04
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_128__2138153938436281765<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:1/input[1]:992/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 57075,
      "real_time": 1.2247121376627054e+04,
      "cpu_time": 1.7463711309551429e+04,
      "time_unit": "ns",
      "items_per_second": 3.9689326581481957e+09,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = true]": 9.0033003156525926e+18,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 9.9200000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 9.9200000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 4.8608000000000000e+04,
      "input_width": 7.0000000000000000e+00,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 5.7075000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 9.9200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 4.8608000000000000e+04,
      "output_width": 7.0000000000000000e+00,
      "predicted_flops": 3.9689326581481957e+09,
      "predicted_flops_count": 4.8608000000000000e+04
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_128__9315111828153586377<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:128/input[1]:192/input[2]:56/input[3]:56/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 246,
      "real_time": 2.8556680024745381e+06,
      "cpu_time": 2.9765781463394398e+06,
      "time_unit": "ns",
      "items_per_second": 2.6988549065653221e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = false]": 1.4627515035010154e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 1.9200000000000000e+02,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 1.9200000000000000e+02,
      "input_height": 5.6000000000000000e+01,
      "input_size": 7.7070336000000000e+07,
      "input_width": 5.6000000000000000e+01,
      "is_training": 0.0000000000000000e+00,
      "num_iterations": 2.4600000000000000e+02,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 1.9200000000000000e+02,
      "output_height": 5.6000000000000000e+01,
      "output_size": 7.7070336000000000e+07,
      "output_width": 5.6000000000000000e+01,
      "predicted_flops": 2.6988549065653221e+10,
      "predicted_flops_count": 7.7070336000000000e+07
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_128__7956980828447184866<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:128/input[1]:192/input[2]:56/input[3]:56/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 160,
      "real_time": 4.3747928080847487e+06,
      "cpu_time": 4.6534693125025230e+06,
      "time_unit": "ns",
      "items_per_second": 1.7616911104354862e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = true]": 9.0033003156525926e+18,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 1.9200000000000000e+02,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 1.9200000000000000e+02,
      "input_height": 5.6000000000000000e+01,
      "input_size": 7.7070336000000000e+07,
      "input_width": 5.6000000000000000e+01,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 1.6000000000000000e+02,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 1.9200000000000000e+02,
      "output_height": 5.6000000000000000e+01,
      "output_size": 7.7070336000000000e+07,
      "output_width": 5.6000000000000000e+01,
      "predicted_flops": 1.7616911104354862e+10,
      "predicted_flops_count": 7.7070336000000000e+07
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_128__11704208335948976675<CUDNN_BATCHNORM_SPATIAL>/input[0]:128/input[1]:960/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 3099,
      "real_time": 2.2591831498388227e+05,
      "cpu_time": 2.3177129235189644e+05,
      "time_unit": "ns",
      "items_per_second": 2.6651756854815273e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 1.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)1; bool is_training = false]": 7.0429798546002954e+18,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 9.6000000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 9.6000000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 6.0211200000000000e+06,
      "input_width": 7.0000000000000000e+00,
      "is_training": 0.0000000000000000e+00,
      "num_iterations": 3.0990000000000000e+03,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 9.6000000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 6.0211200000000000e+06,
      "output_width": 7.0000000000000000e+00,
      "predicted_flops": 2.6651756854815273e+10,
      "predicted_flops_count": 6.0211200000000000e+06
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_128__11704208335948976675<CUDNN_BATCHNORM_SPATIAL_PERSISTENT>/input[0]:128/input[1]:960/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/BATCHNORM_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_128__1925860343640687548<CUDNN_BATCHNORM_SPATIAL>/input[0]:128/input[1]:960/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 3950,
      "real_time": 1.7719370511557930e+05,
      "cpu_time": 1.8278834582240132e+05,
      "time_unit": "ns",
      "items_per_second": 3.3980439632844543e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 1.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)1; bool is_training = true]": 1.2389518253260638e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 9.6000000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 9.6000000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 6.0211200000000000e+06,
      "input_width": 7.0000000000000000e+00,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 3.9500000000000000e+03,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 9.6000000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 6.0211200000000000e+06,
      "output_width": 7.0000000000000000e+00,
      "predicted_flops": 3.3980439632844543e+10,
      "predicted_flops_count": 6.0211200000000000e+06
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_128__1925860343640687548<CUDNN_BATCHNORM_SPATIAL_PERSISTENT>/input[0]:128/input[1]:960/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 3950,
      "real_time": 1.7718141551477293e+05,
      "cpu_time": 1.8278443367071764e+05,
      "time_unit": "ns",
      "items_per_second": 3.3982796573255589e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 2.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)2; bool is_training = true]": 8.6489340726076344e+18,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 9.6000000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 9.6000000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 6.0211200000000000e+06,
      "input_width": 7.0000000000000000e+00,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 3.9500000000000000e+03,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 9.6000000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 6.0211200000000000e+06,
      "output_width": 7.0000000000000000e+00,
      "predicted_flops": 3.3982796573255589e+10,
      "predicted_flops_count": 6.0211200000000000e+06
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_128__2997144610040967143<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:1/input[1]:128/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 139129,
      "real_time": 4.9989278647263836e+03,
      "cpu_time": 1.0089653522969484e+04,
      "time_unit": "ns",
      "items_per_second": 1.2546690349858246e+09,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = false]": 1.4627515035010154e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 1.2800000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 1.2800000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 6.2720000000000000e+03,
      "input_width": 7.0000000000000000e+00,
      "is_training": 0.0000000000000000e+00,
      "num_iterations": 1.3912900000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 6.2720000000000000e+03,
      "output_width": 7.0000000000000000e+00,
      "predicted_flops": 1.2546690349858246e+09,
      "predicted_flops_count": 6.2720000000000000e+03
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_128__14321108276352494284<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:1/input[1]:128/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 84432,
      "real_time": 8.2860256543829528e+03,
      "cpu_time": 1.3493555997837919e+04,
      "time_unit": "ns",
      "items_per_second": 7.5693707232035673e+08,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = true]": 9.0033003156525926e+18,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 1.2800000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 1.2800000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 6.2720000000000000e+03,
      "input_width": 7.0000000000000000e+00,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 8.4432000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 6.2720000000000000e+03,
      "output_width": 7.0000000000000000e+00,
      "predicted_flops": 7.5693707232035673e+08,
      "predicted_flops_count": 6.2720000000000000e+03
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_128__13047406773353044781<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:1/input[1]:800/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 118000,
      "real_time": 5.8886161619215018e+03,
      "cpu_time": 1.0940536711905803e+04,
      "time_unit": "ns",
      "items_per_second": 6.6569120693390083e+09,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = false]": 1.4627515035010154e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 8.0000000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 8.0000000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 3.9200000000000000e+04,
      "input_width": 7.0000000000000000e+00,
      "is_training": 0.0000000000000000e+00,
      "num_iterations": 1.1800000000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 8.0000000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 3.9200000000000000e+04,
      "output_width": 7.0000000000000000e+00,
      "predicted_flops": 6.6569120693390083e+09,
      "predicted_flops_count": 3.9200000000000000e+04
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_128__6501087248181206534<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:1/input[1]:800/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 59711,
      "real_time": 1.1737909378155886e+04,
      "cpu_time": 1.6986507829371549e+04,
      "time_unit": "ns",
      "items_per_second": 3.3396066315651360e+09,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = true]": 9.0033003156525926e+18,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 8.0000000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 8.0000000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 3.9200000000000000e+04,
      "input_width": 7.0000000000000000e+00,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 5.9711000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 8.0000000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 3.9200000000000000e+04,
      "output_width": 7.0000000000000000e+00,
      "predicted_flops": 3.3396066315651360e+09,
      "predicted_flops_count": 3.9200000000000000e+04
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_128__10360143998073788507<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:1/input[1]:832/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 117995,
      "real_time": 5.9612844906840837e+03,
      "cpu_time": 1.1042587050409691e+04,
      "time_unit": "ns",
      "items_per_second": 6.8387945691418743e+09,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = false]": 1.4627515035010154e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 8.3200000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 8.3200000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 4.0768000000000000e+04,
      "input_width": 7.0000000000000000e+00,
      "is_training": 0.0000000000000000e+00,
      "num_iterations": 1.1799500000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 8.3200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 4.0768000000000000e+04,
      "output_width": 7.0000000000000000e+00,
      "predicted_flops": 6.8387945691418743e+09,
      "predicted_flops_count": 4.0768000000000000e+04
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_128__6984963373239049584<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:1/input[1]:832/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 59487,
      "real_time": 1.1759533930072761e+04,
      "cpu_time": 1.6961201506236917e+04,
      "time_unit": "ns",
      "items_per_second": 3.4668040623398886e+09,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = true]": 9.0033003156525926e+18,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 8.3200000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 8.3200000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 4.0768000000000000e+04,
      "input_width": 7.0000000000000000e+00,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 5.9487000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 8.3200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 4.0768000000000000e+04,
      "output_width": 7.0000000000000000e+00,
      "predicted_flops": 3.4668040623398886e+09,
      "predicted_flops_count": 4.0768000000000000e+04
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_128__12668583987080541220<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:1/input[1]:512/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 123579,
      "real_time": 5.6531927393040869e+03,
      "cpu_time": 1.0730072156202905e+04,
      "time_unit": "ns",
      "items_per_second": 4.4378462148609419e+09,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = false]": 1.4627515035010154e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 2.5088000000000000e+04,
      "input_width": 7.0000000000000000e+00,
      "is_training": 0.0000000000000000e+00,
      "num_iterations": 1.2357900000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 2.5088000000000000e+04,
      "output_width": 7.0000000000000000e+00,
      "predicted_flops": 4.4378462148609419e+09,
      "predicted_flops_count": 2.5088000000000000e+04
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_128__4676681718138237199<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:1/input[1]:512/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 74461,
      "real_time": 9.4024248055723947e+03,
      "cpu_time": 1.4573529364561840e+04,
      "time_unit": "ns",
      "items_per_second": 2.6682478742219210e+09,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = true]": 9.0033003156525926e+18,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 2.5088000000000000e+04,
      "input_width": 7.0000000000000000e+00,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 7.4461000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 2.5088000000000000e+04,
      "output_width": 7.0000000000000000e+00,
      "predicted_flops": 2.6682478742219210e+09,
      "predicted_flops_count": 2.5088000000000000e+04
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_128__12384897384250453501<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:128/input[1]:128/input[2]:100/input[3]:100/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 115,
      "real_time": 6.0885551102135489e+06,
      "cpu_time": 6.6241696260832483e+06,
      "time_unit": "ns",
      "items_per_second": 2.6909504313290760e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = false]": 1.4627515035010154e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 1.2800000000000000e+02,
      "input[2]": 1.0000000000000000e+02,
      "input[3]": 1.0000000000000000e+02,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 1.2800000000000000e+02,
      "input_height": 1.0000000000000000e+02,
      "input_size": 1.6384000000000000e+08,
      "input_width": 1.0000000000000000e+02,
      "is_training": 0.0000000000000000e+00,
      "num_iterations": 1.1500000000000000e+02,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 1.0000000000000000e+02,
      "output_size": 1.6384000000000000e+08,
      "output_width": 1.0000000000000000e+02,
      "predicted_flops": 2.6909504313290760e+10,
      "predicted_flops_count": 1.6384000000000000e+08
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_128__4969385398741231830<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:128/input[1]:128/input[2]:100/input[3]:100/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 74,
      "real_time": 9.3959667090628594e+06,
      "cpu_time": 1.0665109689195585e+07,
      "time_unit": "ns",
      "items_per_second": 1.7437269104196430e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = true]": 9.0033003156525926e+18,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 1.2800000000000000e+02,
      "input[2]": 1.0000000000000000e+02,
      "input[3]": 1.0000000000000000e+02,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 1.2800000000000000e+02,
      "input_height": 1.0000000000000000e+02,
      "input_size": 1.6384000000000000e+08,
      "input_width": 1.0000000000000000e+02,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 7.4000000000000000e+01,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 1.0000000000000000e+02,
      "output_size": 1.6384000000000000e+08,
      "output_width": 1.0000000000000000e+02,
      "predicted_flops": 1.7437269104196430e+10,
      "predicted_flops_count": 1.6384000000000000e+08
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_128__11734954346342802385<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:128/input[1]:96/input[2]:28/input[3]:28/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 2267,
      "real_time": 3.0912983854250744e+05,
      "cpu_time": 3.1563738685327751e+05,
      "time_unit": "ns",
      "items_per_second": 3.1164225509325230e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = false]": 1.4627515035010154e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 9.6000000000000000e+01,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 9.6000000000000000e+01,
      "input_height": 2.8000000000000000e+01,
      "input_size": 9.6337920000000000e+06,
      "input_width": 2.8000000000000000e+01,
      "is_training": 0.0000000000000000e+00,
      "num_iterations": 2.2670000000000000e+03,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 9.6000000000000000e+01,
      "output_height": 2.8000000000000000e+01,
      "output_size": 9.6337920000000000e+06,
      "output_width": 2.8000000000000000e+01,
      "predicted_flops": 3.1164225509325230e+10,
      "predicted_flops_count": 9.6337920000000000e+06
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_128__5617077186497488634<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:128/input[1]:96/input[2]:28/input[3]:28/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 1426,
      "real_time": 4.9091596927834727e+05,
      "cpu_time": 4.9951893969161890e+05,
      "time_unit": "ns",
      "items_per_second": 1.9624116147946453e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = true]": 9.0033003156525926e+18,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 9.6000000000000000e+01,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 9.6000000000000000e+01,
      "input_height": 2.8000000000000000e+01,
      "input_size": 9.6337920000000000e+06,
      "input_width": 2.8000000000000000e+01,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 1.4260000000000000e+03,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 9.6000000000000000e+01,
      "output_height": 2.8000000000000000e+01,
      "output_size": 9.6337920000000000e+06,
      "output_width": 2.8000000000000000e+01,
      "predicted_flops": 1.9624116147946453e+10,
      "predicted_flops_count": 9.6337920000000000e+06
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_128__11782951207299271753<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:1/input[1]:864/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 116820,
      "real_time": 5.9616827586120189e+03,
      "cpu_time": 1.0988903500897080e+04,
      "time_unit": "ns",
      "items_per_second": 7.1013506947921762e+09,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = false]": 1.4627515035010154e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 8.6400000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 8.6400000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 4.2336000000000000e+04,
      "input_width": 7.0000000000000000e+00,
      "is_training": 0.0000000000000000e+00,
      "num_iterations": 1.1682000000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 8.6400000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 4.2336000000000000e+04,
      "output_width": 7.0000000000000000e+00,
      "predicted_flops": 7.1013506947921762e+09,
      "predicted_flops_count": 4.2336000000000000e+04
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_128__5524861816150624610<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:1/input[1]:864/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 59222,
      "real_time": 1.2155884838231199e+04,
      "cpu_time": 1.7547536489659185e+04,
      "time_unit": "ns",
      "items_per_second": 3.4827575749031448e+09,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = true]": 9.0033003156525926e+18,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 8.6400000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 8.6400000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 4.2336000000000000e+04,
      "input_width": 7.0000000000000000e+00,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 5.9222000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 8.6400000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 4.2336000000000000e+04,
      "output_width": 7.0000000000000000e+00,
      "predicted_flops": 3.4827575749031448e+09,
      "predicted_flops_count": 4.2336000000000000e+04
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_128__5187831624680532546<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:128/input[1]:32/input[2]:28/input[3]:28/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 9471,
      "real_time": 7.3891905796511157e+04,
      "cpu_time": 7.9436299123825796e+04,
      "time_unit": "ns",
      "items_per_second": 4.3458941346612572e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = false]": 1.4627515035010154e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 3.2000000000000000e+01,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 3.2000000000000000e+01,
      "input_height": 2.8000000000000000e+01,
      "input_size": 3.2112640000000000e+06,
      "input_width": 2.8000000000000000e+01,
      "is_training": 0.0000000000000000e+00,
      "num_iterations": 9.4710000000000000e+03,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 3.2000000000000000e+01,
      "output_height": 2.8000000000000000e+01,
      "output_size": 3.2112640000000000e+06,
      "output_width": 2.8000000000000000e+01,
      "predicted_flops": 4.3458941346612572e+10,
      "predicted_flops_count": 3.2112640000000000e+06
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_128__12166424215969116009<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:128/input[1]:32/input[2]:28/input[3]:28/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 5179,
      "real_time": 1.3512527758395777e+05,
      "cpu_time": 1.4089444564646875e+05,
      "time_unit": "ns",
      "items_per_second": 2.3765087165165943e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = true]": 9.0033003156525926e+18,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 3.2000000000000000e+01,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 3.2000000000000000e+01,
      "input_height": 2.8000000000000000e+01,
      "input_size": 3.2112640000000000e+06,
      "input_width": 2.8000000000000000e+01,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 5.1790000000000000e+03,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 3.2000000000000000e+01,
      "output_height": 2.8000000000000000e+01,
      "output_size": 3.2112640000000000e+06,
      "output_width": 2.8000000000000000e+01,
      "predicted_flops": 2.3765087165165943e+10,
      "predicted_flops_count": 3.2112640000000000e+06
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_128__11942918449905572021<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:128/input[1]:160/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 7680,
      "real_time": 9.0887788902212676e+04,
      "cpu_time": 9.6143360156745563e+04,
      "time_unit": "ns",
      "items_per_second": 4.4165228888105080e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = false]": 1.4627515035010154e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 1.6000000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 1.6000000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 4.0140800000000000e+06,
      "input_width": 1.4000000000000000e+01,
      "is_training": 0.0000000000000000e+00,
      "num_iterations": 7.6800000000000000e+03,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 1.6000000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 4.0140800000000000e+06,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 4.4165228888105080e+10,
      "predicted_flops_count": 4.0140800000000000e+06
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_128__5374190944331947422<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:128/input[1]:160/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 4211,
      "real_time": 1.6613259270824396e+05,
      "cpu_time": 1.7169296176733769e+05,
      "time_unit": "ns",
      "items_per_second": 2.4161905466974697e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = true]": 9.0033003156525926e+18,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 1.6000000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 1.6000000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 4.0140800000000000e+06,
      "input_width": 1.4000000000000000e+01,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 4.2110000000000000e+03,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 1.6000000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 4.0140800000000000e+06,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 2.4161905466974697e+10,
      "predicted_flops_count": 4.0140800000000000e+06
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_128__15427634327624673709<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:128/input[1]:224/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 5513,
      "real_time": 1.2700150477787442e+05,
      "cpu_time": 1.3238991347727677e+05,
      "time_unit": "ns",
      "items_per_second": 4.4249176494631882e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = false]": 1.4627515035010154e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 2.2400000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 2.2400000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 5.6197120000000000e+06,
      "input_width": 1.4000000000000000e+01,
      "is_training": 0.0000000000000000e+00,
      "num_iterations": 5.5130000000000000e+03,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 2.2400000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 5.6197120000000000e+06,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 4.4249176494631882e+10,
      "predicted_flops_count": 5.6197120000000000e+06
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_128__4121009798753987718<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:128/input[1]:224/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 2981,
      "real_time": 2.3426083685109796e+05,
      "cpu_time": 2.4025554008723609e+05,
      "time_unit": "ns",
      "items_per_second": 2.3989122874909004e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = true]": 9.0033003156525926e+18,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 2.2400000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 2.2400000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 5.6197120000000000e+06,
      "input_width": 1.4000000000000000e+01,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 2.9810000000000000e+03,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 2.2400000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 5.6197120000000000e+06,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 2.3989122874909004e+10,
      "predicted_flops_count": 5.6197120000000000e+06
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_128__10412202008746128787<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:1/input[1]:896/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 115446,
      "real_time": 6.0456963436963861e+03,
      "cpu_time": 1.1084575983642620e+04,
      "time_unit": "ns",
      "items_per_second": 7.2620253324130316e+09,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = false]": 1.4627515035010154e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 8.9600000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 8.9600000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 4.3904000000000000e+04,
      "input_width": 7.0000000000000000e+00,
      "is_training": 0.0000000000000000e+00,
      "num_iterations": 1.1544600000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 8.9600000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 4.3904000000000000e+04,
      "output_width": 7.0000000000000000e+00,
      "predicted_flops": 7.2620253324130316e+09,
      "predicted_flops_count": 4.3904000000000000e+04
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_128__9175699080733110456<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:1/input[1]:896/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 58226,
      "real_time": 1.2000107238078479e+04,
      "cpu_time": 1.7181283533214617e+04,
      "time_unit": "ns",
      "items_per_second": 3.6586339712602553e+09,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = true]": 9.0033003156525926e+18,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 8.9600000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 8.9600000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 4.3904000000000000e+04,
      "input_width": 7.0000000000000000e+00,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 5.8226000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 8.9600000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 4.3904000000000000e+04,
      "output_width": 7.0000000000000000e+00,
      "predicted_flops": 3.6586339712602553e+09,
      "predicted_flops_count": 4.3904000000000000e+04
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_128__10608086617193583488<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:128/input[1]:128/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 9550,
      "real_time": 7.3301152966755646e+04,
      "cpu_time": 7.8495928062798324e+04,
      "time_unit": "ns",
      "items_per_second": 4.3809188123635765e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = false]": 1.4627515035010154e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 1.2800000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 1.2800000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 3.2112640000000000e+06,
      "input_width": 1.4000000000000000e+01,
      "is_training": 0.0000000000000000e+00,
      "num_iterations": 9.5500000000000000e+03,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 3.2112640000000000e+06,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 4.3809188123635765e+10,
      "predicted_flops_count": 3.2112640000000000e+06
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_128__8943671321744922283<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:128/input[1]:128/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 5202,
      "real_time": 1.3454123487038020e+05,
      "cpu_time": 1.3996165244142988e+05,
      "time_unit": "ns",
      "items_per_second": 2.3868251269536793e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = true]": 9.0033003156525926e+18,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 1.2800000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 1.2800000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 3.2112640000000000e+06,
      "input_width": 1.4000000000000000e+01,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 5.2020000000000000e+03,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 3.2112640000000000e+06,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 2.3868251269536793e+10,
      "predicted_flops_count": 3.2112640000000000e+06
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_128__8808396215514917642<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:128/input[1]:256/input[2]:100/input[3]:100/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 58,
      "real_time": 1.2128937427468341e+07,
      "cpu_time": 1.4230754206899857e+07,
      "time_unit": "ns",
      "items_per_second": 2.7016381439804020e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = false]": 1.4627515035010154e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 1.0000000000000000e+02,
      "input[3]": 1.0000000000000000e+02,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 1.0000000000000000e+02,
      "input_size": 3.2768000000000000e+08,
      "input_width": 1.0000000000000000e+02,
      "is_training": 0.0000000000000000e+00,
      "num_iterations": 5.8000000000000000e+01,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 1.0000000000000000e+02,
      "output_size": 3.2768000000000000e+08,
      "output_width": 1.0000000000000000e+02,
      "predicted_flops": 2.7016381439804020e+10,
      "predicted_flops_count": 3.2768000000000000e+08
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_128__10742358951715352097<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:128/input[1]:256/input[2]:100/input[3]:100/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 37,
      "real_time": 1.8820560461766012e+07,
      "cpu_time": 2.3901548216209400e+07,
      "time_unit": "ns",
      "items_per_second": 1.7410746118091557e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = true]": 9.0033003156525926e+18,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 1.0000000000000000e+02,
      "input[3]": 1.0000000000000000e+02,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 1.0000000000000000e+02,
      "input_size": 3.2768000000000000e+08,
      "input_width": 1.0000000000000000e+02,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 3.7000000000000000e+01,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 1.0000000000000000e+02,
      "output_size": 3.2768000000000000e+08,
      "output_width": 1.0000000000000000e+02,
      "predicted_flops": 1.7410746118091557e+10,
      "predicted_flops_count": 3.2768000000000000e+08
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_128__17490820606047731802<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:128/input[1]:1024/input[2]:100/input[3]:100/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 14,
      "real_time": 4.8443748482636042e+07,
      "cpu_time": 8.3000724928565115e+07,
      "time_unit": "ns",
      "items_per_second": 2.7056535488161255e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = false]": 1.4627515035010154e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 1.0240000000000000e+03,
      "input[2]": 1.0000000000000000e+02,
      "input[3]": 1.0000000000000000e+02,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 1.0240000000000000e+03,
      "input_height": 1.0000000000000000e+02,
      "input_size": 1.3107200000000000e+09,
      "input_width": 1.0000000000000000e+02,
      "is_training": 0.0000000000000000e+00,
      "num_iterations": 1.4000000000000000e+01,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 1.0240000000000000e+03,
      "output_height": 1.0000000000000000e+02,
      "output_size": 1.3107200000000000e+09,
      "output_width": 1.0000000000000000e+02,
      "predicted_flops": 2.7056535488161255e+10,
      "predicted_flops_count": 1.3107200000000000e+09
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_128__2130998218146481521<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:128/input[1]:1024/input[2]:100/input[3]:100/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 9,
      "real_time": 8.1831438673867121e+07,
      "cpu_time": 1.7276266877776277e+08,
      "time_unit": "ns",
      "items_per_second": 1.6017315853675425e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = true]": 9.0033003156525926e+18,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 1.0240000000000000e+03,
      "input[2]": 1.0000000000000000e+02,
      "input[3]": 1.0000000000000000e+02,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 1.0240000000000000e+03,
      "input_height": 1.0000000000000000e+02,
      "input_size": 1.3107200000000000e+09,
      "input_width": 1.0000000000000000e+02,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 9.0000000000000000e+00,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 1.0240000000000000e+03,
      "output_height": 1.0000000000000000e+02,
      "output_size": 1.3107200000000000e+09,
      "output_width": 1.0000000000000000e+02,
      "predicted_flops": 1.6017315853675425e+10,
      "predicted_flops_count": 1.3107200000000000e+09
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_128__1700967414942911679<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:128/input[1]:64/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 17648,
      "real_time": 3.9622877497917951e+04,
      "cpu_time": 4.4769594629134503e+04,
      "time_unit": "ns",
      "items_per_second": 4.0522851983285934e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = false]": 1.4627515035010154e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 1.4000000000000000e+01,
      "input_size": 1.6056320000000000e+06,
      "input_width": 1.4000000000000000e+01,
      "is_training": 0.0000000000000000e+00,
      "num_iterations": 1.7648000000000000e+04,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 1.4000000000000000e+01,
      "output_size": 1.6056320000000000e+06,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 4.0522851983285934e+10,
      "predicted_flops_count": 1.6056320000000000e+06
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_128__17920456130547255700<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:128/input[1]:64/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 9515,
      "real_time": 7.3615288662519146e+04,
      "cpu_time": 7.8893880504151370e+04,
      "time_unit": "ns",
      "items_per_second": 2.1811121428333130e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = true]": 9.0033003156525926e+18,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 1.4000000000000000e+01,
      "input_size": 1.6056320000000000e+06,
      "input_width": 1.4000000000000000e+01,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 9.5150000000000000e+03,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 1.4000000000000000e+01,
      "output_size": 1.6056320000000000e+06,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 2.1811121428333130e+10,
      "predicted_flops_count": 1.6056320000000000e+06
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_128__8685481160810607313<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:128/input[1]:96/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 12353,
      "real_time": 5.6687004469423438e+04,
      "cpu_time": 6.1846740954329456e+04,
      "time_unit": "ns",
      "items_per_second": 4.2486774923855774e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = false]": 1.4627515035010154e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 9.6000000000000000e+01,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 9.6000000000000000e+01,
      "input_height": 1.4000000000000000e+01,
      "input_size": 2.4084480000000000e+06,
      "input_width": 1.4000000000000000e+01,
      "is_training": 0.0000000000000000e+00,
      "num_iterations": 1.2353000000000000e+04,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 9.6000000000000000e+01,
      "output_height": 1.4000000000000000e+01,
      "output_size": 2.4084480000000000e+06,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 4.2486774923855774e+10,
      "predicted_flops_count": 2.4084480000000000e+06
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_128__10925790026858297338<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:128/input[1]:96/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 6736,
      "real_time": 1.0395353811093190e+05,
      "cpu_time": 1.0927603355126121e+05,
      "time_unit": "ns",
      "items_per_second": 2.3168504350759796e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = true]": 9.0033003156525926e+18,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 9.6000000000000000e+01,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 9.6000000000000000e+01,
      "input_height": 1.4000000000000000e+01,
      "input_size": 2.4084480000000000e+06,
      "input_width": 1.4000000000000000e+01,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 6.7360000000000000e+03,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 9.6000000000000000e+01,
      "output_height": 1.4000000000000000e+01,
      "output_size": 2.4084480000000000e+06,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 2.3168504350759796e+10,
      "predicted_flops_count": 2.4084480000000000e+06
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_128__10131216821502558429<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:128/input[1]:192/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 6441,
      "real_time": 1.0869872841616659e+05,
      "cpu_time": 1.1398170858568785e+05,
      "time_unit": "ns",
      "items_per_second": 4.4314189045136894e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = false]": 1.4627515035010154e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 1.9200000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 1.9200000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 4.8168960000000000e+06,
      "input_width": 1.4000000000000000e+01,
      "is_training": 0.0000000000000000e+00,
      "num_iterations": 6.4410000000000000e+03,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 1.9200000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 4.8168960000000000e+06,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 4.4314189045136894e+10,
      "predicted_flops_count": 4.8168960000000000e+06
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_128__7183350501852644854<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:128/input[1]:192/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 3499,
      "real_time": 1.9988296412839281e+05,
      "cpu_time": 2.0565569619901889e+05,
      "time_unit": "ns",
      "items_per_second": 2.4098581992740089e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = true]": 9.0033003156525926e+18,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 1.9200000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 1.9200000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 4.8168960000000000e+06,
      "input_width": 1.4000000000000000e+01,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 3.4990000000000000e+03,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 1.9200000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 4.8168960000000000e+06,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 2.4098581992740089e+10,
      "predicted_flops_count": 4.8168960000000000e+06
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_128__526845759088817605<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:128/input[1]:160/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 25810,
      "real_time": 2.7110319567307590e+04,
      "cpu_time": 3.2230324564646548e+04,
      "time_unit": "ns",
      "items_per_second": 3.7016162701753891e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = false]": 1.4627515035010154e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 1.6000000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 1.6000000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 1.0035200000000000e+06,
      "input_width": 7.0000000000000000e+00,
      "is_training": 0.0000000000000000e+00,
      "num_iterations": 2.5810000000000000e+04,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 1.6000000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 1.0035200000000000e+06,
      "output_width": 7.0000000000000000e+00,
      "predicted_flops": 3.7016162701753891e+10,
      "predicted_flops_count": 1.0035200000000000e+06
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_128__16746222142910804206<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:128/input[1]:160/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 13778,
      "real_time": 5.0755326517143199e+04,
      "cpu_time": 5.5946690666646413e+04,
      "time_unit": "ns",
      "items_per_second": 1.9771717942964066e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = true]": 9.0033003156525926e+18,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 1.6000000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 1.6000000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 1.0035200000000000e+06,
      "input_width": 7.0000000000000000e+00,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 1.3778000000000000e+04,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 1.6000000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 1.0035200000000000e+06,
      "output_width": 7.0000000000000000e+00,
      "predicted_flops": 1.9771717942964066e+10,
      "predicted_flops_count": 1.0035200000000000e+06
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_128__7394299333228314911<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:128/input[1]:256/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 17657,
      "real_time": 3.9630108739791976e+04,
      "cpu_time": 4.4791701875367435e+04,
      "time_unit": "ns",
      "items_per_second": 4.0515457843995522e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = false]": 1.4627515035010154e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 1.6056320000000000e+06,
      "input_width": 7.0000000000000000e+00,
      "is_training": 0.0000000000000000e+00,
      "num_iterations": 1.7657000000000000e+04,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 1.6056320000000000e+06,
      "output_width": 7.0000000000000000e+00,
      "predicted_flops": 4.0515457843995522e+10,
      "predicted_flops_count": 1.6056320000000000e+06
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_128__9922810056844837940<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:128/input[1]:256/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 9501,
      "real_time": 7.3618500737251641e+04,
      "cpu_time": 7.8848361856856529e+04,
      "time_unit": "ns",
      "items_per_second": 2.1810169779612686e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = true]": 9.0033003156525926e+18,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 1.6056320000000000e+06,
      "input_width": 7.0000000000000000e+00,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 9.5010000000000000e+03,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 1.6056320000000000e+06,
      "output_width": 7.0000000000000000e+00,
      "predicted_flops": 2.1810169779612686e+10,
      "predicted_flops_count": 1.6056320000000000e+06
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_128__5195681524022659666<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:128/input[1]:512/input[2]:100/input[3]:100/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 29,
      "real_time": 2.4294791614701007e+07,
      "cpu_time": 3.2678829034482297e+07,
      "time_unit": "ns",
      "items_per_second": 2.6975329132003563e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = false]": 1.4627515035010154e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 1.0000000000000000e+02,
      "input[3]": 1.0000000000000000e+02,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 1.0000000000000000e+02,
      "input_size": 6.5536000000000000e+08,
      "input_width": 1.0000000000000000e+02,
      "is_training": 0.0000000000000000e+00,
      "num_iterations": 2.9000000000000000e+01,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 1.0000000000000000e+02,
      "output_size": 6.5536000000000000e+08,
      "output_width": 1.0000000000000000e+02,
      "predicted_flops": 2.6975329132003563e+10,
      "predicted_flops_count": 6.5536000000000000e+08
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_128__12048246021289676665<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:128/input[1]:512/input[2]:100/input[3]:100/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 19,
      "real_time": 3.7791897591791652e+07,
      "cpu_time": 5.7634606000006936e+07,
      "time_unit": "ns",
      "items_per_second": 1.7341283231629608e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = true]": 9.0033003156525926e+18,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 1.0000000000000000e+02,
      "input[3]": 1.0000000000000000e+02,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 1.0000000000000000e+02,
      "input_size": 6.5536000000000000e+08,
      "input_width": 1.0000000000000000e+02,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 1.9000000000000000e+01,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 1.0000000000000000e+02,
      "output_size": 6.5536000000000000e+08,
      "output_width": 1.0000000000000000e+02,
      "predicted_flops": 1.7341283231629608e+10,
      "predicted_flops_count": 6.5536000000000000e+08
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_128__7577871760015364520<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:128/input[1]:128/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 30784,
      "real_time": 2.2697181960959610e+04,
      "cpu_time": 2.7850527839198519e+04,
      "time_unit": "ns",
      "items_per_second": 3.5370734630443871e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = false]": 1.4627515035010154e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 1.2800000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 1.2800000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 8.0281600000000000e+05,
      "input_width": 7.0000000000000000e+00,
      "is_training": 0.0000000000000000e+00,
      "num_iterations": 3.0784000000000000e+04,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 8.0281600000000000e+05,
      "output_width": 7.0000000000000000e+00,
      "predicted_flops": 3.5370734630443871e+10,
      "predicted_flops_count": 8.0281600000000000e+05
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_128__9656615945388184707<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:128/input[1]:128/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 16543,
      "real_time": 4.2246632822725987e+04,
      "cpu_time": 4.7439386266108566e+04,
      "time_unit": "ns",
      "items_per_second": 1.9003076608939503e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = true]": 9.0033003156525926e+18,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 1.2800000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 1.2800000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 8.0281600000000000e+05,
      "input_width": 7.0000000000000000e+00,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 1.6543000000000000e+04,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 8.0281600000000000e+05,
      "output_width": 7.0000000000000000e+00,
      "predicted_flops": 1.9003076608939503e+10,
      "predicted_flops_count": 8.0281600000000000e+05
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_128__4496119707191152535<CUDNN_BATCHNORM_SPATIAL>/input[0]:128/input[1]:16/input[2]:416/input[3]:416/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 96,
      "real_time": 7.2905623383121565e+06,
      "cpu_time": 8.0566262291685110e+06,
      "time_unit": "ns",
      "items_per_second": 4.8613354025864037e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 1.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)1; bool is_training = false]": 7.0429798546002954e+18,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 1.6000000000000000e+01,
      "input[2]": 4.1600000000000000e+02,
      "input[3]": 4.1600000000000000e+02,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 1.6000000000000000e+01,
      "input_height": 4.1600000000000000e+02,
      "input_size": 3.5441868800000000e+08,
      "input_width": 4.1600000000000000e+02,
      "is_training": 0.0000000000000000e+00,
      "num_iterations": 9.6000000000000000e+01,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 1.6000000000000000e+01,
      "output_height": 4.1600000000000000e+02,
      "output_size": 3.5441868800000000e+08,
      "output_width": 4.1600000000000000e+02,
      "predicted_flops": 4.8613354025864037e+10,
      "predicted_flops_count": 3.5441868800000000e+08
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_128__4496119707191152535<CUDNN_BATCHNORM_SPATIAL_PERSISTENT>/input[0]:128/input[1]:16/input[2]:416/input[3]:416/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/BATCHNORM_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_128__9706059507243916808<CUDNN_BATCHNORM_SPATIAL>/input[0]:128/input[1]:16/input[2]:416/input[3]:416/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 45,
      "real_time": 1.5395477393435108e+07,
      "cpu_time": 1.8821581111104831e+07,
      "time_unit": "ns",
      "items_per_second": 2.3020961217554070e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 1.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)1; bool is_training = true]": 1.2389518253260638e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 1.6000000000000000e+01,
      "input[2]": 4.1600000000000000e+02,
      "input[3]": 4.1600000000000000e+02,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 1.6000000000000000e+01,
      "input_height": 4.1600000000000000e+02,
      "input_size": 3.5441868800000000e+08,
      "input_width": 4.1600000000000000e+02,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 4.5000000000000000e+01,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 1.6000000000000000e+01,
      "output_height": 4.1600000000000000e+02,
      "output_size": 3.5441868800000000e+08,
      "output_width": 4.1600000000000000e+02,
      "predicted_flops": 2.3020961217554070e+10,
      "predicted_flops_count": 3.5441868800000000e+08
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_128__9706059507243916808<CUDNN_BATCHNORM_SPATIAL_PERSISTENT>/input[0]:128/input[1]:16/input[2]:416/input[3]:416/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 45,
      "real_time": 1.5393941290676594e+07,
      "cpu_time": 1.8819561933325227e+07,
      "time_unit": "ns",
      "items_per_second": 2.3023258391576118e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 2.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)2; bool is_training = true]": 8.6489340726076344e+18,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 1.6000000000000000e+01,
      "input[2]": 4.1600000000000000e+02,
      "input[3]": 4.1600000000000000e+02,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 1.6000000000000000e+01,
      "input_height": 4.1600000000000000e+02,
      "input_size": 3.5441868800000000e+08,
      "input_width": 4.1600000000000000e+02,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 4.5000000000000000e+01,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 1.6000000000000000e+01,
      "output_height": 4.1600000000000000e+02,
      "output_size": 3.5441868800000000e+08,
      "output_width": 4.1600000000000000e+02,
      "predicted_flops": 2.3023258391576118e+10,
      "predicted_flops_count": 3.5441868800000000e+08
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_128__4097505820209792395<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:128/input[1]:64/input[2]:28/input[3]:28/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 4733,
      "real_time": 1.4793831604260270e+05,
      "cpu_time": 1.5338288442905730e+05,
      "time_unit": "ns",
      "items_per_second": 4.3413553512062866e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = false]": 1.4627515035010154e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 2.8000000000000000e+01,
      "input_size": 6.4225280000000000e+06,
      "input_width": 2.8000000000000000e+01,
      "is_training": 0.0000000000000000e+00,
      "num_iterations": 4.7330000000000000e+03,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 2.8000000000000000e+01,
      "output_size": 6.4225280000000000e+06,
      "output_width": 2.8000000000000000e+01,
      "predicted_flops": 4.3413553512062866e+10,
      "predicted_flops_count": 6.4225280000000000e+06
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_128__15561186754250735776<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:128/input[1]:64/input[2]:28/input[3]:28/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 2604,
      "real_time": 2.6925038160508021e+05,
      "cpu_time": 2.7545701728200680e+05,
      "time_unit": "ns",
      "items_per_second": 2.3853366378585739e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = true]": 9.0033003156525926e+18,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 2.8000000000000000e+01,
      "input_size": 6.4225280000000000e+06,
      "input_width": 2.8000000000000000e+01,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 2.6040000000000000e+03,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 2.8000000000000000e+01,
      "output_size": 6.4225280000000000e+06,
      "output_width": 2.8000000000000000e+01,
      "predicted_flops": 2.3853366378585739e+10,
      "predicted_flops_count": 6.4225280000000000e+06
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_128__309343917831893305<CUDNN_BATCHNORM_SPATIAL>/input[0]:128/input[1]:512/input[2]:13/input[3]:13/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 3097,
      "real_time": 2.2647938146442352e+05,
      "cpu_time": 2.3235149241234540e+05,
      "time_unit": "ns",
      "items_per_second": 4.8903277324341354e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 1.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)1; bool is_training = false]": 7.0429798546002954e+18,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 1.3000000000000000e+01,
      "input[3]": 1.3000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 1.3000000000000000e+01,
      "input_size": 1.1075584000000000e+07,
      "input_width": 1.3000000000000000e+01,
      "is_training": 0.0000000000000000e+00,
      "num_iterations": 3.0970000000000000e+03,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 1.3000000000000000e+01,
      "output_size": 1.1075584000000000e+07,
      "output_width": 1.3000000000000000e+01,
      "predicted_flops": 4.8903277324341354e+10,
      "predicted_flops_count": 1.1075584000000000e+07
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_128__309343917831893305<CUDNN_BATCHNORM_SPATIAL_PERSISTENT>/input[0]:128/input[1]:512/input[2]:13/input[3]:13/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/BATCHNORM_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_128__13590937990952951974<CUDNN_BATCHNORM_SPATIAL>/input[0]:128/input[1]:512/input[2]:13/input[3]:13/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 2461,
      "real_time": 2.8460928850002325e+05,
      "cpu_time": 2.9090135473427986e+05,
      "time_unit": "ns",
      "items_per_second": 3.8915047567040649e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 1.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)1; bool is_training = true]": 1.2389518253260638e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 1.3000000000000000e+01,
      "input[3]": 1.3000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 1.3000000000000000e+01,
      "input_size": 1.1075584000000000e+07,
      "input_width": 1.3000000000000000e+01,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 2.4610000000000000e+03,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 1.3000000000000000e+01,
      "output_size": 1.1075584000000000e+07,
      "output_width": 1.3000000000000000e+01,
      "predicted_flops": 3.8915047567040649e+10,
      "predicted_flops_count": 1.1075584000000000e+07
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_128__13590937990952951974<CUDNN_BATCHNORM_SPATIAL_PERSISTENT>/input[0]:128/input[1]:512/input[2]:13/input[3]:13/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 2461,
      "real_time": 2.8454948880873190e+05,
      "cpu_time": 2.9085553311667388e+05,
      "time_unit": "ns",
      "items_per_second": 3.8923225785321198e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 2.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)2; bool is_training = true]": 8.6489340726076344e+18,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 1.3000000000000000e+01,
      "input[3]": 1.3000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 1.3000000000000000e+01,
      "input_size": 1.1075584000000000e+07,
      "input_width": 1.3000000000000000e+01,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 2.4610000000000000e+03,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 1.3000000000000000e+01,
      "output_size": 1.1075584000000000e+07,
      "output_width": 1.3000000000000000e+01,
      "predicted_flops": 3.8923225785321198e+10,
      "predicted_flops_count": 1.1075584000000000e+07
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_128__7006336951657907319<CUDNN_BATCHNORM_SPATIAL>/input[0]:128/input[1]:32/input[2]:208/input[3]:208/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 207,
      "real_time": 3.3792520655040150e+06,
      "cpu_time": 3.5476590048252670e+06,
      "time_unit": "ns",
      "items_per_second": 5.2440404138236214e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 1.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)1; bool is_training = false]": 7.0429798546002954e+18,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 3.2000000000000000e+01,
      "input[2]": 2.0800000000000000e+02,
      "input[3]": 2.0800000000000000e+02,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 3.2000000000000000e+01,
      "input_height": 2.0800000000000000e+02,
      "input_size": 1.7720934400000000e+08,
      "input_width": 2.0800000000000000e+02,
      "is_training": 0.0000000000000000e+00,
      "num_iterations": 2.0700000000000000e+02,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 3.2000000000000000e+01,
      "output_height": 2.0800000000000000e+02,
      "output_size": 1.7720934400000000e+08,
      "output_width": 2.0800000000000000e+02,
      "predicted_flops": 5.2440404138236214e+10,
      "predicted_flops_count": 1.7720934400000000e+08
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_128__7006336951657907319<CUDNN_BATCHNORM_SPATIAL_PERSISTENT>/input[0]:128/input[1]:32/input[2]:208/input[3]:208/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/BATCHNORM_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_128__15702986375770133992<CUDNN_BATCHNORM_SPATIAL>/input[0]:128/input[1]:32/input[2]:208/input[3]:208/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 125,
      "real_time": 5.6012111492455006e+06,
      "cpu_time": 6.0543862640033690e+06,
      "time_unit": "ns",
      "items_per_second": 3.1637683222113598e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 1.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)1; bool is_training = true]": 1.2389518253260638e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 3.2000000000000000e+01,
      "input[2]": 2.0800000000000000e+02,
      "input[3]": 2.0800000000000000e+02,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 3.2000000000000000e+01,
      "input_height": 2.0800000000000000e+02,
      "input_size": 1.7720934400000000e+08,
      "input_width": 2.0800000000000000e+02,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 1.2500000000000000e+02,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 3.2000000000000000e+01,
      "output_height": 2.0800000000000000e+02,
      "output_size": 1.7720934400000000e+08,
      "output_width": 2.0800000000000000e+02,
      "predicted_flops": 3.1637683222113598e+10,
      "predicted_flops_count": 1.7720934400000000e+08
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_128__15702986375770133992<CUDNN_BATCHNORM_SPATIAL_PERSISTENT>/input[0]:128/input[1]:32/input[2]:208/input[3]:208/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 125,
      "real_time": 5.6054141558706760e+06,
      "cpu_time": 6.0591375039957715e+06,
      "time_unit": "ns",
      "items_per_second": 3.1613960908562782e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 2.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)2; bool is_training = true]": 8.6489340726076344e+18,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 3.2000000000000000e+01,
      "input[2]": 2.0800000000000000e+02,
      "input[3]": 2.0800000000000000e+02,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 3.2000000000000000e+01,
      "input_height": 2.0800000000000000e+02,
      "input_size": 1.7720934400000000e+08,
      "input_width": 2.0800000000000000e+02,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 1.2500000000000000e+02,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 3.2000000000000000e+01,
      "output_height": 2.0800000000000000e+02,
      "output_size": 1.7720934400000000e+08,
      "output_width": 2.0800000000000000e+02,
      "predicted_flops": 3.1613960908562782e+10,
      "predicted_flops_count": 1.7720934400000000e+08
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_128__2272772328970393420<CUDNN_BATCHNORM_SPATIAL>/input[0]:128/input[1]:128/input[2]:52/input[3]:52/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 841,
      "real_time": 8.3200415686618956e+05,
      "cpu_time": 8.4703488584821334e+05,
      "time_unit": "ns",
      "items_per_second": 5.3247733961893059e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 1.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)1; bool is_training = false]": 7.0429798546002954e+18,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 1.2800000000000000e+02,
      "input[2]": 5.2000000000000000e+01,
      "input[3]": 5.2000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 1.2800000000000000e+02,
      "input_height": 5.2000000000000000e+01,
      "input_size": 4.4302336000000000e+07,
      "input_width": 5.2000000000000000e+01,
      "is_training": 0.0000000000000000e+00,
      "num_iterations": 8.4100000000000000e+02,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 5.2000000000000000e+01,
      "output_size": 4.4302336000000000e+07,
      "output_width": 5.2000000000000000e+01,
      "predicted_flops": 5.3247733961893059e+10,
      "predicted_flops_count": 4.4302336000000000e+07
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_128__2272772328970393420<CUDNN_BATCHNORM_SPATIAL_PERSISTENT>/input[0]:128/input[1]:128/input[2]:52/input[3]:52/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/BATCHNORM_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_128__12059855691650598611<CUDNN_BATCHNORM_SPATIAL>/input[0]:128/input[1]:128/input[2]:52/input[3]:52/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 461,
      "real_time": 1.5164166234369003e+06,
      "cpu_time": 1.5544364295015314e+06,
      "time_unit": "ns",
      "items_per_second": 2.9215147945022160e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 1.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)1; bool is_training = true]": 1.2389518253260638e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 1.2800000000000000e+02,
      "input[2]": 5.2000000000000000e+01,
      "input[3]": 5.2000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 1.2800000000000000e+02,
      "input_height": 5.2000000000000000e+01,
      "input_size": 4.4302336000000000e+07,
      "input_width": 5.2000000000000000e+01,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 4.6100000000000000e+02,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 5.2000000000000000e+01,
      "output_size": 4.4302336000000000e+07,
      "output_width": 5.2000000000000000e+01,
      "predicted_flops": 2.9215147945022160e+10,
      "predicted_flops_count": 4.4302336000000000e+07
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_128__12059855691650598611<CUDNN_BATCHNORM_SPATIAL_PERSISTENT>/input[0]:128/input[1]:128/input[2]:52/input[3]:52/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 589,
      "real_time": 1.1884852200635851e+06,
      "cpu_time": 1.2137892563672867e+06,
      "time_unit": "ns",
      "items_per_second": 3.7276303694908195e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 2.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)2; bool is_training = true]": 8.6489340726076344e+18,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 1.2800000000000000e+02,
      "input[2]": 5.2000000000000000e+01,
      "input[3]": 5.2000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 1.2800000000000000e+02,
      "input_height": 5.2000000000000000e+01,
      "input_size": 4.4302336000000000e+07,
      "input_width": 5.2000000000000000e+01,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 5.8900000000000000e+02,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 5.2000000000000000e+01,
      "output_size": 4.4302336000000000e+07,
      "output_width": 5.2000000000000000e+01,
      "predicted_flops": 3.7276303694908195e+10,
      "predicted_flops_count": 4.4302336000000000e+07
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_128__17743665713052587241<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:128/input[1]:2048/input[2]:100/input[3]:100/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD failed to cudnnSetTensor4dDescriptor",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_128__1807943229288829378<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:128/input[1]:2048/input[2]:100/input[3]:100/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD failed to cudnnSetTensor4dDescriptor",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_128__5722518830201903470<CUDNN_BATCHNORM_SPATIAL>/input[0]:128/input[1]:256/input[2]:26/input[3]:26/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 1572,
      "real_time": 4.4522794782902108e+05,
      "cpu_time": 4.5320840267258132e+05,
      "time_unit": "ns",
      "items_per_second": 4.9752420323143364e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 1.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)1; bool is_training = false]": 7.0429798546002954e+18,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 2.6000000000000000e+01,
      "input[3]": 2.6000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 2.6000000000000000e+01,
      "input_size": 2.2151168000000000e+07,
      "input_width": 2.6000000000000000e+01,
      "is_training": 0.0000000000000000e+00,
      "num_iterations": 1.5720000000000000e+03,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 2.6000000000000000e+01,
      "output_size": 2.2151168000000000e+07,
      "output_width": 2.6000000000000000e+01,
      "predicted_flops": 4.9752420323143364e+10,
      "predicted_flops_count": 2.2151168000000000e+07
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_128__5722518830201903470<CUDNN_BATCHNORM_SPATIAL_PERSISTENT>/input[0]:128/input[1]:256/input[2]:26/input[3]:26/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/BATCHNORM_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_128__17851649011920636145<CUDNN_BATCHNORM_SPATIAL>/input[0]:128/input[1]:256/input[2]:26/input[3]:26/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 916,
      "real_time": 7.6363503823146294e+05,
      "cpu_time": 7.7713846615948691e+05,
      "time_unit": "ns",
      "items_per_second": 2.9007532251664219e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 1.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)1; bool is_training = true]": 1.2389518253260638e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 2.6000000000000000e+01,
      "input[3]": 2.6000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 2.6000000000000000e+01,
      "input_size": 2.2151168000000000e+07,
      "input_width": 2.6000000000000000e+01,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 9.1600000000000000e+02,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 2.6000000000000000e+01,
      "output_size": 2.2151168000000000e+07,
      "output_width": 2.6000000000000000e+01,
      "predicted_flops": 2.9007532251664219e+10,
      "predicted_flops_count": 2.2151168000000000e+07
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_128__17851649011920636145<CUDNN_BATCHNORM_SPATIAL_PERSISTENT>/input[0]:128/input[1]:256/input[2]:26/input[3]:26/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 1146,
      "real_time": 6.0956604554469045e+05,
      "cpu_time": 6.2004354188353266e+05,
      "time_unit": "ns",
      "items_per_second": 3.6339241927765778e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 2.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)2; bool is_training = true]": 8.6489340726076344e+18,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 2.6000000000000000e+01,
      "input[3]": 2.6000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 2.6000000000000000e+01,
      "input_size": 2.2151168000000000e+07,
      "input_width": 2.6000000000000000e+01,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 1.1460000000000000e+03,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 2.6000000000000000e+01,
      "output_size": 2.2151168000000000e+07,
      "output_width": 2.6000000000000000e+01,
      "predicted_flops": 3.6339241927765778e+10,
      "predicted_flops_count": 2.2151168000000000e+07
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_128__10920519682909109743<CUDNN_BATCHNORM_SPATIAL>/input[0]:128/input[1]:1024/input[2]:12/input[3]:12/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 1859,
      "real_time": 3.7629416571517242e+05,
      "cpu_time": 3.8346864066566422e+05,
      "time_unit": "ns",
      "items_per_second": 5.0158545413873192e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 1.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)1; bool is_training = false]": 7.0429798546002954e+18,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 1.0240000000000000e+03,
      "input[2]": 1.2000000000000000e+01,
      "input[3]": 1.2000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 1.0240000000000000e+03,
      "input_height": 1.2000000000000000e+01,
      "input_size": 1.8874368000000000e+07,
      "input_width": 1.2000000000000000e+01,
      "is_training": 0.0000000000000000e+00,
      "num_iterations": 1.8590000000000000e+03,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 1.0240000000000000e+03,
      "output_height": 1.2000000000000000e+01,
      "output_size": 1.8874368000000000e+07,
      "output_width": 1.2000000000000000e+01,
      "predicted_flops": 5.0158545413873192e+10,
      "predicted_flops_count": 1.8874368000000000e+07
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_128__10920519682909109743<CUDNN_BATCHNORM_SPATIAL_PERSISTENT>/input[0]:128/input[1]:1024/input[2]:12/input[3]:12/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/BATCHNORM_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_128__3412266673798245488<CUDNN_BATCHNORM_SPATIAL>/input[0]:128/input[1]:1024/input[2]:12/input[3]:12/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 1473,
      "real_time": 4.7555823512602970e+05,
      "cpu_time": 4.8392505159382179e+05,
      "time_unit": "ns",
      "items_per_second": 3.9688867957460609e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 1.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)1; bool is_training = true]": 1.2389518253260638e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 1.0240000000000000e+03,
      "input[2]": 1.2000000000000000e+01,
      "input[3]": 1.2000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 1.0240000000000000e+03,
      "input_height": 1.2000000000000000e+01,
      "input_size": 1.8874368000000000e+07,
      "input_width": 1.2000000000000000e+01,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 1.4730000000000000e+03,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 1.0240000000000000e+03,
      "output_height": 1.2000000000000000e+01,
      "output_size": 1.8874368000000000e+07,
      "output_width": 1.2000000000000000e+01,
      "predicted_flops": 3.9688867957460609e+10,
      "predicted_flops_count": 1.8874368000000000e+07
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_128__3412266673798245488<CUDNN_BATCHNORM_SPATIAL_PERSISTENT>/input[0]:128/input[1]:1024/input[2]:12/input[3]:12/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 1472,
      "real_time": 4.7565126112164330e+05,
      "cpu_time": 4.8401388450892078e+05,
      "time_unit": "ns",
      "items_per_second": 3.9681105765370949e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 2.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)2; bool is_training = true]": 8.6489340726076344e+18,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 1.0240000000000000e+03,
      "input[2]": 1.2000000000000000e+01,
      "input[3]": 1.2000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 1.0240000000000000e+03,
      "input_height": 1.2000000000000000e+01,
      "input_size": 1.8874368000000000e+07,
      "input_width": 1.2000000000000000e+01,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 1.4720000000000000e+03,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 1.0240000000000000e+03,
      "output_height": 1.2000000000000000e+01,
      "output_size": 1.8874368000000000e+07,
      "output_width": 1.2000000000000000e+01,
      "predicted_flops": 3.9681105765370949e+10,
      "predicted_flops_count": 1.8874368000000000e+07
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_128__17742941907917574867<CUDNN_BATCHNORM_SPATIAL>/input[0]:128/input[1]:144/input[2]:28/input[3]:28/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 2534,
      "real_time": 2.7620136414534372e+05,
      "cpu_time": 2.8246332714849553e+05,
      "time_unit": "ns",
      "items_per_second": 5.2319394021514336e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 1.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)1; bool is_training = false]": 7.0429798546002954e+18,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 1.4400000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 1.4400000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 1.4450688000000000e+07,
      "input_width": 2.8000000000000000e+01,
      "is_training": 0.0000000000000000e+00,
      "num_iterations": 2.5340000000000000e+03,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 1.4400000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 1.4450688000000000e+07,
      "output_width": 2.8000000000000000e+01,
      "predicted_flops": 5.2319394021514336e+10,
      "predicted_flops_count": 1.4450688000000000e+07
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_128__17742941907917574867<CUDNN_BATCHNORM_SPATIAL_PERSISTENT>/input[0]:128/input[1]:144/input[2]:28/input[3]:28/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/BATCHNORM_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_128__5686959013552522060<CUDNN_BATCHNORM_SPATIAL>/input[0]:128/input[1]:144/input[2]:28/input[3]:28/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 1505,
      "real_time": 4.6498666162002349e+05,
      "cpu_time": 4.7319968970036658e+05,
      "time_unit": "ns",
      "items_per_second": 3.1077639839503124e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 1.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)1; bool is_training = true]": 1.2389518253260638e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 1.4400000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 1.4400000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 1.4450688000000000e+07,
      "input_width": 2.8000000000000000e+01,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 1.5050000000000000e+03,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 1.4400000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 1.4450688000000000e+07,
      "output_width": 2.8000000000000000e+01,
      "predicted_flops": 3.1077639839503124e+10,
      "predicted_flops_count": 1.4450688000000000e+07
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_128__5686959013552522060<CUDNN_BATCHNORM_SPATIAL_PERSISTENT>/input[0]:128/input[1]:144/input[2]:28/input[3]:28/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 1893,
      "real_time": 3.6976387262370437e+05,
      "cpu_time": 3.7687293185321346e+05,
      "time_unit": "ns",
      "items_per_second": 3.9080854215051872e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 2.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)2; bool is_training = true]": 8.6489340726076344e+18,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 1.4400000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 1.4400000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 1.4450688000000000e+07,
      "input_width": 2.8000000000000000e+01,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 1.8930000000000000e+03,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 1.4400000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 1.4450688000000000e+07,
      "output_width": 2.8000000000000000e+01,
      "predicted_flops": 3.9080854215051872e+10,
      "predicted_flops_count": 1.4450688000000000e+07
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_128__2594067515868035456<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:1/input[1]:1024/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 40295,
      "real_time": 1.7372486478111812e+04,
      "cpu_time": 2.2474194813958300e+04,
      "time_unit": "ns",
      "items_per_second": 1.1552980642861563e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = false]": 1.4627515035010154e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 1.0240000000000000e+03,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 1.0240000000000000e+03,
      "input_height": 1.4000000000000000e+01,
      "input_size": 2.0070400000000000e+05,
      "input_width": 1.4000000000000000e+01,
      "is_training": 0.0000000000000000e+00,
      "num_iterations": 4.0295000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 1.0240000000000000e+03,
      "output_height": 1.4000000000000000e+01,
      "output_size": 2.0070400000000000e+05,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 1.1552980642861563e+10,
      "predicted_flops_count": 2.0070400000000000e+05
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_128__14760206466692676779<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:1/input[1]:1024/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 17823,
      "real_time": 3.9263759308191824e+04,
      "cpu_time": 4.4473420076399503e+04,
      "time_unit": "ns",
      "items_per_second": 5.1116857768157196e+09,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = true]": 9.0033003156525926e+18,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 1.0240000000000000e+03,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 1.0240000000000000e+03,
      "input_height": 1.4000000000000000e+01,
      "input_size": 2.0070400000000000e+05,
      "input_width": 1.4000000000000000e+01,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 1.7823000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 1.0240000000000000e+03,
      "output_height": 1.4000000000000000e+01,
      "output_size": 2.0070400000000000e+05,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 5.1116857768157196e+09,
      "predicted_flops_count": 2.0070400000000000e+05
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_128__1791419340914813916<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:1/input[1]:768/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 118990,
      "real_time": 5.8478985042905197e+03,
      "cpu_time": 1.0919826472889175e+04,
      "time_unit": "ns",
      "items_per_second": 6.4351322055931616e+09,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = false]": 1.4627515035010154e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 7.6800000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 7.6800000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 3.7632000000000000e+04,
      "input_width": 7.0000000000000000e+00,
      "is_training": 0.0000000000000000e+00,
      "num_iterations": 1.1899000000000000e+05,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 7.6800000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 3.7632000000000000e+04,
      "output_width": 7.0000000000000000e+00,
      "predicted_flops": 6.4351322055931616e+09,
      "predicted_flops_count": 3.7632000000000000e+04
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_128__17867280947317026551<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:1/input[1]:768/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 60046,
      "real_time": 1.1659503754923491e+04,
      "cpu_time": 1.6793717999513978e+04,
      "time_unit": "ns",
      "items_per_second": 3.2275816184808922e+09,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = true]": 9.0033003156525926e+18,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 7.6800000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 7.6800000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 3.7632000000000000e+04,
      "input_width": 7.0000000000000000e+00,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 6.0046000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 7.6800000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 3.7632000000000000e+04,
      "output_width": 7.0000000000000000e+00,
      "predicted_flops": 3.2275816184808922e+09,
      "predicted_flops_count": 3.7632000000000000e+04
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_128__2713734424672025849<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:128/input[1]:224/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 19695,
      "real_time": 3.5508796646091323e+04,
      "cpu_time": 4.0675500229322657e+04,
      "time_unit": "ns",
      "items_per_second": 3.9565632538962685e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = false]": 1.4627515035010154e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 2.2400000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 2.2400000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 1.4049280000000000e+06,
      "input_width": 7.0000000000000000e+00,
      "is_training": 0.0000000000000000e+00,
      "num_iterations": 1.9695000000000000e+04,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 2.2400000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 1.4049280000000000e+06,
      "output_width": 7.0000000000000000e+00,
      "predicted_flops": 3.9565632538962685e+10,
      "predicted_flops_count": 1.4049280000000000e+06
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_128__14591711350259546578<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:128/input[1]:224/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 10614,
      "real_time": 6.6015248787296077e+04,
      "cpu_time": 7.1283540323480382e+04,
      "time_unit": "ns",
      "items_per_second": 2.1281870867846569e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = true]": 9.0033003156525926e+18,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 2.2400000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 2.2400000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 1.4049280000000000e+06,
      "input_width": 7.0000000000000000e+00,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 1.0614000000000000e+04,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 2.2400000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 1.4049280000000000e+06,
      "output_width": 7.0000000000000000e+00,
      "predicted_flops": 2.1281870867846569e+10,
      "predicted_flops_count": 1.4049280000000000e+06
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_128__16797863604158727113<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:128/input[1]:320/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 14400,
      "real_time": 4.8582529192723690e+04,
      "cpu_time": 5.3765911597152022e+04,
      "time_unit": "ns",
      "items_per_second": 4.1311970236012306e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = false]": 1.4627515035010154e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 3.2000000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 3.2000000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 2.0070400000000000e+06,
      "input_width": 7.0000000000000000e+00,
      "is_training": 0.0000000000000000e+00,
      "num_iterations": 1.4400000000000000e+04,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 3.2000000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 2.0070400000000000e+06,
      "output_width": 7.0000000000000000e+00,
      "predicted_flops": 4.1311970236012306e+10,
      "predicted_flops_count": 2.0070400000000000e+06
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_128__447207454783719138<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:128/input[1]:320/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 7806,
      "real_time": 8.9741996499270914e+04,
      "cpu_time": 9.5020001793714779e+04,
      "time_unit": "ns",
      "items_per_second": 2.2364557044552780e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = true]": 9.0033003156525926e+18,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 3.2000000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 3.2000000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 2.0070400000000000e+06,
      "input_width": 7.0000000000000000e+00,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 7.8060000000000000e+03,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 3.2000000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 2.0070400000000000e+06,
      "output_width": 7.0000000000000000e+00,
      "predicted_flops": 2.2364557044552780e+10,
      "predicted_flops_count": 2.0070400000000000e+06
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_128__10732765357663032777<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:128/input[1]:192/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 22320,
      "real_time": 3.1378952832537867e+04,
      "cpu_time": 3.6503501926669443e+04,
      "time_unit": "ns",
      "items_per_second": 3.8376806467273201e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = false]": 1.4627515035010154e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 1.9200000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 1.9200000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 1.2042240000000000e+06,
      "input_width": 7.0000000000000000e+00,
      "is_training": 0.0000000000000000e+00,
      "num_iterations": 2.2320000000000000e+04,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 1.9200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 1.2042240000000000e+06,
      "output_width": 7.0000000000000000e+00,
      "predicted_flops": 3.8376806467273201e+10,
      "predicted_flops_count": 1.2042240000000000e+06
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_128__8924799684750201058<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:128/input[1]:192/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 11959,
      "real_time": 5.8659364228251688e+04,
      "cpu_time": 6.3881622292359636e+04,
      "time_unit": "ns",
      "items_per_second": 2.0529100781150612e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = true]": 9.0033003156525926e+18,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 1.9200000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 1.9200000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 1.2042240000000000e+06,
      "input_width": 7.0000000000000000e+00,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 1.1959000000000000e+04,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 1.9200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 1.2042240000000000e+06,
      "output_width": 7.0000000000000000e+00,
      "predicted_flops": 2.0529100781150612e+10,
      "predicted_flops_count": 1.2042240000000000e+06
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_128__16838400792959797723<CUDNN_BATCHNORM_SPATIAL>/input[0]:128/input[1]:64/input[2]:104/input[3]:104/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 414,
      "real_time": 1.6906572424847146e+06,
      "cpu_time": 1.7366385458969756e+06,
      "time_unit": "ns",
      "items_per_second": 5.2408418320072990e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 1.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)1; bool is_training = false]": 7.0429798546002954e+18,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 1.0400000000000000e+02,
      "input[3]": 1.0400000000000000e+02,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 1.0400000000000000e+02,
      "input_size": 8.8604672000000000e+07,
      "input_width": 1.0400000000000000e+02,
      "is_training": 0.0000000000000000e+00,
      "num_iterations": 4.1400000000000000e+02,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 1.0400000000000000e+02,
      "output_size": 8.8604672000000000e+07,
      "output_width": 1.0400000000000000e+02,
      "predicted_flops": 5.2408418320072990e+10,
      "predicted_flops_count": 8.8604672000000000e+07
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_128__16838400792959797723<CUDNN_BATCHNORM_SPATIAL_PERSISTENT>/input[0]:128/input[1]:64/input[2]:104/input[3]:104/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/BATCHNORM_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_128__5870918140784203844<CUDNN_BATCHNORM_SPATIAL>/input[0]:128/input[1]:64/input[2]:104/input[3]:104/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 272,
      "real_time": 2.5755648342002295e+06,
      "cpu_time": 2.6751279007283184e+06,
      "time_unit": "ns",
      "items_per_second": 3.4402035166594337e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 1.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)1; bool is_training = true]": 1.2389518253260638e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 1.0400000000000000e+02,
      "input[3]": 1.0400000000000000e+02,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 1.0400000000000000e+02,
      "input_size": 8.8604672000000000e+07,
      "input_width": 1.0400000000000000e+02,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 2.7200000000000000e+02,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 1.0400000000000000e+02,
      "output_size": 8.8604672000000000e+07,
      "output_width": 1.0400000000000000e+02,
      "predicted_flops": 3.4402035166594337e+10,
      "predicted_flops_count": 8.8604672000000000e+07
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_128__5870918140784203844<CUDNN_BATCHNORM_SPATIAL_PERSISTENT>/input[0]:128/input[1]:64/input[2]:104/input[3]:104/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 272,
      "real_time": 2.5763736698803874e+06,
      "cpu_time": 2.6761820330889081e+06,
      "time_unit": "ns",
      "items_per_second": 3.4391234872429672e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 2.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)2; bool is_training = true]": 8.6489340726076344e+18,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 1.0400000000000000e+02,
      "input[3]": 1.0400000000000000e+02,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 1.0400000000000000e+02,
      "input_size": 8.8604672000000000e+07,
      "input_width": 1.0400000000000000e+02,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 2.7200000000000000e+02,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 1.0400000000000000e+02,
      "output_size": 8.8604672000000000e+07,
      "output_width": 1.0400000000000000e+02,
      "predicted_flops": 3.4391234872429672e+10,
      "predicted_flops_count": 8.8604672000000000e+07
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_128__4461149277244782514<CUDNN_BATCHNORM_SPATIAL>/input[0]:128/input[1]:2048/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 1467,
      "real_time": 4.7701293530054367e+05,
      "cpu_time": 4.8540992160676845e+05,
      "time_unit": "ns",
      "items_per_second": 2.6928108337160561e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 1.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)1; bool is_training = false]": 7.0429798546002954e+18,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 2.0480000000000000e+03,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 2.0480000000000000e+03,
      "input_height": 7.0000000000000000e+00,
      "input_size": 1.2845056000000000e+07,
      "input_width": 7.0000000000000000e+00,
      "is_training": 0.0000000000000000e+00,
      "num_iterations": 1.4670000000000000e+03,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 2.0480000000000000e+03,
      "output_height": 7.0000000000000000e+00,
      "output_size": 1.2845056000000000e+07,
      "output_width": 7.0000000000000000e+00,
      "predicted_flops": 2.6928108337160561e+10,
      "predicted_flops_count": 1.2845056000000000e+07
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_128__4461149277244782514<CUDNN_BATCHNORM_SPATIAL_PERSISTENT>/input[0]:128/input[1]:2048/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/BATCHNORM_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_128__9601282011385488941<CUDNN_BATCHNORM_SPATIAL>/input[0]:128/input[1]:2048/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 1906,
      "real_time": 3.6714788845919585e+05,
      "cpu_time": 3.7420631479069951e+05,
      "time_unit": "ns",
      "items_per_second": 3.4986054404143951e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 1.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)1; bool is_training = true]": 1.2389518253260638e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 2.0480000000000000e+03,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 2.0480000000000000e+03,
      "input_height": 7.0000000000000000e+00,
      "input_size": 1.2845056000000000e+07,
      "input_width": 7.0000000000000000e+00,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 1.9060000000000000e+03,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 2.0480000000000000e+03,
      "output_height": 7.0000000000000000e+00,
      "output_size": 1.2845056000000000e+07,
      "output_width": 7.0000000000000000e+00,
      "predicted_flops": 3.4986054404143951e+10,
      "predicted_flops_count": 1.2845056000000000e+07
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_128__9601282011385488941<CUDNN_BATCHNORM_SPATIAL_PERSISTENT>/input[0]:128/input[1]:2048/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 1907,
      "real_time": 3.6713742888454441e+05,
      "cpu_time": 3.7419781908930471e+05,
      "time_unit": "ns",
      "items_per_second": 3.4987051140567451e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 2.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)2; bool is_training = true]": 8.6489340726076344e+18,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 2.0480000000000000e+03,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 2.0480000000000000e+03,
      "input_height": 7.0000000000000000e+00,
      "input_size": 1.2845056000000000e+07,
      "input_width": 7.0000000000000000e+00,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 1.9070000000000000e+03,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 2.0480000000000000e+03,
      "output_height": 7.0000000000000000e+00,
      "output_size": 1.2845056000000000e+07,
      "output_width": 7.0000000000000000e+00,
      "predicted_flops": 3.4987051140567451e+10,
      "predicted_flops_count": 1.2845056000000000e+07
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_128__14227782098438994395<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:128/input[1]:352/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 13269,
      "real_time": 5.2772213474220458e+04,
      "cpu_time": 5.7926819729066738e+04,
      "time_unit": "ns",
      "items_per_second": 4.1835349602655876e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = false]": 1.4627515035010154e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 3.5200000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 3.5200000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 2.2077440000000000e+06,
      "input_width": 7.0000000000000000e+00,
      "is_training": 0.0000000000000000e+00,
      "num_iterations": 1.3269000000000000e+04,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 3.5200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 2.2077440000000000e+06,
      "output_width": 7.0000000000000000e+00,
      "predicted_flops": 4.1835349602655876e+10,
      "predicted_flops_count": 2.2077440000000000e+06
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_128__3051768545631042800<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:128/input[1]:352/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 7222,
      "real_time": 9.6796647827538807e+04,
      "cpu_time": 1.0211076710154253e+05,
      "time_unit": "ns",
      "items_per_second": 2.2808062567760666e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = true]": 9.0033003156525926e+18,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 3.5200000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 3.5200000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 2.2077440000000000e+06,
      "input_width": 7.0000000000000000e+00,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 7.2220000000000000e+03,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 3.5200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 2.2077440000000000e+06,
      "output_width": 7.0000000000000000e+00,
      "predicted_flops": 2.2808062567760666e+10,
      "predicted_flops_count": 2.2077440000000000e+06
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_128__7019092671655129238<CUDNN_BATCHNORM_SPATIAL>/input[0]:128/input[1]:128/input[2]:28/input[3]:28/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 2820,
      "real_time": 2.4820087114902184e+05,
      "cpu_time": 2.5422214042627346e+05,
      "time_unit": "ns",
      "items_per_second": 5.1752662835287636e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 1.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)1; bool is_training = false]": 7.0429798546002954e+18,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 1.2800000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 1.2800000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 1.2845056000000000e+07,
      "input_width": 2.8000000000000000e+01,
      "is_training": 0.0000000000000000e+00,
      "num_iterations": 2.8200000000000000e+03,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 1.2845056000000000e+07,
      "output_width": 2.8000000000000000e+01,
      "predicted_flops": 5.1752662835287636e+10,
      "predicted_flops_count": 1.2845056000000000e+07
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_128__7019092671655129238<CUDNN_BATCHNORM_SPATIAL_PERSISTENT>/input[0]:128/input[1]:128/input[2]:28/input[3]:28/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/BATCHNORM_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_128__15690373046925631753<CUDNN_BATCHNORM_SPATIAL>/input[0]:128/input[1]:128/input[2]:28/input[3]:28/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 1630,
      "real_time": 4.3039632867593202e+05,
      "cpu_time": 4.3816924172067491e+05,
      "time_unit": "ns",
      "items_per_second": 2.9844715542803146e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 1.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)1; bool is_training = true]": 1.2389518253260638e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 1.2800000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 1.2800000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 1.2845056000000000e+07,
      "input_width": 2.8000000000000000e+01,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 1.6300000000000000e+03,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 1.2845056000000000e+07,
      "output_width": 2.8000000000000000e+01,
      "predicted_flops": 2.9844715542803146e+10,
      "predicted_flops_count": 1.2845056000000000e+07
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_128__15690373046925631753<CUDNN_BATCHNORM_SPATIAL_PERSISTENT>/input[0]:128/input[1]:128/input[2]:28/input[3]:28/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 2094,
      "real_time": 3.3426371599788178e+05,
      "cpu_time": 3.4103624689827155e+05,
      "time_unit": "ns",
      "items_per_second": 3.8427910016058693e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 2.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)2; bool is_training = true]": 8.6489340726076344e+18,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 1.2800000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 1.2800000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 1.2845056000000000e+07,
      "input_width": 2.8000000000000000e+01,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 2.0940000000000000e+03,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 1.2845056000000000e+07,
      "output_width": 2.8000000000000000e+01,
      "predicted_flops": 3.8427910016058693e+10,
      "predicted_flops_count": 1.2845056000000000e+07
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_128__16272328137972800345<CUDNN_BATCHNORM_SPATIAL>/input[0]:128/input[1]:512/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 5711,
      "real_time": 1.2251870170735827e+05,
      "cpu_time": 1.2785503361931398e+05,
      "time_unit": "ns",
      "items_per_second": 2.6210398537116859e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 1.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)1; bool is_training = false]": 7.0429798546002954e+18,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 3.2112640000000000e+06,
      "input_width": 7.0000000000000000e+00,
      "is_training": 0.0000000000000000e+00,
      "num_iterations": 5.7110000000000000e+03,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 3.2112640000000000e+06,
      "output_width": 7.0000000000000000e+00,
      "predicted_flops": 2.6210398537116859e+10,
      "predicted_flops_count": 3.2112640000000000e+06
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_128__16272328137972800345<CUDNN_BATCHNORM_SPATIAL_PERSISTENT>/input[0]:128/input[1]:512/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/BATCHNORM_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_128__6414630573195053766<CUDNN_BATCHNORM_SPATIAL>/input[0]:128/input[1]:512/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 6886,
      "real_time": 1.0165145026311002e+05,
      "cpu_time": 1.0693196993969711e+05,
      "time_unit": "ns",
      "items_per_second": 3.1590931478971615e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 1.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)1; bool is_training = true]": 1.2389518253260638e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 3.2112640000000000e+06,
      "input_width": 7.0000000000000000e+00,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 6.8860000000000000e+03,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 3.2112640000000000e+06,
      "output_width": 7.0000000000000000e+00,
      "predicted_flops": 3.1590931478971615e+10,
      "predicted_flops_count": 3.2112640000000000e+06
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_128__6414630573195053766<CUDNN_BATCHNORM_SPATIAL_PERSISTENT>/input[0]:128/input[1]:512/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 6887,
      "real_time": 1.0163221118597763e+05,
      "cpu_time": 1.0691843937667465e+05,
      "time_unit": "ns",
      "items_per_second": 3.1596911673245808e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 2.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)2; bool is_training = true]": 8.6489340726076344e+18,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 3.2112640000000000e+06,
      "input_width": 7.0000000000000000e+00,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 6.8870000000000000e+03,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 3.2112640000000000e+06,
      "output_width": 7.0000000000000000e+00,
      "predicted_flops": 3.1596911673245808e+10,
      "predicted_flops_count": 3.2112640000000000e+06
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_128__7463260461156666753<CUDNN_BATCHNORM_SPATIAL>/input[0]:128/input[1]:1024/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 1350,
      "real_time": 5.1908790095088386e+05,
      "cpu_time": 5.2806499259110785e+05,
      "time_unit": "ns",
      "items_per_second": 4.9490870338029327e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 1.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)1; bool is_training = false]": 7.0429798546002954e+18,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 1.0240000000000000e+03,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 1.0240000000000000e+03,
      "input_height": 1.4000000000000000e+01,
      "input_size": 2.5690112000000000e+07,
      "input_width": 1.4000000000000000e+01,
      "is_training": 0.0000000000000000e+00,
      "num_iterations": 1.3500000000000000e+03,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 1.0240000000000000e+03,
      "output_height": 1.4000000000000000e+01,
      "output_size": 2.5690112000000000e+07,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 4.9490870338029327e+10,
      "predicted_flops_count": 2.5690112000000000e+07
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_128__7463260461156666753<CUDNN_BATCHNORM_SPATIAL_PERSISTENT>/input[0]:128/input[1]:1024/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/BATCHNORM_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_128__16088378939581832222<CUDNN_BATCHNORM_SPATIAL>/input[0]:128/input[1]:1024/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 862,
      "real_time": 8.1235315275795572e+05,
      "cpu_time": 8.2691718561497808e+05,
      "time_unit": "ns",
      "items_per_second": 3.1624315007311218e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 1.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)1; bool is_training = true]": 1.2389518253260638e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 1.0240000000000000e+03,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 1.0240000000000000e+03,
      "input_height": 1.4000000000000000e+01,
      "input_size": 2.5690112000000000e+07,
      "input_width": 1.4000000000000000e+01,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 8.6200000000000000e+02,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 1.0240000000000000e+03,
      "output_height": 1.4000000000000000e+01,
      "output_size": 2.5690112000000000e+07,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 3.1624315007311218e+10,
      "predicted_flops_count": 2.5690112000000000e+07
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_128__16088378939581832222<CUDNN_BATCHNORM_SPATIAL_PERSISTENT>/input[0]:128/input[1]:1024/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 937,
      "real_time": 7.4742659551201819e+05,
      "cpu_time": 7.6055393276577373e+05,
      "time_unit": "ns",
      "items_per_second": 3.4371418082067589e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 2.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)2; bool is_training = true]": 8.6489340726076344e+18,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 1.0240000000000000e+03,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 1.0240000000000000e+03,
      "input_height": 1.4000000000000000e+01,
      "input_size": 2.5690112000000000e+07,
      "input_width": 1.4000000000000000e+01,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 9.3700000000000000e+02,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 1.0240000000000000e+03,
      "output_height": 1.4000000000000000e+01,
      "output_size": 2.5690112000000000e+07,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 3.4371418082067589e+10,
      "predicted_flops_count": 2.5690112000000000e+07
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_128__198034484080130553<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:128/input[1]:64/input[2]:224/input[3]:224/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 46,
      "real_time": 1.5182589302244393e+07,
      "cpu_time": 1.8512935804343887e+07,
      "time_unit": "ns",
      "items_per_second": 2.7073233940355419e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = false]": 1.4627515035010154e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 2.2400000000000000e+02,
      "input[3]": 2.2400000000000000e+02,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 2.2400000000000000e+02,
      "input_size": 4.1104179200000000e+08,
      "input_width": 2.2400000000000000e+02,
      "is_training": 0.0000000000000000e+00,
      "num_iterations": 4.6000000000000000e+01,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 2.2400000000000000e+02,
      "output_size": 4.1104179200000000e+08,
      "output_width": 2.2400000000000000e+02,
      "predicted_flops": 2.7073233940355419e+10,
      "predicted_flops_count": 4.1104179200000000e+08
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_128__17120078210249129170<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:128/input[1]:64/input[2]:224/input[3]:224/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 30,
      "real_time": 2.3551834747195244e+07,
      "cpu_time": 3.1381584600004923e+07,
      "time_unit": "ns",
      "items_per_second": 1.7452644195754234e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = true]": 9.0033003156525926e+18,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 2.2400000000000000e+02,
      "input[3]": 2.2400000000000000e+02,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 2.2400000000000000e+02,
      "input_size": 4.1104179200000000e+08,
      "input_width": 2.2400000000000000e+02,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 3.0000000000000000e+01,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 2.2400000000000000e+02,
      "output_size": 4.1104179200000000e+08,
      "output_width": 2.2400000000000000e+02,
      "predicted_flops": 1.7452644195754234e+10,
      "predicted_flops_count": 4.1104179200000000e+08
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_128__5572927234915852209<CUDNN_BATCHNORM_SPATIAL>/input[0]:128/input[1]:256/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 5212,
      "real_time": 1.3427726424606345e+05,
      "cpu_time": 1.3966293956090914e+05,
      "time_unit": "ns",
      "items_per_second": 4.7830345934295326e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 1.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)1; bool is_training = false]": 7.0429798546002954e+18,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 6.4225280000000000e+06,
      "input_width": 1.4000000000000000e+01,
      "is_training": 0.0000000000000000e+00,
      "num_iterations": 5.2120000000000000e+03,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 6.4225280000000000e+06,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 4.7830345934295326e+10,
      "predicted_flops_count": 6.4225280000000000e+06
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_128__5572927234915852209<CUDNN_BATCHNORM_SPATIAL_PERSISTENT>/input[0]:128/input[1]:256/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/BATCHNORM_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_128__17690341045433454126<CUDNN_BATCHNORM_SPATIAL>/input[0]:128/input[1]:256/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 3135,
      "real_time": 2.2320958323950510e+05,
      "cpu_time": 2.2905575215256040e+05,
      "time_unit": "ns",
      "items_per_second": 2.8773531614494312e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 1.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)1; bool is_training = true]": 1.2389518253260638e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 6.4225280000000000e+06,
      "input_width": 1.4000000000000000e+01,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 3.1350000000000000e+03,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 6.4225280000000000e+06,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 2.8773531614494312e+10,
      "predicted_flops_count": 6.4225280000000000e+06
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_128__17690341045433454126<CUDNN_BATCHNORM_SPATIAL_PERSISTENT>/input[0]:128/input[1]:256/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 3372,
      "real_time": 2.0777453792840461e+05,
      "cpu_time": 2.1356539857638915e+05,
      "time_unit": "ns",
      "items_per_second": 3.0911044558371670e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 2.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)2; bool is_training = true]": 8.6489340726076344e+18,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 6.4225280000000000e+06,
      "input_width": 1.4000000000000000e+01,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 3.3720000000000000e+03,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 6.4225280000000000e+06,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 3.0911044558371670e+10,
      "predicted_flops_count": 6.4225280000000000e+06
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_128__2213003517432460084<CUDNN_BATCHNORM_SPATIAL>/input[0]:128/input[1]:3/input[2]:224/input[3]:224/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 1697,
      "real_time": 4.1257047540857794e+05,
      "cpu_time": 4.2014740836461121e+05,
      "time_unit": "ns",
      "items_per_second": 4.6701315650177994e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 1.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)1; bool is_training = false]": 7.0429798546002954e+18,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 3.0000000000000000e+00,
      "input[2]": 2.2400000000000000e+02,
      "input[3]": 2.2400000000000000e+02,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 3.0000000000000000e+00,
      "input_height": 2.2400000000000000e+02,
      "input_size": 1.9267584000000000e+07,
      "input_width": 2.2400000000000000e+02,
      "is_training": 0.0000000000000000e+00,
      "num_iterations": 1.6970000000000000e+03,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 3.0000000000000000e+00,
      "output_height": 2.2400000000000000e+02,
      "output_size": 1.9267584000000000e+07,
      "output_width": 2.2400000000000000e+02,
      "predicted_flops": 4.6701315650177994e+10,
      "predicted_flops_count": 1.9267584000000000e+07
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_128__2213003517432460084<CUDNN_BATCHNORM_SPATIAL_PERSISTENT>/input[0]:128/input[1]:3/input[2]:224/input[3]:224/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/BATCHNORM_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_128__11989037708326527659<CUDNN_BATCHNORM_SPATIAL>/input[0]:128/input[1]:3/input[2]:224/input[3]:224/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 195,
      "real_time": 3.5821901383594824e+06,
      "cpu_time": 3.7710709179499154e+06,
      "time_unit": "ns",
      "items_per_second": 5.3787161640794086e+09,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 1.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)1; bool is_training = true]": 1.2389518253260638e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 3.0000000000000000e+00,
      "input[2]": 2.2400000000000000e+02,
      "input[3]": 2.2400000000000000e+02,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 3.0000000000000000e+00,
      "input_height": 2.2400000000000000e+02,
      "input_size": 1.9267584000000000e+07,
      "input_width": 2.2400000000000000e+02,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 1.9500000000000000e+02,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 3.0000000000000000e+00,
      "output_height": 2.2400000000000000e+02,
      "output_size": 1.9267584000000000e+07,
      "output_width": 2.2400000000000000e+02,
      "predicted_flops": 5.3787161640794086e+09,
      "predicted_flops_count": 1.9267584000000000e+07
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_128__11989037708326527659<CUDNN_BATCHNORM_SPATIAL_PERSISTENT>/input[0]:128/input[1]:3/input[2]:224/input[3]:224/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 195,
      "real_time": 3.5809767754891743e+06,
      "cpu_time": 3.7697987281985544e+06,
      "time_unit": "ns",
      "items_per_second": 5.3805386652830162e+09,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 2.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)2; bool is_training = true]": 8.6489340726076344e+18,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 3.0000000000000000e+00,
      "input[2]": 2.2400000000000000e+02,
      "input[3]": 2.2400000000000000e+02,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 3.0000000000000000e+00,
      "input_height": 2.2400000000000000e+02,
      "input_size": 1.9267584000000000e+07,
      "input_width": 2.2400000000000000e+02,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 1.9500000000000000e+02,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 3.0000000000000000e+00,
      "output_height": 2.2400000000000000e+02,
      "output_size": 1.9267584000000000e+07,
      "output_width": 2.2400000000000000e+02,
      "predicted_flops": 5.3805386652830162e+09,
      "predicted_flops_count": 1.9267584000000000e+07
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_128__15237176484055752321<CUDNN_BATCHNORM_SPATIAL>/input[0]:128/input[1]:256/input[2]:28/input[3]:28/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 1441,
      "real_time": 4.8584684885173553e+05,
      "cpu_time": 4.9435948646866024e+05,
      "time_unit": "ns",
      "items_per_second": 5.2876975657487030e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 1.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)1; bool is_training = false]": 7.0429798546002954e+18,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 2.5690112000000000e+07,
      "input_width": 2.8000000000000000e+01,
      "is_training": 0.0000000000000000e+00,
      "num_iterations": 1.4410000000000000e+03,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 2.5690112000000000e+07,
      "output_width": 2.8000000000000000e+01,
      "predicted_flops": 5.2876975657487030e+10,
      "predicted_flops_count": 2.5690112000000000e+07
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_128__15237176484055752321<CUDNN_BATCHNORM_SPATIAL_PERSISTENT>/input[0]:128/input[1]:256/input[2]:28/input[3]:28/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/BATCHNORM_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_128__7756016558287392542<CUDNN_BATCHNORM_SPATIAL>/input[0]:128/input[1]:256/input[2]:28/input[3]:28/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 881,
      "real_time": 7.9484080791919492e+05,
      "cpu_time": 8.0898368217908370e+05,
      "time_unit": "ns",
      "items_per_second": 3.2321078314101490e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 1.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)1; bool is_training = true]": 1.2389518253260638e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 2.5690112000000000e+07,
      "input_width": 2.8000000000000000e+01,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 8.8100000000000000e+02,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 2.5690112000000000e+07,
      "output_width": 2.8000000000000000e+01,
      "predicted_flops": 3.2321078314101490e+10,
      "predicted_flops_count": 2.5690112000000000e+07
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_128__7756016558287392542<CUDNN_BATCHNORM_SPATIAL_PERSISTENT>/input[0]:128/input[1]:256/input[2]:28/input[3]:28/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 1061,
      "real_time": 6.5910043797265249e+05,
      "cpu_time": 6.7050619886630320e+05,
      "time_unit": "ns",
      "items_per_second": 3.8977537443338699e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 2.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)2; bool is_training = true]": 8.6489340726076344e+18,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 2.5690112000000000e+07,
      "input_width": 2.8000000000000000e+01,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 1.0610000000000000e+03,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 2.5690112000000000e+07,
      "output_width": 2.8000000000000000e+01,
      "predicted_flops": 3.8977537443338699e+10,
      "predicted_flops_count": 2.5690112000000000e+07
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_128__13532161854996290001<CUDNN_BATCHNORM_SPATIAL>/input[0]:128/input[1]:64/input[2]:112/input[3]:112/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 359,
      "real_time": 1.9495525072435110e+06,
      "cpu_time": 2.0089888189425471e+06,
      "time_unit": "ns",
      "items_per_second": 5.2709761659763596e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 1.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)1; bool is_training = false]": 7.0429798546002954e+18,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 1.1200000000000000e+02,
      "input[3]": 1.1200000000000000e+02,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 1.1200000000000000e+02,
      "input_size": 1.0276044800000000e+08,
      "input_width": 1.1200000000000000e+02,
      "is_training": 0.0000000000000000e+00,
      "num_iterations": 3.5900000000000000e+02,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 1.1200000000000000e+02,
      "output_size": 1.0276044800000000e+08,
      "output_width": 1.1200000000000000e+02,
      "predicted_flops": 5.2709761659763596e+10,
      "predicted_flops_count": 1.0276044800000000e+08
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_128__13532161854996290001<CUDNN_BATCHNORM_SPATIAL_PERSISTENT>/input[0]:128/input[1]:64/input[2]:112/input[3]:112/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/BATCHNORM_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_128__224143406294992974<CUDNN_BATCHNORM_SPATIAL>/input[0]:128/input[1]:64/input[2]:112/input[3]:112/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 235,
      "real_time": 2.9762539745090487e+06,
      "cpu_time": 3.1080797915007118e+06,
      "time_unit": "ns",
      "items_per_second": 3.4526773884258636e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 1.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)1; bool is_training = true]": 1.2389518253260638e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 1.1200000000000000e+02,
      "input[3]": 1.1200000000000000e+02,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 1.1200000000000000e+02,
      "input_size": 1.0276044800000000e+08,
      "input_width": 1.1200000000000000e+02,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 2.3500000000000000e+02,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 1.1200000000000000e+02,
      "output_size": 1.0276044800000000e+08,
      "output_width": 1.1200000000000000e+02,
      "predicted_flops": 3.4526773884258636e+10,
      "predicted_flops_count": 1.0276044800000000e+08
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_128__224143406294992974<CUDNN_BATCHNORM_SPATIAL_PERSISTENT>/input[0]:128/input[1]:64/input[2]:112/input[3]:112/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 235,
      "real_time": 2.9765272513031960e+06,
      "cpu_time": 3.1082469234042172e+06,
      "time_unit": "ns",
      "items_per_second": 3.4523603959953323e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 2.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)2; bool is_training = true]": 8.6489340726076344e+18,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 1.1200000000000000e+02,
      "input[3]": 1.1200000000000000e+02,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 1.1200000000000000e+02,
      "input_size": 1.0276044800000000e+08,
      "input_width": 1.1200000000000000e+02,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 2.3500000000000000e+02,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 1.1200000000000000e+02,
      "output_size": 1.0276044800000000e+08,
      "output_width": 1.1200000000000000e+02,
      "predicted_flops": 3.4523603959953323e+10,
      "predicted_flops_count": 1.0276044800000000e+08
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_128__17303674499206576512<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:128/input[1]:128/input[2]:112/input[3]:112/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 92,
      "real_time": 7.5761332105764225e+06,
      "cpu_time": 8.4097316195702069e+06,
      "time_unit": "ns",
      "items_per_second": 2.7127413191875904e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = false]": 1.4627515035010154e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 1.2800000000000000e+02,
      "input[2]": 1.1200000000000000e+02,
      "input[3]": 1.1200000000000000e+02,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 1.2800000000000000e+02,
      "input_height": 1.1200000000000000e+02,
      "input_size": 2.0552089600000000e+08,
      "input_width": 1.1200000000000000e+02,
      "is_training": 0.0000000000000000e+00,
      "num_iterations": 9.2000000000000000e+01,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 1.1200000000000000e+02,
      "output_size": 2.0552089600000000e+08,
      "output_width": 1.1200000000000000e+02,
      "predicted_flops": 2.7127413191875904e+10,
      "predicted_flops_count": 2.0552089600000000e+08
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_128__2236656765198613675<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:128/input[1]:128/input[2]:112/input[3]:112/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 60,
      "real_time": 1.1688800016418099e+07,
      "cpu_time": 1.3637633466669286e+07,
      "time_unit": "ns",
      "items_per_second": 1.7582719843895451e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = true]": 9.0033003156525926e+18,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 1.2800000000000000e+02,
      "input[2]": 1.1200000000000000e+02,
      "input[3]": 1.1200000000000000e+02,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 1.2800000000000000e+02,
      "input_height": 1.1200000000000000e+02,
      "input_size": 2.0552089600000000e+08,
      "input_width": 1.1200000000000000e+02,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 6.0000000000000000e+01,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 1.1200000000000000e+02,
      "output_size": 2.0552089600000000e+08,
      "output_width": 1.1200000000000000e+02,
      "predicted_flops": 1.7582719843895451e+10,
      "predicted_flops_count": 2.0552089600000000e+08
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_128__13794862331259056757<CUDNN_BATCHNORM_SPATIAL>/input[0]:128/input[1]:64/input[2]:56/input[3]:56/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 1436,
      "real_time": 4.8762587431969360e+05,
      "cpu_time": 4.9614854526743910e+05,
      "time_unit": "ns",
      "items_per_second": 5.2684062419454887e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 1.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)1; bool is_training = false]": 7.0429798546002954e+18,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 2.5690112000000000e+07,
      "input_width": 5.6000000000000000e+01,
      "is_training": 0.0000000000000000e+00,
      "num_iterations": 1.4360000000000000e+03,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 5.6000000000000000e+01,
      "output_size": 2.5690112000000000e+07,
      "output_width": 5.6000000000000000e+01,
      "predicted_flops": 5.2684062419454887e+10,
      "predicted_flops_count": 2.5690112000000000e+07
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_128__13794862331259056757<CUDNN_BATCHNORM_SPATIAL_PERSISTENT>/input[0]:128/input[1]:64/input[2]:56/input[3]:56/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/BATCHNORM_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_128__551275942413886442<CUDNN_BATCHNORM_SPATIAL>/input[0]:128/input[1]:64/input[2]:56/input[3]:56/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 931,
      "real_time": 7.5192654998792941e+05,
      "cpu_time": 7.6515417829505086e+05,
      "time_unit": "ns",
      "items_per_second": 3.4165720043284012e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 1.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)1; bool is_training = true]": 1.2389518253260638e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 2.5690112000000000e+07,
      "input_width": 5.6000000000000000e+01,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 9.3100000000000000e+02,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 5.6000000000000000e+01,
      "output_size": 2.5690112000000000e+07,
      "output_width": 5.6000000000000000e+01,
      "predicted_flops": 3.4165720043284012e+10,
      "predicted_flops_count": 2.5690112000000000e+07
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_128__551275942413886442<CUDNN_BATCHNORM_SPATIAL_PERSISTENT>/input[0]:128/input[1]:64/input[2]:56/input[3]:56/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 1044,
      "real_time": 6.7110654269746540e+05,
      "cpu_time": 6.8268883141781355e+05,
      "time_unit": "ns",
      "items_per_second": 3.8280228794582169e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 2.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)2; bool is_training = true]": 8.6489340726076344e+18,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 2.5690112000000000e+07,
      "input_width": 5.6000000000000000e+01,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 1.0440000000000000e+03,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 5.6000000000000000e+01,
      "output_size": 2.5690112000000000e+07,
      "output_width": 5.6000000000000000e+01,
      "predicted_flops": 3.8280228794582169e+10,
      "predicted_flops_count": 2.5690112000000000e+07
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_128__3151323325098886682<CUDNN_BATCHNORM_SPATIAL>/input[0]:128/input[1]:128/input[2]:56/input[3]:56/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 717,
      "real_time": 9.7692224924157758e+05,
      "cpu_time": 9.9567719665597752e+05,
      "time_unit": "ns",
      "items_per_second": 5.2593974638092697e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 1.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)1; bool is_training = false]": 7.0429798546002954e+18,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 1.2800000000000000e+02,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 1.2800000000000000e+02,
      "input_height": 5.6000000000000000e+01,
      "input_size": 5.1380224000000000e+07,
      "input_width": 5.6000000000000000e+01,
      "is_training": 0.0000000000000000e+00,
      "num_iterations": 7.1700000000000000e+02,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 5.6000000000000000e+01,
      "output_size": 5.1380224000000000e+07,
      "output_width": 5.6000000000000000e+01,
      "predicted_flops": 5.2593974638092697e+10,
      "predicted_flops_count": 5.1380224000000000e+07
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_128__3151323325098886682<CUDNN_BATCHNORM_SPATIAL_PERSISTENT>/input[0]:128/input[1]:128/input[2]:56/input[3]:56/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/BATCHNORM_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_128__10622878132572297093<CUDNN_BATCHNORM_SPATIAL>/input[0]:128/input[1]:128/input[2]:56/input[3]:56/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 412,
      "real_time": 1.6970452021816473e+06,
      "cpu_time": 1.7438662257253542e+06,
      "time_unit": "ns",
      "items_per_second": 3.0276284882658295e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 1.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)1; bool is_training = true]": 1.2389518253260638e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 1.2800000000000000e+02,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 1.2800000000000000e+02,
      "input_height": 5.6000000000000000e+01,
      "input_size": 5.1380224000000000e+07,
      "input_width": 5.6000000000000000e+01,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 4.1200000000000000e+02,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 5.6000000000000000e+01,
      "output_size": 5.1380224000000000e+07,
      "output_width": 5.6000000000000000e+01,
      "predicted_flops": 3.0276284882658295e+10,
      "predicted_flops_count": 5.1380224000000000e+07
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_128__10622878132572297093<CUDNN_BATCHNORM_SPATIAL_PERSISTENT>/input[0]:128/input[1]:128/input[2]:56/input[3]:56/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 529,
      "real_time": 1.3214831305614943e+06,
      "cpu_time": 1.3517246465029346e+06,
      "time_unit": "ns",
      "items_per_second": 3.8880726368537674e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 2.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)2; bool is_training = true]": 8.6489340726076344e+18,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 1.2800000000000000e+02,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 1.2800000000000000e+02,
      "input_height": 5.6000000000000000e+01,
      "input_size": 5.1380224000000000e+07,
      "input_width": 5.6000000000000000e+01,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 5.2900000000000000e+02,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 5.6000000000000000e+01,
      "output_size": 5.1380224000000000e+07,
      "output_width": 5.6000000000000000e+01,
      "predicted_flops": 3.8880726368537674e+10,
      "predicted_flops_count": 5.1380224000000000e+07
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_128__17019452842774484627<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:128/input[1]:512/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 1465,
      "real_time": 4.7632712255384604e+05,
      "cpu_time": 4.8475008941753383e+05,
      "time_unit": "ns",
      "items_per_second": 2.6966879255438450e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = false]": 1.4627515035010154e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 1.2845056000000000e+07,
      "input_width": 1.4000000000000000e+01,
      "is_training": 0.0000000000000000e+00,
      "num_iterations": 1.4650000000000000e+03,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 1.2845056000000000e+07,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 2.6966879255438450e+10,
      "predicted_flops_count": 1.2845056000000000e+07
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_128__222942533071115192<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:128/input[1]:512/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 976,
      "real_time": 7.1986606304026139e+05,
      "cpu_time": 7.3241860041022033e+05,
      "time_unit": "ns",
      "items_per_second": 1.7843674899398041e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = true]": 9.0033003156525926e+18,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 1.2845056000000000e+07,
      "input_width": 1.4000000000000000e+01,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 9.7600000000000000e+02,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 1.2845056000000000e+07,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 1.7843674899398041e+10,
      "predicted_flops_count": 1.2845056000000000e+07
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_128__12927673252549650035<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:128/input[1]:512/input[2]:28/input[3]:28/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 367,
      "real_time": 1.9038111492940695e+06,
      "cpu_time": 1.9608272098040294e+06,
      "time_unit": "ns",
      "items_per_second": 2.6988088613228111e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = false]": 1.4627515035010154e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 5.1380224000000000e+07,
      "input_width": 2.8000000000000000e+01,
      "is_training": 0.0000000000000000e+00,
      "num_iterations": 3.6700000000000000e+02,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 5.1380224000000000e+07,
      "output_width": 2.8000000000000000e+01,
      "predicted_flops": 2.6988088613228111e+10,
      "predicted_flops_count": 5.1380224000000000e+07
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_128__6647701629289636696<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:128/input[1]:512/input[2]:28/input[3]:28/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 241,
      "real_time": 2.9008530642589964e+06,
      "cpu_time": 3.0269744149338361e+06,
      "time_unit": "ns",
      "items_per_second": 1.7712108425293419e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = true]": 9.0033003156525926e+18,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 5.1380224000000000e+07,
      "input_width": 2.8000000000000000e+01,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 2.4100000000000000e+02,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 5.1380224000000000e+07,
      "output_width": 2.8000000000000000e+01,
      "predicted_flops": 1.7712108425293419e+10,
      "predicted_flops_count": 5.1380224000000000e+07
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_FLOAT32__BatchSize_128__7342692363450781667<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:128/input[1]:256/input[2]:56/input[3]:56/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 185,
      "real_time": 3.7922729448591536e+06,
      "cpu_time": 4.0040116108143963e+06,
      "time_unit": "ns",
      "items_per_second": 2.7097323819822407e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = false]": 1.4627515035010154e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 5.6000000000000000e+01,
      "input_size": 1.0276044800000000e+08,
      "input_width": 5.6000000000000000e+01,
      "is_training": 0.0000000000000000e+00,
      "num_iterations": 1.8500000000000000e+02,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 5.6000000000000000e+01,
      "output_size": 1.0276044800000000e+08,
      "output_width": 5.6000000000000000e+01,
      "predicted_flops": 2.7097323819822407e+10,
      "predicted_flops_count": 1.0276044800000000e+08
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_FLOAT32__BatchSize_128__10002293494626339528<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:128/input[1]:256/input[2]:56/input[3]:56/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "iterations": 120,
      "real_time": 5.8281498805930214e+06,
      "cpu_time": 6.3206788416512916e+06,
      "time_unit": "ns",
      "items_per_second": 1.7631744225071987e+10,
      "batch_size": 1.2800000000000000e+02,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 1.2850267679440775e+19,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = float; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = true]": 9.0033003156525926e+18,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 5.6000000000000000e+01,
      "input_size": 1.0276044800000000e+08,
      "input_width": 5.6000000000000000e+01,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 1.2000000000000000e+02,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 5.6000000000000000e+01,
      "output_size": 1.0276044800000000e+08,
      "output_width": 5.6000000000000000e+01,
      "predicted_flops": 1.7631744225071987e+10,
      "predicted_flops_count": 1.0276044800000000e+08
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__9607949287547158492<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:1/input[1]:544/input[2]:7/input[3]:7/filter_count:544/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:4/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__9607949287547158492<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:1/input[1]:544/input[2]:7/input[3]:7/filter_count:544/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:4/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__9607949287547158492<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:1/input[1]:544/input[2]:7/input[3]:7/filter_count:544/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:4/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__9607949287547158492<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:1/input[1]:544/input[2]:7/input[3]:7/filter_count:544/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:4/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__9607949287547158492<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:1/input[1]:544/input[2]:7/input[3]:7/filter_count:544/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:4/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__9607949287547158492<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:1/input[1]:544/input[2]:7/input[3]:7/filter_count:544/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:4/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__9607949287547158492<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:1/input[1]:544/input[2]:7/input[3]:7/filter_count:544/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:4/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__9607949287547158492<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:1/input[1]:544/input[2]:7/input[3]:7/filter_count:544/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:4/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__10859654046309683015<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:256/input[2]:27/input[3]:27/filter_count:32/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 1724,
      "real_time": 4.0600777579984133e+05,
      "cpu_time": 4.1351871635671158e+05,
      "time_unit": "ns",
      "items_per_second": 1.8827518820153071e+12,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 4.1657599806785583e-01,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4730153338016043e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 3.2000000000000000e+01,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "group": 1.0000000000000000e+00,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 2.7000000000000000e+01,
      "input[3]": 2.7000000000000000e+01,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 2.7000000000000000e+01,
      "input_size": 2.3887872000000000e+07,
      "input_width": 2.7000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 3.2000000000000000e+01,
      "num_iterations": 1.7240000000000000e+03,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 3.2000000000000000e+01,
      "output_height": 2.7000000000000000e+01,
      "output_size": 2.9859840000000000e+06,
      "output_width": 2.7000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 1.8827518820153071e+12,
      "predicted_advised_flops_count": 7.6441190400000000e+08,
      "predicted_flops": 1.8827518820153071e+12,
      "predicted_flops_count": 7.6441190400000000e+08,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__10859654046309683015<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:256/input[2]:27/input[3]:27/filter_count:32/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 2045,
      "real_time": 3.4257898179468105e+05,
      "cpu_time": 3.4944010317804094e+05,
      "time_unit": "ns",
      "items_per_second": 2.2313450171269917e+12,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 4.3800000000000000e+03,
      "advised_time": 3.5942399501800537e-01,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.2419525699096977e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 3.2000000000000000e+01,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "group": 1.0000000000000000e+00,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 2.7000000000000000e+01,
      "input[3]": 2.7000000000000000e+01,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 2.7000000000000000e+01,
      "input_size": 2.3887872000000000e+07,
      "input_width": 2.7000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 3.2000000000000000e+01,
      "num_iterations": 2.0450000000000000e+03,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 3.2000000000000000e+01,
      "output_height": 2.7000000000000000e+01,
      "output_size": 2.9859840000000000e+06,
      "output_width": 2.7000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 2.2313450171269917e+12,
      "predicted_advised_flops_count": 7.6441190400000000e+08,
      "predicted_flops": 2.2313450171269917e+12,
      "predicted_flops_count": 7.6441190400000000e+08,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 4.3800000000000000e+03,
      "workspace_megabytes": 4.1770935058593750e-03
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__10859654046309683015<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:256/input[2]:27/input[3]:27/filter_count:32/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 758,
      "real_time": 9.2348293170927570e+05,
      "cpu_time": 9.4074761609428504e+05,
      "time_unit": "ns",
      "items_per_second": 8.2774881673790002e+11,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 9.5551488000000000e+07,
      "advised_time": 9.2979198694229126e-01,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)2; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4280899851402570e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 2.0000000000000000e+00,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 3.2000000000000000e+01,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "group": 1.0000000000000000e+00,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 2.7000000000000000e+01,
      "input[3]": 2.7000000000000000e+01,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 2.7000000000000000e+01,
      "input_size": 2.3887872000000000e+07,
      "input_width": 2.7000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 3.2000000000000000e+01,
      "num_iterations": 7.5800000000000000e+02,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 3.2000000000000000e+01,
      "output_height": 2.7000000000000000e+01,
      "output_size": 2.9859840000000000e+06,
      "output_width": 2.7000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 8.2774881673790002e+11,
      "predicted_advised_flops_count": 7.6441190400000000e+08,
      "predicted_flops": 8.2774881673790002e+11,
      "predicted_flops_count": 7.6441190400000000e+08,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 9.5551488000000000e+07,
      "workspace_megabytes": 9.1125000000000000e+01
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__10859654046309683015<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:256/input[2]:27/input[3]:27/filter_count:32/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__10859654046309683015<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:256/input[2]:27/input[3]:27/filter_count:32/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 437,
      "real_time": 1.6022425651597180e+06,
      "cpu_time": 1.6439122974803194e+06,
      "time_unit": "ns",
      "items_per_second": 4.7708875086825598e+11,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 3.5654860800000000e+08,
      "advised_time": 1.6058239936828613e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)4; cudnnMathType_t math_type = (cudnnMathType_t)0]": 2.3237108083472476e+18,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 4.0000000000000000e+00,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 3.2000000000000000e+01,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "group": 1.0000000000000000e+00,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 2.7000000000000000e+01,
      "input[3]": 2.7000000000000000e+01,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 2.7000000000000000e+01,
      "input_size": 2.3887872000000000e+07,
      "input_width": 2.7000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 3.2000000000000000e+01,
      "num_iterations": 4.3700000000000000e+02,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 3.2000000000000000e+01,
      "output_height": 2.7000000000000000e+01,
      "output_size": 2.9859840000000000e+06,
      "output_width": 2.7000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 4.7708875086825598e+11,
      "predicted_advised_flops_count": 7.6441190400000000e+08,
      "predicted_flops": 6.7203825655723059e+11,
      "predicted_flops_count": 1.0767683000717218e+09,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 3.5654860800000000e+08,
      "workspace_megabytes": 3.4003125000000000e+02
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__10859654046309683015<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:256/input[2]:27/input[3]:27/filter_count:32/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 501,
      "real_time": 1.3961897005314033e+06,
      "cpu_time": 1.4288416646631088e+06,
      "time_unit": "ns",
      "items_per_second": 5.4749859829868207e+11,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.3647913600000000e+08,
      "advised_time": 1.4653439521789551e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)5; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.6667819325789325e+18,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 5.0000000000000000e+00,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 3.2000000000000000e+01,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "group": 1.0000000000000000e+00,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 2.7000000000000000e+01,
      "input[3]": 2.7000000000000000e+01,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 2.7000000000000000e+01,
      "input_size": 2.3887872000000000e+07,
      "input_width": 2.7000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 3.2000000000000000e+01,
      "num_iterations": 5.0100000000000000e+02,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 3.2000000000000000e+01,
      "output_height": 2.7000000000000000e+01,
      "output_size": 2.9859840000000000e+06,
      "output_width": 2.7000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 5.4749859829868207e+11,
      "predicted_advised_flops_count": 7.6441190400000000e+08,
      "predicted_flops": 7.7121919726373376e+11,
      "predicted_flops_count": 1.0767683000717218e+09,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 1.3647913600000000e+08,
      "workspace_megabytes": 1.3015664672851562e+02
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__10859654046309683015<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:256/input[2]:27/input[3]:27/filter_count:32/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__10859654046309683015<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:256/input[2]:27/input[3]:27/filter_count:32/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__14936272760149814657<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:1/input[1]:136/input[2]:28/input[3]:28/filter_count:136/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:136/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__14936272760149814657<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:1/input[1]:136/input[2]:28/input[3]:28/filter_count:136/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:136/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__14936272760149814657<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:1/input[1]:136/input[2]:28/input[3]:28/filter_count:136/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:136/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__14936272760149814657<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:1/input[1]:136/input[2]:28/input[3]:28/filter_count:136/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:136/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__14936272760149814657<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:1/input[1]:136/input[2]:28/input[3]:28/filter_count:136/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:136/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__14936272760149814657<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:1/input[1]:136/input[2]:28/input[3]:28/filter_count:136/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:136/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__14936272760149814657<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:1/input[1]:136/input[2]:28/input[3]:28/filter_count:136/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:136/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__14936272760149814657<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:1/input[1]:136/input[2]:28/input[3]:28/filter_count:136/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:136/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__8883220012763298277<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:1/input[1]:192/input[2]:6/input[3]:6/filter_count:384/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 2881,
      "real_time": 2.4318743576090402e+05,
      "cpu_time": 2.4924012947152683e+05,
      "time_unit": "ns",
      "items_per_second": 1.0914248064236151e+10,
      "advised_convolution_algorithm": 6.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 2.4451200664043427e-01,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4730153338016043e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 3.8400000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "group": 1.0000000000000000e+00,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 1.9200000000000000e+02,
      "input[2]": 6.0000000000000000e+00,
      "input[3]": 6.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 1.9200000000000000e+02,
      "input_height": 6.0000000000000000e+00,
      "input_size": 6.9120000000000000e+03,
      "input_width": 6.0000000000000000e+00,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 3.8400000000000000e+02,
      "num_iterations": 2.8810000000000000e+03,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 3.8400000000000000e+02,
      "output_height": 6.0000000000000000e+00,
      "output_size": 1.3824000000000000e+04,
      "output_width": 6.0000000000000000e+00,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "predicted_advised_flops": -4.1120545429130461e+03,
      "predicted_advised_flops_count": -1.0000000000000000e+00,
      "predicted_flops": 9.8228232578125366e+10,
      "predicted_flops_count": 2.3887872000000000e+07,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__8883220012763298277<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:1/input[1]:192/input[2]:6/input[3]:6/filter_count:384/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 3141,
      "real_time": 2.2273126482245722e+05,
      "cpu_time": 2.2861078446474459e+05,
      "time_unit": "ns",
      "items_per_second": 1.1916638654729111e+10,
      "advised_convolution_algorithm": 6.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 2.2400000000000000e+02,
      "advised_time": 2.4236799776554108e-01,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.2419525699096977e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 3.8400000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "group": 1.0000000000000000e+00,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 1.9200000000000000e+02,
      "input[2]": 6.0000000000000000e+00,
      "input[3]": 6.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 1.9200000000000000e+02,
      "input_height": 6.0000000000000000e+00,
      "input_size": 6.9120000000000000e+03,
      "input_width": 6.0000000000000000e+00,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 3.8400000000000000e+02,
      "num_iterations": 3.1410000000000000e+03,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 3.8400000000000000e+02,
      "output_height": 6.0000000000000000e+00,
      "output_size": 1.3824000000000000e+04,
      "output_width": 6.0000000000000000e+00,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "predicted_advised_flops": -4.4897154460875372e+03,
      "predicted_advised_flops_count": -1.0000000000000000e+00,
      "predicted_flops": 1.0724974789256200e+11,
      "predicted_flops_count": 2.3887872000000000e+07,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 2.2400000000000000e+02,
      "workspace_megabytes": 2.1362304687500000e-04
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__8883220012763298277<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:1/input[1]:192/input[2]:6/input[3]:6/filter_count:384/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 4404,
      "real_time": 1.5891871803816996e+05,
      "cpu_time": 1.6447342506853768e+05,
      "time_unit": "ns",
      "items_per_second": 1.6701670091263245e+10,
      "advised_convolution_algorithm": 6.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 2.4883200000000000e+05,
      "advised_time": 1.7791999876499176e-01,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)2; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4280899851402570e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 2.0000000000000000e+00,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 3.8400000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "group": 1.0000000000000000e+00,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 1.9200000000000000e+02,
      "input[2]": 6.0000000000000000e+00,
      "input[3]": 6.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 1.9200000000000000e+02,
      "input_height": 6.0000000000000000e+00,
      "input_size": 6.9120000000000000e+03,
      "input_width": 6.0000000000000000e+00,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 3.8400000000000000e+02,
      "num_iterations": 4.4040000000000000e+03,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 3.8400000000000000e+02,
      "output_height": 6.0000000000000000e+00,
      "output_size": 1.3824000000000000e+04,
      "output_width": 6.0000000000000000e+00,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "predicted_advised_flops": -6.2925249608407648e+03,
      "predicted_advised_flops_count": -1.0000000000000000e+00,
      "predicted_flops": 1.5031503082136920e+11,
      "predicted_flops_count": 2.3887872000000000e+07,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 2.4883200000000000e+05,
      "workspace_megabytes": 2.3730468750000000e-01
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__8883220012763298277<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:1/input[1]:192/input[2]:6/input[3]:6/filter_count:384/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__8883220012763298277<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:1/input[1]:192/input[2]:6/input[3]:6/filter_count:384/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 1299,
      "real_time": 5.3623412189800141e+05,
      "cpu_time": 5.4548114241369802e+05,
      "time_unit": "ns",
      "items_per_second": 4.9497185867348900e+09,
      "advised_convolution_algorithm": 6.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.7296588800000000e+08,
      "advised_time": 5.7241600751876831e-01,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)4; cudnnMathType_t math_type = (cudnnMathType_t)0]": 2.3237108083472476e+18,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 4.0000000000000000e+00,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 3.8400000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "group": 1.0000000000000000e+00,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 1.9200000000000000e+02,
      "input[2]": 6.0000000000000000e+00,
      "input[3]": 6.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 1.9200000000000000e+02,
      "input_height": 6.0000000000000000e+00,
      "input_size": 6.9120000000000000e+03,
      "input_width": 6.0000000000000000e+00,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 3.8400000000000000e+02,
      "num_iterations": 1.2990000000000000e+03,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 3.8400000000000000e+02,
      "output_height": 6.0000000000000000e+00,
      "output_size": 1.3824000000000000e+04,
      "output_width": 6.0000000000000000e+00,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "predicted_advised_flops": -1.8648570823141556e+03,
      "predicted_advised_flops_count": -1.0000000000000000e+00,
      "predicted_flops": 3.0739311785521687e+10,
      "predicted_flops_count": 1.6483467863058105e+07,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 1.7296588800000000e+08,
      "workspace_megabytes": 1.6495312500000000e+02
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__8883220012763298277<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:1/input[1]:192/input[2]:6/input[3]:6/filter_count:384/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 327,
      "real_time": 2.1454367618609094e+06,
      "cpu_time": 2.2160524495357038e+06,
      "time_unit": "ns",
      "items_per_second": 1.2371411020746155e+09,
      "advised_convolution_algorithm": 6.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 3.2339558400000000e+08,
      "advised_time": 2.1565439701080322e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)5; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.6667819325789325e+18,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 5.0000000000000000e+00,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 3.8400000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "group": 1.0000000000000000e+00,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 1.9200000000000000e+02,
      "input[2]": 6.0000000000000000e+00,
      "input[3]": 6.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 1.9200000000000000e+02,
      "input_height": 6.0000000000000000e+00,
      "input_size": 6.9120000000000000e+03,
      "input_width": 6.0000000000000000e+00,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 3.8400000000000000e+02,
      "num_iterations": 3.2700000000000000e+02,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 3.8400000000000000e+02,
      "output_height": 6.0000000000000000e+00,
      "output_size": 1.3824000000000000e+04,
      "output_width": 6.0000000000000000e+00,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "predicted_advised_flops": -4.6610555844704544e+02,
      "predicted_advised_flops_count": -1.0000000000000000e+00,
      "predicted_flops": 7.6830359934546242e+09,
      "predicted_flops_count": 1.6483467863058105e+07,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 3.2339558400000000e+08,
      "workspace_megabytes": 3.0841406250000000e+02
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__8883220012763298277<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:1/input[1]:192/input[2]:6/input[3]:6/filter_count:384/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 11843,
      "real_time": 5.9094897667135374e+04,
      "cpu_time": 6.4349013593629752e+04,
      "time_unit": "ns",
      "items_per_second": 4.4914334481978340e+10,
      "advised_convolution_algorithm": 6.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 7.3743360000000000e+06,
      "advised_time": 1.0649599879980087e-01,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)6; cudnnMathType_t math_type = (cudnnMathType_t)0]": 5.7500739770702787e+18,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 6.0000000000000000e+00,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 3.8400000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "group": 1.0000000000000000e+00,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 1.9200000000000000e+02,
      "input[2]": 6.0000000000000000e+00,
      "input[3]": 6.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 1.9200000000000000e+02,
      "input_height": 6.0000000000000000e+00,
      "input_size": 6.9120000000000000e+03,
      "input_width": 6.0000000000000000e+00,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 3.8400000000000000e+02,
      "num_iterations": 1.1843000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 3.8400000000000000e+02,
      "output_height": 6.0000000000000000e+00,
      "output_size": 1.3824000000000000e+04,
      "output_width": 6.0000000000000000e+00,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "predicted_advised_flops": -1.6921934709705623e+04,
      "predicted_advised_flops_count": -1.0000000000000000e+00,
      "predicted_flops": -1.6921934709705623e+04,
      "predicted_flops_count": -1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 7.3743360000000000e+06,
      "workspace_megabytes": 7.0327148437500000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__8883220012763298277<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:1/input[1]:192/input[2]:6/input[3]:6/filter_count:384/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 4051,
      "real_time": 1.7252098318131105e+05,
      "cpu_time": 1.7814788619897087e+05,
      "time_unit": "ns",
      "items_per_second": 1.5384841606255852e+10,
      "advised_convolution_algorithm": 6.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.5925248000000000e+07,
      "advised_time": 1.8432000279426575e-01,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)7; cudnnMathType_t math_type = (cudnnMathType_t)0]": 8.2538945752816425e+18,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 7.0000000000000000e+00,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 3.8400000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "group": 1.0000000000000000e+00,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 1.9200000000000000e+02,
      "input[2]": 6.0000000000000000e+00,
      "input[3]": 6.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 1.9200000000000000e+02,
      "input_height": 6.0000000000000000e+00,
      "input_size": 6.9120000000000000e+03,
      "input_width": 6.0000000000000000e+00,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 3.8400000000000000e+02,
      "num_iterations": 4.0510000000000000e+03,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 3.8400000000000000e+02,
      "output_height": 6.0000000000000000e+00,
      "output_size": 1.3824000000000000e+04,
      "output_width": 6.0000000000000000e+00,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "predicted_advised_flops": -5.7963963661686848e+03,
      "predicted_advised_flops_count": -1.0000000000000000e+00,
      "predicted_flops": -5.7963963661686848e+03,
      "predicted_flops_count": -1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 1.5925248000000000e+07,
      "workspace_megabytes": 1.5187500000000000e+01
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__14633515634938261890<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:1/input[1]:832/input[2]:6/input[3]:6/filter_count:192/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 8073,
      "real_time": 8.6613494153886117e+04,
      "cpu_time": 9.2330139229751236e+04,
      "time_unit": "ns",
      "items_per_second": 6.6395935831691391e+10,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 8.7039999663829803e-02,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4730153338016043e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.9200000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "group": 1.0000000000000000e+00,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 8.3200000000000000e+02,
      "input[2]": 6.0000000000000000e+00,
      "input[3]": 6.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 8.3200000000000000e+02,
      "input_height": 6.0000000000000000e+00,
      "input_size": 2.9952000000000000e+04,
      "input_width": 6.0000000000000000e+00,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.9200000000000000e+02,
      "num_iterations": 8.0730000000000000e+03,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 1.9200000000000000e+02,
      "output_height": 6.0000000000000000e+00,
      "output_size": 6.9120000000000000e+03,
      "output_width": 6.0000000000000000e+00,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 6.6395935831691391e+10,
      "predicted_advised_flops_count": 5.7507840000000000e+06,
      "predicted_flops": 6.6395935831691391e+10,
      "predicted_flops_count": 5.7507840000000000e+06,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__14633515634938261890<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:1/input[1]:832/input[2]:6/input[3]:6/filter_count:192/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 5459,
      "real_time": 1.2822249386771621e+05,
      "cpu_time": 1.3373619344168616e+05,
      "time_unit": "ns",
      "items_per_second": 4.4850040164816422e+10,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 2.2400000000000000e+02,
      "advised_time": 1.3094399869441986e-01,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.2419525699096977e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.9200000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "group": 1.0000000000000000e+00,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 8.3200000000000000e+02,
      "input[2]": 6.0000000000000000e+00,
      "input[3]": 6.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 8.3200000000000000e+02,
      "input_height": 6.0000000000000000e+00,
      "input_size": 2.9952000000000000e+04,
      "input_width": 6.0000000000000000e+00,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.9200000000000000e+02,
      "num_iterations": 5.4590000000000000e+03,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 1.9200000000000000e+02,
      "output_height": 6.0000000000000000e+00,
      "output_size": 6.9120000000000000e+03,
      "output_width": 6.0000000000000000e+00,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 4.4850040164816422e+10,
      "predicted_advised_flops_count": 5.7507840000000000e+06,
      "predicted_flops": 4.4850040164816422e+10,
      "predicted_flops_count": 5.7507840000000000e+06,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 2.2400000000000000e+02,
      "workspace_megabytes": 2.1362304687500000e-04
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__14633515634938261890<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:1/input[1]:832/input[2]:6/input[3]:6/filter_count:192/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 5195,
      "real_time": 1.3494471212870535e+05,
      "cpu_time": 1.4098440115521706e+05,
      "time_unit": "ns",
      "items_per_second": 4.2615852887329979e+10,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.1980800000000000e+05,
      "advised_time": 1.4947199821472168e-01,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)2; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4280899851402570e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 2.0000000000000000e+00,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.9200000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "group": 1.0000000000000000e+00,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 8.3200000000000000e+02,
      "input[2]": 6.0000000000000000e+00,
      "input[3]": 6.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 8.3200000000000000e+02,
      "input_height": 6.0000000000000000e+00,
      "input_size": 2.9952000000000000e+04,
      "input_width": 6.0000000000000000e+00,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.9200000000000000e+02,
      "num_iterations": 5.1950000000000000e+03,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 1.9200000000000000e+02,
      "output_height": 6.0000000000000000e+00,
      "output_size": 6.9120000000000000e+03,
      "output_width": 6.0000000000000000e+00,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 4.2615852887329979e+10,
      "predicted_advised_flops_count": 5.7507840000000000e+06,
      "predicted_flops": 4.2615852887329979e+10,
      "predicted_flops_count": 5.7507840000000000e+06,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 1.1980800000000000e+05,
      "workspace_megabytes": 1.1425781250000000e-01
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__14633515634938261890<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:1/input[1]:832/input[2]:6/input[3]:6/filter_count:192/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__14633515634938261890<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:1/input[1]:832/input[2]:6/input[3]:6/filter_count:192/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 668,
      "real_time": 1.0492378444282594e+06,
      "cpu_time": 1.0753934281463111e+06,
      "time_unit": "ns",
      "items_per_second": 5.4809155336306629e+09,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 3.7060608000000000e+08,
      "advised_time": 1.0741759538650513e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)4; cudnnMathType_t math_type = (cudnnMathType_t)0]": 2.3237108083472476e+18,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 4.0000000000000000e+00,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.9200000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "group": 1.0000000000000000e+00,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 8.3200000000000000e+02,
      "input[2]": 6.0000000000000000e+00,
      "input[3]": 6.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 8.3200000000000000e+02,
      "input_height": 6.0000000000000000e+00,
      "input_size": 2.9952000000000000e+04,
      "input_width": 6.0000000000000000e+00,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.9200000000000000e+02,
      "num_iterations": 6.6800000000000000e+02,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 1.9200000000000000e+02,
      "output_height": 6.0000000000000000e+00,
      "output_size": 6.9120000000000000e+03,
      "output_width": 6.0000000000000000e+00,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 5.4809155336306629e+09,
      "predicted_advised_flops_count": 5.7507840000000000e+06,
      "predicted_flops": 3.3998478308972836e+10,
      "predicted_flops_count": 3.5672490094747595e+07,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 3.7060608000000000e+08,
      "workspace_megabytes": 3.5343750000000000e+02
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__14633515634938261890<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:1/input[1]:832/input[2]:6/input[3]:6/filter_count:192/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 2721,
      "real_time": 2.5645539698958362e+05,
      "cpu_time": 2.6243072252790630e+05,
      "time_unit": "ns",
      "items_per_second": 2.2424109874488537e+10,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 2.2561184000000000e+07,
      "advised_time": 2.7647998929023743e-01,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)5; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.6667819325789325e+18,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 5.0000000000000000e+00,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.9200000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "group": 1.0000000000000000e+00,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 8.3200000000000000e+02,
      "input[2]": 6.0000000000000000e+00,
      "input[3]": 6.0000000000000000e+00,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 8.3200000000000000e+02,
      "input_height": 6.0000000000000000e+00,
      "input_size": 2.9952000000000000e+04,
      "input_width": 6.0000000000000000e+00,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.9200000000000000e+02,
      "num_iterations": 2.7210000000000000e+03,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 1.9200000000000000e+02,
      "output_height": 6.0000000000000000e+00,
      "output_size": 6.9120000000000000e+03,
      "output_width": 6.0000000000000000e+00,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 2.2424109874488537e+10,
      "predicted_advised_flops_count": 5.7507840000000000e+06,
      "predicted_flops": 1.3909822336940915e+11,
      "predicted_flops_count": 3.5672490094747595e+07,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 2.2561184000000000e+07,
      "workspace_megabytes": 2.1516021728515625e+01
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__14633515634938261890<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:1/input[1]:832/input[2]:6/input[3]:6/filter_count:192/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__14633515634938261890<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:1/input[1]:832/input[2]:6/input[3]:6/filter_count:192/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__6011671299275867608<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:1/input[1]:224/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 18015,
      "real_time": 3.8883556437390682e+04,
      "cpu_time": 4.4043262671254553e+04,
      "time_unit": "ns",
      "items_per_second": 5.7810679010791797e+11,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 3.9935998618602753e-02,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4730153338016043e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "group": 1.0000000000000000e+00,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 2.2400000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 2.2400000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 1.7561600000000000e+05,
      "input_width": 2.8000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 1.8015000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 1.0035200000000000e+05,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 5.7810679010791797e+11,
      "predicted_advised_flops_count": 2.2478848000000000e+07,
      "predicted_flops": 5.7810679010791797e+11,
      "predicted_flops_count": 2.2478848000000000e+07,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__6011671299275867608<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:1/input[1]:224/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 16396,
      "real_time": 4.3271642791341292e+04,
      "cpu_time": 4.8612195107931875e+04,
      "time_unit": "ns",
      "items_per_second": 5.1948219549681726e+11,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 4.7120000000000000e+03,
      "advised_time": 4.6080000698566437e-02,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.2419525699096977e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "group": 1.0000000000000000e+00,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 2.2400000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 2.2400000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 1.7561600000000000e+05,
      "input_width": 2.8000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 1.6396000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 1.0035200000000000e+05,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 5.1948219549681726e+11,
      "predicted_advised_flops_count": 2.2478848000000000e+07,
      "predicted_flops": 5.1948219549681726e+11,
      "predicted_flops_count": 2.2478848000000000e+07,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 4.7120000000000000e+03,
      "workspace_megabytes": 4.4937133789062500e-03
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__6011671299275867608<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:1/input[1]:224/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 6834,
      "real_time": 1.0227261979936861e+05,
      "cpu_time": 1.0759925182948954e+05,
      "time_unit": "ns",
      "items_per_second": 2.1979341141448666e+11,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 7.0246400000000000e+05,
      "advised_time": 1.0854399949312210e-01,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)2; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4280899851402570e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 2.0000000000000000e+00,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "group": 1.0000000000000000e+00,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 2.2400000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 2.2400000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 1.7561600000000000e+05,
      "input_width": 2.8000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 6.8340000000000000e+03,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 1.0035200000000000e+05,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 2.1979341141448666e+11,
      "predicted_advised_flops_count": 2.2478848000000000e+07,
      "predicted_flops": 2.1979341141448666e+11,
      "predicted_flops_count": 2.2478848000000000e+07,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 7.0246400000000000e+05,
      "workspace_megabytes": 6.6992187500000000e-01
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__6011671299275867608<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:1/input[1]:224/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__6011671299275867608<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:1/input[1]:224/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 1085,
      "real_time": 6.4526849811519007e+05,
      "cpu_time": 6.5808511336181592e+05,
      "time_unit": "ns",
      "items_per_second": 3.4836425558755836e+10,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 2.5162547200000000e+08,
      "advised_time": 6.6630399227142334e-01,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)4; cudnnMathType_t math_type = (cudnnMathType_t)0]": 2.3237108083472476e+18,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 4.0000000000000000e+00,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "group": 1.0000000000000000e+00,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 2.2400000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 2.2400000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 1.7561600000000000e+05,
      "input_width": 2.8000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 1.0850000000000000e+03,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 1.0035200000000000e+05,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 3.4836425558755836e+10,
      "predicted_advised_flops_count": 2.2478848000000000e+07,
      "predicted_flops": 3.7389056199232239e+11,
      "predicted_flops_count": 2.4125980139623022e+08,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 2.5162547200000000e+08,
      "workspace_megabytes": 2.3996875000000000e+02
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__6011671299275867608<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:1/input[1]:224/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 7530,
      "real_time": 9.2896468986521795e+04,
      "cpu_time": 9.8141177290401451e+04,
      "time_unit": "ns",
      "items_per_second": 2.4197742115754068e+11,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 5.2402240000000000e+06,
      "advised_time": 1.0038399696350098e-01,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)5; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.6667819325789325e+18,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 5.0000000000000000e+00,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "group": 1.0000000000000000e+00,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 2.2400000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 2.2400000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 1.7561600000000000e+05,
      "input_width": 2.8000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 7.5300000000000000e+03,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 1.0035200000000000e+05,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 2.4197742115754068e+11,
      "predicted_advised_flops_count": 2.2478848000000000e+07,
      "predicted_flops": 2.5970825805148120e+12,
      "predicted_flops_count": 2.4125980139623022e+08,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 5.2402240000000000e+06,
      "workspace_megabytes": 4.9974670410156250e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__6011671299275867608<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:1/input[1]:224/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__6011671299275867608<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:1/input[1]:224/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__14256040405851014902<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:1/input[1]:512/input[2]:13/input[3]:13/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 12338,
      "real_time": 5.6771260643329624e+04,
      "cpu_time": 6.1952534041329498e+04,
      "time_unit": "ns",
      "items_per_second": 9.7545693670458694e+10,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 5.6320000439882278e-02,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4730153338016043e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "group": 1.0000000000000000e+00,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 1.3000000000000000e+01,
      "input[3]": 1.3000000000000000e+01,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 1.3000000000000000e+01,
      "input_size": 8.6528000000000000e+04,
      "input_width": 1.3000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 1.2338000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 1.3000000000000000e+01,
      "output_size": 1.0816000000000000e+04,
      "output_width": 1.3000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 9.7545693670458694e+10,
      "predicted_advised_flops_count": 5.5377920000000000e+06,
      "predicted_flops": 9.7545693670458694e+10,
      "predicted_flops_count": 5.5377920000000000e+06,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__14256040405851014902<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:1/input[1]:512/input[2]:13/input[3]:13/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 8268,
      "real_time": 8.4660007477333071e+04,
      "cpu_time": 8.9952306965458556e+04,
      "time_unit": "ns",
      "items_per_second": 6.5412136911075661e+10,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.0200000000000000e+03,
      "advised_time": 8.7039999663829803e-02,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.2419525699096977e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "group": 1.0000000000000000e+00,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 1.3000000000000000e+01,
      "input[3]": 1.3000000000000000e+01,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 1.3000000000000000e+01,
      "input_size": 8.6528000000000000e+04,
      "input_width": 1.3000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 8.2680000000000000e+03,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 1.3000000000000000e+01,
      "output_size": 1.0816000000000000e+04,
      "output_width": 1.3000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 6.5412136911075661e+10,
      "predicted_advised_flops_count": 5.5377920000000000e+06,
      "predicted_flops": 6.5412136911075661e+10,
      "predicted_flops_count": 5.5377920000000000e+06,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 1.0200000000000000e+03,
      "workspace_megabytes": 9.7274780273437500e-04
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__14256040405851014902<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:1/input[1]:512/input[2]:13/input[3]:13/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 5809,
      "real_time": 1.2056870393103799e+05,
      "cpu_time": 1.2596246703431898e+05,
      "time_unit": "ns",
      "items_per_second": 4.5930592429420708e+10,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 3.4611200000000000e+05,
      "advised_time": 1.2563200294971466e-01,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)2; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4280899851402570e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 2.0000000000000000e+00,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "group": 1.0000000000000000e+00,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 1.3000000000000000e+01,
      "input[3]": 1.3000000000000000e+01,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 1.3000000000000000e+01,
      "input_size": 8.6528000000000000e+04,
      "input_width": 1.3000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 5.8090000000000000e+03,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 1.3000000000000000e+01,
      "output_size": 1.0816000000000000e+04,
      "output_width": 1.3000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 4.5930592429420708e+10,
      "predicted_advised_flops_count": 5.5377920000000000e+06,
      "predicted_flops": 4.5930592429420708e+10,
      "predicted_flops_count": 5.5377920000000000e+06,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 3.4611200000000000e+05,
      "workspace_megabytes": 3.3007812500000000e-01
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__14256040405851014902<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:1/input[1]:512/input[2]:13/input[3]:13/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__14256040405851014902<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:1/input[1]:512/input[2]:13/input[3]:13/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 3088,
      "real_time": 2.2613697261957437e+05,
      "cpu_time": 2.3209606476856902e+05,
      "time_unit": "ns",
      "items_per_second": 2.4488662494461330e+10,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 7.6808192000000000e+07,
      "advised_time": 2.4233600497245789e-01,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)4; cudnnMathType_t math_type = (cudnnMathType_t)0]": 2.3237108083472476e+18,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 4.0000000000000000e+00,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "group": 1.0000000000000000e+00,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 1.3000000000000000e+01,
      "input[3]": 1.3000000000000000e+01,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 1.3000000000000000e+01,
      "input_size": 8.6528000000000000e+04,
      "input_width": 1.3000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 3.0880000000000000e+03,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 1.3000000000000000e+01,
      "output_size": 1.0816000000000000e+04,
      "output_width": 1.3000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 2.4488662494461330e+10,
      "predicted_advised_flops_count": 5.5377920000000000e+06,
      "predicted_flops": 2.0891211903914960e+11,
      "predicted_flops_count": 4.7242754143053442e+07,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 7.6808192000000000e+07,
      "workspace_megabytes": 7.3250000000000000e+01
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__14256040405851014902<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:1/input[1]:512/input[2]:13/input[3]:13/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 6116,
      "real_time": 1.1480615360771141e+05,
      "cpu_time": 1.2049117642207336e+05,
      "time_unit": "ns",
      "items_per_second": 4.8236020683372421e+10,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 5.4752320000000000e+06,
      "advised_time": 1.1977600306272507e-01,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)5; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.6667819325789325e+18,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 5.0000000000000000e+00,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "group": 1.0000000000000000e+00,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 1.3000000000000000e+01,
      "input[3]": 1.3000000000000000e+01,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 1.3000000000000000e+01,
      "input_size": 8.6528000000000000e+04,
      "input_width": 1.3000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 6.1160000000000000e+03,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 1.3000000000000000e+01,
      "output_size": 1.0816000000000000e+04,
      "output_width": 1.3000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 4.8236020683372421e+10,
      "predicted_advised_flops_count": 5.5377920000000000e+06,
      "predicted_flops": 4.1150019104794910e+11,
      "predicted_flops_count": 4.7242754143053442e+07,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 5.4752320000000000e+06,
      "workspace_megabytes": 5.2215881347656250e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__14256040405851014902<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:1/input[1]:512/input[2]:13/input[3]:13/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__14256040405851014902<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:1/input[1]:512/input[2]:13/input[3]:13/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__16209620136994831937<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:1/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:7/filter_width:7/pad_height:3/pad_width:3/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 8527,
      "real_time": 8.1523388958822194e+04,
      "cpu_time": 8.6771743638110172e+04,
      "time_unit": "ns",
      "items_per_second": 1.1817212364498328e+11,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 8.2943998277187347e-02,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4730153338016043e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 7.0000000000000000e+00,
      "filter_width": 7.0000000000000000e+00,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "group": 1.0000000000000000e+00,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 3.0000000000000000e+00,
      "input[2]": 2.2400000000000000e+02,
      "input[3]": 2.2400000000000000e+02,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 3.0000000000000000e+00,
      "input_height": 2.2400000000000000e+02,
      "input_size": 1.5052800000000000e+05,
      "input_width": 2.2400000000000000e+02,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 8.5270000000000000e+03,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 1.1200000000000000e+02,
      "output_size": 8.0281600000000000e+05,
      "output_width": 1.1200000000000000e+02,
      "pad_height": 3.0000000000000000e+00,
      "pad_width": 3.0000000000000000e+00,
      "predicted_advised_flops": 1.4476085146510452e+12,
      "predicted_advised_flops_count": 1.1801395200000000e+08,
      "predicted_flops": 1.4476085146510452e+12,
      "predicted_flops_count": 1.1801395200000000e+08,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__16209620136994831937<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:1/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:7/filter_width:7/pad_height:3/pad_width:3/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 10724,
      "real_time": 6.3462194432167846e+04,
      "cpu_time": 6.8753495242985038e+04,
      "time_unit": "ns",
      "items_per_second": 1.5180363815337601e+11,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 7.5272000000000000e+04,
      "advised_time": 6.7584000527858734e-02,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.2419525699096977e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 7.0000000000000000e+00,
      "filter_width": 7.0000000000000000e+00,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "group": 1.0000000000000000e+00,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 3.0000000000000000e+00,
      "input[2]": 2.2400000000000000e+02,
      "input[3]": 2.2400000000000000e+02,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 3.0000000000000000e+00,
      "input_height": 2.2400000000000000e+02,
      "input_size": 1.5052800000000000e+05,
      "input_width": 2.2400000000000000e+02,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 1.0724000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 1.1200000000000000e+02,
      "output_size": 8.0281600000000000e+05,
      "output_width": 1.1200000000000000e+02,
      "pad_height": 3.0000000000000000e+00,
      "pad_width": 3.0000000000000000e+00,
      "predicted_advised_flops": 1.8595945673788560e+12,
      "predicted_advised_flops_count": 1.1801395200000000e+08,
      "predicted_flops": 1.8595945673788560e+12,
      "predicted_flops_count": 1.1801395200000000e+08,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "workspace_bytes": 7.5272000000000000e+04,
      "workspace_megabytes": 7.1784973144531250e-02
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__16209620136994831937<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:1/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:7/filter_width:7/pad_height:3/pad_width:3/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 6031,
      "real_time": 1.1637378745057240e+05,
      "cpu_time": 1.2203253556531269e+05,
      "time_unit": "ns",
      "items_per_second": 8.2783178334655243e+10,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 7.3758720000000000e+06,
      "advised_time": 1.2083200365304947e-01,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)2; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4280899851402570e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 2.0000000000000000e+00,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 7.0000000000000000e+00,
      "filter_width": 7.0000000000000000e+00,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "group": 1.0000000000000000e+00,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 3.0000000000000000e+00,
      "input[2]": 2.2400000000000000e+02,
      "input[3]": 2.2400000000000000e+02,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 3.0000000000000000e+00,
      "input_height": 2.2400000000000000e+02,
      "input_size": 1.5052800000000000e+05,
      "input_width": 2.2400000000000000e+02,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 6.0310000000000000e+03,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 1.1200000000000000e+02,
      "output_size": 8.0281600000000000e+05,
      "output_width": 1.1200000000000000e+02,
      "pad_height": 3.0000000000000000e+00,
      "pad_width": 3.0000000000000000e+00,
      "predicted_advised_flops": 1.0140939345995267e+12,
      "predicted_advised_flops_count": 1.1801395200000000e+08,
      "predicted_flops": 1.0140939345995267e+12,
      "predicted_flops_count": 1.1801395200000000e+08,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "workspace_bytes": 7.3758720000000000e+06,
      "workspace_megabytes": 7.0341796875000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__16209620136994831937<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:1/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:7/filter_width:7/pad_height:3/pad_width:3/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__16209620136994831937<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:1/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:7/filter_width:7/pad_height:3/pad_width:3/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__16209620136994831937<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:1/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:7/filter_width:7/pad_height:3/pad_width:3/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 233,
      "real_time": 3.0096830968053555e+06,
      "cpu_time": 3.1226359313343931e+06,
      "time_unit": "ns",
      "items_per_second": 3.2009323540494480e+09,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.4679040000000000e+06,
      "advised_time": 3.0115840435028076e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)5; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.6667819325789325e+18,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 5.0000000000000000e+00,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 7.0000000000000000e+00,
      "filter_width": 7.0000000000000000e+00,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "group": 1.0000000000000000e+00,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 3.0000000000000000e+00,
      "input[2]": 2.2400000000000000e+02,
      "input[3]": 2.2400000000000000e+02,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 3.0000000000000000e+00,
      "input_height": 2.2400000000000000e+02,
      "input_size": 1.5052800000000000e+05,
      "input_width": 2.2400000000000000e+02,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 2.3300000000000000e+02,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 1.1200000000000000e+02,
      "output_size": 8.0281600000000000e+05,
      "output_width": 1.1200000000000000e+02,
      "pad_height": 3.0000000000000000e+00,
      "pad_width": 3.0000000000000000e+00,
      "predicted_advised_flops": 3.9211421337105743e+10,
      "predicted_advised_flops_count": 1.1801395200000000e+08,
      "predicted_flops": 7.0624068574011963e+10,
      "predicted_flops_count": 2.1255606541482610e+08,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "workspace_bytes": 1.4679040000000000e+06,
      "workspace_megabytes": 1.3999023437500000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__16209620136994831937<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:1/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:7/filter_width:7/pad_height:3/pad_width:3/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__16209620136994831937<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:1/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:7/filter_width:7/pad_height:3/pad_width:3/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__3955321705791342273<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:1/input[1]:192/input[2]:27/input[3]:27/filter_count:96/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 24395,
      "real_time": 2.8657289129408517e+04,
      "cpu_time": 3.3825077022930200e+04,
      "time_unit": "ns",
      "items_per_second": 4.6888342924979718e+11,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 2.9376000165939331e-02,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4730153338016043e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 9.6000000000000000e+01,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "group": 1.0000000000000000e+00,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 1.9200000000000000e+02,
      "input[2]": 2.7000000000000000e+01,
      "input[3]": 2.7000000000000000e+01,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 1.9200000000000000e+02,
      "input_height": 2.7000000000000000e+01,
      "input_size": 1.3996800000000000e+05,
      "input_width": 2.7000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 9.6000000000000000e+01,
      "num_iterations": 2.4395000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 9.6000000000000000e+01,
      "output_height": 2.7000000000000000e+01,
      "output_size": 6.9984000000000000e+04,
      "output_width": 2.7000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 4.6888342924979718e+11,
      "predicted_advised_flops_count": 1.3436928000000000e+07,
      "predicted_flops": 4.6888342924979718e+11,
      "predicted_flops_count": 1.3436928000000000e+07,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__3955321705791342273<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:1/input[1]:192/input[2]:27/input[3]:27/filter_count:96/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 20685,
      "real_time": 3.3903696988963376e+04,
      "cpu_time": 3.9031285182805193e+04,
      "time_unit": "ns",
      "items_per_second": 3.9632633586756348e+11,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 4.3800000000000000e+03,
      "advised_time": 3.5679999738931656e-02,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.2419525699096977e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 9.6000000000000000e+01,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "group": 1.0000000000000000e+00,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 1.9200000000000000e+02,
      "input[2]": 2.7000000000000000e+01,
      "input[3]": 2.7000000000000000e+01,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 1.9200000000000000e+02,
      "input_height": 2.7000000000000000e+01,
      "input_size": 1.3996800000000000e+05,
      "input_width": 2.7000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 9.6000000000000000e+01,
      "num_iterations": 2.0685000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 9.6000000000000000e+01,
      "output_height": 2.7000000000000000e+01,
      "output_size": 6.9984000000000000e+04,
      "output_width": 2.7000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 3.9632633586756348e+11,
      "predicted_advised_flops_count": 1.3436928000000000e+07,
      "predicted_flops": 3.9632633586756348e+11,
      "predicted_flops_count": 1.3436928000000000e+07,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 4.3800000000000000e+03,
      "workspace_megabytes": 4.1770935058593750e-03
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__3955321705791342273<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:1/input[1]:192/input[2]:27/input[3]:27/filter_count:96/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 7939,
      "real_time": 8.8196981674174793e+04,
      "cpu_time": 9.3476289958811714e+04,
      "time_unit": "ns",
      "items_per_second": 1.5235133612213519e+11,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 5.5987200000000000e+05,
      "advised_time": 9.0112000703811646e-02,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)2; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4280899851402570e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 2.0000000000000000e+00,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 9.6000000000000000e+01,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "group": 1.0000000000000000e+00,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 1.9200000000000000e+02,
      "input[2]": 2.7000000000000000e+01,
      "input[3]": 2.7000000000000000e+01,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 1.9200000000000000e+02,
      "input_height": 2.7000000000000000e+01,
      "input_size": 1.3996800000000000e+05,
      "input_width": 2.7000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 9.6000000000000000e+01,
      "num_iterations": 7.9390000000000000e+03,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 9.6000000000000000e+01,
      "output_height": 2.7000000000000000e+01,
      "output_size": 6.9984000000000000e+04,
      "output_width": 2.7000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 1.5235133612213519e+11,
      "predicted_advised_flops_count": 1.3436928000000000e+07,
      "predicted_flops": 1.5235133612213519e+11,
      "predicted_flops_count": 1.3436928000000000e+07,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 5.5987200000000000e+05,
      "workspace_megabytes": 5.3393554687500000e-01
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__3955321705791342273<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:1/input[1]:192/input[2]:27/input[3]:27/filter_count:96/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__3955321705791342273<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:1/input[1]:192/input[2]:27/input[3]:27/filter_count:96/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 1484,
      "real_time": 4.8051849181366572e+05,
      "cpu_time": 4.8885309029652132e+05,
      "time_unit": "ns",
      "items_per_second": 2.7963394185484413e+10,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.6217702400000000e+08,
      "advised_time": 4.7702398896217346e-01,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)4; cudnnMathType_t math_type = (cudnnMathType_t)0]": 2.3237108083472476e+18,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 4.0000000000000000e+00,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 9.6000000000000000e+01,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "group": 1.0000000000000000e+00,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 1.9200000000000000e+02,
      "input[2]": 2.7000000000000000e+01,
      "input[3]": 2.7000000000000000e+01,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 1.9200000000000000e+02,
      "input_height": 2.7000000000000000e+01,
      "input_size": 1.3996800000000000e+05,
      "input_width": 2.7000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 9.6000000000000000e+01,
      "num_iterations": 1.4840000000000000e+03,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 9.6000000000000000e+01,
      "output_height": 2.7000000000000000e+01,
      "output_size": 6.9984000000000000e+04,
      "output_width": 2.7000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 2.7963394185484413e+10,
      "predicted_advised_flops_count": 1.3436928000000000e+07,
      "predicted_flops": 2.9804406854457745e+11,
      "predicted_flops_count": 1.4321568631104916e+08,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 1.6217702400000000e+08,
      "workspace_megabytes": 1.5466406250000000e+02
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__3955321705791342273<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:1/input[1]:192/input[2]:27/input[3]:27/filter_count:96/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 8580,
      "real_time": 8.1485980605693825e+04,
      "cpu_time": 8.6706113051291148e+04,
      "time_unit": "ns",
      "items_per_second": 1.6489864759707019e+11,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 3.5647040000000000e+06,
      "advised_time": 8.7071999907493591e-02,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)5; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.6667819325789325e+18,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 5.0000000000000000e+00,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 9.6000000000000000e+01,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "group": 1.0000000000000000e+00,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 1.9200000000000000e+02,
      "input[2]": 2.7000000000000000e+01,
      "input[3]": 2.7000000000000000e+01,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 1.9200000000000000e+02,
      "input_height": 2.7000000000000000e+01,
      "input_size": 1.3996800000000000e+05,
      "input_width": 2.7000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 9.6000000000000000e+01,
      "num_iterations": 8.5800000000000000e+03,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 9.6000000000000000e+01,
      "output_height": 2.7000000000000000e+01,
      "output_size": 6.9984000000000000e+04,
      "output_width": 2.7000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 1.6489864759707019e+11,
      "predicted_advised_flops_count": 1.3436928000000000e+07,
      "predicted_flops": 1.7575500134687217e+12,
      "predicted_flops_count": 1.4321568631104916e+08,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 3.5647040000000000e+06,
      "workspace_megabytes": 3.3995666503906250e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__3955321705791342273<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:1/input[1]:192/input[2]:27/input[3]:27/filter_count:96/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__3955321705791342273<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:1/input[1]:192/input[2]:27/input[3]:27/filter_count:96/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__6709418483479307307<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:384/input[2]:13/input[3]:13/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:2/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__6709418483479307307<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:384/input[2]:13/input[3]:13/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:2/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__6709418483479307307<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:384/input[2]:13/input[3]:13/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:2/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__6709418483479307307<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:384/input[2]:13/input[3]:13/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:2/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__6709418483479307307<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:384/input[2]:13/input[3]:13/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:2/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__6709418483479307307<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:384/input[2]:13/input[3]:13/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:2/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__6709418483479307307<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:384/input[2]:13/input[3]:13/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:2/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__6709418483479307307<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:384/input[2]:13/input[3]:13/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:2/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__2821109436439167584<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:1/input[1]:64/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 23770,
      "real_time": 2.8870551150504863e+04,
      "cpu_time": 3.4136006899816253e+04,
      "time_unit": "ns",
      "items_per_second": 8.8983794822880469e+11,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 3.7856001406908035e-02,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4730153338016043e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "group": 1.0000000000000000e+00,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 2.0070400000000000e+05,
      "input_width": 5.6000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 2.3770000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 5.6000000000000000e+01,
      "output_size": 4.0140800000000000e+05,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 8.8983794822880469e+11,
      "predicted_advised_flops_count": 2.5690112000000000e+07,
      "predicted_flops": 8.8983794822880469e+11,
      "predicted_flops_count": 2.5690112000000000e+07,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__2821109436439167584<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:1/input[1]:64/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 29800,
      "real_time": 2.3497783769877340e+04,
      "cpu_time": 2.8655093389705376e+04,
      "time_unit": "ns",
      "items_per_second": 1.0932993618288838e+12,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.8824000000000000e+04,
      "advised_time": 3.2767999917268753e-02,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.2419525699096977e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "group": 1.0000000000000000e+00,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 2.0070400000000000e+05,
      "input_width": 5.6000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 2.9800000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 5.6000000000000000e+01,
      "output_size": 4.0140800000000000e+05,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 1.0932993618288838e+12,
      "predicted_advised_flops_count": 2.5690112000000000e+07,
      "predicted_flops": 1.0932993618288838e+12,
      "predicted_flops_count": 2.5690112000000000e+07,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 1.8824000000000000e+04,
      "workspace_megabytes": 1.7951965332031250e-02
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__2821109436439167584<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:1/input[1]:64/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 12755,
      "real_time": 5.4794575113521394e+04,
      "cpu_time": 6.0051671813741828e+04,
      "time_unit": "ns",
      "items_per_second": 4.6884407711486340e+11,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 8.0281600000000000e+05,
      "advised_time": 5.9424001723527908e-02,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)2; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4280899851402570e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 2.0000000000000000e+00,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "group": 1.0000000000000000e+00,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 2.0070400000000000e+05,
      "input_width": 5.6000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 1.2755000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 5.6000000000000000e+01,
      "output_size": 4.0140800000000000e+05,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 4.6884407711486340e+11,
      "predicted_advised_flops_count": 2.5690112000000000e+07,
      "predicted_flops": 4.6884407711486340e+11,
      "predicted_flops_count": 2.5690112000000000e+07,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 8.0281600000000000e+05,
      "workspace_megabytes": 7.6562500000000000e-01
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__2821109436439167584<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:1/input[1]:64/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__2821109436439167584<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:1/input[1]:64/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 460,
      "real_time": 1.5297276418372665e+06,
      "cpu_time": 1.5680206804300607e+06,
      "time_unit": "ns",
      "items_per_second": 1.6793912391584366e+10,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 2.7908505600000000e+08,
      "advised_time": 1.5267839431762695e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)4; cudnnMathType_t math_type = (cudnnMathType_t)0]": 2.3237108083472476e+18,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 4.0000000000000000e+00,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "group": 1.0000000000000000e+00,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 2.0070400000000000e+05,
      "input_width": 5.6000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 4.6000000000000000e+02,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 5.6000000000000000e+01,
      "output_size": 4.0140800000000000e+05,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 1.6793912391584366e+10,
      "predicted_advised_flops_count": 2.5690112000000000e+07,
      "predicted_flops": 2.1642196680113412e+11,
      "predicted_flops_count": 3.3106666491648209e+08,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 2.7908505600000000e+08,
      "workspace_megabytes": 2.6615625000000000e+02
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__2821109436439167584<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:1/input[1]:64/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 10488,
      "real_time": 6.7361967995433879e+04,
      "cpu_time": 7.2532279653748643e+04,
      "time_unit": "ns",
      "items_per_second": 3.8137413090041260e+11,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 4.0394880000000000e+06,
      "advised_time": 9.8304003477096558e-02,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)5; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.6667819325789325e+18,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 5.0000000000000000e+00,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "group": 1.0000000000000000e+00,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 2.0070400000000000e+05,
      "input_width": 5.6000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 1.0488000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 5.6000000000000000e+01,
      "output_size": 4.0140800000000000e+05,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 3.8137413090041260e+11,
      "predicted_advised_flops_count": 2.5690112000000000e+07,
      "predicted_flops": 4.9147415784960947e+12,
      "predicted_flops_count": 3.3106666491648209e+08,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 4.0394880000000000e+06,
      "workspace_megabytes": 3.8523559570312500e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__2821109436439167584<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:1/input[1]:64/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__2821109436439167584<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:1/input[1]:64/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__2255578786481836553<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:1/input[1]:96/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 19962,
      "real_time": 3.5040970922507702e+04,
      "cpu_time": 4.0193703886889438e+04,
      "time_unit": "ns",
      "items_per_second": 1.0997174731607646e+12,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 3.6864001303911209e-02,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4730153338016043e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "group": 1.0000000000000000e+00,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 9.6000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 9.6000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 3.0105600000000000e+05,
      "input_width": 5.6000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 1.9962000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 5.6000000000000000e+01,
      "output_size": 4.0140800000000000e+05,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 1.0997174731607646e+12,
      "predicted_advised_flops_count": 3.8535168000000000e+07,
      "predicted_flops": 1.0997174731607646e+12,
      "predicted_flops_count": 3.8535168000000000e+07,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__2255578786481836553<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:1/input[1]:96/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 25284,
      "real_time": 2.7700347631642308e+04,
      "cpu_time": 3.2846368810354186e+04,
      "time_unit": "ns",
      "items_per_second": 1.3911438409524148e+12,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.8824000000000000e+04,
      "advised_time": 3.6864001303911209e-02,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.2419525699096977e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "group": 1.0000000000000000e+00,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 9.6000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 9.6000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 3.0105600000000000e+05,
      "input_width": 5.6000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 2.5284000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 5.6000000000000000e+01,
      "output_size": 4.0140800000000000e+05,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 1.3911438409524148e+12,
      "predicted_advised_flops_count": 3.8535168000000000e+07,
      "predicted_flops": 1.3911438409524148e+12,
      "predicted_flops_count": 3.8535168000000000e+07,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 1.8824000000000000e+04,
      "workspace_megabytes": 1.7951965332031250e-02
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__2255578786481836553<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:1/input[1]:96/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 8961,
      "real_time": 7.8166311879173532e+04,
      "cpu_time": 8.3444390914640579e+04,
      "time_unit": "ns",
      "items_per_second": 4.9298946149034351e+11,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.2042240000000000e+06,
      "advised_time": 8.2624003291130066e-02,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)2; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4280899851402570e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 2.0000000000000000e+00,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "group": 1.0000000000000000e+00,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 9.6000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 9.6000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 3.0105600000000000e+05,
      "input_width": 5.6000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 8.9610000000000000e+03,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 5.6000000000000000e+01,
      "output_size": 4.0140800000000000e+05,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 4.9298946149034351e+11,
      "predicted_advised_flops_count": 3.8535168000000000e+07,
      "predicted_flops": 4.9298946149034351e+11,
      "predicted_flops_count": 3.8535168000000000e+07,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 1.2042240000000000e+06,
      "workspace_megabytes": 1.1484375000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__2255578786481836553<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:1/input[1]:96/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__2255578786481836553<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:1/input[1]:96/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 322,
      "real_time": 2.1368127557744058e+06,
      "cpu_time": 2.2084412267096685e+06,
      "time_unit": "ns",
      "items_per_second": 1.8033947006289940e+10,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 4.1857843200000000e+08,
      "advised_time": 2.1727359294891357e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)4; cudnnMathType_t math_type = (cudnnMathType_t)0]": 2.3237108083472476e+18,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 4.0000000000000000e+00,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "group": 1.0000000000000000e+00,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 9.6000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 9.6000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 3.0105600000000000e+05,
      "input_width": 5.6000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 3.2200000000000000e+02,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 5.6000000000000000e+01,
      "output_size": 4.0140800000000000e+05,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 1.8033947006289940e+10,
      "predicted_advised_flops_count": 3.8535168000000000e+07,
      "predicted_flops": 2.3131127297629834e+11,
      "predicted_flops_count": 4.9426887865016985e+08,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 4.1857843200000000e+08,
      "workspace_megabytes": 3.9918750000000000e+02
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__2255578786481836553<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:1/input[1]:96/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 8692,
      "real_time": 7.9781433008806751e+04,
      "cpu_time": 8.4959056832730246e+04,
      "time_unit": "ns",
      "items_per_second": 4.8300922340848730e+11,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 5.0839680000000000e+06,
      "advised_time": 1.1977600306272507e-01,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)5; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.6667819325789325e+18,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 5.0000000000000000e+00,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "group": 1.0000000000000000e+00,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 9.6000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 9.6000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 3.0105600000000000e+05,
      "input_width": 5.6000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 8.6920000000000000e+03,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 5.6000000000000000e+01,
      "output_size": 4.0140800000000000e+05,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 4.8300922340848730e+11,
      "predicted_advised_flops_count": 3.8535168000000000e+07,
      "predicted_flops": 6.1952870487499209e+12,
      "predicted_flops_count": 4.9426887865016985e+08,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 5.0839680000000000e+06,
      "workspace_megabytes": 4.8484497070312500e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__2255578786481836553<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:1/input[1]:96/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__2255578786481836553<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:1/input[1]:96/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__15656687763263169433<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:1/input[1]:192/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 12018,
      "real_time": 5.8041921818669711e+04,
      "cpu_time": 6.3504526210505042e+04,
      "time_unit": "ns",
      "items_per_second": 1.3278391477245957e+12,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 5.9296000748872757e-02,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4730153338016043e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "group": 1.0000000000000000e+00,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 1.9200000000000000e+02,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 1.9200000000000000e+02,
      "input_height": 5.6000000000000000e+01,
      "input_size": 6.0211200000000000e+05,
      "input_width": 5.6000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 1.2018000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 5.6000000000000000e+01,
      "output_size": 4.0140800000000000e+05,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 1.3278391477245957e+12,
      "predicted_advised_flops_count": 7.7070336000000000e+07,
      "predicted_flops": 1.3278391477245957e+12,
      "predicted_flops_count": 7.7070336000000000e+07,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__15656687763263169433<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:1/input[1]:192/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 16517,
      "real_time": 4.2455140201773407e+04,
      "cpu_time": 4.7831203730535686e+04,
      "time_unit": "ns",
      "items_per_second": 1.8153358023012881e+12,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.8824000000000000e+04,
      "advised_time": 5.0879999995231628e-02,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.2419525699096977e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "group": 1.0000000000000000e+00,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 1.9200000000000000e+02,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 1.9200000000000000e+02,
      "input_height": 5.6000000000000000e+01,
      "input_size": 6.0211200000000000e+05,
      "input_width": 5.6000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 1.6517000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 5.6000000000000000e+01,
      "output_size": 4.0140800000000000e+05,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 1.8153358023012881e+12,
      "predicted_advised_flops_count": 7.7070336000000000e+07,
      "predicted_flops": 1.8153358023012881e+12,
      "predicted_flops_count": 7.7070336000000000e+07,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 1.8824000000000000e+04,
      "workspace_megabytes": 1.7951965332031250e-02
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__15656687763263169433<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:1/input[1]:192/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 5019,
      "real_time": 1.3973569051845212e+05,
      "cpu_time": 1.4577859932216114e+05,
      "time_unit": "ns",
      "items_per_second": 5.5154367301618506e+11,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 2.4084480000000000e+06,
      "advised_time": 1.4336000382900238e-01,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)2; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4280899851402570e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 2.0000000000000000e+00,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "group": 1.0000000000000000e+00,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 1.9200000000000000e+02,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 1.9200000000000000e+02,
      "input_height": 5.6000000000000000e+01,
      "input_size": 6.0211200000000000e+05,
      "input_width": 5.6000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 5.0190000000000000e+03,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 5.6000000000000000e+01,
      "output_size": 4.0140800000000000e+05,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 5.5154367301618506e+11,
      "predicted_advised_flops_count": 7.7070336000000000e+07,
      "predicted_flops": 5.5154367301618506e+11,
      "predicted_flops_count": 7.7070336000000000e+07,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 2.4084480000000000e+06,
      "workspace_megabytes": 2.2968750000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__15656687763263169433<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:1/input[1]:192/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__15656687763263169433<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:1/input[1]:192/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 166,
      "real_time": 4.1664769362478731e+06,
      "cpu_time": 4.4473678373630820e+06,
      "time_unit": "ns",
      "items_per_second": 1.8497722939372803e+10,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 8.3705856000000000e+08,
      "advised_time": 4.2228479385375977e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)4; cudnnMathType_t math_type = (cudnnMathType_t)0]": 2.3237108083472476e+18,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 4.0000000000000000e+00,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "group": 1.0000000000000000e+00,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 1.9200000000000000e+02,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 1.9200000000000000e+02,
      "input_height": 5.6000000000000000e+01,
      "input_size": 6.0211200000000000e+05,
      "input_width": 5.6000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 1.6600000000000000e+02,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 5.6000000000000000e+01,
      "output_size": 4.0140800000000000e+05,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 1.8497722939372803e+10,
      "predicted_advised_flops_count": 7.7070336000000000e+07,
      "predicted_flops": 2.3614087751011615e+11,
      "predicted_flops_count": 9.8387551985123312e+08,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 8.3705856000000000e+08,
      "workspace_megabytes": 7.9828125000000000e+02
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__15656687763263169433<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:1/input[1]:192/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 5389,
      "real_time": 1.2857951610479165e+05,
      "cpu_time": 1.3443942846591977e+05,
      "time_unit": "ns",
      "items_per_second": 5.9939824269666772e+11,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 8.2174080000000000e+06,
      "advised_time": 1.5667200088500977e-01,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)5; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.6667819325789325e+18,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 5.0000000000000000e+00,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "group": 1.0000000000000000e+00,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 1.9200000000000000e+02,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 1.9200000000000000e+02,
      "input_height": 5.6000000000000000e+01,
      "input_size": 6.0211200000000000e+05,
      "input_width": 5.6000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 5.3890000000000000e+03,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 5.6000000000000000e+01,
      "output_size": 4.0140800000000000e+05,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 5.9939824269666772e+11,
      "predicted_advised_flops_count": 7.7070336000000000e+07,
      "predicted_flops": 7.6518838276648945e+12,
      "predicted_flops_count": 9.8387551985123312e+08,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 8.2174080000000000e+06,
      "workspace_megabytes": 7.8367309570312500e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__15656687763263169433<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:1/input[1]:192/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__15656687763263169433<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:1/input[1]:192/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__17605375797884481413<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:1/input[1]:128/input[2]:27/input[3]:27/filter_count:192/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 3728,
      "real_time": 1.8779584427183427e+05,
      "cpu_time": 1.9346820171652728e+05,
      "time_unit": "ns",
      "items_per_second": 9.5400960918319092e+10,
      "advised_convolution_algorithm": 6.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 1.9865599274635315e-01,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4730153338016043e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.9200000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "group": 1.0000000000000000e+00,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 1.2800000000000000e+02,
      "input[2]": 2.7000000000000000e+01,
      "input[3]": 2.7000000000000000e+01,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 1.2800000000000000e+02,
      "input_height": 2.7000000000000000e+01,
      "input_size": 9.3312000000000000e+04,
      "input_width": 2.7000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.9200000000000000e+02,
      "num_iterations": 3.7280000000000000e+03,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 1.9200000000000000e+02,
      "output_height": 2.7000000000000000e+01,
      "output_size": 1.3996800000000000e+05,
      "output_width": 2.7000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "predicted_advised_flops": -5.3249314641515766e+03,
      "predicted_advised_flops_count": -1.0000000000000000e+00,
      "predicted_flops": 8.5860864826487183e+11,
      "predicted_flops_count": 1.6124313600000000e+08,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__17605375797884481413<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:1/input[1]:128/input[2]:27/input[3]:27/filter_count:192/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 3920,
      "real_time": 1.7848593775406884e+05,
      "cpu_time": 1.8407748163272164e+05,
      "time_unit": "ns",
      "items_per_second": 1.0037711780233276e+11,
      "advised_convolution_algorithm": 6.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 4.3800000000000000e+03,
      "advised_time": 1.8227200210094452e-01,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.2419525699096977e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.9200000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "group": 1.0000000000000000e+00,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 1.2800000000000000e+02,
      "input[2]": 2.7000000000000000e+01,
      "input[3]": 2.7000000000000000e+01,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 1.2800000000000000e+02,
      "input_height": 2.7000000000000000e+01,
      "input_size": 9.3312000000000000e+04,
      "input_width": 2.7000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.9200000000000000e+02,
      "num_iterations": 3.9200000000000000e+03,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 1.9200000000000000e+02,
      "output_height": 2.7000000000000000e+01,
      "output_size": 1.3996800000000000e+05,
      "output_width": 2.7000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "predicted_advised_flops": -5.6026822761683006e+03,
      "predicted_advised_flops_count": -1.0000000000000000e+00,
      "predicted_flops": 9.0339406022099487e+11,
      "predicted_flops_count": 1.6124313600000000e+08,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 4.3800000000000000e+03,
      "workspace_megabytes": 4.1770935058593750e-03
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__17605375797884481413<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:1/input[1]:128/input[2]:27/input[3]:27/filter_count:192/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 3944,
      "real_time": 1.7764506995117478e+05,
      "cpu_time": 1.8324520283973974e+05,
      "time_unit": "ns",
      "items_per_second": 1.0085224433711632e+11,
      "advised_convolution_algorithm": 6.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 3.3592320000000000e+06,
      "advised_time": 1.8739199638366699e-01,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)2; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4280899851402570e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 2.0000000000000000e+00,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.9200000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "group": 1.0000000000000000e+00,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 1.2800000000000000e+02,
      "input[2]": 2.7000000000000000e+01,
      "input[3]": 2.7000000000000000e+01,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 1.2800000000000000e+02,
      "input_height": 2.7000000000000000e+01,
      "input_size": 9.3312000000000000e+04,
      "input_width": 2.7000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.9200000000000000e+02,
      "num_iterations": 3.9440000000000000e+03,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 1.9200000000000000e+02,
      "output_height": 2.7000000000000000e+01,
      "output_size": 1.3996800000000000e+05,
      "output_width": 2.7000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "predicted_advised_flops": -5.6292020953626634e+03,
      "predicted_advised_flops_count": -1.0000000000000000e+00,
      "predicted_flops": 9.0767019903404688e+11,
      "predicted_flops_count": 1.6124313600000000e+08,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 3.3592320000000000e+06,
      "workspace_megabytes": 3.2036132812500000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__17605375797884481413<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:1/input[1]:128/input[2]:27/input[3]:27/filter_count:192/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__17605375797884481413<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:1/input[1]:128/input[2]:27/input[3]:27/filter_count:192/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 931,
      "real_time": 7.4722959745523264e+05,
      "cpu_time": 7.6047493662181799e+05,
      "time_unit": "ns",
      "items_per_second": 2.3976437845896969e+10,
      "advised_convolution_algorithm": 6.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 2.1590835200000000e+08,
      "advised_time": 7.6080000400543213e-01,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)4; cudnnMathType_t math_type = (cudnnMathType_t)0]": 2.3237108083472476e+18,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 4.0000000000000000e+00,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.9200000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "group": 1.0000000000000000e+00,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 1.2800000000000000e+02,
      "input[2]": 2.7000000000000000e+01,
      "input[3]": 2.7000000000000000e+01,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 1.2800000000000000e+02,
      "input_height": 2.7000000000000000e+01,
      "input_size": 9.3312000000000000e+04,
      "input_width": 2.7000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.9200000000000000e+02,
      "num_iterations": 9.3100000000000000e+02,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 1.9200000000000000e+02,
      "output_height": 2.7000000000000000e+01,
      "output_size": 1.3996800000000000e+05,
      "output_width": 2.7000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "predicted_advised_flops": -1.3382767537656471e+03,
      "predicted_advised_flops_count": -1.0000000000000000e+00,
      "predicted_flops": 2.5495585426612341e+11,
      "predicted_flops_count": 1.9051056035213035e+08,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 2.1590835200000000e+08,
      "workspace_megabytes": 2.0590625000000000e+02
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__17605375797884481413<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:1/input[1]:128/input[2]:27/input[3]:27/filter_count:192/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 929,
      "real_time": 7.4960668438462086e+05,
      "cpu_time": 7.6264486867611529e+05,
      "time_unit": "ns",
      "items_per_second": 2.3900405870456997e+10,
      "advised_convolution_algorithm": 6.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.0837196800000000e+08,
      "advised_time": 8.0076801776885986e-01,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)5; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.6667819325789325e+18,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 5.0000000000000000e+00,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.9200000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "group": 1.0000000000000000e+00,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 1.2800000000000000e+02,
      "input[2]": 2.7000000000000000e+01,
      "input[3]": 2.7000000000000000e+01,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 1.2800000000000000e+02,
      "input_height": 2.7000000000000000e+01,
      "input_size": 9.3312000000000000e+04,
      "input_width": 2.7000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.9200000000000000e+02,
      "num_iterations": 9.2900000000000000e+02,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 1.9200000000000000e+02,
      "output_height": 2.7000000000000000e+01,
      "output_size": 1.3996800000000000e+05,
      "output_width": 2.7000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "predicted_advised_flops": -1.3340329279760037e+03,
      "predicted_advised_flops_count": -1.0000000000000000e+00,
      "predicted_flops": 2.5414736063690161e+11,
      "predicted_flops_count": 1.9051056035213035e+08,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 1.0837196800000000e+08,
      "workspace_megabytes": 1.0335156250000000e+02
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__17605375797884481413<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:1/input[1]:128/input[2]:27/input[3]:27/filter_count:192/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 13714,
      "real_time": 5.0562695702407851e+04,
      "cpu_time": 5.5743183971791099e+04,
      "time_unit": "ns",
      "items_per_second": 3.5433047528648334e+11,
      "advised_convolution_algorithm": 6.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 2.4583680000000000e+06,
      "advised_time": 9.1136001050472260e-02,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)6; cudnnMathType_t math_type = (cudnnMathType_t)0]": 5.7500739770702787e+18,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 6.0000000000000000e+00,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.9200000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "group": 1.0000000000000000e+00,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 1.2800000000000000e+02,
      "input[2]": 2.7000000000000000e+01,
      "input[3]": 2.7000000000000000e+01,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 1.2800000000000000e+02,
      "input_height": 2.7000000000000000e+01,
      "input_size": 9.3312000000000000e+04,
      "input_width": 2.7000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.9200000000000000e+02,
      "num_iterations": 1.3714000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 1.9200000000000000e+02,
      "output_height": 2.7000000000000000e+01,
      "output_size": 1.3996800000000000e+05,
      "output_width": 2.7000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "predicted_advised_flops": -1.9777426541607016e+04,
      "predicted_advised_flops_count": -1.0000000000000000e+00,
      "predicted_flops": -1.9777426541607016e+04,
      "predicted_flops_count": -1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 2.4583680000000000e+06,
      "workspace_megabytes": 2.3444824218750000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__17605375797884481413<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:1/input[1]:128/input[2]:27/input[3]:27/filter_count:192/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 2139,
      "real_time": 3.2710460179658234e+05,
      "cpu_time": 3.3373812903426040e+05,
      "time_unit": "ns",
      "items_per_second": 5.4771176870025887e+10,
      "advised_convolution_algorithm": 6.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 3.9665664000000000e+07,
      "advised_time": 3.4303998947143555e-01,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)7; cudnnMathType_t math_type = (cudnnMathType_t)0]": 8.2538945752816425e+18,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 7.0000000000000000e+00,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.9200000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "group": 1.0000000000000000e+00,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 1.2800000000000000e+02,
      "input[2]": 2.7000000000000000e+01,
      "input[3]": 2.7000000000000000e+01,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 1.2800000000000000e+02,
      "input_height": 2.7000000000000000e+01,
      "input_size": 9.3312000000000000e+04,
      "input_width": 2.7000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.9200000000000000e+02,
      "num_iterations": 2.1390000000000000e+03,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 1.9200000000000000e+02,
      "output_height": 2.7000000000000000e+01,
      "output_size": 1.3996800000000000e+05,
      "output_width": 2.7000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "predicted_advised_flops": -3.0571260523625206e+03,
      "predicted_advised_flops_count": -1.0000000000000000e+00,
      "predicted_flops": -3.0571260523625206e+03,
      "predicted_flops_count": -1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 3.9665664000000000e+07,
      "workspace_megabytes": 3.7828125000000000e+01
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__6065165212417003451<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:1/input[1]:160/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 23166,
      "real_time": 3.0199326574664206e+04,
      "cpu_time": 3.5350196150047093e+04,
      "time_unit": "ns",
      "items_per_second": 5.3167808097649725e+11,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 3.1743999570608139e-02,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4730153338016043e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "group": 1.0000000000000000e+00,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 1.6000000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 1.6000000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 1.2544000000000000e+05,
      "input_width": 2.8000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 2.3166000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 1.0035200000000000e+05,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 5.3167808097649725e+11,
      "predicted_advised_flops_count": 1.6056320000000000e+07,
      "predicted_flops": 5.3167808097649725e+11,
      "predicted_flops_count": 1.6056320000000000e+07,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__6065165212417003451<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:1/input[1]:160/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 20095,
      "real_time": 3.4747720526050907e+04,
      "cpu_time": 3.9992721673022046e+04,
      "time_unit": "ns",
      "items_per_second": 4.6208268504871643e+11,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 4.7120000000000000e+03,
      "advised_time": 3.8911998271942139e-02,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.2419525699096977e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "group": 1.0000000000000000e+00,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 1.6000000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 1.6000000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 1.2544000000000000e+05,
      "input_width": 2.8000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 2.0095000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 1.0035200000000000e+05,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 4.6208268504871643e+11,
      "predicted_advised_flops_count": 1.6056320000000000e+07,
      "predicted_flops": 4.6208268504871643e+11,
      "predicted_flops_count": 1.6056320000000000e+07,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 4.7120000000000000e+03,
      "workspace_megabytes": 4.4937133789062500e-03
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__6065165212417003451<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:1/input[1]:160/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 9167,
      "real_time": 7.5975707369478143e+04,
      "cpu_time": 8.1229999127884250e+04,
      "time_unit": "ns",
      "items_per_second": 2.1133491948836179e+11,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 5.0176000000000000e+05,
      "advised_time": 7.7696003019809723e-02,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)2; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4280899851402570e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 2.0000000000000000e+00,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "group": 1.0000000000000000e+00,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 1.6000000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 1.6000000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 1.2544000000000000e+05,
      "input_width": 2.8000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 9.1670000000000000e+03,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 1.0035200000000000e+05,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 2.1133491948836179e+11,
      "predicted_advised_flops_count": 1.6056320000000000e+07,
      "predicted_flops": 2.1133491948836179e+11,
      "predicted_flops_count": 1.6056320000000000e+07,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 5.0176000000000000e+05,
      "workspace_megabytes": 4.7851562500000000e-01
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__6065165212417003451<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:1/input[1]:160/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__6065165212417003451<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:1/input[1]:160/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 1426,
      "real_time": 4.8878767940644856e+05,
      "cpu_time": 4.9734841514324280e+05,
      "time_unit": "ns",
      "items_per_second": 3.2849273163958908e+10,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.7973248000000000e+08,
      "advised_time": 4.9561598896980286e-01,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)4; cudnnMathType_t math_type = (cudnnMathType_t)0]": 2.3237108083472476e+18,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 4.0000000000000000e+00,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "group": 1.0000000000000000e+00,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 1.6000000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 1.6000000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 1.2544000000000000e+05,
      "input_width": 2.8000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 1.4260000000000000e+03,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 1.0035200000000000e+05,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 3.2849273163958908e+10,
      "predicted_advised_flops_count": 1.6056320000000000e+07,
      "predicted_flops": 3.5312695021074463e+11,
      "predicted_flops_count": 1.7260410252938634e+08,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 1.7973248000000000e+08,
      "workspace_megabytes": 1.7140625000000000e+02
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__6065165212417003451<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:1/input[1]:160/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 8592,
      "real_time": 8.1258545824938672e+04,
      "cpu_time": 8.6466056099230904e+04,
      "time_unit": "ns",
      "items_per_second": 1.9759546318477472e+11,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 3.8824000000000000e+06,
      "advised_time": 8.8831998407840729e-02,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)5; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.6667819325789325e+18,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 5.0000000000000000e+00,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "group": 1.0000000000000000e+00,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 1.6000000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 1.6000000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 1.2544000000000000e+05,
      "input_width": 2.8000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 8.5920000000000000e+03,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 1.0035200000000000e+05,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 1.9759546318477472e+11,
      "predicted_advised_flops_count": 1.6056320000000000e+07,
      "predicted_flops": 2.1241347697907393e+12,
      "predicted_flops_count": 1.7260410252938634e+08,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 3.8824000000000000e+06,
      "workspace_megabytes": 3.7025451660156250e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__6065165212417003451<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:1/input[1]:160/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__6065165212417003451<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:1/input[1]:160/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__12513461715419514171<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:1/input[1]:320/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 13497,
      "real_time": 5.2075994158111018e+04,
      "cpu_time": 5.7273586279784104e+04,
      "time_unit": "ns",
      "items_per_second": 6.1664958142711414e+11,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 5.5135998874902725e-02,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4730153338016043e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "group": 1.0000000000000000e+00,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 3.2000000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 3.2000000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 2.5088000000000000e+05,
      "input_width": 2.8000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 1.3497000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 1.0035200000000000e+05,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 6.1664958142711414e+11,
      "predicted_advised_flops_count": 3.2112640000000000e+07,
      "predicted_flops": 6.1664958142711414e+11,
      "predicted_flops_count": 3.2112640000000000e+07,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__12513461715419514171<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:1/input[1]:320/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 12622,
      "real_time": 5.5455409755694905e+04,
      "cpu_time": 6.0950778639327116e+04,
      "time_unit": "ns",
      "items_per_second": 5.7907136817616321e+11,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 4.7120000000000000e+03,
      "advised_time": 5.9392001479864120e-02,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.2419525699096977e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "group": 1.0000000000000000e+00,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 3.2000000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 3.2000000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 2.5088000000000000e+05,
      "input_width": 2.8000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 1.2622000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 1.0035200000000000e+05,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 5.7907136817616321e+11,
      "predicted_advised_flops_count": 3.2112640000000000e+07,
      "predicted_flops": 5.7907136817616321e+11,
      "predicted_flops_count": 3.2112640000000000e+07,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 4.7120000000000000e+03,
      "workspace_megabytes": 4.4937133789062500e-03
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__12513461715419514171<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:1/input[1]:320/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 5819,
      "real_time": 1.2024616509270297e+05,
      "cpu_time": 1.2563206031994712e+05,
      "time_unit": "ns",
      "items_per_second": 2.6705749805195847e+11,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.0035200000000000e+06,
      "advised_time": 1.2492799758911133e-01,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)2; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4280899851402570e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 2.0000000000000000e+00,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "group": 1.0000000000000000e+00,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 3.2000000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 3.2000000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 2.5088000000000000e+05,
      "input_width": 2.8000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 5.8190000000000000e+03,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 1.0035200000000000e+05,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 2.6705749805195847e+11,
      "predicted_advised_flops_count": 3.2112640000000000e+07,
      "predicted_flops": 2.6705749805195847e+11,
      "predicted_flops_count": 3.2112640000000000e+07,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 1.0035200000000000e+06,
      "workspace_megabytes": 9.5703125000000000e-01
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__12513461715419514171<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:1/input[1]:320/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__12513461715419514171<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:1/input[1]:320/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 773,
      "real_time": 9.0960484211312619e+05,
      "cpu_time": 9.3055542173860082e+05,
      "time_unit": "ns",
      "items_per_second": 3.5303945750110901e+10,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 3.5946496000000000e+08,
      "advised_time": 9.1036802530288696e-01,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)4; cudnnMathType_t math_type = (cudnnMathType_t)0]": 2.3237108083472476e+18,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 4.0000000000000000e+00,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "group": 1.0000000000000000e+00,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 3.2000000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 3.2000000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 2.5088000000000000e+05,
      "input_width": 2.8000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 7.7300000000000000e+02,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 1.0035200000000000e+05,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 3.5303945750110901e+10,
      "predicted_advised_flops_count": 3.2112640000000000e+07,
      "predicted_flops": 3.7845373480727692e+11,
      "predicted_flops_count": 3.4424334969649607e+08,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 3.5946496000000000e+08,
      "workspace_megabytes": 3.4281250000000000e+02
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__12513461715419514171<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:1/input[1]:320/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 5979,
      "real_time": 1.1664508607611668e+05,
      "cpu_time": 1.2200448519667375e+05,
      "time_unit": "ns",
      "items_per_second": 2.7530212442078284e+11,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 7.2769600000000000e+06,
      "advised_time": 1.2390399724245071e-01,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)5; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.6667819325789325e+18,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 5.0000000000000000e+00,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "group": 1.0000000000000000e+00,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 3.2000000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 3.2000000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 2.5088000000000000e+05,
      "input_width": 2.8000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 5.9790000000000000e+03,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 1.0035200000000000e+05,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 2.7530212442078284e+11,
      "predicted_advised_flops_count": 3.2112640000000000e+07,
      "predicted_flops": 2.9512031863207705e+12,
      "predicted_flops_count": 3.4424334969649607e+08,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 7.2769600000000000e+06,
      "workspace_megabytes": 6.9398498535156250e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__12513461715419514171<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:1/input[1]:320/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__12513461715419514171<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:1/input[1]:320/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__1930434020982545224<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:1/input[1]:544/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 11720,
      "real_time": 5.9786512825207756e+04,
      "cpu_time": 6.4983668856912242e+04,
      "time_unit": "ns",
      "items_per_second": 2.2827676937607999e+11,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 6.0416001826524734e-02,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4730153338016043e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "group": 1.0000000000000000e+00,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 5.4400000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 5.4400000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 1.0662400000000000e+05,
      "input_width": 1.4000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 1.1720000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 2.5088000000000000e+04,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 2.2827676937607999e+11,
      "predicted_advised_flops_count": 1.3647872000000000e+07,
      "predicted_flops": 2.2827676937607999e+11,
      "predicted_flops_count": 1.3647872000000000e+07,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__1930434020982545224<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:1/input[1]:544/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 8565,
      "real_time": 8.1225367754241655e+04,
      "cpu_time": 8.6497674953597627e+04,
      "time_unit": "ns",
      "items_per_second": 1.6802474863879330e+11,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.1840000000000000e+03,
      "advised_time": 8.4959998726844788e-02,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.2419525699096977e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "group": 1.0000000000000000e+00,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 5.4400000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 5.4400000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 1.0662400000000000e+05,
      "input_width": 1.4000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 8.5650000000000000e+03,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 2.5088000000000000e+04,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 1.6802474863879330e+11,
      "predicted_advised_flops_count": 1.3647872000000000e+07,
      "predicted_flops": 1.6802474863879330e+11,
      "predicted_flops_count": 1.3647872000000000e+07,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 1.1840000000000000e+03,
      "workspace_megabytes": 1.1291503906250000e-03
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__1930434020982545224<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:1/input[1]:544/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 5719,
      "real_time": 1.2240183877082336e+05,
      "cpu_time": 1.2783136527348419e+05,
      "time_unit": "ns",
      "items_per_second": 1.1150054718992677e+11,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 4.2649600000000000e+05,
      "advised_time": 1.2470400333404541e-01,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)2; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4280899851402570e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 2.0000000000000000e+00,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "group": 1.0000000000000000e+00,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 5.4400000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 5.4400000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 1.0662400000000000e+05,
      "input_width": 1.4000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 5.7190000000000000e+03,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 2.5088000000000000e+04,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 1.1150054718992677e+11,
      "predicted_advised_flops_count": 1.3647872000000000e+07,
      "predicted_flops": 1.1150054718992677e+11,
      "predicted_flops_count": 1.3647872000000000e+07,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 4.2649600000000000e+05,
      "workspace_megabytes": 4.0673828125000000e-01
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__1930434020982545224<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:1/input[1]:544/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__1930434020982545224<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:1/input[1]:544/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 1618,
      "real_time": 4.3323623233478243e+05,
      "cpu_time": 4.4105854264401132e+05,
      "time_unit": "ns",
      "items_per_second": 3.1502148207801868e+10,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.6196403200000000e+08,
      "advised_time": 4.4851198792457581e-01,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)4; cudnnMathType_t math_type = (cudnnMathType_t)0]": 2.3237108083472476e+18,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 4.0000000000000000e+00,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "group": 1.0000000000000000e+00,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 5.4400000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 5.4400000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 1.0662400000000000e+05,
      "input_width": 1.4000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 1.6180000000000000e+03,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 2.5088000000000000e+04,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 3.1502148207801868e+10,
      "predicted_advised_flops_count": 1.3647872000000000e+07,
      "predicted_flops": 2.7369688193803583e+11,
      "predicted_flops_count": 1.1857540593261242e+08,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 1.6196403200000000e+08,
      "workspace_megabytes": 1.5446093750000000e+02
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__1930434020982545224<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:1/input[1]:544/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 4428,
      "real_time": 1.5829039637072774e+05,
      "cpu_time": 1.6374433897866088e+05,
      "time_unit": "ns",
      "items_per_second": 8.6220467652602768e+10,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.0749856000000000e+07,
      "advised_time": 1.7817600071430206e-01,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)5; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.6667819325789325e+18,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 5.0000000000000000e+00,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "group": 1.0000000000000000e+00,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 5.4400000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 5.4400000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 1.0662400000000000e+05,
      "input_width": 1.4000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 4.4280000000000000e+03,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 2.5088000000000000e+04,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 8.6220467652602768e+10,
      "predicted_advised_flops_count": 1.3647872000000000e+07,
      "predicted_flops": 7.4910044229657568e+11,
      "predicted_flops_count": 1.1857540593261242e+08,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 1.0749856000000000e+07,
      "workspace_megabytes": 1.0251861572265625e+01
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__1930434020982545224<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:1/input[1]:544/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__1930434020982545224<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:1/input[1]:544/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__7032941452476097680<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:8/input[2]:14/input[3]:14/filter_count:16/filter_height:5/filter_width:5/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 11911,
      "real_time": 5.8610992252338845e+04,
      "cpu_time": 6.3817928132265472e+04,
      "time_unit": "ns",
      "items_per_second": 5.4789449497365509e+10,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 5.9392001479864120e-02,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4730153338016043e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.6000000000000000e+01,
      "filter_height": 5.0000000000000000e+00,
      "filter_width": 5.0000000000000000e+00,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "group": 1.0000000000000000e+00,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 8.0000000000000000e+00,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 8.0000000000000000e+00,
      "input_height": 1.4000000000000000e+01,
      "input_size": 2.0070400000000000e+05,
      "input_width": 1.4000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.6000000000000000e+01,
      "num_iterations": 1.1911000000000000e+04,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 1.6000000000000000e+01,
      "output_height": 1.0000000000000000e+01,
      "output_size": 2.0480000000000000e+05,
      "output_width": 1.0000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 6.9884501909904980e+11,
      "predicted_advised_flops_count": 4.0960000000000000e+07,
      "predicted_flops": 6.9884501909904980e+11,
      "predicted_flops_count": 4.0960000000000000e+07,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__7032941452476097680<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:8/input[2]:14/input[3]:14/filter_count:16/filter_height:5/filter_width:5/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 15711,
      "real_time": 4.4586623784659459e+04,
      "cpu_time": 4.9783189993607535e+04,
      "time_unit": "ns",
      "items_per_second": 7.2023035776592545e+10,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 6.0800000000000000e+02,
      "advised_time": 4.9088001251220703e-02,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.2419525699096977e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.6000000000000000e+01,
      "filter_height": 5.0000000000000000e+00,
      "filter_width": 5.0000000000000000e+00,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "group": 1.0000000000000000e+00,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 8.0000000000000000e+00,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 8.0000000000000000e+00,
      "input_height": 1.4000000000000000e+01,
      "input_size": 2.0070400000000000e+05,
      "input_width": 1.4000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.6000000000000000e+01,
      "num_iterations": 1.5711000000000000e+04,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 1.6000000000000000e+01,
      "output_height": 1.0000000000000000e+01,
      "output_size": 2.0480000000000000e+05,
      "output_width": 1.0000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 9.1866117061980286e+11,
      "predicted_advised_flops_count": 4.0960000000000000e+07,
      "predicted_flops": 9.1866117061980286e+11,
      "predicted_flops_count": 4.0960000000000000e+07,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 6.0800000000000000e+02,
      "workspace_megabytes": 5.7983398437500000e-04
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__7032941452476097680<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:8/input[2]:14/input[3]:14/filter_count:16/filter_height:5/filter_width:5/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 6206,
      "real_time": 1.1290707605236408e+05,
      "cpu_time": 1.1821929632602700e+05,
      "time_unit": "ns",
      "items_per_second": 2.8441654077647701e+10,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.0240000000000000e+07,
      "advised_time": 1.1468800157308578e-01,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)2; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4280899851402570e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 2.0000000000000000e+00,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.6000000000000000e+01,
      "filter_height": 5.0000000000000000e+00,
      "filter_width": 5.0000000000000000e+00,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "group": 1.0000000000000000e+00,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 8.0000000000000000e+00,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 8.0000000000000000e+00,
      "input_height": 1.4000000000000000e+01,
      "input_size": 2.0070400000000000e+05,
      "input_width": 1.4000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.6000000000000000e+01,
      "num_iterations": 6.2060000000000000e+03,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 1.6000000000000000e+01,
      "output_height": 1.0000000000000000e+01,
      "output_size": 2.0480000000000000e+05,
      "output_width": 1.0000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 3.6277619996999622e+11,
      "predicted_advised_flops_count": 4.0960000000000000e+07,
      "predicted_flops": 3.6277619996999622e+11,
      "predicted_flops_count": 4.0960000000000000e+07,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 1.0240000000000000e+07,
      "workspace_megabytes": 9.7656250000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__7032941452476097680<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:8/input[2]:14/input[3]:14/filter_count:16/filter_height:5/filter_width:5/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__7032941452476097680<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:8/input[2]:14/input[3]:14/filter_count:16/filter_height:5/filter_width:5/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 13304,
      "real_time": 5.2724938343655391e+04,
      "cpu_time": 5.7950195729477135e+04,
      "time_unit": "ns",
      "items_per_second": 6.0905979236416214e+10,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 4.7313920000000000e+06,
      "advised_time": 6.0320001095533371e-02,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)4; cudnnMathType_t math_type = (cudnnMathType_t)0]": 2.3237108083472476e+18,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 4.0000000000000000e+00,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.6000000000000000e+01,
      "filter_height": 5.0000000000000000e+00,
      "filter_width": 5.0000000000000000e+00,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "group": 1.0000000000000000e+00,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 8.0000000000000000e+00,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 8.0000000000000000e+00,
      "input_height": 1.4000000000000000e+01,
      "input_size": 2.0070400000000000e+05,
      "input_width": 1.4000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.6000000000000000e+01,
      "num_iterations": 1.3304000000000000e+04,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 1.6000000000000000e+01,
      "output_height": 1.0000000000000000e+01,
      "output_size": 2.0480000000000000e+05,
      "output_width": 1.0000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 7.7686198005632935e+11,
      "predicted_advised_flops_count": 4.0960000000000000e+07,
      "predicted_flops": 1.5148827604442697e+11,
      "predicted_flops_count": 7.9872100142290583e+06,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 4.7313920000000000e+06,
      "workspace_megabytes": 4.5122070312500000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__7032941452476097680<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:8/input[2]:14/input[3]:14/filter_count:16/filter_height:5/filter_width:5/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 4419,
      "real_time": 1.5856564545177363e+05,
      "cpu_time": 1.6399956302560156e+05,
      "time_unit": "ns",
      "items_per_second": 2.0251953005650764e+10,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.3950976000000000e+07,
      "advised_time": 1.6179199516773224e-01,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)5; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.6667819325789325e+18,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 5.0000000000000000e+00,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.6000000000000000e+01,
      "filter_height": 5.0000000000000000e+00,
      "filter_width": 5.0000000000000000e+00,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "group": 1.0000000000000000e+00,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 8.0000000000000000e+00,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 8.0000000000000000e+00,
      "input_height": 1.4000000000000000e+01,
      "input_size": 2.0070400000000000e+05,
      "input_width": 1.4000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.6000000000000000e+01,
      "num_iterations": 4.4190000000000000e+03,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 1.6000000000000000e+01,
      "output_height": 1.0000000000000000e+01,
      "output_size": 2.0480000000000000e+05,
      "output_width": 1.0000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 2.5831572711289243e+11,
      "predicted_advised_flops_count": 4.0960000000000000e+07,
      "predicted_flops": 5.0371629942113167e+10,
      "predicted_flops_count": 7.9872100142290583e+06,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 1.3950976000000000e+07,
      "workspace_megabytes": 1.3304687500000000e+01
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__7032941452476097680<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:8/input[2]:14/input[3]:14/filter_count:16/filter_height:5/filter_width:5/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__7032941452476097680<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:8/input[2]:14/input[3]:14/filter_count:16/filter_height:5/filter_width:5/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 4923,
      "real_time": 1.4227328510712733e+05,
      "cpu_time": 1.4769413081300701e+05,
      "time_unit": "ns",
      "items_per_second": 2.2571096165959888e+10,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 8.3932160000000000e+06,
      "advised_time": 1.5155200660228729e-01,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)7; cudnnMathType_t math_type = (cudnnMathType_t)0]": 8.2538945752816425e+18,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 7.0000000000000000e+00,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.6000000000000000e+01,
      "filter_height": 5.0000000000000000e+00,
      "filter_width": 5.0000000000000000e+00,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "group": 1.0000000000000000e+00,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 8.0000000000000000e+00,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 8.0000000000000000e+00,
      "input_height": 1.4000000000000000e+01,
      "input_size": 2.0070400000000000e+05,
      "input_width": 1.4000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.6000000000000000e+01,
      "num_iterations": 4.9230000000000000e+03,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 1.6000000000000000e+01,
      "output_height": 1.0000000000000000e+01,
      "output_size": 2.0480000000000000e+05,
      "output_width": 1.0000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 2.8789663476989655e+11,
      "predicted_advised_flops_count": 4.0960000000000000e+07,
      "predicted_flops": -7.0287264348119270e+03,
      "predicted_flops_count": -1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 8.3932160000000000e+06,
      "workspace_megabytes": 8.0043945312500000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__12881974682802933222<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:1/input[1]:96/input[2]:13/input[3]:13/filter_count:208/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 5588,
      "real_time": 1.2533203966139533e+05,
      "cpu_time": 1.3072139352278922e+05,
      "time_unit": "ns",
      "items_per_second": 2.6925214088249126e+10,
      "advised_convolution_algorithm": 6.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 1.2595200538635254e-01,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4730153338016043e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.0800000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "group": 1.0000000000000000e+00,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 9.6000000000000000e+01,
      "input[2]": 1.3000000000000000e+01,
      "input[3]": 1.3000000000000000e+01,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 9.6000000000000000e+01,
      "input_height": 1.3000000000000000e+01,
      "input_size": 1.6224000000000000e+04,
      "input_width": 1.3000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 2.0800000000000000e+02,
      "num_iterations": 5.5880000000000000e+03,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 2.0800000000000000e+02,
      "output_height": 1.3000000000000000e+01,
      "output_size": 3.5152000000000000e+04,
      "output_width": 1.3000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "predicted_advised_flops": -7.9788057602960971e+03,
      "predicted_advised_flops_count": -1.0000000000000000e+00,
      "predicted_flops": 2.4232692679424216e+11,
      "predicted_flops_count": 3.0371328000000000e+07,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__12881974682802933222<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:1/input[1]:96/input[2]:13/input[3]:13/filter_count:208/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 5814,
      "real_time": 1.2038803240187210e+05,
      "cpu_time": 1.2573717457777007e+05,
      "time_unit": "ns",
      "items_per_second": 2.8030958997113098e+10,
      "advised_convolution_algorithm": 6.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.0200000000000000e+03,
      "advised_time": 1.2287999689579010e-01,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.2419525699096977e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.0800000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "group": 1.0000000000000000e+00,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 9.6000000000000000e+01,
      "input[2]": 1.3000000000000000e+01,
      "input[3]": 1.3000000000000000e+01,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 9.6000000000000000e+01,
      "input_height": 1.3000000000000000e+01,
      "input_size": 1.6224000000000000e+04,
      "input_width": 1.3000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 2.0800000000000000e+02,
      "num_iterations": 5.8140000000000000e+03,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 2.0800000000000000e+02,
      "output_height": 1.3000000000000000e+01,
      "output_size": 3.5152000000000000e+04,
      "output_width": 1.3000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "predicted_advised_flops": -8.3064734928290873e+03,
      "predicted_advised_flops_count": -1.0000000000000000e+00,
      "predicted_flops": 2.5227863097401788e+11,
      "predicted_flops_count": 3.0371328000000000e+07,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 1.0200000000000000e+03,
      "workspace_megabytes": 9.7274780273437500e-04
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__12881974682802933222<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:1/input[1]:96/input[2]:13/input[3]:13/filter_count:208/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 6079,
      "real_time": 1.1496372572112652e+05,
      "cpu_time": 1.2032070373299830e+05,
      "time_unit": "ns",
      "items_per_second": 2.9353537203429916e+10,
      "advised_convolution_algorithm": 6.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 5.8406400000000000e+05,
      "advised_time": 1.1776000261306763e-01,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)2; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4280899851402570e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 2.0000000000000000e+00,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.0800000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "group": 1.0000000000000000e+00,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 9.6000000000000000e+01,
      "input[2]": 1.3000000000000000e+01,
      "input[3]": 1.3000000000000000e+01,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 9.6000000000000000e+01,
      "input_height": 1.3000000000000000e+01,
      "input_size": 1.6224000000000000e+04,
      "input_width": 1.3000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 2.0800000000000000e+02,
      "num_iterations": 6.0790000000000000e+03,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 2.0800000000000000e+02,
      "output_height": 1.3000000000000000e+01,
      "output_size": 3.5152000000000000e+04,
      "output_width": 1.3000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "predicted_advised_flops": -8.6983958959868087e+03,
      "predicted_advised_flops_count": -1.0000000000000000e+00,
      "predicted_flops": 2.6418183483086926e+11,
      "predicted_flops_count": 3.0371328000000000e+07,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 5.8406400000000000e+05,
      "workspace_megabytes": 5.5700683593750000e-01
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__12881974682802933222<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:1/input[1]:96/input[2]:13/input[3]:13/filter_count:208/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__12881974682802933222<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:1/input[1]:96/input[2]:13/input[3]:13/filter_count:208/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 4559,
      "real_time": 1.5322272677481052e+05,
      "cpu_time": 1.5873145755664469e+05,
      "time_unit": "ns",
      "items_per_second": 2.2024095713683483e+10,
      "advised_convolution_algorithm": 6.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 4.6946304000000000e+07,
      "advised_time": 1.7612800002098083e-01,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)4; cudnnMathType_t math_type = (cudnnMathType_t)0]": 2.3237108083472476e+18,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 4.0000000000000000e+00,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.0800000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "group": 1.0000000000000000e+00,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 9.6000000000000000e+01,
      "input[2]": 1.3000000000000000e+01,
      "input[3]": 1.3000000000000000e+01,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 9.6000000000000000e+01,
      "input_height": 1.3000000000000000e+01,
      "input_size": 1.6224000000000000e+04,
      "input_width": 1.3000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 2.0800000000000000e+02,
      "num_iterations": 4.5590000000000000e+03,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 2.0800000000000000e+02,
      "output_height": 1.3000000000000000e+01,
      "output_size": 3.5152000000000000e+04,
      "output_width": 1.3000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "predicted_advised_flops": -6.5264469641614405e+03,
      "predicted_advised_flops_count": -1.0000000000000000e+00,
      "predicted_flops": 1.8750330793149619e+11,
      "predicted_flops_count": 2.8729768120560803e+07,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 4.6946304000000000e+07,
      "workspace_megabytes": 4.4771484375000000e+01
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__12881974682802933222<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:1/input[1]:96/input[2]:13/input[3]:13/filter_count:208/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 1379,
      "real_time": 5.0671373630223487e+05,
      "cpu_time": 5.1543347497956833e+05,
      "time_unit": "ns",
      "items_per_second": 6.6597602516683865e+09,
      "advised_convolution_algorithm": 6.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 8.8248320000000000e+07,
      "advised_time": 5.1590400934219360e-01,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)5; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.6667819325789325e+18,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 5.0000000000000000e+00,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.0800000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "group": 1.0000000000000000e+00,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 9.6000000000000000e+01,
      "input[2]": 1.3000000000000000e+01,
      "input[3]": 1.3000000000000000e+01,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 9.6000000000000000e+01,
      "input_height": 1.3000000000000000e+01,
      "input_size": 1.6224000000000000e+04,
      "input_width": 1.3000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 2.0800000000000000e+02,
      "num_iterations": 1.3790000000000000e+03,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 2.0800000000000000e+02,
      "output_height": 1.3000000000000000e+01,
      "output_size": 3.5152000000000000e+04,
      "output_width": 1.3000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "predicted_advised_flops": -1.9735008711181638e+03,
      "predicted_advised_flops_count": -1.0000000000000000e+00,
      "predicted_flops": 5.6698222412949600e+10,
      "predicted_flops_count": 2.8729768120560803e+07,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 8.8248320000000000e+07,
      "workspace_megabytes": 8.4160156250000000e+01
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__12881974682802933222<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:1/input[1]:96/input[2]:13/input[3]:13/filter_count:208/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 22814,
      "real_time": 3.0258029542205826e+04,
      "cpu_time": 3.5433327211054362e+04,
      "time_unit": "ns",
      "items_per_second": 1.1152715662772766e+11,
      "advised_convolution_algorithm": 6.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 2.0959360000000000e+06,
      "advised_time": 6.0416001826524734e-02,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)6; cudnnMathType_t math_type = (cudnnMathType_t)0]": 5.7500739770702787e+18,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 6.0000000000000000e+00,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.0800000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "group": 1.0000000000000000e+00,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 9.6000000000000000e+01,
      "input[2]": 1.3000000000000000e+01,
      "input[3]": 1.3000000000000000e+01,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 9.6000000000000000e+01,
      "input_height": 1.3000000000000000e+01,
      "input_size": 1.6224000000000000e+04,
      "input_width": 1.3000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 2.0800000000000000e+02,
      "num_iterations": 2.2814000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 2.0800000000000000e+02,
      "output_height": 1.3000000000000000e+01,
      "output_size": 3.5152000000000000e+04,
      "output_width": 1.3000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "predicted_advised_flops": -3.3049078711656897e+04,
      "predicted_advised_flops_count": -1.0000000000000000e+00,
      "predicted_flops": -3.3049078711656897e+04,
      "predicted_flops_count": -1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 2.0959360000000000e+06,
      "workspace_megabytes": 1.9988403320312500e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__12881974682802933222<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:1/input[1]:96/input[2]:13/input[3]:13/filter_count:208/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 5439,
      "real_time": 1.2821694550172589e+05,
      "cpu_time": 1.3362465140657173e+05,
      "time_unit": "ns",
      "items_per_second": 2.6319391612355759e+10,
      "advised_convolution_algorithm": 6.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.4082048000000000e+07,
      "advised_time": 1.3820800185203552e-01,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)7; cudnnMathType_t math_type = (cudnnMathType_t)0]": 8.2538945752816425e+18,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 7.0000000000000000e+00,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.0800000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "group": 1.0000000000000000e+00,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 9.6000000000000000e+01,
      "input[2]": 1.3000000000000000e+01,
      "input[3]": 1.3000000000000000e+01,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 9.6000000000000000e+01,
      "input_height": 1.3000000000000000e+01,
      "input_size": 1.6224000000000000e+04,
      "input_width": 1.3000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 2.0800000000000000e+02,
      "num_iterations": 5.4390000000000000e+03,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 2.0800000000000000e+02,
      "output_height": 1.3000000000000000e+01,
      "output_size": 3.5152000000000000e+04,
      "output_width": 1.3000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "predicted_advised_flops": -7.7992811019393630e+03,
      "predicted_advised_flops_count": -1.0000000000000000e+00,
      "predicted_flops": -7.7992811019393630e+03,
      "predicted_flops_count": -1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 1.4082048000000000e+07,
      "workspace_megabytes": 1.3429687500000000e+01
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__736502095446915514<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:1/input[1]:608/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 8245,
      "real_time": 8.4949021395221032e+04,
      "cpu_time": 9.0185913037697319e+04,
      "time_unit": "ns",
      "items_per_second": 1.7956067944601556e+11,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 8.6015999317169189e-02,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4730153338016043e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "group": 1.0000000000000000e+00,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 6.0800000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 6.0800000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 1.1916800000000000e+05,
      "input_width": 1.4000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 8.2450000000000000e+03,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 2.5088000000000000e+04,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 1.7956067944601556e+11,
      "predicted_advised_flops_count": 1.5253504000000000e+07,
      "predicted_flops": 1.7956067944601556e+11,
      "predicted_flops_count": 1.5253504000000000e+07,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__736502095446915514<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:1/input[1]:608/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 7873,
      "real_time": 8.8948575970484322e+04,
      "cpu_time": 9.4236598502802517e+04,
      "time_unit": "ns",
      "items_per_second": 1.7148677012054187e+11,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.1840000000000000e+03,
      "advised_time": 9.2160001397132874e-02,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.2419525699096977e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "group": 1.0000000000000000e+00,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 6.0800000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 6.0800000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 1.1916800000000000e+05,
      "input_width": 1.4000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 7.8730000000000000e+03,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 2.5088000000000000e+04,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 1.7148677012054187e+11,
      "predicted_advised_flops_count": 1.5253504000000000e+07,
      "predicted_flops": 1.7148677012054187e+11,
      "predicted_flops_count": 1.5253504000000000e+07,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 1.1840000000000000e+03,
      "workspace_megabytes": 1.1291503906250000e-03
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__736502095446915514<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:1/input[1]:608/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 5575,
      "real_time": 1.2551585025719949e+05,
      "cpu_time": 1.3092827031546894e+05,
      "time_unit": "ns",
      "items_per_second": 1.2152651612321028e+11,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 4.7667200000000000e+05,
      "advised_time": 1.3007999956607819e-01,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)2; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4280899851402570e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 2.0000000000000000e+00,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "group": 1.0000000000000000e+00,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 6.0800000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 6.0800000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 1.1916800000000000e+05,
      "input_width": 1.4000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 5.5750000000000000e+03,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 2.5088000000000000e+04,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 1.2152651612321028e+11,
      "predicted_advised_flops_count": 1.5253504000000000e+07,
      "predicted_flops": 1.2152651612321028e+11,
      "predicted_flops_count": 1.5253504000000000e+07,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 4.7667200000000000e+05,
      "workspace_megabytes": 4.5458984375000000e-01
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__736502095446915514<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:1/input[1]:608/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__736502095446915514<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:1/input[1]:608/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 1461,
      "real_time": 4.7817552099428291e+05,
      "cpu_time": 4.8662876522934786e+05,
      "time_unit": "ns",
      "items_per_second": 3.1899382821360214e+10,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.8101862400000000e+08,
      "advised_time": 4.9539199471473694e-01,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)4; cudnnMathType_t math_type = (cudnnMathType_t)0]": 2.3237108083472476e+18,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 4.0000000000000000e+00,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "group": 1.0000000000000000e+00,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 6.0800000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 6.0800000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 1.1916800000000000e+05,
      "input_width": 1.4000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 1.4610000000000000e+03,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 2.5088000000000000e+04,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 3.1899382821360214e+10,
      "predicted_advised_flops_count": 1.5253504000000000e+07,
      "predicted_flops": 2.7710113301870087e+11,
      "predicted_flops_count": 1.3250297864932339e+08,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 1.8101862400000000e+08,
      "workspace_megabytes": 1.7263281250000000e+02
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__736502095446915514<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:1/input[1]:608/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 3983,
      "real_time": 1.7578103889617321e+05,
      "cpu_time": 1.8134001104284261e+05,
      "time_unit": "ns",
      "items_per_second": 8.6775593635042923e+10,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.1985824000000000e+07,
      "advised_time": 1.8739199638366699e-01,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)5; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.6667819325789325e+18,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 5.0000000000000000e+00,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "group": 1.0000000000000000e+00,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 6.0800000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 6.0800000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 1.1916800000000000e+05,
      "input_width": 1.4000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 3.9830000000000000e+03,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 2.5088000000000000e+04,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 8.6775593635042923e+10,
      "predicted_advised_flops_count": 1.5253504000000000e+07,
      "predicted_flops": 7.5379562825082385e+11,
      "predicted_flops_count": 1.3250297864932339e+08,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 1.1985824000000000e+07,
      "workspace_megabytes": 1.1430572509765625e+01
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__736502095446915514<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:1/input[1]:608/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__736502095446915514<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:1/input[1]:608/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__16728485132556763852<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:32/input[2]:112/input[3]:112/filter_count:32/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 482,
      "real_time": 1.4508714014471071e+06,
      "cpu_time": 1.4869132593280654e+06,
      "time_unit": "ns",
      "items_per_second": 1.1332273600266008e+12,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 1.4846080541610718e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4730153338016043e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 3.2000000000000000e+01,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "group": 1.0000000000000000e+00,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 3.2000000000000000e+01,
      "input[2]": 1.1200000000000000e+02,
      "input[3]": 1.1200000000000000e+02,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 3.2000000000000000e+01,
      "input_height": 1.1200000000000000e+02,
      "input_size": 5.1380224000000000e+07,
      "input_width": 1.1200000000000000e+02,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 3.2000000000000000e+01,
      "num_iterations": 4.8200000000000000e+02,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 3.2000000000000000e+01,
      "output_height": 1.1200000000000000e+02,
      "output_size": 5.1380224000000000e+07,
      "output_width": 1.1200000000000000e+02,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 1.1332273600266008e+12,
      "predicted_advised_flops_count": 1.6441671680000000e+09,
      "predicted_flops": 1.1332273600266008e+12,
      "predicted_flops_count": 1.6441671680000000e+09,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__16728485132556763852<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:32/input[2]:112/input[3]:112/filter_count:32/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 581,
      "real_time": 1.2041522707331690e+06,
      "cpu_time": 1.2307550189336212e+06,
      "time_unit": "ns",
      "items_per_second": 1.3654146638771196e+12,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 7.5272000000000000e+04,
      "advised_time": 1.2050559520721436e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.2419525699096977e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 3.2000000000000000e+01,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "group": 1.0000000000000000e+00,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 3.2000000000000000e+01,
      "input[2]": 1.1200000000000000e+02,
      "input[3]": 1.1200000000000000e+02,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 3.2000000000000000e+01,
      "input_height": 1.1200000000000000e+02,
      "input_size": 5.1380224000000000e+07,
      "input_width": 1.1200000000000000e+02,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 3.2000000000000000e+01,
      "num_iterations": 5.8100000000000000e+02,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 3.2000000000000000e+01,
      "output_height": 1.1200000000000000e+02,
      "output_size": 5.1380224000000000e+07,
      "output_width": 1.1200000000000000e+02,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 1.3654146638771196e+12,
      "predicted_advised_flops_count": 1.6441671680000000e+09,
      "predicted_flops": 1.3654146638771196e+12,
      "predicted_flops_count": 1.6441671680000000e+09,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 7.5272000000000000e+04,
      "workspace_megabytes": 7.1784973144531250e-02
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__16728485132556763852<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:32/input[2]:112/input[3]:112/filter_count:32/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 267,
      "real_time": 2.6192298343872535e+06,
      "cpu_time": 2.7239309812743268e+06,
      "time_unit": "ns",
      "items_per_second": 6.2772924560270178e+11,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 2.0552089600000000e+08,
      "advised_time": 2.6286079883575439e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)2; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4280899851402570e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 2.0000000000000000e+00,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 3.2000000000000000e+01,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "group": 1.0000000000000000e+00,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 3.2000000000000000e+01,
      "input[2]": 1.1200000000000000e+02,
      "input[3]": 1.1200000000000000e+02,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 3.2000000000000000e+01,
      "input_height": 1.1200000000000000e+02,
      "input_size": 5.1380224000000000e+07,
      "input_width": 1.1200000000000000e+02,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 3.2000000000000000e+01,
      "num_iterations": 2.6700000000000000e+02,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 3.2000000000000000e+01,
      "output_height": 1.1200000000000000e+02,
      "output_size": 5.1380224000000000e+07,
      "output_width": 1.1200000000000000e+02,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 6.2772924560270178e+11,
      "predicted_advised_flops_count": 1.6441671680000000e+09,
      "predicted_flops": 6.2772924560270178e+11,
      "predicted_flops_count": 1.6441671680000000e+09,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 2.0552089600000000e+08,
      "workspace_megabytes": 1.9600000000000000e+02
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__16728485132556763852<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:32/input[2]:112/input[3]:112/filter_count:32/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__16728485132556763852<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:32/input[2]:112/input[3]:112/filter_count:32/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 64,
      "real_time": 1.0924647038336843e+07,
      "cpu_time": 1.2641793374978505e+07,
      "time_unit": "ns",
      "items_per_second": 1.5050071295029285e+11,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 6.8196761600000000e+08,
      "advised_time": 1.0937343597412109e+01,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)4; cudnnMathType_t math_type = (cudnnMathType_t)0]": 2.3237108083472476e+18,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 4.0000000000000000e+00,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 3.2000000000000000e+01,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "group": 1.0000000000000000e+00,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 3.2000000000000000e+01,
      "input[2]": 1.1200000000000000e+02,
      "input[3]": 1.1200000000000000e+02,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 3.2000000000000000e+01,
      "input_height": 1.1200000000000000e+02,
      "input_size": 5.1380224000000000e+07,
      "input_width": 1.1200000000000000e+02,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 3.2000000000000000e+01,
      "num_iterations": 6.4000000000000000e+01,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 3.2000000000000000e+01,
      "output_height": 1.1200000000000000e+02,
      "output_size": 5.1380224000000000e+07,
      "output_width": 1.1200000000000000e+02,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 1.5050071295029285e+11,
      "predicted_advised_flops_count": 1.6441671680000000e+09,
      "predicted_flops": 2.9457268047651459e+11,
      "predicted_flops_count": 3.2181025613427000e+09,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 6.8196761600000000e+08,
      "workspace_megabytes": 6.5037500000000000e+02
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__16728485132556763852<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:32/input[2]:112/input[3]:112/filter_count:32/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 142,
      "real_time": 4.9276195997765791e+06,
      "cpu_time": 5.2802229154920010e+06,
      "time_unit": "ns",
      "items_per_second": 3.3366357420823383e+11,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 2.4970118400000000e+08,
      "advised_time": 5.0923199653625488e+00,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)5; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.6667819325789325e+18,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 5.0000000000000000e+00,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 3.2000000000000000e+01,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "group": 1.0000000000000000e+00,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.2800000000000000e+02,
      "input[1]": 3.2000000000000000e+01,
      "input[2]": 1.1200000000000000e+02,
      "input[3]": 1.1200000000000000e+02,
      "input_batch_size": 1.2800000000000000e+02,
      "input_channels": 3.2000000000000000e+01,
      "input_height": 1.1200000000000000e+02,
      "input_size": 5.1380224000000000e+07,
      "input_width": 1.1200000000000000e+02,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 3.2000000000000000e+01,
      "num_iterations": 1.4200000000000000e+02,
      "output_batch_size": 1.2800000000000000e+02,
      "output_channels": 3.2000000000000000e+01,
      "output_height": 1.1200000000000000e+02,
      "output_size": 5.1380224000000000e+07,
      "output_width": 1.1200000000000000e+02,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 3.3366357420823383e+11,
      "predicted_advised_flops_count": 1.6441671680000000e+09,
      "predicted_flops": 6.5307447057979285e+11,
      "predicted_flops_count": 3.2181025613427000e+09,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 2.4970118400000000e+08,
      "workspace_megabytes": 2.3813360595703125e+02
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__16728485132556763852<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:32/input[2]:112/input[3]:112/filter_count:32/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__16728485132556763852<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:32/input[2]:112/input[3]:112/filter_count:32/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__5841195909144926381<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:1/input[1]:16/input[2]:13/input[3]:13/filter_count:48/filter_height:5/filter_width:5/pad_height:2/pad_width:2/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 11206,
      "real_time": 6.2422308616716480e+04,
      "cpu_time": 6.7624995983747169e+04,
      "time_unit": "ns",
      "items_per_second": 2.0792566451994720e+09,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 6.3487999141216278e-02,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4730153338016043e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 4.8000000000000000e+01,
      "filter_height": 5.0000000000000000e+00,
      "filter_width": 5.0000000000000000e+00,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "group": 1.0000000000000000e+00,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 1.6000000000000000e+01,
      "input[2]": 1.3000000000000000e+01,
      "input[3]": 1.3000000000000000e+01,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 1.6000000000000000e+01,
      "input_height": 1.3000000000000000e+01,
      "input_size": 2.7040000000000000e+03,
      "input_width": 1.3000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 4.8000000000000000e+01,
      "num_iterations": 1.1206000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 4.8000000000000000e+01,
      "output_height": 1.3000000000000000e+01,
      "output_size": 8.1120000000000000e+03,
      "output_width": 1.3000000000000000e+01,
      "pad_height": 2.0000000000000000e+00,
      "pad_width": 2.0000000000000000e+00,
      "predicted_advised_flops": 5.1981416129986801e+10,
      "predicted_advised_flops_count": 3.2448000000000000e+06,
      "predicted_flops": 5.1981416129986801e+10,
      "predicted_flops_count": 3.2448000000000000e+06,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__5841195909144926381<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:1/input[1]:16/input[2]:13/input[3]:13/filter_count:48/filter_height:5/filter_width:5/pad_height:2/pad_width:2/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 9917,
      "real_time": 7.0564273577312371e+04,
      "cpu_time": 7.5779351316205211e+04,
      "time_unit": "ns",
      "items_per_second": 1.8393443795293367e+09,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.0200000000000000e+03,
      "advised_time": 7.2704002261161804e-02,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.2419525699096977e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 4.8000000000000000e+01,
      "filter_height": 5.0000000000000000e+00,
      "filter_width": 5.0000000000000000e+00,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "group": 1.0000000000000000e+00,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 1.6000000000000000e+01,
      "input[2]": 1.3000000000000000e+01,
      "input[3]": 1.3000000000000000e+01,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 1.6000000000000000e+01,
      "input_height": 1.3000000000000000e+01,
      "input_size": 2.7040000000000000e+03,
      "input_width": 1.3000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 4.8000000000000000e+01,
      "num_iterations": 9.9170000000000000e+03,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 4.8000000000000000e+01,
      "output_height": 1.3000000000000000e+01,
      "output_size": 8.1120000000000000e+03,
      "output_width": 1.3000000000000000e+01,
      "pad_height": 2.0000000000000000e+00,
      "pad_width": 2.0000000000000000e+00,
      "predicted_advised_flops": 4.5983609488233414e+10,
      "predicted_advised_flops_count": 3.2448000000000000e+06,
      "predicted_flops": 4.5983609488233414e+10,
      "predicted_flops_count": 3.2448000000000000e+06,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 1.0200000000000000e+03,
      "workspace_megabytes": 9.7274780273437500e-04
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__5841195909144926381<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:1/input[1]:16/input[2]:13/input[3]:13/filter_count:48/filter_height:5/filter_width:5/pad_height:2/pad_width:2/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 7922,
      "real_time": 8.8207797813745943e+04,
      "cpu_time": 9.3631861018309923e+04,
      "time_unit": "ns",
      "items_per_second": 1.4714345354597862e+09,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 2.7040000000000000e+05,
      "advised_time": 9.0112000703811646e-02,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)2; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4280899851402570e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 2.0000000000000000e+00,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 4.8000000000000000e+01,
      "filter_height": 5.0000000000000000e+00,
      "filter_width": 5.0000000000000000e+00,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "group": 1.0000000000000000e+00,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 1.6000000000000000e+01,
      "input[2]": 1.3000000000000000e+01,
      "input[3]": 1.3000000000000000e+01,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 1.6000000000000000e+01,
      "input_height": 1.3000000000000000e+01,
      "input_size": 2.7040000000000000e+03,
      "input_width": 1.3000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 4.8000000000000000e+01,
      "num_iterations": 7.9220000000000000e+03,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 4.8000000000000000e+01,
      "output_height": 1.3000000000000000e+01,
      "output_size": 8.1120000000000000e+03,
      "output_width": 1.3000000000000000e+01,
      "pad_height": 2.0000000000000000e+00,
      "pad_width": 2.0000000000000000e+00,
      "predicted_advised_flops": 3.6785863386494652e+10,
      "predicted_advised_flops_count": 3.2448000000000000e+06,
      "predicted_flops": 3.6785863386494652e+10,
      "predicted_flops_count": 3.2448000000000000e+06,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 2.7040000000000000e+05,
      "workspace_megabytes": 2.5787353515625000e-01
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__5841195909144926381<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:1/input[1]:16/input[2]:13/input[3]:13/filter_count:48/filter_height:5/filter_width:5/pad_height:2/pad_width:2/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__5841195909144926381<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:1/input[1]:16/input[2]:13/input[3]:13/filter_count:48/filter_height:5/filter_width:5/pad_height:2/pad_width:2/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 9274,
      "real_time": 7.5253378955756009e+04,
      "cpu_time": 8.0489236899527081e+04,
      "time_unit": "ns",
      "items_per_second": 1.7247331854202731e+09,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 6.9007360000000000e+06,
      "advised_time": 8.2943998277187347e-02,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)4; cudnnMathType_t math_type = (cudnnMathType_t)0]": 2.3237108083472476e+18,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 4.0000000000000000e+00,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 4.8000000000000000e+01,
      "filter_height": 5.0000000000000000e+00,
      "filter_width": 5.0000000000000000e+00,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "group": 1.0000000000000000e+00,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 1.6000000000000000e+01,
      "input[2]": 1.3000000000000000e+01,
      "input[3]": 1.3000000000000000e+01,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 1.6000000000000000e+01,
      "input_height": 1.3000000000000000e+01,
      "input_size": 2.7040000000000000e+03,
      "input_width": 1.3000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 4.8000000000000000e+01,
      "num_iterations": 9.2740000000000000e+03,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 4.8000000000000000e+01,
      "output_height": 1.3000000000000000e+01,
      "output_size": 8.1120000000000000e+03,
      "output_width": 1.3000000000000000e+01,
      "pad_height": 2.0000000000000000e+00,
      "pad_width": 2.0000000000000000e+00,
      "predicted_advised_flops": 4.3118329635506828e+10,
      "predicted_advised_flops_count": 3.2448000000000000e+06,
      "predicted_flops": 1.5552987414224838e+10,
      "predicted_flops_count": 1.1704148557767654e+06,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 6.9007360000000000e+06,
      "workspace_megabytes": 6.5810546875000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__5841195909144926381<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:1/input[1]:16/input[2]:13/input[3]:13/filter_count:48/filter_height:5/filter_width:5/pad_height:2/pad_width:2/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 9985,
      "real_time": 7.0678975807103430e+04,
      "cpu_time": 7.5853485428459768e+04,
      "time_unit": "ns",
      "items_per_second": 1.8363593772811229e+09,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 3.6454400000000000e+06,
      "advised_time": 7.5808003544807434e-02,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)5; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.6667819325789325e+18,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 5.0000000000000000e+00,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 4.8000000000000000e+01,
      "filter_height": 5.0000000000000000e+00,
      "filter_width": 5.0000000000000000e+00,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "group": 1.0000000000000000e+00,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 1.6000000000000000e+01,
      "input[2]": 1.3000000000000000e+01,
      "input[3]": 1.3000000000000000e+01,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 1.6000000000000000e+01,
      "input_height": 1.3000000000000000e+01,
      "input_size": 2.7040000000000000e+03,
      "input_width": 1.3000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 4.8000000000000000e+01,
      "num_iterations": 9.9850000000000000e+03,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 4.8000000000000000e+01,
      "output_height": 1.3000000000000000e+01,
      "output_size": 8.1120000000000000e+03,
      "output_width": 1.3000000000000000e+01,
      "pad_height": 2.0000000000000000e+00,
      "pad_width": 2.0000000000000000e+00,
      "predicted_advised_flops": 4.5908984432028069e+10,
      "predicted_advised_flops_count": 3.2448000000000000e+06,
      "predicted_flops": 1.6559589926303593e+10,
      "predicted_flops_count": 1.1704148557767654e+06,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 3.6454400000000000e+06,
      "workspace_megabytes": 3.4765625000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__5841195909144926381<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:1/input[1]:16/input[2]:13/input[3]:13/filter_count:48/filter_height:5/filter_width:5/pad_height:2/pad_width:2/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__5841195909144926381<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:1/input[1]:16/input[2]:13/input[3]:13/filter_count:48/filter_height:5/filter_width:5/pad_height:2/pad_width:2/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 12500,
      "real_time": 5.5983898136764765e+04,
      "cpu_time": 6.1205855279986274e+04,
      "time_unit": "ns",
      "items_per_second": 2.3183808973595796e+09,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 3.2880640000000000e+06,
      "advised_time": 6.6560000181198120e-02,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)7; cudnnMathType_t math_type = (cudnnMathType_t)0]": 8.2538945752816425e+18,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 7.0000000000000000e+00,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 4.8000000000000000e+01,
      "filter_height": 5.0000000000000000e+00,
      "filter_width": 5.0000000000000000e+00,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "group": 1.0000000000000000e+00,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 1.6000000000000000e+01,
      "input[2]": 1.3000000000000000e+01,
      "input[3]": 1.3000000000000000e+01,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 1.6000000000000000e+01,
      "input_height": 1.3000000000000000e+01,
      "input_size": 2.7040000000000000e+03,
      "input_width": 1.3000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 4.8000000000000000e+01,
      "num_iterations": 1.2500000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 4.8000000000000000e+01,
      "output_height": 1.3000000000000000e+01,
      "output_size": 8.1120000000000000e+03,
      "output_width": 1.3000000000000000e+01,
      "pad_height": 2.0000000000000000e+00,
      "pad_width": 2.0000000000000000e+00,
      "predicted_advised_flops": 5.7959522433989494e+10,
      "predicted_advised_flops_count": 3.2448000000000000e+06,
      "predicted_flops": -1.7862278856628913e+04,
      "predicted_flops_count": -1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 3.2880640000000000e+06,
      "workspace_megabytes": 3.1357421875000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__1569287348367311653<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:1/input[1]:352/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 16797,
      "real_time": 4.1613829114608452e+04,
      "cpu_time": 4.6795737512215266e+04,
      "time_unit": "ns",
      "items_per_second": 2.1221253097566797e+11,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 4.3007999658584595e-02,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4730153338016043e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "group": 1.0000000000000000e+00,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 3.5200000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 3.5200000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 6.8992000000000000e+04,
      "input_width": 1.4000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 1.6797000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 2.5088000000000000e+04,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 2.1221253097566797e+11,
      "predicted_advised_flops_count": 8.8309760000000000e+06,
      "predicted_flops": 2.1221253097566797e+11,
      "predicted_flops_count": 8.8309760000000000e+06,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__1569287348367311653<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:1/input[1]:352/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 12070,
      "real_time": 5.8050018300794422e+04,
      "cpu_time": 6.3254208036337324e+04,
      "time_unit": "ns",
      "items_per_second": 1.5212701491739493e+11,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.1840000000000000e+03,
      "advised_time": 6.2111999839544296e-02,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.2419525699096977e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "group": 1.0000000000000000e+00,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 3.5200000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 3.5200000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 6.8992000000000000e+04,
      "input_width": 1.4000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 1.2070000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 2.5088000000000000e+04,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 1.5212701491739493e+11,
      "predicted_advised_flops_count": 8.8309760000000000e+06,
      "predicted_flops": 1.5212701491739493e+11,
      "predicted_flops_count": 8.8309760000000000e+06,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 1.1840000000000000e+03,
      "workspace_megabytes": 1.1291503906250000e-03
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__1569287348367311653<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:1/input[1]:352/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 6200,
      "real_time": 1.1280669014893413e+05,
      "cpu_time": 1.1818969354807919e+05,
      "time_unit": "ns",
      "items_per_second": 7.8284151306459030e+10,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 2.7596800000000000e+05,
      "advised_time": 1.1462400108575821e-01,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)2; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4280899851402570e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 2.0000000000000000e+00,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "group": 1.0000000000000000e+00,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 3.5200000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 3.5200000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 6.8992000000000000e+04,
      "input_width": 1.4000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 6.2000000000000000e+03,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 2.5088000000000000e+04,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 7.8284151306459030e+10,
      "predicted_advised_flops_count": 8.8309760000000000e+06,
      "predicted_flops": 7.8284151306459030e+10,
      "predicted_flops_count": 8.8309760000000000e+06,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 2.7596800000000000e+05,
      "workspace_megabytes": 2.6318359375000000e-01
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__1569287348367311653<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:1/input[1]:352/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__1569287348367311653<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:1/input[1]:352/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 2396,
      "real_time": 2.9247510912579380e+05,
      "cpu_time": 2.9883448163459077e+05,
      "time_unit": "ns",
      "items_per_second": 3.0193940354089378e+10,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.0480025600000000e+08,
      "advised_time": 3.0646398663520813e-01,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)4; cudnnMathType_t math_type = (cudnnMathType_t)0]": 2.3237108083472476e+18,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 4.0000000000000000e+00,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "group": 1.0000000000000000e+00,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 3.5200000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 3.5200000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 6.8992000000000000e+04,
      "input_width": 1.4000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 2.3960000000000000e+03,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 2.5088000000000000e+04,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 3.0193940354089378e+10,
      "predicted_advised_flops_count": 8.8309760000000000e+06,
      "predicted_flops": 2.6256144672280780e+11,
      "predicted_flops_count": 7.6792687782479510e+07,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 1.0480025600000000e+08,
      "workspace_megabytes": 9.9945312500000000e+01
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__1569287348367311653<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:1/input[1]:352/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 5811,
      "real_time": 1.2059498397501653e+05,
      "cpu_time": 1.2590474651470307e+05,
      "time_unit": "ns",
      "items_per_second": 7.3228385699935074e+10,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 7.0419520000000000e+06,
      "advised_time": 1.2800000607967377e-01,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)5; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.6667819325789325e+18,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 5.0000000000000000e+00,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "group": 1.0000000000000000e+00,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 3.5200000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 3.5200000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 6.8992000000000000e+04,
      "input_width": 1.4000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 5.8110000000000000e+03,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 2.5088000000000000e+04,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 7.3228385699935074e+10,
      "predicted_advised_flops_count": 8.8309760000000000e+06,
      "predicted_flops": 6.3678177359672375e+11,
      "predicted_flops_count": 7.6792687782479510e+07,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 7.0419520000000000e+06,
      "workspace_megabytes": 6.7157287597656250e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__1569287348367311653<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:1/input[1]:352/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__1569287348367311653<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:1/input[1]:352/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__2162950824770925913<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:1/input[1]:352/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 12457,
      "real_time": 5.6372042578934044e+04,
      "cpu_time": 6.1600869712185187e+04,
      "time_unit": "ns",
      "items_per_second": 6.2662096996996814e+11,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 5.8304000645875931e-02,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4730153338016043e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "group": 1.0000000000000000e+00,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 3.5200000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 3.5200000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 2.7596800000000000e+05,
      "input_width": 2.8000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 1.2457000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 1.0035200000000000e+05,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 6.2662096996996814e+11,
      "predicted_advised_flops_count": 3.5323904000000000e+07,
      "predicted_flops": 6.2662096996996814e+11,
      "predicted_flops_count": 3.5323904000000000e+07,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__2162950824770925913<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:1/input[1]:352/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 12060,
      "real_time": 5.9079411792958170e+04,
      "cpu_time": 6.4524675123447953e+04,
      "time_unit": "ns",
      "items_per_second": 5.9790547887970593e+11,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 4.7120000000000000e+03,
      "advised_time": 6.4511999487876892e-02,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.2419525699096977e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "group": 1.0000000000000000e+00,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 3.5200000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 3.5200000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 2.7596800000000000e+05,
      "input_width": 2.8000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 1.2060000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 1.0035200000000000e+05,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 5.9790547887970593e+11,
      "predicted_advised_flops_count": 3.5323904000000000e+07,
      "predicted_flops": 5.9790547887970593e+11,
      "predicted_flops_count": 3.5323904000000000e+07,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 4.7120000000000000e+03,
      "workspace_megabytes": 4.4937133789062500e-03
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__2162950824770925913<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:1/input[1]:352/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 5684,
      "real_time": 1.2241366773678154e+05,
      "cpu_time": 1.2780259957863569e+05,
      "time_unit": "ns",
      "items_per_second": 2.8856176481824548e+11,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.1038720000000000e+06,
      "advised_time": 1.2902399897575378e-01,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)2; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4280899851402570e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 2.0000000000000000e+00,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "group": 1.0000000000000000e+00,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 3.5200000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 3.5200000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 2.7596800000000000e+05,
      "input_width": 2.8000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 5.6840000000000000e+03,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 1.0035200000000000e+05,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 2.8856176481824548e+11,
      "predicted_advised_flops_count": 3.5323904000000000e+07,
      "predicted_flops": 2.8856176481824548e+11,
      "predicted_flops_count": 3.5323904000000000e+07,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 1.1038720000000000e+06,
      "workspace_megabytes": 1.0527343750000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__2162950824770925913<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:1/input[1]:352/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__2162950824770925913<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:1/input[1]:352/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 718,
      "real_time": 9.7600855966083042e+05,
      "cpu_time": 9.9931302785063873e+05,
      "time_unit": "ns",
      "items_per_second": 3.6192207179284676e+10,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 3.9541145600000000e+08,
      "advised_time": 9.7779202461242676e-01,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)4; cudnnMathType_t math_type = (cudnnMathType_t)0]": 2.3237108083472476e+18,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 4.0000000000000000e+00,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "group": 1.0000000000000000e+00,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 3.5200000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 3.5200000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 2.7596800000000000e+05,
      "input_width": 2.8000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 7.1800000000000000e+02,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 1.0035200000000000e+05,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 3.6192207179284676e+10,
      "predicted_advised_flops_count": 3.5323904000000000e+07,
      "predicted_flops": 3.8787692524077252e+11,
      "predicted_flops_count": 3.7857119912991798e+08,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 3.9541145600000000e+08,
      "workspace_megabytes": 3.7709375000000000e+02
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__2162950824770925913<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:1/input[1]:352/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 5631,
      "real_time": 1.2410524028421906e+05,
      "cpu_time": 1.2942171692369352e+05,
      "time_unit": "ns",
      "items_per_second": 2.8462862582678314e+11,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 7.9558720000000000e+06,
      "advised_time": 1.3443200290203094e-01,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)5; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.6667819325789325e+18,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 5.0000000000000000e+00,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "group": 1.0000000000000000e+00,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 3.5200000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 3.5200000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 2.7596800000000000e+05,
      "input_width": 2.8000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 5.6310000000000000e+03,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 1.0035200000000000e+05,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 2.8462862582678314e+11,
      "predicted_advised_flops_count": 3.5323904000000000e+07,
      "predicted_flops": 3.0504046264519922e+12,
      "predicted_flops_count": 3.7857119912991798e+08,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 7.9558720000000000e+06,
      "workspace_megabytes": 7.5873107910156250e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__2162950824770925913<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:1/input[1]:352/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__2162950824770925913<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:1/input[1]:352/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__7106924633654065131<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:1/input[1]:512/input[2]:13/input[3]:13/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 9623,
      "real_time": 7.2784818385001214e+04,
      "cpu_time": 7.7984702587719948e+04,
      "time_unit": "ns",
      "items_per_second": 1.5216887595177881e+11,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 7.2704002261161804e-02,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4730153338016043e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "group": 1.0000000000000000e+00,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 1.3000000000000000e+01,
      "input[3]": 1.3000000000000000e+01,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 1.3000000000000000e+01,
      "input_size": 8.6528000000000000e+04,
      "input_width": 1.3000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 9.6230000000000000e+03,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 1.3000000000000000e+01,
      "output_size": 2.1632000000000000e+04,
      "output_width": 1.3000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 1.5216887595177881e+11,
      "predicted_advised_flops_count": 1.1075584000000000e+07,
      "predicted_flops": 1.5216887595177881e+11,
      "predicted_flops_count": 1.1075584000000000e+07,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__7106924633654065131<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:1/input[1]:512/input[2]:13/input[3]:13/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 9043,
      "real_time": 7.7956660172895252e+04,
      "cpu_time": 8.3315576135304800e+04,
      "time_unit": "ns",
      "items_per_second": 1.4207360827716513e+11,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.0200000000000000e+03,
      "advised_time": 8.2687996327877045e-02,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.2419525699096977e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "group": 1.0000000000000000e+00,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 1.3000000000000000e+01,
      "input[3]": 1.3000000000000000e+01,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 1.3000000000000000e+01,
      "input_size": 8.6528000000000000e+04,
      "input_width": 1.3000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 9.0430000000000000e+03,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 1.3000000000000000e+01,
      "output_size": 2.1632000000000000e+04,
      "output_width": 1.3000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 1.4207360827716513e+11,
      "predicted_advised_flops_count": 1.1075584000000000e+07,
      "predicted_flops": 1.4207360827716513e+11,
      "predicted_flops_count": 1.1075584000000000e+07,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 1.0200000000000000e+03,
      "workspace_megabytes": 9.7274780273437500e-04
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__7106924633654065131<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:1/input[1]:512/input[2]:13/input[3]:13/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 5765,
      "real_time": 1.2142283810844405e+05,
      "cpu_time": 1.2708706972928550e+05,
      "time_unit": "ns",
      "items_per_second": 9.1214998533540085e+10,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 3.4611200000000000e+05,
      "advised_time": 1.2390399724245071e-01,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)2; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4280899851402570e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 2.0000000000000000e+00,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "group": 1.0000000000000000e+00,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 1.3000000000000000e+01,
      "input[3]": 1.3000000000000000e+01,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 1.3000000000000000e+01,
      "input_size": 8.6528000000000000e+04,
      "input_width": 1.3000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 5.7650000000000000e+03,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 1.3000000000000000e+01,
      "output_size": 2.1632000000000000e+04,
      "output_width": 1.3000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 9.1214998533540085e+10,
      "predicted_advised_flops_count": 1.1075584000000000e+07,
      "predicted_flops": 9.1214998533540085e+10,
      "predicted_flops_count": 1.1075584000000000e+07,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 3.4611200000000000e+05,
      "workspace_megabytes": 3.3007812500000000e-01
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__7106924633654065131<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:1/input[1]:512/input[2]:13/input[3]:13/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__7106924633654065131<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:1/input[1]:512/input[2]:13/input[3]:13/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 1689,
      "real_time": 4.1397560675338446e+05,
      "cpu_time": 4.2156419715956389e+05,
      "time_unit": "ns",
      "items_per_second": 2.6754194738333942e+10,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.5243673600000000e+08,
      "advised_time": 4.3113601207733154e-01,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)4; cudnnMathType_t math_type = (cudnnMathType_t)0]": 2.3237108083472476e+18,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 4.0000000000000000e+00,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "group": 1.0000000000000000e+00,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 1.3000000000000000e+01,
      "input[3]": 1.3000000000000000e+01,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 1.3000000000000000e+01,
      "input_size": 8.6528000000000000e+04,
      "input_width": 1.3000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 1.6890000000000000e+03,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 1.3000000000000000e+01,
      "output_size": 2.1632000000000000e+04,
      "output_width": 1.3000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 2.6754194738333942e+10,
      "predicted_advised_flops_count": 1.1075584000000000e+07,
      "predicted_flops": 2.2669240278727371e+11,
      "predicted_flops_count": 9.3845124990244254e+07,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 1.5243673600000000e+08,
      "workspace_megabytes": 1.4537500000000000e+02
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__7106924633654065131<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:1/input[1]:512/input[2]:13/input[3]:13/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 4563,
      "real_time": 1.5369409409854966e+05,
      "cpu_time": 1.5912256344618314e+05,
      "time_unit": "ns",
      "items_per_second": 7.2062521757656235e+10,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.0044832000000000e+07,
      "advised_time": 1.6467200219631195e-01,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)5; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.6667819325789325e+18,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 5.0000000000000000e+00,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "group": 1.0000000000000000e+00,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 1.3000000000000000e+01,
      "input[3]": 1.3000000000000000e+01,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 1.3000000000000000e+01,
      "input_size": 8.6528000000000000e+04,
      "input_width": 1.3000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 4.5630000000000000e+03,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 1.3000000000000000e+01,
      "output_size": 2.1632000000000000e+04,
      "output_width": 1.3000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 7.2062521757656235e+10,
      "predicted_advised_flops_count": 1.1075584000000000e+07,
      "predicted_flops": 6.1059681922501306e+11,
      "predicted_flops_count": 9.3845124990244254e+07,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 1.0044832000000000e+07,
      "workspace_megabytes": 9.5794982910156250e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__7106924633654065131<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:1/input[1]:512/input[2]:13/input[3]:13/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__7106924633654065131<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:1/input[1]:512/input[2]:13/input[3]:13/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__1731047546501595228<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:1/input[1]:24/input[2]:13/input[3]:13/filter_count:64/filter_height:5/filter_width:5/pad_height:2/pad_width:2/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 10814,
      "real_time": 6.4674095446491265e+04,
      "cpu_time": 6.9865550490141351e+04,
      "time_unit": "ns",
      "items_per_second": 4.0137244782150731e+09,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 6.5535999834537506e-02,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4730153338016043e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 5.0000000000000000e+00,
      "filter_width": 5.0000000000000000e+00,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "group": 1.0000000000000000e+00,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 2.4000000000000000e+01,
      "input[2]": 1.3000000000000000e+01,
      "input[3]": 1.3000000000000000e+01,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 2.4000000000000000e+01,
      "input_height": 1.3000000000000000e+01,
      "input_size": 4.0560000000000000e+03,
      "input_width": 1.3000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 1.0814000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 1.3000000000000000e+01,
      "output_size": 1.0816000000000000e+04,
      "output_width": 1.3000000000000000e+01,
      "pad_height": 2.0000000000000000e+00,
      "pad_width": 2.0000000000000000e+00,
      "predicted_advised_flops": 1.0034311195537683e+11,
      "predicted_advised_flops_count": 6.4896000000000000e+06,
      "predicted_flops": 1.0034311195537683e+11,
      "predicted_flops_count": 6.4896000000000000e+06,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__1731047546501595228<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:1/input[1]:24/input[2]:13/input[3]:13/filter_count:64/filter_height:5/filter_width:5/pad_height:2/pad_width:2/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 7111,
      "real_time": 9.8519572161523509e+04,
      "cpu_time": 1.0377459133831967e+05,
      "time_unit": "ns",
      "items_per_second": 2.6348470086168289e+09,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.0200000000000000e+03,
      "advised_time": 1.0035199671983719e-01,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.2419525699096977e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 5.0000000000000000e+00,
      "filter_width": 5.0000000000000000e+00,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "group": 1.0000000000000000e+00,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 2.4000000000000000e+01,
      "input[2]": 1.3000000000000000e+01,
      "input[3]": 1.3000000000000000e+01,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 2.4000000000000000e+01,
      "input_height": 1.3000000000000000e+01,
      "input_size": 4.0560000000000000e+03,
      "input_width": 1.3000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 7.1110000000000000e+03,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 1.3000000000000000e+01,
      "output_size": 1.0816000000000000e+04,
      "output_width": 1.3000000000000000e+01,
      "pad_height": 2.0000000000000000e+00,
      "pad_width": 2.0000000000000000e+00,
      "predicted_advised_flops": 6.5871175215420723e+10,
      "predicted_advised_flops_count": 6.4896000000000000e+06,
      "predicted_flops": 6.5871175215420723e+10,
      "predicted_flops_count": 6.4896000000000000e+06,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 1.0200000000000000e+03,
      "workspace_megabytes": 9.7274780273437500e-04
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__1731047546501595228<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:1/input[1]:24/input[2]:13/input[3]:13/filter_count:64/filter_height:5/filter_width:5/pad_height:2/pad_width:2/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 7123,
      "real_time": 9.8300191623760984e+04,
      "cpu_time": 1.0366769296593912e+05,
      "time_unit": "ns",
      "items_per_second": 2.6407273039054151e+09,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 4.0560000000000000e+05,
      "advised_time": 1.0854399949312210e-01,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)2; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.4280899851402570e+19,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 2.0000000000000000e+00,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 5.0000000000000000e+00,
      "filter_width": 5.0000000000000000e+00,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "group": 1.0000000000000000e+00,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 2.4000000000000000e+01,
      "input[2]": 1.3000000000000000e+01,
      "input[3]": 1.3000000000000000e+01,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 2.4000000000000000e+01,
      "input_height": 1.3000000000000000e+01,
      "input_size": 4.0560000000000000e+03,
      "input_width": 1.3000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 7.1230000000000000e+03,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 1.3000000000000000e+01,
      "output_size": 1.0816000000000000e+04,
      "output_width": 1.3000000000000000e+01,
      "pad_height": 2.0000000000000000e+00,
      "pad_width": 2.0000000000000000e+00,
      "predicted_advised_flops": 6.6018182597635376e+10,
      "predicted_advised_flops_count": 6.4896000000000000e+06,
      "predicted_flops": 6.6018182597635376e+10,
      "predicted_flops_count": 6.4896000000000000e+06,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 4.0560000000000000e+05,
      "workspace_megabytes": 3.8681030273437500e-01
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__1731047546501595228<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:1/input[1]:24/input[2]:13/input[3]:13/filter_count:64/filter_height:5/filter_width:5/pad_height:2/pad_width:2/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__1731047546501595228<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:1/input[1]:24/input[2]:13/input[3]:13/filter_count:64/filter_height:5/filter_width:5/pad_height:2/pad_width:2/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 6734,
      "real_time": 1.0340996653612150e+05,
      "cpu_time": 1.0870383813518267e+05,
      "time_unit": "ns",
      "items_per_second": 2.5102416014159169e+09,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.3731840000000000e+07,
      "advised_time": 1.2688000500202179e-01,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)4; cudnnMathType_t math_type = (cudnnMathType_t)0]": 2.3237108083472476e+18,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 4.0000000000000000e+00,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 5.0000000000000000e+00,
      "filter_width": 5.0000000000000000e+00,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "group": 1.0000000000000000e+00,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 2.4000000000000000e+01,
      "input[2]": 1.3000000000000000e+01,
      "input[3]": 1.3000000000000000e+01,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 2.4000000000000000e+01,
      "input_height": 1.3000000000000000e+01,
      "input_size": 4.0560000000000000e+03,
      "input_width": 1.3000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 6.7340000000000000e+03,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 1.3000000000000000e+01,
      "output_size": 1.0816000000000000e+04,
      "output_width": 1.3000000000000000e+01,
      "pad_height": 2.0000000000000000e+00,
      "pad_width": 2.0000000000000000e+00,
      "predicted_advised_flops": 6.2756040035397919e+10,
      "predicted_advised_flops_count": 6.4896000000000000e+06,
      "predicted_flops": 2.2152601371977795e+10,
      "predicted_flops_count": 2.2907997665642630e+06,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 1.3731840000000000e+07,
      "workspace_megabytes": 1.3095703125000000e+01
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__1731047546501595228<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:1/input[1]:24/input[2]:13/input[3]:13/filter_count:64/filter_height:5/filter_width:5/pad_height:2/pad_width:2/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 7617,
      "real_time": 9.1922137740571765e+04,
      "cpu_time": 9.7161321256467010e+04,
      "time_unit": "ns",
      "items_per_second": 2.8239552123190794e+09,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 7.0922240000000000e+06,
      "advised_time": 9.8080001771450043e-02,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)5; cudnnMathType_t math_type = (cudnnMathType_t)0]": 1.6667819325789325e+18,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 5.0000000000000000e+00,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 5.0000000000000000e+00,
      "filter_width": 5.0000000000000000e+00,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "group": 1.0000000000000000e+00,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 2.4000000000000000e+01,
      "input[2]": 1.3000000000000000e+01,
      "input[3]": 1.3000000000000000e+01,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 2.4000000000000000e+01,
      "input_height": 1.3000000000000000e+01,
      "input_size": 4.0560000000000000e+03,
      "input_width": 1.3000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 7.6170000000000000e+03,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 1.3000000000000000e+01,
      "output_size": 1.0816000000000000e+04,
      "output_width": 1.3000000000000000e+01,
      "pad_height": 2.0000000000000000e+00,
      "pad_width": 2.0000000000000000e+00,
      "predicted_advised_flops": 7.0598880307976990e+10,
      "predicted_advised_flops_count": 6.4896000000000000e+06,
      "predicted_flops": 2.4921088900581242e+10,
      "predicted_flops_count": 2.2907997665642630e+06,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 7.0922240000000000e+06,
      "workspace_megabytes": 6.7636718750000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__1731047546501595228<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:1/input[1]:24/input[2]:13/input[3]:13/filter_count:64/filter_height:5/filter_width:5/pad_height:2/pad_width:2/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__1731047546501595228<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:1/input[1]:24/input[2]:13/input[3]:13/filter_count:64/filter_height:5/filter_width:5/pad_height:2/pad_width:2/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 10831,
      "real_time": 6.4719034997369861e+04,
      "cpu_time": 6.9918528207243522e+04,
      "time_unit": "ns",
      "items_per_second": 4.0109374314766798e+09,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 4.8455680000000000e+06,
      "advised_time": 7.4752002954483032e-02,
      "batch_size": 1.2800000000000000e+02,
      "benchmark_file:/home/abduld/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 6.3416289576367145e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = float; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)7; cudnnMathType_t math_type = (cudnnMathType_t)0]": 8.2538945752816425e+18,
      "compute_capability:6.1": 4.4519655652347223e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "convolution_algorithm": 7.0000000000000000e+00,
      "cublas_version:10.0": 9.6389120198504717e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.10": 3.1909591731558548e+18,
      "cudnn_version:7.3": 3.8315606316223933e+18,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 5.0000000000000000e+00,
      "filter_width": 5.0000000000000000e+00,
      "gpu_name:TITAN Xp": 7.2235257218963241e+18,
      "group": 1.0000000000000000e+00,
      "host_name:whatever": 1.2416275329644214e+19,
      "input[0]": 1.0000000000000000e+00,
      "input[1]": 2.4000000000000000e+01,
      "input[2]": 1.3000000000000000e+01,
      "input[3]": 1.3000000000000000e+01,
      "input_batch_size": 1.0000000000000000e+00,
      "input_channels": 2.4000000000000000e+01,
      "input_height": 1.3000000000000000e+01,
      "input_size": 4.0560000000000000e+03,
      "input_width": 1.3000000000000000e+01,
      "math_type": 0.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 1.0831000000000000e+04,
      "output_batch_size": 1.0000000000000000e+00,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 1.3000000000000000e+01,
      "output_size": 1.0816000000000000e+04,
      "output_width": 1.3000000000000000e+01,
      "pad_height": 2.0000000000000000e+00,
      "pad_width": 2.0000000000000000e+00,
      "predicted_advised_flops": 1.0027343578691699e+11,
      "predicted_advised_flops_count": 6.4896000000000000e+06,
      "predicted_flops": -1.5451404676238442e+04,
      "predicted_flops_count": -1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "workspace_bytes": 4.8455680000000000e+06,
      "workspace_megabytes": 4.6210937500000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__13797260650345318816<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:64/input[2]:400/input[3]:400/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to synchronize kernel because of an illegal memory access was encountered",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__13797260650345318816<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:64/input[2]:400/input[3]:400/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__13797260650345318816<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:64/input[2]:400/input[3]:400/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__13797260650345318816<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:64/input[2]:400/input[3]:400/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__13797260650345318816<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:64/input[2]:400/input[3]:400/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__13797260650345318816<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:64/input[2]:400/input[3]:400/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__13797260650345318816<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:64/input[2]:400/input[3]:400/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__13797260650345318816<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:64/input[2]:400/input[3]:400/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__7091747671013340097<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:528/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__7091747671013340097<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:528/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__7091747671013340097<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:528/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__7091747671013340097<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:528/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__7091747671013340097<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:528/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__7091747671013340097<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:528/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__7091747671013340097<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:528/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__7091747671013340097<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:528/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__1768020777244711864<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:1/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__1768020777244711864<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:1/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__1768020777244711864<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:1/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__1768020777244711864<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:1/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__1768020777244711864<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:1/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__1768020777244711864<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:1/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__1768020777244711864<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:1/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__1768020777244711864<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:1/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__9409420012661581938<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:1/input[1]:576/input[2]:7/input[3]:7/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__9409420012661581938<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:1/input[1]:576/input[2]:7/input[3]:7/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__9409420012661581938<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:1/input[1]:576/input[2]:7/input[3]:7/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__9409420012661581938<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:1/input[1]:576/input[2]:7/input[3]:7/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__9409420012661581938<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:1/input[1]:576/input[2]:7/input[3]:7/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__9409420012661581938<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:1/input[1]:576/input[2]:7/input[3]:7/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__9409420012661581938<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:1/input[1]:576/input[2]:7/input[3]:7/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__9409420012661581938<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:1/input[1]:576/input[2]:7/input[3]:7/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__14680996522150098724<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:1/input[1]:144/input[2]:13/input[3]:13/filter_count:288/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__14680996522150098724<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:1/input[1]:144/input[2]:13/input[3]:13/filter_count:288/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__14680996522150098724<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:1/input[1]:144/input[2]:13/input[3]:13/filter_count:288/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__14680996522150098724<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:1/input[1]:144/input[2]:13/input[3]:13/filter_count:288/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__14680996522150098724<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:1/input[1]:144/input[2]:13/input[3]:13/filter_count:288/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__14680996522150098724<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:1/input[1]:144/input[2]:13/input[3]:13/filter_count:288/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__14680996522150098724<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:1/input[1]:144/input[2]:13/input[3]:13/filter_count:288/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__14680996522150098724<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:1/input[1]:144/input[2]:13/input[3]:13/filter_count:288/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__12193271206321775474<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:1/input[1]:448/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__12193271206321775474<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:1/input[1]:448/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__12193271206321775474<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:1/input[1]:448/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__12193271206321775474<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:1/input[1]:448/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__12193271206321775474<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:1/input[1]:448/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__12193271206321775474<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:1/input[1]:448/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__12193271206321775474<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:1/input[1]:448/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__12193271206321775474<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:1/input[1]:448/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__5930736360517590879<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:1/input[1]:32/input[2]:13/input[3]:13/filter_count:64/filter_height:5/filter_width:5/pad_height:2/pad_width:2/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__5930736360517590879<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:1/input[1]:32/input[2]:13/input[3]:13/filter_count:64/filter_height:5/filter_width:5/pad_height:2/pad_width:2/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__5930736360517590879<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:1/input[1]:32/input[2]:13/input[3]:13/filter_count:64/filter_height:5/filter_width:5/pad_height:2/pad_width:2/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__5930736360517590879<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:1/input[1]:32/input[2]:13/input[3]:13/filter_count:64/filter_height:5/filter_width:5/pad_height:2/pad_width:2/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__5930736360517590879<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:1/input[1]:32/input[2]:13/input[3]:13/filter_count:64/filter_height:5/filter_width:5/pad_height:2/pad_width:2/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__5930736360517590879<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:1/input[1]:32/input[2]:13/input[3]:13/filter_count:64/filter_height:5/filter_width:5/pad_height:2/pad_width:2/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__5930736360517590879<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:1/input[1]:32/input[2]:13/input[3]:13/filter_count:64/filter_height:5/filter_width:5/pad_height:2/pad_width:2/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__5930736360517590879<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:1/input[1]:32/input[2]:13/input[3]:13/filter_count:64/filter_height:5/filter_width:5/pad_height:2/pad_width:2/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__17796363000139811937<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:128/input[2]:199/input[3]:199/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__17796363000139811937<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:128/input[2]:199/input[3]:199/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__17796363000139811937<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:128/input[2]:199/input[3]:199/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__17796363000139811937<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:128/input[2]:199/input[3]:199/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__17796363000139811937<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:128/input[2]:199/input[3]:199/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__17796363000139811937<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:128/input[2]:199/input[3]:199/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__17796363000139811937<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:128/input[2]:199/input[3]:199/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__17796363000139811937<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:128/input[2]:199/input[3]:199/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__12125566219013605913<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:384/input[2]:28/input[3]:28/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__12125566219013605913<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:384/input[2]:28/input[3]:28/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__12125566219013605913<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:384/input[2]:28/input[3]:28/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__12125566219013605913<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:384/input[2]:28/input[3]:28/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__12125566219013605913<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:384/input[2]:28/input[3]:28/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__12125566219013605913<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:384/input[2]:28/input[3]:28/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__12125566219013605913<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:384/input[2]:28/input[3]:28/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__12125566219013605913<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:384/input[2]:28/input[3]:28/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__12640678818964938623<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:1/input[1]:704/input[2]:7/input[3]:7/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__12640678818964938623<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:1/input[1]:704/input[2]:7/input[3]:7/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__12640678818964938623<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:1/input[1]:704/input[2]:7/input[3]:7/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__12640678818964938623<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:1/input[1]:704/input[2]:7/input[3]:7/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__12640678818964938623<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:1/input[1]:704/input[2]:7/input[3]:7/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__12640678818964938623<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:1/input[1]:704/input[2]:7/input[3]:7/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__12640678818964938623<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:1/input[1]:704/input[2]:7/input[3]:7/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__12640678818964938623<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:1/input[1]:704/input[2]:7/input[3]:7/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__13485303612506040645<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:64/input[2]:199/input[3]:199/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__13485303612506040645<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:64/input[2]:199/input[3]:199/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__13485303612506040645<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:64/input[2]:199/input[3]:199/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__13485303612506040645<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:64/input[2]:199/input[3]:199/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__13485303612506040645<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:64/input[2]:199/input[3]:199/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__13485303612506040645<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:64/input[2]:199/input[3]:199/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__13485303612506040645<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:64/input[2]:199/input[3]:199/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__13485303612506040645<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:64/input[2]:199/input[3]:199/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__9085028110051225048<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:256/input[2]:199/input[3]:199/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__9085028110051225048<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:256/input[2]:199/input[3]:199/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__9085028110051225048<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:256/input[2]:199/input[3]:199/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__9085028110051225048<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:256/input[2]:199/input[3]:199/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__9085028110051225048<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:256/input[2]:199/input[3]:199/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__9085028110051225048<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:256/input[2]:199/input[3]:199/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__9085028110051225048<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:256/input[2]:199/input[3]:199/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__9085028110051225048<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:256/input[2]:199/input[3]:199/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__11997250825768733865<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:1/input[1]:992/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__11997250825768733865<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:1/input[1]:992/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__11997250825768733865<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:1/input[1]:992/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__11997250825768733865<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:1/input[1]:992/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__11997250825768733865<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:1/input[1]:992/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__11997250825768733865<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:1/input[1]:992/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__11997250825768733865<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:1/input[1]:992/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__11997250825768733865<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:1/input[1]:992/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__9507450290912991006<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:1/input[1]:640/input[2]:7/input[3]:7/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__9507450290912991006<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:1/input[1]:640/input[2]:7/input[3]:7/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__9507450290912991006<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:1/input[1]:640/input[2]:7/input[3]:7/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__9507450290912991006<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:1/input[1]:640/input[2]:7/input[3]:7/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__9507450290912991006<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:1/input[1]:640/input[2]:7/input[3]:7/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__9507450290912991006<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:1/input[1]:640/input[2]:7/input[3]:7/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__9507450290912991006<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:1/input[1]:640/input[2]:7/input[3]:7/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__9507450290912991006<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:1/input[1]:640/input[2]:7/input[3]:7/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__850383584850063067<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:96/input[2]:14/input[3]:14/filter_count:576/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__850383584850063067<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:96/input[2]:14/input[3]:14/filter_count:576/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__850383584850063067<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:96/input[2]:14/input[3]:14/filter_count:576/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__850383584850063067<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:96/input[2]:14/input[3]:14/filter_count:576/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__850383584850063067<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:96/input[2]:14/input[3]:14/filter_count:576/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__850383584850063067<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:96/input[2]:14/input[3]:14/filter_count:576/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__850383584850063067<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:96/input[2]:14/input[3]:14/filter_count:576/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__850383584850063067<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:96/input[2]:14/input[3]:14/filter_count:576/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__17163396260421646650<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:832/input[2]:7/input[3]:7/filter_count:48/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__17163396260421646650<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:832/input[2]:7/input[3]:7/filter_count:48/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__17163396260421646650<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:832/input[2]:7/input[3]:7/filter_count:48/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__17163396260421646650<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:832/input[2]:7/input[3]:7/filter_count:48/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__17163396260421646650<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:832/input[2]:7/input[3]:7/filter_count:48/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__17163396260421646650<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:832/input[2]:7/input[3]:7/filter_count:48/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__17163396260421646650<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:832/input[2]:7/input[3]:7/filter_count:48/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__17163396260421646650<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:832/input[2]:7/input[3]:7/filter_count:48/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__11433205015984938990<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:1/input[1]:128/input[2]:7/input[3]:7/filter_count:32/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__11433205015984938990<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:1/input[1]:128/input[2]:7/input[3]:7/filter_count:32/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__11433205015984938990<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:1/input[1]:128/input[2]:7/input[3]:7/filter_count:32/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__11433205015984938990<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:1/input[1]:128/input[2]:7/input[3]:7/filter_count:32/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__11433205015984938990<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:1/input[1]:128/input[2]:7/input[3]:7/filter_count:32/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__11433205015984938990<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:1/input[1]:128/input[2]:7/input[3]:7/filter_count:32/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__11433205015984938990<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:1/input[1]:128/input[2]:7/input[3]:7/filter_count:32/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__11433205015984938990<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:1/input[1]:128/input[2]:7/input[3]:7/filter_count:32/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__691194427455094244<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:256/input[2]:100/input[3]:100/filter_count:256/filter_height:3/filter_width:3/pad_height:9/pad_width:9/stride_height:1/stride_width:1/dilation_height:9/dilation_width:9/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__691194427455094244<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:256/input[2]:100/input[3]:100/filter_count:256/filter_height:3/filter_width:3/pad_height:9/pad_width:9/stride_height:1/stride_width:1/dilation_height:9/dilation_width:9/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__691194427455094244<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:256/input[2]:100/input[3]:100/filter_count:256/filter_height:3/filter_width:3/pad_height:9/pad_width:9/stride_height:1/stride_width:1/dilation_height:9/dilation_width:9/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__691194427455094244<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:256/input[2]:100/input[3]:100/filter_count:256/filter_height:3/filter_width:3/pad_height:9/pad_width:9/stride_height:1/stride_width:1/dilation_height:9/dilation_width:9/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__691194427455094244<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:256/input[2]:100/input[3]:100/filter_count:256/filter_height:3/filter_width:3/pad_height:9/pad_width:9/stride_height:1/stride_width:1/dilation_height:9/dilation_width:9/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__691194427455094244<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:256/input[2]:100/input[3]:100/filter_count:256/filter_height:3/filter_width:3/pad_height:9/pad_width:9/stride_height:1/stride_width:1/dilation_height:9/dilation_width:9/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__691194427455094244<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:256/input[2]:100/input[3]:100/filter_count:256/filter_height:3/filter_width:3/pad_height:9/pad_width:9/stride_height:1/stride_width:1/dilation_height:9/dilation_width:9/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__691194427455094244<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:256/input[2]:100/input[3]:100/filter_count:256/filter_height:3/filter_width:3/pad_height:9/pad_width:9/stride_height:1/stride_width:1/dilation_height:9/dilation_width:9/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__912020504027219009<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:1/input[1]:960/input[2]:7/input[3]:7/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__912020504027219009<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:1/input[1]:960/input[2]:7/input[3]:7/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__912020504027219009<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:1/input[1]:960/input[2]:7/input[3]:7/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__912020504027219009<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:1/input[1]:960/input[2]:7/input[3]:7/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__912020504027219009<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:1/input[1]:960/input[2]:7/input[3]:7/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__912020504027219009<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:1/input[1]:960/input[2]:7/input[3]:7/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__912020504027219009<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:1/input[1]:960/input[2]:7/input[3]:7/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__912020504027219009<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:1/input[1]:960/input[2]:7/input[3]:7/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__5477693792388512456<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:96/input[2]:14/input[3]:14/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__5477693792388512456<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:96/input[2]:14/input[3]:14/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__5477693792388512456<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:96/input[2]:14/input[3]:14/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__5477693792388512456<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:96/input[2]:14/input[3]:14/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__5477693792388512456<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:96/input[2]:14/input[3]:14/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__5477693792388512456<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:96/input[2]:14/input[3]:14/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__5477693792388512456<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:96/input[2]:14/input[3]:14/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__5477693792388512456<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:96/input[2]:14/input[3]:14/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__6997417940924550871<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:192/input[2]:28/input[3]:28/filter_count:32/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__6997417940924550871<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:192/input[2]:28/input[3]:28/filter_count:32/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__6997417940924550871<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:192/input[2]:28/input[3]:28/filter_count:32/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__6997417940924550871<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:192/input[2]:28/input[3]:28/filter_count:32/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__6997417940924550871<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:192/input[2]:28/input[3]:28/filter_count:32/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__6997417940924550871<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:192/input[2]:28/input[3]:28/filter_count:32/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__6997417940924550871<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:192/input[2]:28/input[3]:28/filter_count:32/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__6997417940924550871<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:192/input[2]:28/input[3]:28/filter_count:32/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__2513762024360639810<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:128/input[2]:100/input[3]:100/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__2513762024360639810<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:128/input[2]:100/input[3]:100/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__2513762024360639810<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:128/input[2]:100/input[3]:100/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__2513762024360639810<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:128/input[2]:100/input[3]:100/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__2513762024360639810<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:128/input[2]:100/input[3]:100/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__2513762024360639810<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:128/input[2]:100/input[3]:100/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__2513762024360639810<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:128/input[2]:100/input[3]:100/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__2513762024360639810<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:128/input[2]:100/input[3]:100/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__1242877044803516064<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:128/input[2]:14/input[3]:14/filter_count:192/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__1242877044803516064<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:128/input[2]:14/input[3]:14/filter_count:192/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__1242877044803516064<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:128/input[2]:14/input[3]:14/filter_count:192/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__1242877044803516064<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:128/input[2]:14/input[3]:14/filter_count:192/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__1242877044803516064<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:128/input[2]:14/input[3]:14/filter_count:192/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__1242877044803516064<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:128/input[2]:14/input[3]:14/filter_count:192/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__1242877044803516064<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:128/input[2]:14/input[3]:14/filter_count:192/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__1242877044803516064<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:128/input[2]:14/input[3]:14/filter_count:192/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__5678575516939244325<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:1/input[1]:160/input[2]:6/input[3]:6/filter_count:320/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__5678575516939244325<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:1/input[1]:160/input[2]:6/input[3]:6/filter_count:320/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__5678575516939244325<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:1/input[1]:160/input[2]:6/input[3]:6/filter_count:320/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__5678575516939244325<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:1/input[1]:160/input[2]:6/input[3]:6/filter_count:320/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__5678575516939244325<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:1/input[1]:160/input[2]:6/input[3]:6/filter_count:320/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__5678575516939244325<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:1/input[1]:160/input[2]:6/input[3]:6/filter_count:320/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__5678575516939244325<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:1/input[1]:160/input[2]:6/input[3]:6/filter_count:320/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__5678575516939244325<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:1/input[1]:160/input[2]:6/input[3]:6/filter_count:320/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__11078936420021101015<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:1/input[1]:864/input[2]:7/input[3]:7/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__11078936420021101015<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:1/input[1]:864/input[2]:7/input[3]:7/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__11078936420021101015<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:1/input[1]:864/input[2]:7/input[3]:7/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__11078936420021101015<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:1/input[1]:864/input[2]:7/input[3]:7/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__11078936420021101015<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:1/input[1]:864/input[2]:7/input[3]:7/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__11078936420021101015<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:1/input[1]:864/input[2]:7/input[3]:7/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__11078936420021101015<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:1/input[1]:864/input[2]:7/input[3]:7/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__11078936420021101015<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:1/input[1]:864/input[2]:7/input[3]:7/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__12750890609632099864<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:192/input[2]:14/input[3]:14/filter_count:192/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__12750890609632099864<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:192/input[2]:14/input[3]:14/filter_count:192/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__12750890609632099864<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:192/input[2]:14/input[3]:14/filter_count:192/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__12750890609632099864<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:192/input[2]:14/input[3]:14/filter_count:192/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__12750890609632099864<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:192/input[2]:14/input[3]:14/filter_count:192/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__12750890609632099864<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:192/input[2]:14/input[3]:14/filter_count:192/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__12750890609632099864<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:192/input[2]:14/input[3]:14/filter_count:192/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__12750890609632099864<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:192/input[2]:14/input[3]:14/filter_count:192/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__10093872770875139570<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:576/input[2]:14/input[3]:14/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__10093872770875139570<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:576/input[2]:14/input[3]:14/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__10093872770875139570<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:576/input[2]:14/input[3]:14/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__10093872770875139570<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:576/input[2]:14/input[3]:14/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__10093872770875139570<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:576/input[2]:14/input[3]:14/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__10093872770875139570<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:576/input[2]:14/input[3]:14/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__10093872770875139570<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:576/input[2]:14/input[3]:14/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__10093872770875139570<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:576/input[2]:14/input[3]:14/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__3126585237483672815<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:576/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__3126585237483672815<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:576/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__3126585237483672815<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:576/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__3126585237483672815<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:576/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__3126585237483672815<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:576/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__3126585237483672815<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:576/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__3126585237483672815<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:576/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__3126585237483672815<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:576/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__1268296387196985775<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:576/input[2]:14/input[3]:14/filter_count:192/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__1268296387196985775<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:576/input[2]:14/input[3]:14/filter_count:192/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__1268296387196985775<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:576/input[2]:14/input[3]:14/filter_count:192/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__1268296387196985775<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:576/input[2]:14/input[3]:14/filter_count:192/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__1268296387196985775<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:576/input[2]:14/input[3]:14/filter_count:192/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__1268296387196985775<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:576/input[2]:14/input[3]:14/filter_count:192/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__1268296387196985775<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:576/input[2]:14/input[3]:14/filter_count:192/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__1268296387196985775<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:576/input[2]:14/input[3]:14/filter_count:192/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__18276339072188303294<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:2048/input[2]:100/input[3]:100/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD failed to cudnnSetTensor4dDescriptor",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__18276339072188303294<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:2048/input[2]:100/input[3]:100/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD failed to cudnnSetTensor4dDescriptor",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__18276339072188303294<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:2048/input[2]:100/input[3]:100/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD failed to cudnnSetTensor4dDescriptor",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__18276339072188303294<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:2048/input[2]:100/input[3]:100/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD failed to cudnnSetTensor4dDescriptor",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__18276339072188303294<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:2048/input[2]:100/input[3]:100/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD failed to cudnnSetTensor4dDescriptor",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__18276339072188303294<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:2048/input[2]:100/input[3]:100/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD failed to cudnnSetTensor4dDescriptor",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__18276339072188303294<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:2048/input[2]:100/input[3]:100/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD failed to cudnnSetTensor4dDescriptor",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__18276339072188303294<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:2048/input[2]:100/input[3]:100/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD failed to cudnnSetTensor4dDescriptor",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__10736650755504955266<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:256/input[2]:56/input[3]:56/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__10736650755504955266<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:256/input[2]:56/input[3]:56/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__10736650755504955266<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:256/input[2]:56/input[3]:56/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__10736650755504955266<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:256/input[2]:56/input[3]:56/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__10736650755504955266<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:256/input[2]:56/input[3]:56/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__10736650755504955266<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:256/input[2]:56/input[3]:56/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__10736650755504955266<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:256/input[2]:56/input[3]:56/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__10736650755504955266<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:256/input[2]:56/input[3]:56/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__3646521398858508652<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:512/input[2]:14/input[3]:14/filter_count:160/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__3646521398858508652<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:512/input[2]:14/input[3]:14/filter_count:160/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__3646521398858508652<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:512/input[2]:14/input[3]:14/filter_count:160/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__3646521398858508652<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:512/input[2]:14/input[3]:14/filter_count:160/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__3646521398858508652<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:512/input[2]:14/input[3]:14/filter_count:160/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__3646521398858508652<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:512/input[2]:14/input[3]:14/filter_count:160/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__3646521398858508652<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:512/input[2]:14/input[3]:14/filter_count:160/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__3646521398858508652<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:512/input[2]:14/input[3]:14/filter_count:160/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__9592262995097671660<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:1/input[1]:112/input[2]:56/input[3]:56/filter_count:112/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:112/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__9592262995097671660<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:1/input[1]:112/input[2]:56/input[3]:56/filter_count:112/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:112/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__9592262995097671660<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:1/input[1]:112/input[2]:56/input[3]:56/filter_count:112/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:112/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__9592262995097671660<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:1/input[1]:112/input[2]:56/input[3]:56/filter_count:112/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:112/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__9592262995097671660<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:1/input[1]:112/input[2]:56/input[3]:56/filter_count:112/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:112/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__9592262995097671660<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:1/input[1]:112/input[2]:56/input[3]:56/filter_count:112/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:112/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__9592262995097671660<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:1/input[1]:112/input[2]:56/input[3]:56/filter_count:112/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:112/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__9592262995097671660<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:1/input[1]:112/input[2]:56/input[3]:56/filter_count:112/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:112/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__10781708914388989157<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:3/input[2]:224/input[3]:224/filter_count:96/filter_height:7/filter_width:7/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__10781708914388989157<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:3/input[2]:224/input[3]:224/filter_count:96/filter_height:7/filter_width:7/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__10781708914388989157<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:3/input[2]:224/input[3]:224/filter_count:96/filter_height:7/filter_width:7/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__10781708914388989157<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:3/input[2]:224/input[3]:224/filter_count:96/filter_height:7/filter_width:7/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__10781708914388989157<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:3/input[2]:224/input[3]:224/filter_count:96/filter_height:7/filter_width:7/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__10781708914388989157<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:3/input[2]:224/input[3]:224/filter_count:96/filter_height:7/filter_width:7/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__10781708914388989157<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:3/input[2]:224/input[3]:224/filter_count:96/filter_height:7/filter_width:7/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__10781708914388989157<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:3/input[2]:224/input[3]:224/filter_count:96/filter_height:7/filter_width:7/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__17876446781505989659<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:2048/input[2]:100/input[3]:100/filter_count:304/filter_height:3/filter_width:3/pad_height:18/pad_width:18/stride_height:1/stride_width:1/dilation_height:18/dilation_width:18/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD failed to cudnnSetTensor4dDescriptor",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__17876446781505989659<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:2048/input[2]:100/input[3]:100/filter_count:304/filter_height:3/filter_width:3/pad_height:18/pad_width:18/stride_height:1/stride_width:1/dilation_height:18/dilation_width:18/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD failed to cudnnSetTensor4dDescriptor",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__17876446781505989659<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:2048/input[2]:100/input[3]:100/filter_count:304/filter_height:3/filter_width:3/pad_height:18/pad_width:18/stride_height:1/stride_width:1/dilation_height:18/dilation_width:18/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD failed to cudnnSetTensor4dDescriptor",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__17876446781505989659<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:2048/input[2]:100/input[3]:100/filter_count:304/filter_height:3/filter_width:3/pad_height:18/pad_width:18/stride_height:1/stride_width:1/dilation_height:18/dilation_width:18/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD failed to cudnnSetTensor4dDescriptor",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__17876446781505989659<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:2048/input[2]:100/input[3]:100/filter_count:304/filter_height:3/filter_width:3/pad_height:18/pad_width:18/stride_height:1/stride_width:1/dilation_height:18/dilation_width:18/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD failed to cudnnSetTensor4dDescriptor",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__17876446781505989659<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:2048/input[2]:100/input[3]:100/filter_count:304/filter_height:3/filter_width:3/pad_height:18/pad_width:18/stride_height:1/stride_width:1/dilation_height:18/dilation_width:18/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD failed to cudnnSetTensor4dDescriptor",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__17876446781505989659<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:2048/input[2]:100/input[3]:100/filter_count:304/filter_height:3/filter_width:3/pad_height:18/pad_width:18/stride_height:1/stride_width:1/dilation_height:18/dilation_width:18/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD failed to cudnnSetTensor4dDescriptor",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__17876446781505989659<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:2048/input[2]:100/input[3]:100/filter_count:304/filter_height:3/filter_width:3/pad_height:18/pad_width:18/stride_height:1/stride_width:1/dilation_height:18/dilation_width:18/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD failed to cudnnSetTensor4dDescriptor",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__2002090538345329140<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__2002090538345329140<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__2002090538345329140<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__2002090538345329140<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__2002090538345329140<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__2002090538345329140<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__2002090538345329140<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__2002090538345329140<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__2307756902124189084<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:128/input[2]:28/input[3]:28/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__2307756902124189084<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:128/input[2]:28/input[3]:28/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__2307756902124189084<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:128/input[2]:28/input[3]:28/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__2307756902124189084<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:128/input[2]:28/input[3]:28/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__2307756902124189084<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:128/input[2]:28/input[3]:28/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__2307756902124189084<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:128/input[2]:28/input[3]:28/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__2307756902124189084<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:128/input[2]:28/input[3]:28/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__2307756902124189084<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:128/input[2]:28/input[3]:28/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__13695261584197046314<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:32/input[2]:104/input[3]:104/filter_count:64/filter_height:3/filter_width:3/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__13695261584197046314<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:32/input[2]:104/input[3]:104/filter_count:64/filter_height:3/filter_width:3/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__13695261584197046314<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:32/input[2]:104/input[3]:104/filter_count:64/filter_height:3/filter_width:3/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__13695261584197046314<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:32/input[2]:104/input[3]:104/filter_count:64/filter_height:3/filter_width:3/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__13695261584197046314<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:32/input[2]:104/input[3]:104/filter_count:64/filter_height:3/filter_width:3/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__13695261584197046314<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:32/input[2]:104/input[3]:104/filter_count:64/filter_height:3/filter_width:3/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__13695261584197046314<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:32/input[2]:104/input[3]:104/filter_count:64/filter_height:3/filter_width:3/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__13695261584197046314<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:32/input[2]:104/input[3]:104/filter_count:64/filter_height:3/filter_width:3/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__12715654751713490101<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:64/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__12715654751713490101<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:64/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__12715654751713490101<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:64/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__12715654751713490101<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:64/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__12715654751713490101<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:64/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__12715654751713490101<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:64/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__12715654751713490101<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:64/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__12715654751713490101<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:64/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__13208991728305251644<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:64/input[2]:224/input[3]:224/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__13208991728305251644<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:64/input[2]:224/input[3]:224/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__13208991728305251644<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:64/input[2]:224/input[3]:224/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__13208991728305251644<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:64/input[2]:224/input[3]:224/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__13208991728305251644<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:64/input[2]:224/input[3]:224/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__13208991728305251644<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:64/input[2]:224/input[3]:224/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__13208991728305251644<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:64/input[2]:224/input[3]:224/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__13208991728305251644<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:64/input[2]:224/input[3]:224/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__10391216152337922405<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:512/input[2]:100/input[3]:100/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__10391216152337922405<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:512/input[2]:100/input[3]:100/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__10391216152337922405<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:512/input[2]:100/input[3]:100/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__10391216152337922405<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:512/input[2]:100/input[3]:100/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__10391216152337922405<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:512/input[2]:100/input[3]:100/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__10391216152337922405<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:512/input[2]:100/input[3]:100/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__10391216152337922405<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:512/input[2]:100/input[3]:100/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__10391216152337922405<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:512/input[2]:100/input[3]:100/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__12266371639433535290<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__12266371639433535290<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__12266371639433535290<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__12266371639433535290<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__12266371639433535290<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__12266371639433535290<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__12266371639433535290<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__12266371639433535290<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__13071701914491934609<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:64/input[2]:56/input[3]:56/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__13071701914491934609<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:64/input[2]:56/input[3]:56/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__13071701914491934609<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:64/input[2]:56/input[3]:56/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__13071701914491934609<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:64/input[2]:56/input[3]:56/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__13071701914491934609<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:64/input[2]:56/input[3]:56/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__13071701914491934609<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:64/input[2]:56/input[3]:56/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__13071701914491934609<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:64/input[2]:56/input[3]:56/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__13071701914491934609<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:64/input[2]:56/input[3]:56/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__9874246820725629768<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:256/input[2]:56/input[3]:56/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__9874246820725629768<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:256/input[2]:56/input[3]:56/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__9874246820725629768<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:256/input[2]:56/input[3]:56/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__9874246820725629768<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:256/input[2]:56/input[3]:56/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__9874246820725629768<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:256/input[2]:56/input[3]:56/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__9874246820725629768<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:256/input[2]:56/input[3]:56/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__9874246820725629768<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:256/input[2]:56/input[3]:56/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__9874246820725629768<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:256/input[2]:56/input[3]:56/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__14618399664044940892<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:64/input[2]:112/input[3]:112/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__14618399664044940892<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:64/input[2]:112/input[3]:112/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__14618399664044940892<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:64/input[2]:112/input[3]:112/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__14618399664044940892<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:64/input[2]:112/input[3]:112/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__14618399664044940892<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:64/input[2]:112/input[3]:112/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__14618399664044940892<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:64/input[2]:112/input[3]:112/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__14618399664044940892<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:64/input[2]:112/input[3]:112/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_FLOAT32__BatchSize_128__14618399664044940892<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:64/input[2]:112/input[3]:112/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__11927182451544443047<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:3/input[2]:224/input[3]:224/filter_count:24/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__11927182451544443047<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:3/input[2]:224/input[3]:224/filter_count:24/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__11927182451544443047<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:3/input[2]:224/input[3]:224/filter_count:24/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__11927182451544443047<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:3/input[2]:224/input[3]:224/filter_count:24/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__11927182451544443047<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:3/input[2]:224/input[3]:224/filter_count:24/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__11927182451544443047<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:3/input[2]:224/input[3]:224/filter_count:24/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__11927182451544443047<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:3/input[2]:224/input[3]:224/filter_count:24/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__11927182451544443047<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:3/input[2]:224/input[3]:224/filter_count:24/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__5952850647978343049<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:480/input[2]:14/input[3]:14/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__5952850647978343049<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:480/input[2]:14/input[3]:14/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__5952850647978343049<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:480/input[2]:14/input[3]:14/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__5952850647978343049<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:480/input[2]:14/input[3]:14/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__5952850647978343049<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:480/input[2]:14/input[3]:14/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__5952850647978343049<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:480/input[2]:14/input[3]:14/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__5952850647978343049<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:480/input[2]:14/input[3]:14/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__5952850647978343049<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:480/input[2]:14/input[3]:14/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__14827840326238670748<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:1/input[1]:32/input[2]:6/input[3]:6/filter_count:128/filter_height:5/filter_width:5/pad_height:2/pad_width:2/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__14827840326238670748<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:1/input[1]:32/input[2]:6/input[3]:6/filter_count:128/filter_height:5/filter_width:5/pad_height:2/pad_width:2/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__14827840326238670748<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:1/input[1]:32/input[2]:6/input[3]:6/filter_count:128/filter_height:5/filter_width:5/pad_height:2/pad_width:2/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__14827840326238670748<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:1/input[1]:32/input[2]:6/input[3]:6/filter_count:128/filter_height:5/filter_width:5/pad_height:2/pad_width:2/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__14827840326238670748<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:1/input[1]:32/input[2]:6/input[3]:6/filter_count:128/filter_height:5/filter_width:5/pad_height:2/pad_width:2/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__14827840326238670748<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:1/input[1]:32/input[2]:6/input[3]:6/filter_count:128/filter_height:5/filter_width:5/pad_height:2/pad_width:2/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__14827840326238670748<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:1/input[1]:32/input[2]:6/input[3]:6/filter_count:128/filter_height:5/filter_width:5/pad_height:2/pad_width:2/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__14827840326238670748<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:1/input[1]:32/input[2]:6/input[3]:6/filter_count:128/filter_height:5/filter_width:5/pad_height:2/pad_width:2/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__17087991756524041832<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:512/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__17087991756524041832<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:512/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__17087991756524041832<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:512/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__17087991756524041832<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:512/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__17087991756524041832<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:512/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__17087991756524041832<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:512/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__17087991756524041832<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:512/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__17087991756524041832<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:512/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__7393018973176244761<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:32/input[2]:27/input[3]:27/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__7393018973176244761<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:32/input[2]:27/input[3]:27/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__7393018973176244761<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:32/input[2]:27/input[3]:27/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__7393018973176244761<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:32/input[2]:27/input[3]:27/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__7393018973176244761<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:32/input[2]:27/input[3]:27/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__7393018973176244761<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:32/input[2]:27/input[3]:27/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__7393018973176244761<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:32/input[2]:27/input[3]:27/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__7393018973176244761<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:32/input[2]:27/input[3]:27/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__11157633841959188857<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:32/input[2]:27/input[3]:27/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__11157633841959188857<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:32/input[2]:27/input[3]:27/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__11157633841959188857<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:32/input[2]:27/input[3]:27/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__11157633841959188857<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:32/input[2]:27/input[3]:27/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__11157633841959188857<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:32/input[2]:27/input[3]:27/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__11157633841959188857<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:32/input[2]:27/input[3]:27/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__11157633841959188857<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:32/input[2]:27/input[3]:27/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__11157633841959188857<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:32/input[2]:27/input[3]:27/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__1324504187228283026<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:1/input[1]:64/input[2]:55/input[3]:55/filter_count:192/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__1324504187228283026<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:1/input[1]:64/input[2]:55/input[3]:55/filter_count:192/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__1324504187228283026<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:1/input[1]:64/input[2]:55/input[3]:55/filter_count:192/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__1324504187228283026<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:1/input[1]:64/input[2]:55/input[3]:55/filter_count:192/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__1324504187228283026<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:1/input[1]:64/input[2]:55/input[3]:55/filter_count:192/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__1324504187228283026<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:1/input[1]:64/input[2]:55/input[3]:55/filter_count:192/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__1324504187228283026<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:1/input[1]:64/input[2]:55/input[3]:55/filter_count:192/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__1324504187228283026<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:1/input[1]:64/input[2]:55/input[3]:55/filter_count:192/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__5815648101690016187<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:1/input[1]:96/input[2]:27/input[3]:27/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__5815648101690016187<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:1/input[1]:96/input[2]:27/input[3]:27/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__5815648101690016187<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:1/input[1]:96/input[2]:27/input[3]:27/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__5815648101690016187<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:1/input[1]:96/input[2]:27/input[3]:27/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__5815648101690016187<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:1/input[1]:96/input[2]:27/input[3]:27/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__5815648101690016187<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:1/input[1]:96/input[2]:27/input[3]:27/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__5815648101690016187<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:1/input[1]:96/input[2]:27/input[3]:27/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__5815648101690016187<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:1/input[1]:96/input[2]:27/input[3]:27/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__8532430157110871000<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:1/input[1]:192/input[2]:27/input[3]:27/filter_count:32/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__8532430157110871000<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:1/input[1]:192/input[2]:27/input[3]:27/filter_count:32/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__8532430157110871000<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:1/input[1]:192/input[2]:27/input[3]:27/filter_count:32/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__8532430157110871000<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:1/input[1]:192/input[2]:27/input[3]:27/filter_count:32/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__8532430157110871000<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:1/input[1]:192/input[2]:27/input[3]:27/filter_count:32/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__8532430157110871000<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:1/input[1]:192/input[2]:27/input[3]:27/filter_count:32/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__8532430157110871000<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:1/input[1]:192/input[2]:27/input[3]:27/filter_count:32/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__8532430157110871000<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:1/input[1]:192/input[2]:27/input[3]:27/filter_count:32/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__14505120118170555514<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:1/input[1]:272/input[2]:7/input[3]:7/filter_count:272/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:4/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__14505120118170555514<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:1/input[1]:272/input[2]:7/input[3]:7/filter_count:272/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:4/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__14505120118170555514<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:1/input[1]:272/input[2]:7/input[3]:7/filter_count:272/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:4/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__14505120118170555514<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:1/input[1]:272/input[2]:7/input[3]:7/filter_count:272/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:4/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__14505120118170555514<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:1/input[1]:272/input[2]:7/input[3]:7/filter_count:272/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:4/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__14505120118170555514<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:1/input[1]:272/input[2]:7/input[3]:7/filter_count:272/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:4/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__14505120118170555514<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:1/input[1]:272/input[2]:7/input[3]:7/filter_count:272/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:4/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__14505120118170555514<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:1/input[1]:272/input[2]:7/input[3]:7/filter_count:272/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:4/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__6312907282717829527<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:1/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__6312907282717829527<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:1/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__6312907282717829527<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:1/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__6312907282717829527<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:1/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__6312907282717829527<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:1/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__6312907282717829527<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:1/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__6312907282717829527<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:1/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__6312907282717829527<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:1/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__16738348338854482257<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:96/input[2]:27/input[3]:27/filter_count:256/filter_height:5/filter_width:5/pad_height:2/pad_width:2/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:2/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__16738348338854482257<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:96/input[2]:27/input[3]:27/filter_count:256/filter_height:5/filter_width:5/pad_height:2/pad_width:2/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:2/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__16738348338854482257<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:96/input[2]:27/input[3]:27/filter_count:256/filter_height:5/filter_width:5/pad_height:2/pad_width:2/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:2/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__16738348338854482257<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:96/input[2]:27/input[3]:27/filter_count:256/filter_height:5/filter_width:5/pad_height:2/pad_width:2/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:2/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__16738348338854482257<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:96/input[2]:27/input[3]:27/filter_count:256/filter_height:5/filter_width:5/pad_height:2/pad_width:2/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:2/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__16738348338854482257<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:96/input[2]:27/input[3]:27/filter_count:256/filter_height:5/filter_width:5/pad_height:2/pad_width:2/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:2/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__16738348338854482257<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:96/input[2]:27/input[3]:27/filter_count:256/filter_height:5/filter_width:5/pad_height:2/pad_width:2/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:2/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__16738348338854482257<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:96/input[2]:27/input[3]:27/filter_count:256/filter_height:5/filter_width:5/pad_height:2/pad_width:2/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:2/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__7428856221268368590<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:128/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__7428856221268368590<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:128/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__7428856221268368590<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:128/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__7428856221268368590<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:128/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__7428856221268368590<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:128/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__7428856221268368590<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:128/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__7428856221268368590<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:128/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__7428856221268368590<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:128/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__4460365411425090557<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:1/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__4460365411425090557<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:1/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__4460365411425090557<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:1/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__4460365411425090557<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:1/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__4460365411425090557<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:1/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__4460365411425090557<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:1/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__4460365411425090557<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:1/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__4460365411425090557<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:1/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__2956120337198267246<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:1/input[2]:28/input[3]:28/filter_count:8/filter_height:5/filter_width:5/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__2956120337198267246<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:1/input[2]:28/input[3]:28/filter_count:8/filter_height:5/filter_width:5/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__2956120337198267246<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:1/input[2]:28/input[3]:28/filter_count:8/filter_height:5/filter_width:5/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__2956120337198267246<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:1/input[2]:28/input[3]:28/filter_count:8/filter_height:5/filter_width:5/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__2956120337198267246<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:1/input[2]:28/input[3]:28/filter_count:8/filter_height:5/filter_width:5/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__2956120337198267246<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:1/input[2]:28/input[3]:28/filter_count:8/filter_height:5/filter_width:5/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__2956120337198267246<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:1/input[2]:28/input[3]:28/filter_count:8/filter_height:5/filter_width:5/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__2956120337198267246<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:1/input[2]:28/input[3]:28/filter_count:8/filter_height:5/filter_width:5/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__7768986256863016776<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:512/input[2]:14/input[3]:14/filter_count:112/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__7768986256863016776<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:512/input[2]:14/input[3]:14/filter_count:112/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__7768986256863016776<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:512/input[2]:14/input[3]:14/filter_count:112/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__7768986256863016776<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:512/input[2]:14/input[3]:14/filter_count:112/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__7768986256863016776<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:512/input[2]:14/input[3]:14/filter_count:112/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__7768986256863016776<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:512/input[2]:14/input[3]:14/filter_count:112/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__7768986256863016776<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:512/input[2]:14/input[3]:14/filter_count:112/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__7768986256863016776<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:512/input[2]:14/input[3]:14/filter_count:112/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__11577289863291515496<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:3/input[2]:224/input[3]:224/filter_count:32/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__11577289863291515496<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:3/input[2]:224/input[3]:224/filter_count:32/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__11577289863291515496<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:3/input[2]:224/input[3]:224/filter_count:32/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__11577289863291515496<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:3/input[2]:224/input[3]:224/filter_count:32/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__11577289863291515496<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:3/input[2]:224/input[3]:224/filter_count:32/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__11577289863291515496<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:3/input[2]:224/input[3]:224/filter_count:32/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__11577289863291515496<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:3/input[2]:224/input[3]:224/filter_count:32/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__11577289863291515496<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:3/input[2]:224/input[3]:224/filter_count:32/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__15981681849204448988<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:32/input[2]:14/input[3]:14/filter_count:64/filter_height:5/filter_width:5/pad_height:2/pad_width:2/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__15981681849204448988<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:32/input[2]:14/input[3]:14/filter_count:64/filter_height:5/filter_width:5/pad_height:2/pad_width:2/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__15981681849204448988<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:32/input[2]:14/input[3]:14/filter_count:64/filter_height:5/filter_width:5/pad_height:2/pad_width:2/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__15981681849204448988<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:32/input[2]:14/input[3]:14/filter_count:64/filter_height:5/filter_width:5/pad_height:2/pad_width:2/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__15981681849204448988<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:32/input[2]:14/input[3]:14/filter_count:64/filter_height:5/filter_width:5/pad_height:2/pad_width:2/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__15981681849204448988<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:32/input[2]:14/input[3]:14/filter_count:64/filter_height:5/filter_width:5/pad_height:2/pad_width:2/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__15981681849204448988<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:32/input[2]:14/input[3]:14/filter_count:64/filter_height:5/filter_width:5/pad_height:2/pad_width:2/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__15981681849204448988<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:32/input[2]:14/input[3]:14/filter_count:64/filter_height:5/filter_width:5/pad_height:2/pad_width:2/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__13678915300245728453<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:528/input[2]:14/input[3]:14/filter_count:160/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__13678915300245728453<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:528/input[2]:14/input[3]:14/filter_count:160/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__13678915300245728453<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:528/input[2]:14/input[3]:14/filter_count:160/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__13678915300245728453<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:528/input[2]:14/input[3]:14/filter_count:160/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__13678915300245728453<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:528/input[2]:14/input[3]:14/filter_count:160/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__13678915300245728453<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:528/input[2]:14/input[3]:14/filter_count:160/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__13678915300245728453<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:528/input[2]:14/input[3]:14/filter_count:160/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__13678915300245728453<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:528/input[2]:14/input[3]:14/filter_count:160/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__10619789271330040946<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:256/input[2]:12/input[3]:12/filter_count:384/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__10619789271330040946<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:256/input[2]:12/input[3]:12/filter_count:384/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__10619789271330040946<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:256/input[2]:12/input[3]:12/filter_count:384/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__10619789271330040946<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:256/input[2]:12/input[3]:12/filter_count:384/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__10619789271330040946<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:256/input[2]:12/input[3]:12/filter_count:384/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__10619789271330040946<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:256/input[2]:12/input[3]:12/filter_count:384/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__10619789271330040946<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:256/input[2]:12/input[3]:12/filter_count:384/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__10619789271330040946<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:256/input[2]:12/input[3]:12/filter_count:384/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__13680409596138327876<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:1/input[1]:640/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__13680409596138327876<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:1/input[1]:640/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__13680409596138327876<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:1/input[1]:640/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__13680409596138327876<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:1/input[1]:640/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__13680409596138327876<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:1/input[1]:640/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__13680409596138327876<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:1/input[1]:640/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__13680409596138327876<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:1/input[1]:640/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__13680409596138327876<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:1/input[1]:640/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__2649268772222277980<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:1/input[1]:480/input[2]:13/input[3]:13/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__2649268772222277980<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:1/input[1]:480/input[2]:13/input[3]:13/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__2649268772222277980<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:1/input[1]:480/input[2]:13/input[3]:13/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__2649268772222277980<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:1/input[1]:480/input[2]:13/input[3]:13/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__2649268772222277980<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:1/input[1]:480/input[2]:13/input[3]:13/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__2649268772222277980<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:1/input[1]:480/input[2]:13/input[3]:13/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__2649268772222277980<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:1/input[1]:480/input[2]:13/input[3]:13/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__2649268772222277980<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:1/input[1]:480/input[2]:13/input[3]:13/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__16724414524887588321<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:144/input[2]:56/input[3]:56/filter_count:144/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:144/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__16724414524887588321<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:144/input[2]:56/input[3]:56/filter_count:144/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:144/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__16724414524887588321<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:144/input[2]:56/input[3]:56/filter_count:144/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:144/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__16724414524887588321<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:144/input[2]:56/input[3]:56/filter_count:144/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:144/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__16724414524887588321<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:144/input[2]:56/input[3]:56/filter_count:144/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:144/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__16724414524887588321<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:144/input[2]:56/input[3]:56/filter_count:144/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:144/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__16724414524887588321<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:144/input[2]:56/input[3]:56/filter_count:144/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:144/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__16724414524887588321<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:144/input[2]:56/input[3]:56/filter_count:144/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:144/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__11019564957041385411<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:1/input[1]:384/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__11019564957041385411<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:1/input[1]:384/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__11019564957041385411<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:1/input[1]:384/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__11019564957041385411<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:1/input[1]:384/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__11019564957041385411<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:1/input[1]:384/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__11019564957041385411<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:1/input[1]:384/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__11019564957041385411<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:1/input[1]:384/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__11019564957041385411<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:1/input[1]:384/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__12889272076445828432<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:144/input[2]:56/input[3]:56/filter_count:24/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__12889272076445828432<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:144/input[2]:56/input[3]:56/filter_count:24/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__12889272076445828432<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:144/input[2]:56/input[3]:56/filter_count:24/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__12889272076445828432<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:144/input[2]:56/input[3]:56/filter_count:24/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__12889272076445828432<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:144/input[2]:56/input[3]:56/filter_count:24/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__12889272076445828432<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:144/input[2]:56/input[3]:56/filter_count:24/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__12889272076445828432<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:144/input[2]:56/input[3]:56/filter_count:24/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__12889272076445828432<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:144/input[2]:56/input[3]:56/filter_count:24/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__13627725758214777071<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:1/input[1]:512/input[2]:13/input[3]:13/filter_count:160/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__13627725758214777071<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:1/input[1]:512/input[2]:13/input[3]:13/filter_count:160/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__13627725758214777071<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:1/input[1]:512/input[2]:13/input[3]:13/filter_count:160/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__13627725758214777071<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:1/input[1]:512/input[2]:13/input[3]:13/filter_count:160/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__13627725758214777071<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:1/input[1]:512/input[2]:13/input[3]:13/filter_count:160/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__13627725758214777071<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:1/input[1]:512/input[2]:13/input[3]:13/filter_count:160/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__13627725758214777071<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:1/input[1]:512/input[2]:13/input[3]:13/filter_count:160/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__13627725758214777071<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:1/input[1]:512/input[2]:13/input[3]:13/filter_count:160/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__10605477009605945791<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:1/input[1]:384/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__10605477009605945791<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:1/input[1]:384/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__10605477009605945791<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:1/input[1]:384/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__10605477009605945791<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:1/input[1]:384/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__10605477009605945791<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:1/input[1]:384/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__10605477009605945791<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:1/input[1]:384/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__10605477009605945791<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:1/input[1]:384/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__10605477009605945791<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:1/input[1]:384/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__17419028347672368891<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:512/input[2]:14/input[3]:14/filter_count:32/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__17419028347672368891<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:512/input[2]:14/input[3]:14/filter_count:32/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__17419028347672368891<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:512/input[2]:14/input[3]:14/filter_count:32/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__17419028347672368891<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:512/input[2]:14/input[3]:14/filter_count:32/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__17419028347672368891<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:512/input[2]:14/input[3]:14/filter_count:32/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__17419028347672368891<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:512/input[2]:14/input[3]:14/filter_count:32/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__17419028347672368891<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:512/input[2]:14/input[3]:14/filter_count:32/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__17419028347672368891<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:512/input[2]:14/input[3]:14/filter_count:32/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__11565609722490455988<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:1/input[1]:128/input[2]:14/input[3]:14/filter_count:32/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__11565609722490455988<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:1/input[1]:128/input[2]:14/input[3]:14/filter_count:32/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__11565609722490455988<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:1/input[1]:128/input[2]:14/input[3]:14/filter_count:32/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__11565609722490455988<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:1/input[1]:128/input[2]:14/input[3]:14/filter_count:32/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__11565609722490455988<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:1/input[1]:128/input[2]:14/input[3]:14/filter_count:32/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__11565609722490455988<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:1/input[1]:128/input[2]:14/input[3]:14/filter_count:32/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__11565609722490455988<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:1/input[1]:128/input[2]:14/input[3]:14/filter_count:32/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__11565609722490455988<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:1/input[1]:128/input[2]:14/input[3]:14/filter_count:32/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__8857686263146550798<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:3/input[2]:800/input[3]:800/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__8857686263146550798<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:3/input[2]:800/input[3]:800/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__8857686263146550798<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:3/input[2]:800/input[3]:800/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__8857686263146550798<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:3/input[2]:800/input[3]:800/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__8857686263146550798<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:3/input[2]:800/input[3]:800/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__8857686263146550798<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:3/input[2]:800/input[3]:800/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__8857686263146550798<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:3/input[2]:800/input[3]:800/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__8857686263146550798<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:3/input[2]:800/input[3]:800/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__13639767614016771533<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:32/input[2]:7/input[3]:7/filter_count:128/filter_height:5/filter_width:5/pad_height:2/pad_width:2/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__13639767614016771533<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:32/input[2]:7/input[3]:7/filter_count:128/filter_height:5/filter_width:5/pad_height:2/pad_width:2/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__13639767614016771533<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:32/input[2]:7/input[3]:7/filter_count:128/filter_height:5/filter_width:5/pad_height:2/pad_width:2/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__13639767614016771533<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:32/input[2]:7/input[3]:7/filter_count:128/filter_height:5/filter_width:5/pad_height:2/pad_width:2/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__13639767614016771533<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:32/input[2]:7/input[3]:7/filter_count:128/filter_height:5/filter_width:5/pad_height:2/pad_width:2/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__13639767614016771533<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:32/input[2]:7/input[3]:7/filter_count:128/filter_height:5/filter_width:5/pad_height:2/pad_width:2/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__13639767614016771533<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:32/input[2]:7/input[3]:7/filter_count:128/filter_height:5/filter_width:5/pad_height:2/pad_width:2/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__13639767614016771533<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:32/input[2]:7/input[3]:7/filter_count:128/filter_height:5/filter_width:5/pad_height:2/pad_width:2/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__16272202834644277995<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:64/input[2]:400/input[3]:400/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD failed to cudnnSetTensor4dDescriptor",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__16272202834644277995<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:64/input[2]:400/input[3]:400/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD failed to cudnnSetTensor4dDescriptor",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__16272202834644277995<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:64/input[2]:400/input[3]:400/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD failed to cudnnSetTensor4dDescriptor",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__16272202834644277995<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:64/input[2]:400/input[3]:400/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD failed to cudnnSetTensor4dDescriptor",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__16272202834644277995<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:64/input[2]:400/input[3]:400/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD failed to cudnnSetTensor4dDescriptor",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__16272202834644277995<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:64/input[2]:400/input[3]:400/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD failed to cudnnSetTensor4dDescriptor",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__16272202834644277995<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:64/input[2]:400/input[3]:400/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD failed to cudnnSetTensor4dDescriptor",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__16272202834644277995<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:64/input[2]:400/input[3]:400/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD failed to cudnnSetTensor4dDescriptor",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__4959475736084728565<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:1/input[1]:512/input[2]:7/input[3]:7/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__4959475736084728565<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:1/input[1]:512/input[2]:7/input[3]:7/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__4959475736084728565<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:1/input[1]:512/input[2]:7/input[3]:7/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__4959475736084728565<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:1/input[1]:512/input[2]:7/input[3]:7/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__4959475736084728565<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:1/input[1]:512/input[2]:7/input[3]:7/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__4959475736084728565<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:1/input[1]:512/input[2]:7/input[3]:7/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__4959475736084728565<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:1/input[1]:512/input[2]:7/input[3]:7/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__4959475736084728565<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:1/input[1]:512/input[2]:7/input[3]:7/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__4972795948663690583<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:384/input[2]:28/input[3]:28/filter_count:384/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:384/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__4972795948663690583<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:384/input[2]:28/input[3]:28/filter_count:384/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:384/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__4972795948663690583<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:384/input[2]:28/input[3]:28/filter_count:384/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:384/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__4972795948663690583<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:384/input[2]:28/input[3]:28/filter_count:384/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:384/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__4972795948663690583<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:384/input[2]:28/input[3]:28/filter_count:384/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:384/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__4972795948663690583<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:384/input[2]:28/input[3]:28/filter_count:384/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:384/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__4972795948663690583<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:384/input[2]:28/input[3]:28/filter_count:384/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:384/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__4972795948663690583<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:384/input[2]:28/input[3]:28/filter_count:384/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:384/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__12448375135032284182<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:64/input[2]:199/input[3]:199/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__12448375135032284182<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:64/input[2]:199/input[3]:199/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__12448375135032284182<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:64/input[2]:199/input[3]:199/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__12448375135032284182<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:64/input[2]:199/input[3]:199/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__12448375135032284182<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:64/input[2]:199/input[3]:199/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__12448375135032284182<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:64/input[2]:199/input[3]:199/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__12448375135032284182<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:64/input[2]:199/input[3]:199/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__12448375135032284182<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:64/input[2]:199/input[3]:199/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__8700699975786020037<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:832/input[2]:7/input[3]:7/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__8700699975786020037<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:832/input[2]:7/input[3]:7/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__8700699975786020037<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:832/input[2]:7/input[3]:7/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__8700699975786020037<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:832/input[2]:7/input[3]:7/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__8700699975786020037<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:832/input[2]:7/input[3]:7/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__8700699975786020037<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:832/input[2]:7/input[3]:7/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__8700699975786020037<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:832/input[2]:7/input[3]:7/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__8700699975786020037<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:832/input[2]:7/input[3]:7/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__3752412604221858272<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:1/input[1]:608/input[2]:7/input[3]:7/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__3752412604221858272<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:1/input[1]:608/input[2]:7/input[3]:7/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__3752412604221858272<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:1/input[1]:608/input[2]:7/input[3]:7/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__3752412604221858272<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:1/input[1]:608/input[2]:7/input[3]:7/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__3752412604221858272<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:1/input[1]:608/input[2]:7/input[3]:7/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__3752412604221858272<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:1/input[1]:608/input[2]:7/input[3]:7/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__3752412604221858272<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:1/input[1]:608/input[2]:7/input[3]:7/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__3752412604221858272<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:1/input[1]:608/input[2]:7/input[3]:7/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__8965924181340504580<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:160/input[2]:7/input[3]:7/filter_count:960/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__8965924181340504580<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:160/input[2]:7/input[3]:7/filter_count:960/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__8965924181340504580<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:160/input[2]:7/input[3]:7/filter_count:960/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__8965924181340504580<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:160/input[2]:7/input[3]:7/filter_count:960/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__8965924181340504580<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:160/input[2]:7/input[3]:7/filter_count:960/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__8965924181340504580<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:160/input[2]:7/input[3]:7/filter_count:960/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__8965924181340504580<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:160/input[2]:7/input[3]:7/filter_count:960/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__8965924181340504580<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:160/input[2]:7/input[3]:7/filter_count:960/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__3883948256281316512<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:320/input[2]:7/input[3]:7/filter_count:1280/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__3883948256281316512<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:320/input[2]:7/input[3]:7/filter_count:1280/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__3883948256281316512<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:320/input[2]:7/input[3]:7/filter_count:1280/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__3883948256281316512<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:320/input[2]:7/input[3]:7/filter_count:1280/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__3883948256281316512<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:320/input[2]:7/input[3]:7/filter_count:1280/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__3883948256281316512<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:320/input[2]:7/input[3]:7/filter_count:1280/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__3883948256281316512<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:320/input[2]:7/input[3]:7/filter_count:1280/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__3883948256281316512<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:320/input[2]:7/input[3]:7/filter_count:1280/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__11071459659656059334<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:128/input[2]:32/input[3]:32/filter_count:128/filter_height:3/filter_width:3/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__11071459659656059334<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:128/input[2]:32/input[3]:32/filter_count:128/filter_height:3/filter_width:3/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__11071459659656059334<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:128/input[2]:32/input[3]:32/filter_count:128/filter_height:3/filter_width:3/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__11071459659656059334<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:128/input[2]:32/input[3]:32/filter_count:128/filter_height:3/filter_width:3/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__11071459659656059334<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:128/input[2]:32/input[3]:32/filter_count:128/filter_height:3/filter_width:3/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__11071459659656059334<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:128/input[2]:32/input[3]:32/filter_count:128/filter_height:3/filter_width:3/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__11071459659656059334<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:128/input[2]:32/input[3]:32/filter_count:128/filter_height:3/filter_width:3/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__11071459659656059334<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:128/input[2]:32/input[3]:32/filter_count:128/filter_height:3/filter_width:3/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__2420327101660498894<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:192/input[2]:28/input[3]:28/filter_count:96/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__2420327101660498894<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:192/input[2]:28/input[3]:28/filter_count:96/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__2420327101660498894<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:192/input[2]:28/input[3]:28/filter_count:96/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__2420327101660498894<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:192/input[2]:28/input[3]:28/filter_count:96/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__2420327101660498894<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:192/input[2]:28/input[3]:28/filter_count:96/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__2420327101660498894<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:192/input[2]:28/input[3]:28/filter_count:96/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__2420327101660498894<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:192/input[2]:28/input[3]:28/filter_count:96/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__2420327101660498894<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:192/input[2]:28/input[3]:28/filter_count:96/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__17393828788132268648<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:1280/input[2]:1/input[3]:1/filter_count:1000/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__17393828788132268648<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:1280/input[2]:1/input[3]:1/filter_count:1000/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__17393828788132268648<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:1280/input[2]:1/input[3]:1/filter_count:1000/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__17393828788132268648<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:1280/input[2]:1/input[3]:1/filter_count:1000/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__17393828788132268648<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:1280/input[2]:1/input[3]:1/filter_count:1000/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__17393828788132268648<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:1280/input[2]:1/input[3]:1/filter_count:1000/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__17393828788132268648<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:1280/input[2]:1/input[3]:1/filter_count:1000/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__17393828788132268648<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:1280/input[2]:1/input[3]:1/filter_count:1000/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__3161176298056772888<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:256/input[2]:199/input[3]:199/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__3161176298056772888<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:256/input[2]:199/input[3]:199/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__3161176298056772888<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:256/input[2]:199/input[3]:199/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__3161176298056772888<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:256/input[2]:199/input[3]:199/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__3161176298056772888<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:256/input[2]:199/input[3]:199/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__3161176298056772888<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:256/input[2]:199/input[3]:199/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__3161176298056772888<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:256/input[2]:199/input[3]:199/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__3161176298056772888<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:256/input[2]:199/input[3]:199/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__15327998276204830305<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:32/input[2]:28/input[3]:28/filter_count:96/filter_height:5/filter_width:5/pad_height:2/pad_width:2/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__15327998276204830305<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:32/input[2]:28/input[3]:28/filter_count:96/filter_height:5/filter_width:5/pad_height:2/pad_width:2/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__15327998276204830305<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:32/input[2]:28/input[3]:28/filter_count:96/filter_height:5/filter_width:5/pad_height:2/pad_width:2/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__15327998276204830305<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:32/input[2]:28/input[3]:28/filter_count:96/filter_height:5/filter_width:5/pad_height:2/pad_width:2/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__15327998276204830305<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:32/input[2]:28/input[3]:28/filter_count:96/filter_height:5/filter_width:5/pad_height:2/pad_width:2/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__15327998276204830305<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:32/input[2]:28/input[3]:28/filter_count:96/filter_height:5/filter_width:5/pad_height:2/pad_width:2/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__15327998276204830305<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:32/input[2]:28/input[3]:28/filter_count:96/filter_height:5/filter_width:5/pad_height:2/pad_width:2/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__15327998276204830305<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:32/input[2]:28/input[3]:28/filter_count:96/filter_height:5/filter_width:5/pad_height:2/pad_width:2/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__8638040242652728820<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:1/input[1]:800/input[2]:7/input[3]:7/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__8638040242652728820<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:1/input[1]:800/input[2]:7/input[3]:7/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__8638040242652728820<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:1/input[1]:800/input[2]:7/input[3]:7/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__8638040242652728820<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:1/input[1]:800/input[2]:7/input[3]:7/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__8638040242652728820<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:1/input[1]:800/input[2]:7/input[3]:7/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__8638040242652728820<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:1/input[1]:800/input[2]:7/input[3]:7/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__8638040242652728820<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:1/input[1]:800/input[2]:7/input[3]:7/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__8638040242652728820<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:1/input[1]:800/input[2]:7/input[3]:7/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__17144800627473478210<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:1/input[1]:528/input[2]:13/input[3]:13/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__17144800627473478210<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:1/input[1]:528/input[2]:13/input[3]:13/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__17144800627473478210<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:1/input[1]:528/input[2]:13/input[3]:13/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__17144800627473478210<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:1/input[1]:528/input[2]:13/input[3]:13/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__17144800627473478210<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:1/input[1]:528/input[2]:13/input[3]:13/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__17144800627473478210<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:1/input[1]:528/input[2]:13/input[3]:13/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__17144800627473478210<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:1/input[1]:528/input[2]:13/input[3]:13/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__17144800627473478210<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:1/input[1]:528/input[2]:13/input[3]:13/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__1659228898513315938<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:256/input[2]:100/input[3]:100/filter_count:256/filter_height:3/filter_width:3/pad_height:2/pad_width:2/stride_height:1/stride_width:1/dilation_height:2/dilation_width:2/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__1659228898513315938<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:256/input[2]:100/input[3]:100/filter_count:256/filter_height:3/filter_width:3/pad_height:2/pad_width:2/stride_height:1/stride_width:1/dilation_height:2/dilation_width:2/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__1659228898513315938<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:256/input[2]:100/input[3]:100/filter_count:256/filter_height:3/filter_width:3/pad_height:2/pad_width:2/stride_height:1/stride_width:1/dilation_height:2/dilation_width:2/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__1659228898513315938<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:256/input[2]:100/input[3]:100/filter_count:256/filter_height:3/filter_width:3/pad_height:2/pad_width:2/stride_height:1/stride_width:1/dilation_height:2/dilation_width:2/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__1659228898513315938<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:256/input[2]:100/input[3]:100/filter_count:256/filter_height:3/filter_width:3/pad_height:2/pad_width:2/stride_height:1/stride_width:1/dilation_height:2/dilation_width:2/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__1659228898513315938<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:256/input[2]:100/input[3]:100/filter_count:256/filter_height:3/filter_width:3/pad_height:2/pad_width:2/stride_height:1/stride_width:1/dilation_height:2/dilation_width:2/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__1659228898513315938<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:256/input[2]:100/input[3]:100/filter_count:256/filter_height:3/filter_width:3/pad_height:2/pad_width:2/stride_height:1/stride_width:1/dilation_height:2/dilation_width:2/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__1659228898513315938<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:256/input[2]:100/input[3]:100/filter_count:256/filter_height:3/filter_width:3/pad_height:2/pad_width:2/stride_height:1/stride_width:1/dilation_height:2/dilation_width:2/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__16322025586738731386<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:96/input[2]:28/input[3]:28/filter_count:96/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__16322025586738731386<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:96/input[2]:28/input[3]:28/filter_count:96/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__16322025586738731386<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:96/input[2]:28/input[3]:28/filter_count:96/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__16322025586738731386<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:96/input[2]:28/input[3]:28/filter_count:96/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__16322025586738731386<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:96/input[2]:28/input[3]:28/filter_count:96/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__16322025586738731386<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:96/input[2]:28/input[3]:28/filter_count:96/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__16322025586738731386<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:96/input[2]:28/input[3]:28/filter_count:96/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__16322025586738731386<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:96/input[2]:28/input[3]:28/filter_count:96/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__13633451302510418924<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:1/input[1]:832/input[2]:6/input[3]:6/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__13633451302510418924<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:1/input[1]:832/input[2]:6/input[3]:6/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__13633451302510418924<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:1/input[1]:832/input[2]:6/input[3]:6/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__13633451302510418924<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:1/input[1]:832/input[2]:6/input[3]:6/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__13633451302510418924<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:1/input[1]:832/input[2]:6/input[3]:6/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__13633451302510418924<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:1/input[1]:832/input[2]:6/input[3]:6/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__13633451302510418924<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:1/input[1]:832/input[2]:6/input[3]:6/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__13633451302510418924<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:1/input[1]:832/input[2]:6/input[3]:6/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__14933349575401484229<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:1024/input[2]:100/input[3]:100/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__14933349575401484229<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:1024/input[2]:100/input[3]:100/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__14933349575401484229<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:1024/input[2]:100/input[3]:100/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__14933349575401484229<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:1024/input[2]:100/input[3]:100/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__14933349575401484229<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:1024/input[2]:100/input[3]:100/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__14933349575401484229<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:1024/input[2]:100/input[3]:100/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__14933349575401484229<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:1024/input[2]:100/input[3]:100/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__14933349575401484229<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:1024/input[2]:100/input[3]:100/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__1639068900549720660<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:1/input[1]:832/input[2]:7/input[3]:7/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__1639068900549720660<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:1/input[1]:832/input[2]:7/input[3]:7/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__1639068900549720660<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:1/input[1]:832/input[2]:7/input[3]:7/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__1639068900549720660<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:1/input[1]:832/input[2]:7/input[3]:7/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__1639068900549720660<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:1/input[1]:832/input[2]:7/input[3]:7/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__1639068900549720660<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:1/input[1]:832/input[2]:7/input[3]:7/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__1639068900549720660<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:1/input[1]:832/input[2]:7/input[3]:7/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__1639068900549720660<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:1/input[1]:832/input[2]:7/input[3]:7/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__2574158358121789783<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:64/input[2]:28/input[3]:28/filter_count:96/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__2574158358121789783<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:64/input[2]:28/input[3]:28/filter_count:96/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__2574158358121789783<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:64/input[2]:28/input[3]:28/filter_count:96/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__2574158358121789783<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:64/input[2]:28/input[3]:28/filter_count:96/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__2574158358121789783<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:64/input[2]:28/input[3]:28/filter_count:96/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__2574158358121789783<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:64/input[2]:28/input[3]:28/filter_count:96/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__2574158358121789783<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:64/input[2]:28/input[3]:28/filter_count:96/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__2574158358121789783<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:64/input[2]:28/input[3]:28/filter_count:96/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__17644094702410566635<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:576/input[2]:14/input[3]:14/filter_count:160/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__17644094702410566635<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:576/input[2]:14/input[3]:14/filter_count:160/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__17644094702410566635<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:576/input[2]:14/input[3]:14/filter_count:160/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__17644094702410566635<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:576/input[2]:14/input[3]:14/filter_count:160/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__17644094702410566635<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:576/input[2]:14/input[3]:14/filter_count:160/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__17644094702410566635<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:576/input[2]:14/input[3]:14/filter_count:160/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__17644094702410566635<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:576/input[2]:14/input[3]:14/filter_count:160/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__17644094702410566635<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:576/input[2]:14/input[3]:14/filter_count:160/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__1045038387023690528<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:160/input[2]:14/input[3]:14/filter_count:192/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__1045038387023690528<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:160/input[2]:14/input[3]:14/filter_count:192/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__1045038387023690528<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:160/input[2]:14/input[3]:14/filter_count:192/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__1045038387023690528<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:160/input[2]:14/input[3]:14/filter_count:192/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__1045038387023690528<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:160/input[2]:14/input[3]:14/filter_count:192/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__1045038387023690528<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:160/input[2]:14/input[3]:14/filter_count:192/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__1045038387023690528<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:160/input[2]:14/input[3]:14/filter_count:192/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__1045038387023690528<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:160/input[2]:14/input[3]:14/filter_count:192/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__5224746311443582058<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:256/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__5224746311443582058<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:256/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__5224746311443582058<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:256/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__5224746311443582058<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:256/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__5224746311443582058<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:256/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__5224746311443582058<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:256/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__5224746311443582058<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:256/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__5224746311443582058<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:256/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__15139162640679756214<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:128/input[2]:14/input[3]:14/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__15139162640679756214<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:128/input[2]:14/input[3]:14/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__15139162640679756214<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:128/input[2]:14/input[3]:14/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__15139162640679756214<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:128/input[2]:14/input[3]:14/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__15139162640679756214<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:128/input[2]:14/input[3]:14/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__15139162640679756214<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:128/input[2]:14/input[3]:14/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__15139162640679756214<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:128/input[2]:14/input[3]:14/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__15139162640679756214<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:128/input[2]:14/input[3]:14/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__13788911520875671642<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:224/input[2]:7/input[3]:7/filter_count:224/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__13788911520875671642<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:224/input[2]:7/input[3]:7/filter_count:224/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__13788911520875671642<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:224/input[2]:7/input[3]:7/filter_count:224/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__13788911520875671642<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:224/input[2]:7/input[3]:7/filter_count:224/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__13788911520875671642<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:224/input[2]:7/input[3]:7/filter_count:224/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__13788911520875671642<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:224/input[2]:7/input[3]:7/filter_count:224/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__13788911520875671642<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:224/input[2]:7/input[3]:7/filter_count:224/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__13788911520875671642<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:224/input[2]:7/input[3]:7/filter_count:224/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__15432319161527955499<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:1024/input[2]:100/input[3]:100/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__15432319161527955499<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:1024/input[2]:100/input[3]:100/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__15432319161527955499<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:1024/input[2]:100/input[3]:100/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__15432319161527955499<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:1024/input[2]:100/input[3]:100/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__15432319161527955499<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:1024/input[2]:100/input[3]:100/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__15432319161527955499<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:1024/input[2]:100/input[3]:100/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__15432319161527955499<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:1024/input[2]:100/input[3]:100/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__15432319161527955499<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:1024/input[2]:100/input[3]:100/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__16366158616103068298<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:128/input[2]:28/input[3]:28/filter_count:192/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__16366158616103068298<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:128/input[2]:28/input[3]:28/filter_count:192/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__16366158616103068298<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:128/input[2]:28/input[3]:28/filter_count:192/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__16366158616103068298<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:128/input[2]:28/input[3]:28/filter_count:192/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__16366158616103068298<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:128/input[2]:28/input[3]:28/filter_count:192/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__16366158616103068298<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:128/input[2]:28/input[3]:28/filter_count:192/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__16366158616103068298<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:128/input[2]:28/input[3]:28/filter_count:192/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__16366158616103068298<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:128/input[2]:28/input[3]:28/filter_count:192/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__8332351828842117039<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:1/input[1]:64/input[2]:55/input[3]:55/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__8332351828842117039<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:1/input[1]:64/input[2]:55/input[3]:55/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__8332351828842117039<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:1/input[1]:64/input[2]:55/input[3]:55/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__8332351828842117039<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:1/input[1]:64/input[2]:55/input[3]:55/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__8332351828842117039<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:1/input[1]:64/input[2]:55/input[3]:55/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__8332351828842117039<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:1/input[1]:64/input[2]:55/input[3]:55/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__8332351828842117039<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:1/input[1]:64/input[2]:55/input[3]:55/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__8332351828842117039<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:1/input[1]:64/input[2]:55/input[3]:55/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__14192976833899925430<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:128/input[2]:26/input[3]:26/filter_count:256/filter_height:3/filter_width:3/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__14192976833899925430<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:128/input[2]:26/input[3]:26/filter_count:256/filter_height:3/filter_width:3/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__14192976833899925430<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:128/input[2]:26/input[3]:26/filter_count:256/filter_height:3/filter_width:3/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__14192976833899925430<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:128/input[2]:26/input[3]:26/filter_count:256/filter_height:3/filter_width:3/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__14192976833899925430<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:128/input[2]:26/input[3]:26/filter_count:256/filter_height:3/filter_width:3/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__14192976833899925430<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:128/input[2]:26/input[3]:26/filter_count:256/filter_height:3/filter_width:3/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__14192976833899925430<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:128/input[2]:26/input[3]:26/filter_count:256/filter_height:3/filter_width:3/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__14192976833899925430<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:128/input[2]:26/input[3]:26/filter_count:256/filter_height:3/filter_width:3/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__12388934306483241048<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:1024/input[2]:12/input[3]:12/filter_count:125/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__12388934306483241048<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:1024/input[2]:12/input[3]:12/filter_count:125/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__12388934306483241048<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:1024/input[2]:12/input[3]:12/filter_count:125/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__12388934306483241048<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:1024/input[2]:12/input[3]:12/filter_count:125/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__12388934306483241048<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:1024/input[2]:12/input[3]:12/filter_count:125/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__12388934306483241048<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:1024/input[2]:12/input[3]:12/filter_count:125/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__12388934306483241048<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:1024/input[2]:12/input[3]:12/filter_count:125/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__12388934306483241048<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:1024/input[2]:12/input[3]:12/filter_count:125/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__310140893076242184<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:512/input[2]:100/input[3]:100/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD failed to cudnnSetTensor4dDescriptor",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__310140893076242184<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:512/input[2]:100/input[3]:100/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD failed to cudnnSetTensor4dDescriptor",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__310140893076242184<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:512/input[2]:100/input[3]:100/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD failed to cudnnSetTensor4dDescriptor",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__310140893076242184<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:512/input[2]:100/input[3]:100/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD failed to cudnnSetTensor4dDescriptor",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__310140893076242184<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:512/input[2]:100/input[3]:100/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD failed to cudnnSetTensor4dDescriptor",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__310140893076242184<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:512/input[2]:100/input[3]:100/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD failed to cudnnSetTensor4dDescriptor",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__310140893076242184<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:512/input[2]:100/input[3]:100/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD failed to cudnnSetTensor4dDescriptor",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__310140893076242184<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:512/input[2]:100/input[3]:100/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD failed to cudnnSetTensor4dDescriptor",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__16959463500015053299<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:512/input[2]:12/input[3]:12/filter_count:1024/filter_height:3/filter_width:3/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__16959463500015053299<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:512/input[2]:12/input[3]:12/filter_count:1024/filter_height:3/filter_width:3/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__16959463500015053299<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:512/input[2]:12/input[3]:12/filter_count:1024/filter_height:3/filter_width:3/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__16959463500015053299<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:512/input[2]:12/input[3]:12/filter_count:1024/filter_height:3/filter_width:3/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__16959463500015053299<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:512/input[2]:12/input[3]:12/filter_count:1024/filter_height:3/filter_width:3/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__16959463500015053299<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:512/input[2]:12/input[3]:12/filter_count:1024/filter_height:3/filter_width:3/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__16959463500015053299<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:512/input[2]:12/input[3]:12/filter_count:1024/filter_height:3/filter_width:3/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__16959463500015053299<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:512/input[2]:12/input[3]:12/filter_count:1024/filter_height:3/filter_width:3/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__13106884104705623427<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:64/input[2]:56/input[3]:56/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__13106884104705623427<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:64/input[2]:56/input[3]:56/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__13106884104705623427<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:64/input[2]:56/input[3]:56/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__13106884104705623427<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:64/input[2]:56/input[3]:56/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__13106884104705623427<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:64/input[2]:56/input[3]:56/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__13106884104705623427<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:64/input[2]:56/input[3]:56/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__13106884104705623427<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:64/input[2]:56/input[3]:56/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__13106884104705623427<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:64/input[2]:56/input[3]:56/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__6537280592369137394<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:256/input[2]:13/input[3]:13/filter_count:384/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__6537280592369137394<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:256/input[2]:13/input[3]:13/filter_count:384/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__6537280592369137394<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:256/input[2]:13/input[3]:13/filter_count:384/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__6537280592369137394<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:256/input[2]:13/input[3]:13/filter_count:384/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__6537280592369137394<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:256/input[2]:13/input[3]:13/filter_count:384/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__6537280592369137394<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:256/input[2]:13/input[3]:13/filter_count:384/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__6537280592369137394<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:256/input[2]:13/input[3]:13/filter_count:384/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__6537280592369137394<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:256/input[2]:13/input[3]:13/filter_count:384/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__5774194195527126088<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:480/input[2]:14/input[3]:14/filter_count:96/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__5774194195527126088<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:480/input[2]:14/input[3]:14/filter_count:96/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__5774194195527126088<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:480/input[2]:14/input[3]:14/filter_count:96/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__5774194195527126088<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:480/input[2]:14/input[3]:14/filter_count:96/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__5774194195527126088<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:480/input[2]:14/input[3]:14/filter_count:96/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__5774194195527126088<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:480/input[2]:14/input[3]:14/filter_count:96/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__5774194195527126088<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:480/input[2]:14/input[3]:14/filter_count:96/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__5774194195527126088<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:480/input[2]:14/input[3]:14/filter_count:96/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__16018768463980303013<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:1024/input[2]:7/input[3]:7/filter_count:192/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__16018768463980303013<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:1024/input[2]:7/input[3]:7/filter_count:192/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__16018768463980303013<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:1024/input[2]:7/input[3]:7/filter_count:192/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__16018768463980303013<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:1024/input[2]:7/input[3]:7/filter_count:192/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__16018768463980303013<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:1024/input[2]:7/input[3]:7/filter_count:192/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__16018768463980303013<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:1024/input[2]:7/input[3]:7/filter_count:192/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__16018768463980303013<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:1024/input[2]:7/input[3]:7/filter_count:192/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__16018768463980303013<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:1024/input[2]:7/input[3]:7/filter_count:192/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__2679300359503704121<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:256/input[2]:14/input[3]:14/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__2679300359503704121<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:256/input[2]:14/input[3]:14/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__2679300359503704121<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:256/input[2]:14/input[3]:14/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__2679300359503704121<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:256/input[2]:14/input[3]:14/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__2679300359503704121<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:256/input[2]:14/input[3]:14/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__2679300359503704121<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:256/input[2]:14/input[3]:14/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__2679300359503704121<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:256/input[2]:14/input[3]:14/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__2679300359503704121<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:256/input[2]:14/input[3]:14/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__10328384754174181247<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__10328384754174181247<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__10328384754174181247<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__10328384754174181247<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__10328384754174181247<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__10328384754174181247<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__10328384754174181247<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__10328384754174181247<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__16638512679836844052<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:512/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__16638512679836844052<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:512/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__16638512679836844052<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:512/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__16638512679836844052<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:512/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__16638512679836844052<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:512/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__16638512679836844052<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:512/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__16638512679836844052<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:512/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__16638512679836844052<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:512/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__4287056191271545717<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:2048/input[2]:100/input[3]:100/filter_count:304/filter_height:3/filter_width:3/pad_height:24/pad_width:24/stride_height:1/stride_width:1/dilation_height:24/dilation_width:24/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD failed to cudnnSetTensor4dDescriptor",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__4287056191271545717<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:2048/input[2]:100/input[3]:100/filter_count:304/filter_height:3/filter_width:3/pad_height:24/pad_width:24/stride_height:1/stride_width:1/dilation_height:24/dilation_width:24/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD failed to cudnnSetTensor4dDescriptor",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__4287056191271545717<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:2048/input[2]:100/input[3]:100/filter_count:304/filter_height:3/filter_width:3/pad_height:24/pad_width:24/stride_height:1/stride_width:1/dilation_height:24/dilation_width:24/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD failed to cudnnSetTensor4dDescriptor",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__4287056191271545717<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:2048/input[2]:100/input[3]:100/filter_count:304/filter_height:3/filter_width:3/pad_height:24/pad_width:24/stride_height:1/stride_width:1/dilation_height:24/dilation_width:24/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD failed to cudnnSetTensor4dDescriptor",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__4287056191271545717<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:2048/input[2]:100/input[3]:100/filter_count:304/filter_height:3/filter_width:3/pad_height:24/pad_width:24/stride_height:1/stride_width:1/dilation_height:24/dilation_width:24/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD failed to cudnnSetTensor4dDescriptor",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__4287056191271545717<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:2048/input[2]:100/input[3]:100/filter_count:304/filter_height:3/filter_width:3/pad_height:24/pad_width:24/stride_height:1/stride_width:1/dilation_height:24/dilation_width:24/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD failed to cudnnSetTensor4dDescriptor",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__4287056191271545717<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:2048/input[2]:100/input[3]:100/filter_count:304/filter_height:3/filter_width:3/pad_height:24/pad_width:24/stride_height:1/stride_width:1/dilation_height:24/dilation_width:24/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD failed to cudnnSetTensor4dDescriptor",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__4287056191271545717<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:2048/input[2]:100/input[3]:100/filter_count:304/filter_height:3/filter_width:3/pad_height:24/pad_width:24/stride_height:1/stride_width:1/dilation_height:24/dilation_width:24/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD failed to cudnnSetTensor4dDescriptor",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__12161057706613040064<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:256/input[2]:14/input[3]:14/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__12161057706613040064<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:256/input[2]:14/input[3]:14/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__12161057706613040064<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:256/input[2]:14/input[3]:14/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__12161057706613040064<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:256/input[2]:14/input[3]:14/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__12161057706613040064<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:256/input[2]:14/input[3]:14/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__12161057706613040064<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:256/input[2]:14/input[3]:14/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__12161057706613040064<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:256/input[2]:14/input[3]:14/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__12161057706613040064<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:256/input[2]:14/input[3]:14/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__13980355697479897695<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:512/input[2]:28/input[3]:28/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__13980355697479897695<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:512/input[2]:28/input[3]:28/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__13980355697479897695<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:512/input[2]:28/input[3]:28/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__13980355697479897695<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:512/input[2]:28/input[3]:28/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__13980355697479897695<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:512/input[2]:28/input[3]:28/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__13980355697479897695<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:512/input[2]:28/input[3]:28/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__13980355697479897695<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:512/input[2]:28/input[3]:28/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__13980355697479897695<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:512/input[2]:28/input[3]:28/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__12301558193333996840<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__12301558193333996840<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__12301558193333996840<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__12301558193333996840<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__12301558193333996840<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__12301558193333996840<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__12301558193333996840<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__12301558193333996840<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__1697129041833138106<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__1697129041833138106<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__1697129041833138106<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__1697129041833138106<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__1697129041833138106<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__1697129041833138106<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__1697129041833138106<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__1697129041833138106<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__8586302975266953862<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:7/filter_width:7/pad_height:3/pad_width:3/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__8586302975266953862<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:7/filter_width:7/pad_height:3/pad_width:3/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__8586302975266953862<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:7/filter_width:7/pad_height:3/pad_width:3/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__8586302975266953862<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:7/filter_width:7/pad_height:3/pad_width:3/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__8586302975266953862<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:7/filter_width:7/pad_height:3/pad_width:3/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__8586302975266953862<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:7/filter_width:7/pad_height:3/pad_width:3/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__8586302975266953862<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:7/filter_width:7/pad_height:3/pad_width:3/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__8586302975266953862<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:7/filter_width:7/pad_height:3/pad_width:3/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__14579276858520636494<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:64/input[2]:112/input[3]:112/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__14579276858520636494<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:64/input[2]:112/input[3]:112/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__14579276858520636494<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:64/input[2]:112/input[3]:112/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__14579276858520636494<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:64/input[2]:112/input[3]:112/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__14579276858520636494<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:64/input[2]:112/input[3]:112/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__14579276858520636494<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:64/input[2]:112/input[3]:112/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__14579276858520636494<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:64/input[2]:112/input[3]:112/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__14579276858520636494<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:64/input[2]:112/input[3]:112/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__13168397564478026210<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:512/input[2]:28/input[3]:28/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__13168397564478026210<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:512/input[2]:28/input[3]:28/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__13168397564478026210<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:512/input[2]:28/input[3]:28/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__13168397564478026210<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:512/input[2]:28/input[3]:28/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__13168397564478026210<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:512/input[2]:28/input[3]:28/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__13168397564478026210<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:512/input[2]:28/input[3]:28/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__13168397564478026210<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:512/input[2]:28/input[3]:28/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__13168397564478026210<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:512/input[2]:28/input[3]:28/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__7864552091543666003<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:64/input[2]:112/input[3]:112/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__7864552091543666003<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:64/input[2]:112/input[3]:112/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__7864552091543666003<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:64/input[2]:112/input[3]:112/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__7864552091543666003<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:64/input[2]:112/input[3]:112/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__7864552091543666003<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:64/input[2]:112/input[3]:112/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__7864552091543666003<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:64/input[2]:112/input[3]:112/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__7864552091543666003<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:64/input[2]:112/input[3]:112/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_FLOAT32__BatchSize_128__7864552091543666003<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:64/input[2]:112/input[3]:112/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__5883824584100407201<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:1/input[1]:112/input[2]:28/input[3]:28/filter_count:112/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:4/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__5883824584100407201<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:1/input[1]:112/input[2]:28/input[3]:28/filter_count:112/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:4/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__5883824584100407201<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:1/input[1]:112/input[2]:28/input[3]:28/filter_count:112/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:4/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__5883824584100407201<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:1/input[1]:112/input[2]:28/input[3]:28/filter_count:112/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:4/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__5883824584100407201<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:1/input[1]:112/input[2]:28/input[3]:28/filter_count:112/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:4/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__5883824584100407201<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:1/input[1]:112/input[2]:28/input[3]:28/filter_count:112/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:4/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__5883824584100407201<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:1/input[1]:112/input[2]:28/input[3]:28/filter_count:112/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:4/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__5883824584100407201<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:1/input[1]:112/input[2]:28/input[3]:28/filter_count:112/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:4/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__7294631967447529929<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:16/input[2]:55/input[3]:55/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__7294631967447529929<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:16/input[2]:55/input[3]:55/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__7294631967447529929<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:16/input[2]:55/input[3]:55/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__7294631967447529929<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:16/input[2]:55/input[3]:55/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__7294631967447529929<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:16/input[2]:55/input[3]:55/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__7294631967447529929<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:16/input[2]:55/input[3]:55/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__7294631967447529929<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:16/input[2]:55/input[3]:55/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__7294631967447529929<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:16/input[2]:55/input[3]:55/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__17401534409097948837<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:16/input[2]:14/input[3]:14/filter_count:48/filter_height:5/filter_width:5/pad_height:2/pad_width:2/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__17401534409097948837<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:16/input[2]:14/input[3]:14/filter_count:48/filter_height:5/filter_width:5/pad_height:2/pad_width:2/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__17401534409097948837<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:16/input[2]:14/input[3]:14/filter_count:48/filter_height:5/filter_width:5/pad_height:2/pad_width:2/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__17401534409097948837<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:16/input[2]:14/input[3]:14/filter_count:48/filter_height:5/filter_width:5/pad_height:2/pad_width:2/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__17401534409097948837<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:16/input[2]:14/input[3]:14/filter_count:48/filter_height:5/filter_width:5/pad_height:2/pad_width:2/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__17401534409097948837<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:16/input[2]:14/input[3]:14/filter_count:48/filter_height:5/filter_width:5/pad_height:2/pad_width:2/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__17401534409097948837<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:16/input[2]:14/input[3]:14/filter_count:48/filter_height:5/filter_width:5/pad_height:2/pad_width:2/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__17401534409097948837<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:16/input[2]:14/input[3]:14/filter_count:48/filter_height:5/filter_width:5/pad_height:2/pad_width:2/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__16929402243370612992<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:1/input[1]:272/input[2]:14/input[3]:14/filter_count:272/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:272/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__16929402243370612992<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:1/input[1]:272/input[2]:14/input[3]:14/filter_count:272/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:272/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__16929402243370612992<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:1/input[1]:272/input[2]:14/input[3]:14/filter_count:272/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:272/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__16929402243370612992<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:1/input[1]:272/input[2]:14/input[3]:14/filter_count:272/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:272/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__16929402243370612992<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:1/input[1]:272/input[2]:14/input[3]:14/filter_count:272/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:272/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__16929402243370612992<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:1/input[1]:272/input[2]:14/input[3]:14/filter_count:272/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:272/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__16929402243370612992<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:1/input[1]:272/input[2]:14/input[3]:14/filter_count:272/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:272/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__16929402243370612992<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:1/input[1]:272/input[2]:14/input[3]:14/filter_count:272/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:272/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__4609750275717855604<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:112/input[2]:14/input[3]:14/filter_count:224/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__4609750275717855604<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:112/input[2]:14/input[3]:14/filter_count:224/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__4609750275717855604<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:112/input[2]:14/input[3]:14/filter_count:224/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__4609750275717855604<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:112/input[2]:14/input[3]:14/filter_count:224/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__4609750275717855604<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:112/input[2]:14/input[3]:14/filter_count:224/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__4609750275717855604<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:112/input[2]:14/input[3]:14/filter_count:224/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__4609750275717855604<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:112/input[2]:14/input[3]:14/filter_count:224/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__4609750275717855604<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:112/input[2]:14/input[3]:14/filter_count:224/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__7055772436135724031<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:1/input[1]:832/input[2]:6/input[3]:6/filter_count:384/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__7055772436135724031<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:1/input[1]:832/input[2]:6/input[3]:6/filter_count:384/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__7055772436135724031<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:1/input[1]:832/input[2]:6/input[3]:6/filter_count:384/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__7055772436135724031<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:1/input[1]:832/input[2]:6/input[3]:6/filter_count:384/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__7055772436135724031<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:1/input[1]:832/input[2]:6/input[3]:6/filter_count:384/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__7055772436135724031<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:1/input[1]:832/input[2]:6/input[3]:6/filter_count:384/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__7055772436135724031<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:1/input[1]:832/input[2]:6/input[3]:6/filter_count:384/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__7055772436135724031<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:1/input[1]:832/input[2]:6/input[3]:6/filter_count:384/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__15814697207591492543<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:512/input[2]:14/input[3]:14/filter_count:24/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__15814697207591492543<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:512/input[2]:14/input[3]:14/filter_count:24/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__15814697207591492543<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:512/input[2]:14/input[3]:14/filter_count:24/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__15814697207591492543<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:512/input[2]:14/input[3]:14/filter_count:24/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__15814697207591492543<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:512/input[2]:14/input[3]:14/filter_count:24/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__15814697207591492543<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:512/input[2]:14/input[3]:14/filter_count:24/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__15814697207591492543<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:512/input[2]:14/input[3]:14/filter_count:24/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__15814697207591492543<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:512/input[2]:14/input[3]:14/filter_count:24/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__1345244070712327150<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:96/input[2]:14/input[3]:14/filter_count:208/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__1345244070712327150<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:96/input[2]:14/input[3]:14/filter_count:208/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__1345244070712327150<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:96/input[2]:14/input[3]:14/filter_count:208/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__1345244070712327150<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:96/input[2]:14/input[3]:14/filter_count:208/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__1345244070712327150<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:96/input[2]:14/input[3]:14/filter_count:208/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__1345244070712327150<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:96/input[2]:14/input[3]:14/filter_count:208/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__1345244070712327150<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:96/input[2]:14/input[3]:14/filter_count:208/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__1345244070712327150<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:96/input[2]:14/input[3]:14/filter_count:208/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__13545769056383518144<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:48/input[2]:13/input[3]:13/filter_count:192/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__13545769056383518144<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:48/input[2]:13/input[3]:13/filter_count:192/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__13545769056383518144<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:48/input[2]:13/input[3]:13/filter_count:192/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__13545769056383518144<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:48/input[2]:13/input[3]:13/filter_count:192/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__13545769056383518144<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:48/input[2]:13/input[3]:13/filter_count:192/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__13545769056383518144<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:48/input[2]:13/input[3]:13/filter_count:192/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__13545769056383518144<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:48/input[2]:13/input[3]:13/filter_count:192/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__13545769056383518144<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:48/input[2]:13/input[3]:13/filter_count:192/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__17532219393405842464<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:64/input[2]:13/input[3]:13/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__17532219393405842464<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:64/input[2]:13/input[3]:13/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__17532219393405842464<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:64/input[2]:13/input[3]:13/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__17532219393405842464<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:64/input[2]:13/input[3]:13/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__17532219393405842464<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:64/input[2]:13/input[3]:13/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__17532219393405842464<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:64/input[2]:13/input[3]:13/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__17532219393405842464<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:64/input[2]:13/input[3]:13/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__17532219393405842464<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:64/input[2]:13/input[3]:13/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__2973496187577443933<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:96/input[2]:54/input[3]:54/filter_count:256/filter_height:5/filter_width:5/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__2973496187577443933<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:96/input[2]:54/input[3]:54/filter_count:256/filter_height:5/filter_width:5/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__2973496187577443933<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:96/input[2]:54/input[3]:54/filter_count:256/filter_height:5/filter_width:5/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__2973496187577443933<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:96/input[2]:54/input[3]:54/filter_count:256/filter_height:5/filter_width:5/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__2973496187577443933<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:96/input[2]:54/input[3]:54/filter_count:256/filter_height:5/filter_width:5/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__2973496187577443933<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:96/input[2]:54/input[3]:54/filter_count:256/filter_height:5/filter_width:5/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__2973496187577443933<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:96/input[2]:54/input[3]:54/filter_count:256/filter_height:5/filter_width:5/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__2973496187577443933<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:96/input[2]:54/input[3]:54/filter_count:256/filter_height:5/filter_width:5/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__5651110032271641871<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:1/input[1]:128/input[2]:56/input[3]:56/filter_count:32/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__5651110032271641871<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:1/input[1]:128/input[2]:56/input[3]:56/filter_count:32/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__5651110032271641871<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:1/input[1]:128/input[2]:56/input[3]:56/filter_count:32/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__5651110032271641871<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:1/input[1]:128/input[2]:56/input[3]:56/filter_count:32/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__5651110032271641871<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:1/input[1]:128/input[2]:56/input[3]:56/filter_count:32/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__5651110032271641871<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:1/input[1]:128/input[2]:56/input[3]:56/filter_count:32/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__5651110032271641871<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:1/input[1]:128/input[2]:56/input[3]:56/filter_count:32/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__5651110032271641871<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:1/input[1]:128/input[2]:56/input[3]:56/filter_count:32/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__6246203362482580367<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:256/input[2]:12/input[3]:12/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__6246203362482580367<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:256/input[2]:12/input[3]:12/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__6246203362482580367<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:256/input[2]:12/input[3]:12/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__6246203362482580367<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:256/input[2]:12/input[3]:12/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__6246203362482580367<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:256/input[2]:12/input[3]:12/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__6246203362482580367<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:256/input[2]:12/input[3]:12/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__6246203362482580367<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:256/input[2]:12/input[3]:12/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__6246203362482580367<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:256/input[2]:12/input[3]:12/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__10767104277952499077<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:1/input[1]:256/input[2]:27/input[3]:27/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__10767104277952499077<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:1/input[1]:256/input[2]:27/input[3]:27/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__10767104277952499077<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:1/input[1]:256/input[2]:27/input[3]:27/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__10767104277952499077<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:1/input[1]:256/input[2]:27/input[3]:27/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__10767104277952499077<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:1/input[1]:256/input[2]:27/input[3]:27/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__10767104277952499077<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:1/input[1]:256/input[2]:27/input[3]:27/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__10767104277952499077<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:1/input[1]:256/input[2]:27/input[3]:27/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__10767104277952499077<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:1/input[1]:256/input[2]:27/input[3]:27/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__15699825022673145363<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:1/input[1]:288/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__15699825022673145363<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:1/input[1]:288/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__15699825022673145363<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:1/input[1]:288/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__15699825022673145363<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:1/input[1]:288/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__15699825022673145363<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:1/input[1]:288/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__15699825022673145363<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:1/input[1]:288/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__15699825022673145363<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:1/input[1]:288/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__15699825022673145363<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:1/input[1]:288/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__5291984476540063523<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:32/input[2]:112/input[3]:112/filter_count:32/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:32/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__5291984476540063523<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:32/input[2]:112/input[3]:112/filter_count:32/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:32/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__5291984476540063523<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:32/input[2]:112/input[3]:112/filter_count:32/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:32/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__5291984476540063523<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:32/input[2]:112/input[3]:112/filter_count:32/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:32/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__5291984476540063523<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:32/input[2]:112/input[3]:112/filter_count:32/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:32/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__5291984476540063523<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:32/input[2]:112/input[3]:112/filter_count:32/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:32/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__5291984476540063523<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:32/input[2]:112/input[3]:112/filter_count:32/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:32/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__5291984476540063523<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:32/input[2]:112/input[3]:112/filter_count:32/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:32/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__7482878634220941498<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:1/input[1]:16/input[2]:27/input[3]:27/filter_count:32/filter_height:5/filter_width:5/pad_height:2/pad_width:2/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__7482878634220941498<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:1/input[1]:16/input[2]:27/input[3]:27/filter_count:32/filter_height:5/filter_width:5/pad_height:2/pad_width:2/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__7482878634220941498<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:1/input[1]:16/input[2]:27/input[3]:27/filter_count:32/filter_height:5/filter_width:5/pad_height:2/pad_width:2/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__7482878634220941498<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:1/input[1]:16/input[2]:27/input[3]:27/filter_count:32/filter_height:5/filter_width:5/pad_height:2/pad_width:2/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__7482878634220941498<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:1/input[1]:16/input[2]:27/input[3]:27/filter_count:32/filter_height:5/filter_width:5/pad_height:2/pad_width:2/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__7482878634220941498<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:1/input[1]:16/input[2]:27/input[3]:27/filter_count:32/filter_height:5/filter_width:5/pad_height:2/pad_width:2/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__7482878634220941498<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:1/input[1]:16/input[2]:27/input[3]:27/filter_count:32/filter_height:5/filter_width:5/pad_height:2/pad_width:2/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__7482878634220941498<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:1/input[1]:16/input[2]:27/input[3]:27/filter_count:32/filter_height:5/filter_width:5/pad_height:2/pad_width:2/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__6009562148837156860<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:3/input[2]:224/input[3]:224/filter_count:96/filter_height:11/filter_width:11/pad_height:0/pad_width:0/stride_height:4/stride_width:4/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__6009562148837156860<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:3/input[2]:224/input[3]:224/filter_count:96/filter_height:11/filter_width:11/pad_height:0/pad_width:0/stride_height:4/stride_width:4/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__6009562148837156860<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:3/input[2]:224/input[3]:224/filter_count:96/filter_height:11/filter_width:11/pad_height:0/pad_width:0/stride_height:4/stride_width:4/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__6009562148837156860<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:3/input[2]:224/input[3]:224/filter_count:96/filter_height:11/filter_width:11/pad_height:0/pad_width:0/stride_height:4/stride_width:4/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__6009562148837156860<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:3/input[2]:224/input[3]:224/filter_count:96/filter_height:11/filter_width:11/pad_height:0/pad_width:0/stride_height:4/stride_width:4/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__6009562148837156860<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:3/input[2]:224/input[3]:224/filter_count:96/filter_height:11/filter_width:11/pad_height:0/pad_width:0/stride_height:4/stride_width:4/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__6009562148837156860<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:3/input[2]:224/input[3]:224/filter_count:96/filter_height:11/filter_width:11/pad_height:0/pad_width:0/stride_height:4/stride_width:4/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__6009562148837156860<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:3/input[2]:224/input[3]:224/filter_count:96/filter_height:11/filter_width:11/pad_height:0/pad_width:0/stride_height:4/stride_width:4/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__14027509288488142173<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:3/filter_width:3/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__14027509288488142173<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:3/filter_width:3/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__14027509288488142173<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:3/filter_width:3/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__14027509288488142173<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:3/filter_width:3/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__14027509288488142173<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:3/filter_width:3/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__14027509288488142173<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:3/filter_width:3/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__14027509288488142173<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:3/filter_width:3/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__14027509288488142173<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:3/filter_width:3/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__13364002913789469484<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:1/input[1]:256/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__13364002913789469484<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:1/input[1]:256/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__13364002913789469484<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:1/input[1]:256/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__13364002913789469484<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:1/input[1]:256/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__13364002913789469484<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:1/input[1]:256/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__13364002913789469484<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:1/input[1]:256/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__13364002913789469484<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:1/input[1]:256/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__13364002913789469484<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:1/input[1]:256/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__12808394306551760110<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:384/input[2]:12/input[3]:12/filter_count:384/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:2/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__12808394306551760110<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:384/input[2]:12/input[3]:12/filter_count:384/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:2/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__12808394306551760110<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:384/input[2]:12/input[3]:12/filter_count:384/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:2/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__12808394306551760110<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:384/input[2]:12/input[3]:12/filter_count:384/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:2/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__12808394306551760110<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:384/input[2]:12/input[3]:12/filter_count:384/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:2/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__12808394306551760110<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:384/input[2]:12/input[3]:12/filter_count:384/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:2/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__12808394306551760110<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:384/input[2]:12/input[3]:12/filter_count:384/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:2/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__12808394306551760110<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:384/input[2]:12/input[3]:12/filter_count:384/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:2/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__12970742691583392398<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:1/input[1]:480/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__12970742691583392398<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:1/input[1]:480/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__12970742691583392398<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:1/input[1]:480/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__12970742691583392398<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:1/input[1]:480/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__12970742691583392398<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:1/input[1]:480/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__12970742691583392398<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:1/input[1]:480/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__12970742691583392398<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:1/input[1]:480/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__12970742691583392398<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:1/input[1]:480/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__98258492131154788<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:528/input[2]:14/input[3]:14/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__98258492131154788<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:528/input[2]:14/input[3]:14/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__98258492131154788<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:528/input[2]:14/input[3]:14/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__98258492131154788<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:528/input[2]:14/input[3]:14/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__98258492131154788<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:528/input[2]:14/input[3]:14/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__98258492131154788<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:528/input[2]:14/input[3]:14/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__98258492131154788<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:528/input[2]:14/input[3]:14/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__98258492131154788<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:528/input[2]:14/input[3]:14/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__15899585116456914216<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:128/input[2]:55/input[3]:55/filter_count:16/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__15899585116456914216<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:128/input[2]:55/input[3]:55/filter_count:16/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__15899585116456914216<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:128/input[2]:55/input[3]:55/filter_count:16/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__15899585116456914216<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:128/input[2]:55/input[3]:55/filter_count:16/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__15899585116456914216<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:128/input[2]:55/input[3]:55/filter_count:16/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__15899585116456914216<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:128/input[2]:55/input[3]:55/filter_count:16/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__15899585116456914216<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:128/input[2]:55/input[3]:55/filter_count:16/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__15899585116456914216<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:128/input[2]:55/input[3]:55/filter_count:16/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__3718474585642574453<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:1/input[1]:672/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__3718474585642574453<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:1/input[1]:672/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__3718474585642574453<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:1/input[1]:672/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__3718474585642574453<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:1/input[1]:672/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__3718474585642574453<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:1/input[1]:672/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__3718474585642574453<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:1/input[1]:672/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__3718474585642574453<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:1/input[1]:672/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__3718474585642574453<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:1/input[1]:672/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__16308745601208923702<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:832/input[2]:7/input[3]:7/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__16308745601208923702<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:832/input[2]:7/input[3]:7/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__16308745601208923702<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:832/input[2]:7/input[3]:7/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__16308745601208923702<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:832/input[2]:7/input[3]:7/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__16308745601208923702<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:832/input[2]:7/input[3]:7/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__16308745601208923702<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:832/input[2]:7/input[3]:7/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__16308745601208923702<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:832/input[2]:7/input[3]:7/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__16308745601208923702<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:832/input[2]:7/input[3]:7/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__11528566747172749427<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:1/input[1]:800/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__11528566747172749427<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:1/input[1]:800/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__11528566747172749427<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:1/input[1]:800/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__11528566747172749427<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:1/input[1]:800/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__11528566747172749427<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:1/input[1]:800/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__11528566747172749427<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:1/input[1]:800/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__11528566747172749427<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:1/input[1]:800/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__11528566747172749427<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:1/input[1]:800/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__18346765285892052204<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:1/input[1]:416/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__18346765285892052204<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:1/input[1]:416/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__18346765285892052204<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:1/input[1]:416/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__18346765285892052204<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:1/input[1]:416/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__18346765285892052204<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:1/input[1]:416/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__18346765285892052204<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:1/input[1]:416/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__18346765285892052204<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:1/input[1]:416/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__18346765285892052204<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:1/input[1]:416/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__1253691686172694958<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:832/input[2]:7/input[3]:7/filter_count:384/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__1253691686172694958<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:832/input[2]:7/input[3]:7/filter_count:384/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__1253691686172694958<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:832/input[2]:7/input[3]:7/filter_count:384/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__1253691686172694958<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:832/input[2]:7/input[3]:7/filter_count:384/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__1253691686172694958<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:832/input[2]:7/input[3]:7/filter_count:384/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__1253691686172694958<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:832/input[2]:7/input[3]:7/filter_count:384/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__1253691686172694958<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:832/input[2]:7/input[3]:7/filter_count:384/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__1253691686172694958<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:832/input[2]:7/input[3]:7/filter_count:384/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__1434175747540207744<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:64/input[2]:28/input[3]:28/filter_count:384/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__1434175747540207744<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:64/input[2]:28/input[3]:28/filter_count:384/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__1434175747540207744<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:64/input[2]:28/input[3]:28/filter_count:384/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__1434175747540207744<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:64/input[2]:28/input[3]:28/filter_count:384/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__1434175747540207744<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:64/input[2]:28/input[3]:28/filter_count:384/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__1434175747540207744<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:64/input[2]:28/input[3]:28/filter_count:384/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__1434175747540207744<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:64/input[2]:28/input[3]:28/filter_count:384/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__1434175747540207744<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:64/input[2]:28/input[3]:28/filter_count:384/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__17727344372519926108<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:256/input[2]:199/input[3]:199/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__17727344372519926108<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:256/input[2]:199/input[3]:199/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__17727344372519926108<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:256/input[2]:199/input[3]:199/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__17727344372519926108<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:256/input[2]:199/input[3]:199/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__17727344372519926108<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:256/input[2]:199/input[3]:199/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__17727344372519926108<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:256/input[2]:199/input[3]:199/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__17727344372519926108<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:256/input[2]:199/input[3]:199/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__17727344372519926108<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:256/input[2]:199/input[3]:199/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__8578622682347888505<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:384/input[2]:14/input[3]:14/filter_count:96/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__8578622682347888505<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:384/input[2]:14/input[3]:14/filter_count:96/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__8578622682347888505<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:384/input[2]:14/input[3]:14/filter_count:96/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__8578622682347888505<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:384/input[2]:14/input[3]:14/filter_count:96/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__8578622682347888505<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:384/input[2]:14/input[3]:14/filter_count:96/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__8578622682347888505<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:384/input[2]:14/input[3]:14/filter_count:96/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__8578622682347888505<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:384/input[2]:14/input[3]:14/filter_count:96/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__8578622682347888505<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:384/input[2]:14/input[3]:14/filter_count:96/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__12279251011610599773<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:64/input[2]:64/input[3]:64/filter_count:64/filter_height:3/filter_width:3/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__12279251011610599773<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:64/input[2]:64/input[3]:64/filter_count:64/filter_height:3/filter_width:3/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__12279251011610599773<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:64/input[2]:64/input[3]:64/filter_count:64/filter_height:3/filter_width:3/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__12279251011610599773<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:64/input[2]:64/input[3]:64/filter_count:64/filter_height:3/filter_width:3/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__12279251011610599773<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:64/input[2]:64/input[3]:64/filter_count:64/filter_height:3/filter_width:3/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__12279251011610599773<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:64/input[2]:64/input[3]:64/filter_count:64/filter_height:3/filter_width:3/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__12279251011610599773<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:64/input[2]:64/input[3]:64/filter_count:64/filter_height:3/filter_width:3/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__12279251011610599773<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:64/input[2]:64/input[3]:64/filter_count:64/filter_height:3/filter_width:3/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__2072116609808074348<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:576/input[2]:7/input[3]:7/filter_count:160/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__2072116609808074348<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:576/input[2]:7/input[3]:7/filter_count:160/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__2072116609808074348<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:576/input[2]:7/input[3]:7/filter_count:160/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__2072116609808074348<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:576/input[2]:7/input[3]:7/filter_count:160/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__2072116609808074348<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:576/input[2]:7/input[3]:7/filter_count:160/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__2072116609808074348<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:576/input[2]:7/input[3]:7/filter_count:160/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__2072116609808074348<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:576/input[2]:7/input[3]:7/filter_count:160/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__2072116609808074348<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:576/input[2]:7/input[3]:7/filter_count:160/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__10591761978794142303<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:960/input[2]:7/input[3]:7/filter_count:160/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__10591761978794142303<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:960/input[2]:7/input[3]:7/filter_count:160/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__10591761978794142303<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:960/input[2]:7/input[3]:7/filter_count:160/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__10591761978794142303<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:960/input[2]:7/input[3]:7/filter_count:160/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__10591761978794142303<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:960/input[2]:7/input[3]:7/filter_count:160/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__10591761978794142303<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:960/input[2]:7/input[3]:7/filter_count:160/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__10591761978794142303<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:960/input[2]:7/input[3]:7/filter_count:160/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__10591761978794142303<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:960/input[2]:7/input[3]:7/filter_count:160/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__6721434084661973125<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:1/input[1]:928/input[2]:7/input[3]:7/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__6721434084661973125<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:1/input[1]:928/input[2]:7/input[3]:7/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__6721434084661973125<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:1/input[1]:928/input[2]:7/input[3]:7/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__6721434084661973125<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:1/input[1]:928/input[2]:7/input[3]:7/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__6721434084661973125<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:1/input[1]:928/input[2]:7/input[3]:7/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__6721434084661973125<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:1/input[1]:928/input[2]:7/input[3]:7/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__6721434084661973125<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:1/input[1]:928/input[2]:7/input[3]:7/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__6721434084661973125<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:1/input[1]:928/input[2]:7/input[3]:7/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__9262822633063204931<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:960/input[2]:7/input[3]:7/filter_count:320/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__9262822633063204931<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:960/input[2]:7/input[3]:7/filter_count:320/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__9262822633063204931<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:960/input[2]:7/input[3]:7/filter_count:320/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__9262822633063204931<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:960/input[2]:7/input[3]:7/filter_count:320/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__9262822633063204931<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:960/input[2]:7/input[3]:7/filter_count:320/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__9262822633063204931<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:960/input[2]:7/input[3]:7/filter_count:320/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__9262822633063204931<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:960/input[2]:7/input[3]:7/filter_count:320/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__9262822633063204931<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:960/input[2]:7/input[3]:7/filter_count:320/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__13656709652785473624<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:192/input[2]:28/input[3]:28/filter_count:16/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__13656709652785473624<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:192/input[2]:28/input[3]:28/filter_count:16/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__13656709652785473624<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:192/input[2]:28/input[3]:28/filter_count:16/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__13656709652785473624<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:192/input[2]:28/input[3]:28/filter_count:16/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__13656709652785473624<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:192/input[2]:28/input[3]:28/filter_count:16/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__13656709652785473624<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:192/input[2]:28/input[3]:28/filter_count:16/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__13656709652785473624<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:192/input[2]:28/input[3]:28/filter_count:16/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__13656709652785473624<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:192/input[2]:28/input[3]:28/filter_count:16/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__6474718317458539888<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:1/input[1]:160/input[2]:13/input[3]:13/filter_count:320/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__6474718317458539888<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:1/input[1]:160/input[2]:13/input[3]:13/filter_count:320/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__6474718317458539888<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:1/input[1]:160/input[2]:13/input[3]:13/filter_count:320/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__6474718317458539888<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:1/input[1]:160/input[2]:13/input[3]:13/filter_count:320/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__6474718317458539888<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:1/input[1]:160/input[2]:13/input[3]:13/filter_count:320/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__6474718317458539888<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:1/input[1]:160/input[2]:13/input[3]:13/filter_count:320/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__6474718317458539888<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:1/input[1]:160/input[2]:13/input[3]:13/filter_count:320/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__6474718317458539888<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:1/input[1]:160/input[2]:13/input[3]:13/filter_count:320/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__16040745474523587930<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:1/input[1]:528/input[2]:13/input[3]:13/filter_count:32/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__16040745474523587930<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:1/input[1]:528/input[2]:13/input[3]:13/filter_count:32/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__16040745474523587930<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:1/input[1]:528/input[2]:13/input[3]:13/filter_count:32/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__16040745474523587930<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:1/input[1]:528/input[2]:13/input[3]:13/filter_count:32/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__16040745474523587930<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:1/input[1]:528/input[2]:13/input[3]:13/filter_count:32/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__16040745474523587930<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:1/input[1]:528/input[2]:13/input[3]:13/filter_count:32/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__16040745474523587930<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:1/input[1]:528/input[2]:13/input[3]:13/filter_count:32/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__16040745474523587930<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:1/input[1]:528/input[2]:13/input[3]:13/filter_count:32/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__13240503702556320632<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:1/input[1]:992/input[2]:7/input[3]:7/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__13240503702556320632<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:1/input[1]:992/input[2]:7/input[3]:7/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__13240503702556320632<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:1/input[1]:992/input[2]:7/input[3]:7/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__13240503702556320632<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:1/input[1]:992/input[2]:7/input[3]:7/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__13240503702556320632<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:1/input[1]:992/input[2]:7/input[3]:7/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__13240503702556320632<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:1/input[1]:992/input[2]:7/input[3]:7/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__13240503702556320632<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:1/input[1]:992/input[2]:7/input[3]:7/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__13240503702556320632<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:1/input[1]:992/input[2]:7/input[3]:7/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__9905296551043506147<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:16/input[2]:28/input[3]:28/filter_count:32/filter_height:5/filter_width:5/pad_height:2/pad_width:2/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__9905296551043506147<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:16/input[2]:28/input[3]:28/filter_count:32/filter_height:5/filter_width:5/pad_height:2/pad_width:2/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__9905296551043506147<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:16/input[2]:28/input[3]:28/filter_count:32/filter_height:5/filter_width:5/pad_height:2/pad_width:2/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__9905296551043506147<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:16/input[2]:28/input[3]:28/filter_count:32/filter_height:5/filter_width:5/pad_height:2/pad_width:2/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__9905296551043506147<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:16/input[2]:28/input[3]:28/filter_count:32/filter_height:5/filter_width:5/pad_height:2/pad_width:2/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__9905296551043506147<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:16/input[2]:28/input[3]:28/filter_count:32/filter_height:5/filter_width:5/pad_height:2/pad_width:2/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__9905296551043506147<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:16/input[2]:28/input[3]:28/filter_count:32/filter_height:5/filter_width:5/pad_height:2/pad_width:2/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__9905296551043506147<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:16/input[2]:28/input[3]:28/filter_count:32/filter_height:5/filter_width:5/pad_height:2/pad_width:2/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__6459386565734905612<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:64/input[2]:56/input[3]:56/filter_count:192/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__6459386565734905612<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:64/input[2]:56/input[3]:56/filter_count:192/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__6459386565734905612<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:64/input[2]:56/input[3]:56/filter_count:192/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__6459386565734905612<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:64/input[2]:56/input[3]:56/filter_count:192/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__6459386565734905612<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:64/input[2]:56/input[3]:56/filter_count:192/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__6459386565734905612<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:64/input[2]:56/input[3]:56/filter_count:192/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__6459386565734905612<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:64/input[2]:56/input[3]:56/filter_count:192/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__6459386565734905612<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:64/input[2]:56/input[3]:56/filter_count:192/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__749907884000792474<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:1/input[1]:768/input[2]:7/input[3]:7/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__749907884000792474<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:1/input[1]:768/input[2]:7/input[3]:7/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__749907884000792474<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:1/input[1]:768/input[2]:7/input[3]:7/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__749907884000792474<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:1/input[1]:768/input[2]:7/input[3]:7/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__749907884000792474<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:1/input[1]:768/input[2]:7/input[3]:7/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__749907884000792474<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:1/input[1]:768/input[2]:7/input[3]:7/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__749907884000792474<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:1/input[1]:768/input[2]:7/input[3]:7/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__749907884000792474<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:1/input[1]:768/input[2]:7/input[3]:7/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__11218812037149380279<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:512/input[2]:100/input[3]:100/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__11218812037149380279<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:512/input[2]:100/input[3]:100/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__11218812037149380279<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:512/input[2]:100/input[3]:100/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__11218812037149380279<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:512/input[2]:100/input[3]:100/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__11218812037149380279<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:512/input[2]:100/input[3]:100/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__11218812037149380279<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:512/input[2]:100/input[3]:100/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__11218812037149380279<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:512/input[2]:100/input[3]:100/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__11218812037149380279<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:512/input[2]:100/input[3]:100/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__8576477005427472561<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:1/input[1]:528/input[2]:13/input[3]:13/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__8576477005427472561<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:1/input[1]:528/input[2]:13/input[3]:13/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__8576477005427472561<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:1/input[1]:528/input[2]:13/input[3]:13/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__8576477005427472561<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:1/input[1]:528/input[2]:13/input[3]:13/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__8576477005427472561<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:1/input[1]:528/input[2]:13/input[3]:13/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__8576477005427472561<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:1/input[1]:528/input[2]:13/input[3]:13/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__8576477005427472561<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:1/input[1]:528/input[2]:13/input[3]:13/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__8576477005427472561<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:1/input[1]:528/input[2]:13/input[3]:13/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__1075557814309107741<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:64/input[2]:28/input[3]:28/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__1075557814309107741<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:64/input[2]:28/input[3]:28/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__1075557814309107741<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:64/input[2]:28/input[3]:28/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__1075557814309107741<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:64/input[2]:28/input[3]:28/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__1075557814309107741<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:64/input[2]:28/input[3]:28/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__1075557814309107741<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:64/input[2]:28/input[3]:28/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__1075557814309107741<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:64/input[2]:28/input[3]:28/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__1075557814309107741<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:64/input[2]:28/input[3]:28/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__124956025572928589<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:1/input[1]:832/input[2]:6/input[3]:6/filter_count:160/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__124956025572928589<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:1/input[1]:832/input[2]:6/input[3]:6/filter_count:160/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__124956025572928589<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:1/input[1]:832/input[2]:6/input[3]:6/filter_count:160/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__124956025572928589<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:1/input[1]:832/input[2]:6/input[3]:6/filter_count:160/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__124956025572928589<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:1/input[1]:832/input[2]:6/input[3]:6/filter_count:160/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__124956025572928589<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:1/input[1]:832/input[2]:6/input[3]:6/filter_count:160/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__124956025572928589<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:1/input[1]:832/input[2]:6/input[3]:6/filter_count:160/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__124956025572928589<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:1/input[1]:832/input[2]:6/input[3]:6/filter_count:160/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__15741394152993204417<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:256/input[2]:100/input[3]:100/filter_count:256/filter_height:3/filter_width:3/pad_height:5/pad_width:5/stride_height:1/stride_width:1/dilation_height:5/dilation_width:5/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__15741394152993204417<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:256/input[2]:100/input[3]:100/filter_count:256/filter_height:3/filter_width:3/pad_height:5/pad_width:5/stride_height:1/stride_width:1/dilation_height:5/dilation_width:5/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__15741394152993204417<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:256/input[2]:100/input[3]:100/filter_count:256/filter_height:3/filter_width:3/pad_height:5/pad_width:5/stride_height:1/stride_width:1/dilation_height:5/dilation_width:5/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__15741394152993204417<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:256/input[2]:100/input[3]:100/filter_count:256/filter_height:3/filter_width:3/pad_height:5/pad_width:5/stride_height:1/stride_width:1/dilation_height:5/dilation_width:5/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__15741394152993204417<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:256/input[2]:100/input[3]:100/filter_count:256/filter_height:3/filter_width:3/pad_height:5/pad_width:5/stride_height:1/stride_width:1/dilation_height:5/dilation_width:5/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__15741394152993204417<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:256/input[2]:100/input[3]:100/filter_count:256/filter_height:3/filter_width:3/pad_height:5/pad_width:5/stride_height:1/stride_width:1/dilation_height:5/dilation_width:5/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__15741394152993204417<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:256/input[2]:100/input[3]:100/filter_count:256/filter_height:3/filter_width:3/pad_height:5/pad_width:5/stride_height:1/stride_width:1/dilation_height:5/dilation_width:5/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__15741394152993204417<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:256/input[2]:100/input[3]:100/filter_count:256/filter_height:3/filter_width:3/pad_height:5/pad_width:5/stride_height:1/stride_width:1/dilation_height:5/dilation_width:5/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__13169192344929832807<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:576/input[2]:14/input[3]:14/filter_count:224/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__13169192344929832807<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:576/input[2]:14/input[3]:14/filter_count:224/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__13169192344929832807<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:576/input[2]:14/input[3]:14/filter_count:224/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__13169192344929832807<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:576/input[2]:14/input[3]:14/filter_count:224/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__13169192344929832807<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:576/input[2]:14/input[3]:14/filter_count:224/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__13169192344929832807<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:576/input[2]:14/input[3]:14/filter_count:224/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__13169192344929832807<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:576/input[2]:14/input[3]:14/filter_count:224/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__13169192344929832807<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:576/input[2]:14/input[3]:14/filter_count:224/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__6033502540376180966<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:256/input[2]:100/input[3]:100/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__6033502540376180966<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:256/input[2]:100/input[3]:100/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__6033502540376180966<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:256/input[2]:100/input[3]:100/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__6033502540376180966<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:256/input[2]:100/input[3]:100/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__6033502540376180966<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:256/input[2]:100/input[3]:100/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__6033502540376180966<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:256/input[2]:100/input[3]:100/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__6033502540376180966<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:256/input[2]:100/input[3]:100/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__6033502540376180966<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:256/input[2]:100/input[3]:100/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__4492415720741311289<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:128/input[2]:14/input[3]:14/filter_count:192/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__4492415720741311289<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:128/input[2]:14/input[3]:14/filter_count:192/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__4492415720741311289<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:128/input[2]:14/input[3]:14/filter_count:192/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__4492415720741311289<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:128/input[2]:14/input[3]:14/filter_count:192/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__4492415720741311289<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:128/input[2]:14/input[3]:14/filter_count:192/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__4492415720741311289<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:128/input[2]:14/input[3]:14/filter_count:192/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__4492415720741311289<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:128/input[2]:14/input[3]:14/filter_count:192/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__4492415720741311289<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:128/input[2]:14/input[3]:14/filter_count:192/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__16555375563811906306<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:1024/input[2]:100/input[3]:100/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD failed to cudnnSetTensor4dDescriptor",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__16555375563811906306<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:1024/input[2]:100/input[3]:100/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD failed to cudnnSetTensor4dDescriptor",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__16555375563811906306<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:1024/input[2]:100/input[3]:100/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD failed to cudnnSetTensor4dDescriptor",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__16555375563811906306<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:1024/input[2]:100/input[3]:100/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD failed to cudnnSetTensor4dDescriptor",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__16555375563811906306<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:1024/input[2]:100/input[3]:100/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD failed to cudnnSetTensor4dDescriptor",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__16555375563811906306<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:1024/input[2]:100/input[3]:100/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD failed to cudnnSetTensor4dDescriptor",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__16555375563811906306<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:1024/input[2]:100/input[3]:100/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD failed to cudnnSetTensor4dDescriptor",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__16555375563811906306<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:1024/input[2]:100/input[3]:100/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD failed to cudnnSetTensor4dDescriptor",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__17095089582642638140<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:1024/input[2]:7/input[3]:7/filter_count:160/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__17095089582642638140<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:1024/input[2]:7/input[3]:7/filter_count:160/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__17095089582642638140<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:1024/input[2]:7/input[3]:7/filter_count:160/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__17095089582642638140<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:1024/input[2]:7/input[3]:7/filter_count:160/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__17095089582642638140<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:1024/input[2]:7/input[3]:7/filter_count:160/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__17095089582642638140<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:1024/input[2]:7/input[3]:7/filter_count:160/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__17095089582642638140<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:1024/input[2]:7/input[3]:7/filter_count:160/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__17095089582642638140<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:1024/input[2]:7/input[3]:7/filter_count:160/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__12895836372525236342<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:1024/input[2]:7/input[3]:7/filter_count:352/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__12895836372525236342<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:1024/input[2]:7/input[3]:7/filter_count:352/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__12895836372525236342<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:1024/input[2]:7/input[3]:7/filter_count:352/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__12895836372525236342<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:1024/input[2]:7/input[3]:7/filter_count:352/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__12895836372525236342<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:1024/input[2]:7/input[3]:7/filter_count:352/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__12895836372525236342<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:1024/input[2]:7/input[3]:7/filter_count:352/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__12895836372525236342<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:1024/input[2]:7/input[3]:7/filter_count:352/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__12895836372525236342<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:1024/input[2]:7/input[3]:7/filter_count:352/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__12892009898921617258<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:320/input[2]:28/input[3]:28/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__12892009898921617258<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:320/input[2]:28/input[3]:28/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__12892009898921617258<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:320/input[2]:28/input[3]:28/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__12892009898921617258<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:320/input[2]:28/input[3]:28/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__12892009898921617258<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:320/input[2]:28/input[3]:28/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__12892009898921617258<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:320/input[2]:28/input[3]:28/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__12892009898921617258<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:320/input[2]:28/input[3]:28/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__12892009898921617258<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:320/input[2]:28/input[3]:28/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__15903661585554707393<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:256/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__15903661585554707393<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:256/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__15903661585554707393<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:256/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__15903661585554707393<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:256/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__15903661585554707393<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:256/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__15903661585554707393<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:256/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__15903661585554707393<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:256/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__15903661585554707393<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:256/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__779486747125413369<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:1024/input[2]:12/input[3]:12/filter_count:1024/filter_height:3/filter_width:3/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__779486747125413369<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:1024/input[2]:12/input[3]:12/filter_count:1024/filter_height:3/filter_width:3/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__779486747125413369<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:1024/input[2]:12/input[3]:12/filter_count:1024/filter_height:3/filter_width:3/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__779486747125413369<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:1024/input[2]:12/input[3]:12/filter_count:1024/filter_height:3/filter_width:3/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__779486747125413369<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:1024/input[2]:12/input[3]:12/filter_count:1024/filter_height:3/filter_width:3/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__779486747125413369<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:1024/input[2]:12/input[3]:12/filter_count:1024/filter_height:3/filter_width:3/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__779486747125413369<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:1024/input[2]:12/input[3]:12/filter_count:1024/filter_height:3/filter_width:3/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__779486747125413369<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:1024/input[2]:12/input[3]:12/filter_count:1024/filter_height:3/filter_width:3/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__118008862325183851<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:16/input[2]:208/input[3]:208/filter_count:32/filter_height:3/filter_width:3/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__118008862325183851<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:16/input[2]:208/input[3]:208/filter_count:32/filter_height:3/filter_width:3/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__118008862325183851<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:16/input[2]:208/input[3]:208/filter_count:32/filter_height:3/filter_width:3/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__118008862325183851<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:16/input[2]:208/input[3]:208/filter_count:32/filter_height:3/filter_width:3/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__118008862325183851<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:16/input[2]:208/input[3]:208/filter_count:32/filter_height:3/filter_width:3/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__118008862325183851<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:16/input[2]:208/input[3]:208/filter_count:32/filter_height:3/filter_width:3/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__118008862325183851<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:16/input[2]:208/input[3]:208/filter_count:32/filter_height:3/filter_width:3/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__118008862325183851<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:16/input[2]:208/input[3]:208/filter_count:32/filter_height:3/filter_width:3/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__1557930777712989815<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:320/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__1557930777712989815<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:320/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__1557930777712989815<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:320/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__1557930777712989815<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:320/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__1557930777712989815<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:320/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__1557930777712989815<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:320/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__1557930777712989815<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:320/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__1557930777712989815<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:320/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__7598220594316386367<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:256/input[2]:13/input[3]:13/filter_count:512/filter_height:3/filter_width:3/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__7598220594316386367<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:256/input[2]:13/input[3]:13/filter_count:512/filter_height:3/filter_width:3/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__7598220594316386367<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:256/input[2]:13/input[3]:13/filter_count:512/filter_height:3/filter_width:3/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__7598220594316386367<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:256/input[2]:13/input[3]:13/filter_count:512/filter_height:3/filter_width:3/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__7598220594316386367<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:256/input[2]:13/input[3]:13/filter_count:512/filter_height:3/filter_width:3/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__7598220594316386367<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:256/input[2]:13/input[3]:13/filter_count:512/filter_height:3/filter_width:3/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__7598220594316386367<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:256/input[2]:13/input[3]:13/filter_count:512/filter_height:3/filter_width:3/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__7598220594316386367<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:256/input[2]:13/input[3]:13/filter_count:512/filter_height:3/filter_width:3/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__17832252081713507686<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:2048/input[2]:100/input[3]:100/filter_count:304/filter_height:3/filter_width:3/pad_height:12/pad_width:12/stride_height:1/stride_width:1/dilation_height:12/dilation_width:12/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD failed to cudnnSetTensor4dDescriptor",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__17832252081713507686<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:2048/input[2]:100/input[3]:100/filter_count:304/filter_height:3/filter_width:3/pad_height:12/pad_width:12/stride_height:1/stride_width:1/dilation_height:12/dilation_width:12/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD failed to cudnnSetTensor4dDescriptor",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__17832252081713507686<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:2048/input[2]:100/input[3]:100/filter_count:304/filter_height:3/filter_width:3/pad_height:12/pad_width:12/stride_height:1/stride_width:1/dilation_height:12/dilation_width:12/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD failed to cudnnSetTensor4dDescriptor",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__17832252081713507686<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:2048/input[2]:100/input[3]:100/filter_count:304/filter_height:3/filter_width:3/pad_height:12/pad_width:12/stride_height:1/stride_width:1/dilation_height:12/dilation_width:12/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD failed to cudnnSetTensor4dDescriptor",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__17832252081713507686<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:2048/input[2]:100/input[3]:100/filter_count:304/filter_height:3/filter_width:3/pad_height:12/pad_width:12/stride_height:1/stride_width:1/dilation_height:12/dilation_width:12/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD failed to cudnnSetTensor4dDescriptor",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__17832252081713507686<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:2048/input[2]:100/input[3]:100/filter_count:304/filter_height:3/filter_width:3/pad_height:12/pad_width:12/stride_height:1/stride_width:1/dilation_height:12/dilation_width:12/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD failed to cudnnSetTensor4dDescriptor",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__17832252081713507686<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:2048/input[2]:100/input[3]:100/filter_count:304/filter_height:3/filter_width:3/pad_height:12/pad_width:12/stride_height:1/stride_width:1/dilation_height:12/dilation_width:12/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD failed to cudnnSetTensor4dDescriptor",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__17832252081713507686<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:2048/input[2]:100/input[3]:100/filter_count:304/filter_height:3/filter_width:3/pad_height:12/pad_width:12/stride_height:1/stride_width:1/dilation_height:12/dilation_width:12/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD failed to cudnnSetTensor4dDescriptor",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__12672377033579609031<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:192/input[2]:7/input[3]:7/filter_count:320/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__12672377033579609031<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:192/input[2]:7/input[3]:7/filter_count:320/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__12672377033579609031<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:192/input[2]:7/input[3]:7/filter_count:320/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__12672377033579609031<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:192/input[2]:7/input[3]:7/filter_count:320/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__12672377033579609031<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:192/input[2]:7/input[3]:7/filter_count:320/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__12672377033579609031<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:192/input[2]:7/input[3]:7/filter_count:320/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__12672377033579609031<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:192/input[2]:7/input[3]:7/filter_count:320/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__12672377033579609031<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:192/input[2]:7/input[3]:7/filter_count:320/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__9381287018770364271<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:256/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__9381287018770364271<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:256/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__9381287018770364271<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:256/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__9381287018770364271<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:256/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__9381287018770364271<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:256/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__9381287018770364271<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:256/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__9381287018770364271<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:256/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__9381287018770364271<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:256/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__11991109196061151671<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:128/input[2]:28/input[3]:28/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__11991109196061151671<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:128/input[2]:28/input[3]:28/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__11991109196061151671<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:128/input[2]:28/input[3]:28/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__11991109196061151671<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:128/input[2]:28/input[3]:28/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__11991109196061151671<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:128/input[2]:28/input[3]:28/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__11991109196061151671<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:128/input[2]:28/input[3]:28/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__11991109196061151671<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:128/input[2]:28/input[3]:28/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__11991109196061151671<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:128/input[2]:28/input[3]:28/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__5057046312658664989<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:128/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__5057046312658664989<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:128/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__5057046312658664989<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:128/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__5057046312658664989<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:128/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__5057046312658664989<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:128/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__5057046312658664989<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:128/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__5057046312658664989<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:128/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__5057046312658664989<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:128/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__7830552044787699101<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:256/input[2]:28/input[3]:28/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__7830552044787699101<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:256/input[2]:28/input[3]:28/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__7830552044787699101<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:256/input[2]:28/input[3]:28/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__7830552044787699101<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:256/input[2]:28/input[3]:28/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__7830552044787699101<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:256/input[2]:28/input[3]:28/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__7830552044787699101<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:256/input[2]:28/input[3]:28/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__7830552044787699101<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:256/input[2]:28/input[3]:28/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__7830552044787699101<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:256/input[2]:28/input[3]:28/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__9940872911106430581<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:128/input[2]:56/input[3]:56/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__9940872911106430581<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:128/input[2]:56/input[3]:56/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__9940872911106430581<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:128/input[2]:56/input[3]:56/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__9940872911106430581<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:128/input[2]:56/input[3]:56/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__9940872911106430581<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:128/input[2]:56/input[3]:56/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__9940872911106430581<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:128/input[2]:56/input[3]:56/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__9940872911106430581<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:128/input[2]:56/input[3]:56/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__9940872911106430581<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:128/input[2]:56/input[3]:56/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__12755988992407562640<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:256/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__12755988992407562640<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:256/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__12755988992407562640<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:256/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__12755988992407562640<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:256/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__12755988992407562640<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:256/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__12755988992407562640<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:256/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__12755988992407562640<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:256/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__12755988992407562640<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:256/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__10154899191652246071<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:256/input[2]:28/input[3]:28/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__10154899191652246071<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:256/input[2]:28/input[3]:28/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__10154899191652246071<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:256/input[2]:28/input[3]:28/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__10154899191652246071<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:256/input[2]:28/input[3]:28/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__10154899191652246071<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:256/input[2]:28/input[3]:28/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__10154899191652246071<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:256/input[2]:28/input[3]:28/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__10154899191652246071<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:256/input[2]:28/input[3]:28/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_FLOAT32__BatchSize_128__10154899191652246071<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:256/input[2]:28/input[3]:28/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__327276140951920607<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:128/input[2]:27/input[3]:27/filter_count:32/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__327276140951920607<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:128/input[2]:27/input[3]:27/filter_count:32/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__327276140951920607<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:128/input[2]:27/input[3]:27/filter_count:32/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__327276140951920607<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:128/input[2]:27/input[3]:27/filter_count:32/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__327276140951920607<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:128/input[2]:27/input[3]:27/filter_count:32/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__327276140951920607<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:128/input[2]:27/input[3]:27/filter_count:32/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__327276140951920607<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:128/input[2]:27/input[3]:27/filter_count:32/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__327276140951920607<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:128/input[2]:27/input[3]:27/filter_count:32/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__8281372607104593341<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:1/input[1]:136/input[2]:28/input[3]:28/filter_count:136/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:136/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__8281372607104593341<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:1/input[1]:136/input[2]:28/input[3]:28/filter_count:136/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:136/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__8281372607104593341<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:1/input[1]:136/input[2]:28/input[3]:28/filter_count:136/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:136/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__8281372607104593341<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:1/input[1]:136/input[2]:28/input[3]:28/filter_count:136/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:136/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__8281372607104593341<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:1/input[1]:136/input[2]:28/input[3]:28/filter_count:136/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:136/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__8281372607104593341<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:1/input[1]:136/input[2]:28/input[3]:28/filter_count:136/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:136/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__8281372607104593341<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:1/input[1]:136/input[2]:28/input[3]:28/filter_count:136/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:136/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__8281372607104593341<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:1/input[1]:136/input[2]:28/input[3]:28/filter_count:136/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:136/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__17109011874869762936<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:1/input[1]:136/input[2]:28/input[3]:28/filter_count:136/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:4/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__17109011874869762936<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:1/input[1]:136/input[2]:28/input[3]:28/filter_count:136/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:4/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__17109011874869762936<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:1/input[1]:136/input[2]:28/input[3]:28/filter_count:136/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:4/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__17109011874869762936<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:1/input[1]:136/input[2]:28/input[3]:28/filter_count:136/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:4/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__17109011874869762936<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:1/input[1]:136/input[2]:28/input[3]:28/filter_count:136/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:4/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__17109011874869762936<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:1/input[1]:136/input[2]:28/input[3]:28/filter_count:136/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:4/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__17109011874869762936<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:1/input[1]:136/input[2]:28/input[3]:28/filter_count:136/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:4/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__17109011874869762936<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:1/input[1]:136/input[2]:28/input[3]:28/filter_count:136/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:4/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__15379894244763202309<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:48/input[2]:13/input[3]:13/filter_count:192/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__15379894244763202309<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:48/input[2]:13/input[3]:13/filter_count:192/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__15379894244763202309<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:48/input[2]:13/input[3]:13/filter_count:192/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__15379894244763202309<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:48/input[2]:13/input[3]:13/filter_count:192/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__15379894244763202309<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:48/input[2]:13/input[3]:13/filter_count:192/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__15379894244763202309<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:48/input[2]:13/input[3]:13/filter_count:192/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__15379894244763202309<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:48/input[2]:13/input[3]:13/filter_count:192/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__15379894244763202309<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:48/input[2]:13/input[3]:13/filter_count:192/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__8119511847073628280<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:1/input[1]:192/input[2]:27/input[3]:27/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__8119511847073628280<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:1/input[1]:192/input[2]:27/input[3]:27/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__8119511847073628280<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:1/input[1]:192/input[2]:27/input[3]:27/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__8119511847073628280<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:1/input[1]:192/input[2]:27/input[3]:27/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__8119511847073628280<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:1/input[1]:192/input[2]:27/input[3]:27/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__8119511847073628280<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:1/input[1]:192/input[2]:27/input[3]:27/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__8119511847073628280<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:1/input[1]:192/input[2]:27/input[3]:27/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__8119511847073628280<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:1/input[1]:192/input[2]:27/input[3]:27/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__3656752739290940149<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:256/input[2]:13/input[3]:13/filter_count:48/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__3656752739290940149<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:256/input[2]:13/input[3]:13/filter_count:48/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__3656752739290940149<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:256/input[2]:13/input[3]:13/filter_count:48/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__3656752739290940149<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:256/input[2]:13/input[3]:13/filter_count:48/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__3656752739290940149<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:256/input[2]:13/input[3]:13/filter_count:48/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__3656752739290940149<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:256/input[2]:13/input[3]:13/filter_count:48/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__3656752739290940149<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:256/input[2]:13/input[3]:13/filter_count:48/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__3656752739290940149<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:256/input[2]:13/input[3]:13/filter_count:48/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__15729146718882943763<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:1/input[1]:832/input[2]:6/input[3]:6/filter_count:48/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__15729146718882943763<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:1/input[1]:832/input[2]:6/input[3]:6/filter_count:48/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__15729146718882943763<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:1/input[1]:832/input[2]:6/input[3]:6/filter_count:48/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__15729146718882943763<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:1/input[1]:832/input[2]:6/input[3]:6/filter_count:48/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__15729146718882943763<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:1/input[1]:832/input[2]:6/input[3]:6/filter_count:48/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__15729146718882943763<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:1/input[1]:832/input[2]:6/input[3]:6/filter_count:48/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__15729146718882943763<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:1/input[1]:832/input[2]:6/input[3]:6/filter_count:48/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__15729146718882943763<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:1/input[1]:832/input[2]:6/input[3]:6/filter_count:48/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__17231680306118389791<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:512/input[2]:13/input[3]:13/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__17231680306118389791<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:512/input[2]:13/input[3]:13/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__17231680306118389791<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:512/input[2]:13/input[3]:13/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__17231680306118389791<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:512/input[2]:13/input[3]:13/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__17231680306118389791<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:512/input[2]:13/input[3]:13/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__17231680306118389791<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:512/input[2]:13/input[3]:13/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__17231680306118389791<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:512/input[2]:13/input[3]:13/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__17231680306118389791<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:512/input[2]:13/input[3]:13/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__18386369741520431449<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:384/input[2]:13/input[3]:13/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__18386369741520431449<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:384/input[2]:13/input[3]:13/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__18386369741520431449<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:384/input[2]:13/input[3]:13/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__18386369741520431449<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:384/input[2]:13/input[3]:13/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__18386369741520431449<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:384/input[2]:13/input[3]:13/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__18386369741520431449<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:384/input[2]:13/input[3]:13/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__18386369741520431449<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:384/input[2]:13/input[3]:13/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__18386369741520431449<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:384/input[2]:13/input[3]:13/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__15716251480759776399<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:1/input[1]:160/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__15716251480759776399<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:1/input[1]:160/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__15716251480759776399<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:1/input[1]:160/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__15716251480759776399<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:1/input[1]:160/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__15716251480759776399<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:1/input[1]:160/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__15716251480759776399<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:1/input[1]:160/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__15716251480759776399<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:1/input[1]:160/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__15716251480759776399<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:1/input[1]:160/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__6302548282292377773<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:1/input[1]:192/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__6302548282292377773<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:1/input[1]:192/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__6302548282292377773<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:1/input[1]:192/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__6302548282292377773<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:1/input[1]:192/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__6302548282292377773<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:1/input[1]:192/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__6302548282292377773<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:1/input[1]:192/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__6302548282292377773<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:1/input[1]:192/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__6302548282292377773<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:1/input[1]:192/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__9741782480126829334<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:1/input[1]:32/input[2]:27/input[3]:27/filter_count:96/filter_height:5/filter_width:5/pad_height:2/pad_width:2/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__9741782480126829334<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:1/input[1]:32/input[2]:27/input[3]:27/filter_count:96/filter_height:5/filter_width:5/pad_height:2/pad_width:2/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__9741782480126829334<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:1/input[1]:32/input[2]:27/input[3]:27/filter_count:96/filter_height:5/filter_width:5/pad_height:2/pad_width:2/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__9741782480126829334<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:1/input[1]:32/input[2]:27/input[3]:27/filter_count:96/filter_height:5/filter_width:5/pad_height:2/pad_width:2/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__9741782480126829334<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:1/input[1]:32/input[2]:27/input[3]:27/filter_count:96/filter_height:5/filter_width:5/pad_height:2/pad_width:2/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__9741782480126829334<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:1/input[1]:32/input[2]:27/input[3]:27/filter_count:96/filter_height:5/filter_width:5/pad_height:2/pad_width:2/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__9741782480126829334<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:1/input[1]:32/input[2]:27/input[3]:27/filter_count:96/filter_height:5/filter_width:5/pad_height:2/pad_width:2/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__9741782480126829334<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:1/input[1]:32/input[2]:27/input[3]:27/filter_count:96/filter_height:5/filter_width:5/pad_height:2/pad_width:2/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__5440919204575625281<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:1/input[1]:544/input[2]:7/input[3]:7/filter_count:544/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:544/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__5440919204575625281<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:1/input[1]:544/input[2]:7/input[3]:7/filter_count:544/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:544/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__5440919204575625281<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:1/input[1]:544/input[2]:7/input[3]:7/filter_count:544/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:544/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__5440919204575625281<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:1/input[1]:544/input[2]:7/input[3]:7/filter_count:544/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:544/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__5440919204575625281<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:1/input[1]:544/input[2]:7/input[3]:7/filter_count:544/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:544/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__5440919204575625281<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:1/input[1]:544/input[2]:7/input[3]:7/filter_count:544/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:544/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__5440919204575625281<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:1/input[1]:544/input[2]:7/input[3]:7/filter_count:544/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:544/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__5440919204575625281<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:1/input[1]:544/input[2]:7/input[3]:7/filter_count:544/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:544/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__3074163452045284337<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:24/input[2]:14/input[3]:14/filter_count:64/filter_height:5/filter_width:5/pad_height:2/pad_width:2/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__3074163452045284337<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:24/input[2]:14/input[3]:14/filter_count:64/filter_height:5/filter_width:5/pad_height:2/pad_width:2/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__3074163452045284337<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:24/input[2]:14/input[3]:14/filter_count:64/filter_height:5/filter_width:5/pad_height:2/pad_width:2/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__3074163452045284337<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:24/input[2]:14/input[3]:14/filter_count:64/filter_height:5/filter_width:5/pad_height:2/pad_width:2/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__3074163452045284337<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:24/input[2]:14/input[3]:14/filter_count:64/filter_height:5/filter_width:5/pad_height:2/pad_width:2/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__3074163452045284337<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:24/input[2]:14/input[3]:14/filter_count:64/filter_height:5/filter_width:5/pad_height:2/pad_width:2/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__3074163452045284337<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:24/input[2]:14/input[3]:14/filter_count:64/filter_height:5/filter_width:5/pad_height:2/pad_width:2/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__3074163452045284337<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:24/input[2]:14/input[3]:14/filter_count:64/filter_height:5/filter_width:5/pad_height:2/pad_width:2/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__4471115093569823447<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:1/input[1]:512/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__4471115093569823447<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:1/input[1]:512/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__4471115093569823447<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:1/input[1]:512/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__4471115093569823447<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:1/input[1]:512/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__4471115093569823447<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:1/input[1]:512/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__4471115093569823447<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:1/input[1]:512/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__4471115093569823447<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:1/input[1]:512/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__4471115093569823447<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:1/input[1]:512/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__114635572058497542<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:1/input[1]:576/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__114635572058497542<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:1/input[1]:576/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__114635572058497542<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:1/input[1]:576/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__114635572058497542<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:1/input[1]:576/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__114635572058497542<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:1/input[1]:576/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__114635572058497542<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:1/input[1]:576/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__114635572058497542<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:1/input[1]:576/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__114635572058497542<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:1/input[1]:576/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__11590516252436977981<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:1/input[1]:256/input[2]:27/input[3]:27/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__11590516252436977981<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:1/input[1]:256/input[2]:27/input[3]:27/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__11590516252436977981<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:1/input[1]:256/input[2]:27/input[3]:27/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__11590516252436977981<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:1/input[1]:256/input[2]:27/input[3]:27/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__11590516252436977981<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:1/input[1]:256/input[2]:27/input[3]:27/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__11590516252436977981<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:1/input[1]:256/input[2]:27/input[3]:27/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__11590516252436977981<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:1/input[1]:256/input[2]:27/input[3]:27/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__11590516252436977981<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:1/input[1]:256/input[2]:27/input[3]:27/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__17833081323610330459<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:512/input[2]:14/input[3]:14/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__17833081323610330459<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:512/input[2]:14/input[3]:14/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__17833081323610330459<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:512/input[2]:14/input[3]:14/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__17833081323610330459<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:512/input[2]:14/input[3]:14/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__17833081323610330459<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:512/input[2]:14/input[3]:14/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__17833081323610330459<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:512/input[2]:14/input[3]:14/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__17833081323610330459<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:512/input[2]:14/input[3]:14/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__17833081323610330459<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:512/input[2]:14/input[3]:14/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__11192228507655028147<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:1/input[1]:480/input[2]:13/input[3]:13/filter_count:96/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__11192228507655028147<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:1/input[1]:480/input[2]:13/input[3]:13/filter_count:96/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__11192228507655028147<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:1/input[1]:480/input[2]:13/input[3]:13/filter_count:96/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__11192228507655028147<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:1/input[1]:480/input[2]:13/input[3]:13/filter_count:96/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__11192228507655028147<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:1/input[1]:480/input[2]:13/input[3]:13/filter_count:96/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__11192228507655028147<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:1/input[1]:480/input[2]:13/input[3]:13/filter_count:96/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__11192228507655028147<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:1/input[1]:480/input[2]:13/input[3]:13/filter_count:96/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__11192228507655028147<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:1/input[1]:480/input[2]:13/input[3]:13/filter_count:96/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__11995602787379986918<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:32/input[2]:112/input[3]:112/filter_count:16/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__11995602787379986918<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:32/input[2]:112/input[3]:112/filter_count:16/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__11995602787379986918<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:32/input[2]:112/input[3]:112/filter_count:16/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__11995602787379986918<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:32/input[2]:112/input[3]:112/filter_count:16/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__11995602787379986918<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:32/input[2]:112/input[3]:112/filter_count:16/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__11995602787379986918<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:32/input[2]:112/input[3]:112/filter_count:16/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__11995602787379986918<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:32/input[2]:112/input[3]:112/filter_count:16/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__11995602787379986918<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:32/input[2]:112/input[3]:112/filter_count:16/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__15001495479754903251<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:384/input[2]:12/input[3]:12/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:2/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__15001495479754903251<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:384/input[2]:12/input[3]:12/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:2/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__15001495479754903251<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:384/input[2]:12/input[3]:12/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:2/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__15001495479754903251<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:384/input[2]:12/input[3]:12/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:2/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__15001495479754903251<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:384/input[2]:12/input[3]:12/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:2/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__15001495479754903251<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:384/input[2]:12/input[3]:12/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:2/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__15001495479754903251<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:384/input[2]:12/input[3]:12/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:2/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__15001495479754903251<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:384/input[2]:12/input[3]:12/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:2/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__2929806377115036078<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:1/input[1]:480/input[2]:13/input[3]:13/filter_count:16/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__2929806377115036078<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:1/input[1]:480/input[2]:13/input[3]:13/filter_count:16/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__2929806377115036078<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:1/input[1]:480/input[2]:13/input[3]:13/filter_count:16/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__2929806377115036078<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:1/input[1]:480/input[2]:13/input[3]:13/filter_count:16/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__2929806377115036078<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:1/input[1]:480/input[2]:13/input[3]:13/filter_count:16/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__2929806377115036078<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:1/input[1]:480/input[2]:13/input[3]:13/filter_count:16/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__2929806377115036078<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:1/input[1]:480/input[2]:13/input[3]:13/filter_count:16/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__2929806377115036078<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:1/input[1]:480/input[2]:13/input[3]:13/filter_count:16/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__3174631807111741116<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:96/input[2]:56/input[3]:56/filter_count:24/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__3174631807111741116<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:96/input[2]:56/input[3]:56/filter_count:24/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__3174631807111741116<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:96/input[2]:56/input[3]:56/filter_count:24/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__3174631807111741116<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:96/input[2]:56/input[3]:56/filter_count:24/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__3174631807111741116<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:96/input[2]:56/input[3]:56/filter_count:24/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__3174631807111741116<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:96/input[2]:56/input[3]:56/filter_count:24/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__3174631807111741116<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:96/input[2]:56/input[3]:56/filter_count:24/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__3174631807111741116<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:96/input[2]:56/input[3]:56/filter_count:24/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__7809290002932028022<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:1/input[1]:832/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__7809290002932028022<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:1/input[1]:832/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__7809290002932028022<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:1/input[1]:832/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__7809290002932028022<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:1/input[1]:832/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__7809290002932028022<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:1/input[1]:832/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__7809290002932028022<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:1/input[1]:832/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__7809290002932028022<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:1/input[1]:832/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__7809290002932028022<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:1/input[1]:832/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__7466239390065346357<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:1/input[1]:416/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__7466239390065346357<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:1/input[1]:416/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__7466239390065346357<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:1/input[1]:416/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__7466239390065346357<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:1/input[1]:416/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__7466239390065346357<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:1/input[1]:416/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__7466239390065346357<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:1/input[1]:416/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__7466239390065346357<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:1/input[1]:416/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__7466239390065346357<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:1/input[1]:416/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__4181094022726787882<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:528/input[2]:14/input[3]:14/filter_count:32/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__4181094022726787882<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:528/input[2]:14/input[3]:14/filter_count:32/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__4181094022726787882<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:528/input[2]:14/input[3]:14/filter_count:32/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__4181094022726787882<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:528/input[2]:14/input[3]:14/filter_count:32/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__4181094022726787882<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:528/input[2]:14/input[3]:14/filter_count:32/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__4181094022726787882<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:528/input[2]:14/input[3]:14/filter_count:32/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__4181094022726787882<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:528/input[2]:14/input[3]:14/filter_count:32/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__4181094022726787882<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:528/input[2]:14/input[3]:14/filter_count:32/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__15517853207744983808<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:1/input[1]:736/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__15517853207744983808<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:1/input[1]:736/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__15517853207744983808<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:1/input[1]:736/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__15517853207744983808<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:1/input[1]:736/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__15517853207744983808<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:1/input[1]:736/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__15517853207744983808<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:1/input[1]:736/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__15517853207744983808<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:1/input[1]:736/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__15517853207744983808<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:1/input[1]:736/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__4014735847207117486<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:24/input[2]:56/input[3]:56/filter_count:144/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__4014735847207117486<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:24/input[2]:56/input[3]:56/filter_count:144/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__4014735847207117486<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:24/input[2]:56/input[3]:56/filter_count:144/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__4014735847207117486<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:24/input[2]:56/input[3]:56/filter_count:144/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__4014735847207117486<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:24/input[2]:56/input[3]:56/filter_count:144/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__4014735847207117486<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:24/input[2]:56/input[3]:56/filter_count:144/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__4014735847207117486<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:24/input[2]:56/input[3]:56/filter_count:144/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__4014735847207117486<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:24/input[2]:56/input[3]:56/filter_count:144/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__14381471328508771823<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:32/input[2]:14/input[3]:14/filter_count:128/filter_height:5/filter_width:5/pad_height:2/pad_width:2/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__14381471328508771823<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:32/input[2]:14/input[3]:14/filter_count:128/filter_height:5/filter_width:5/pad_height:2/pad_width:2/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__14381471328508771823<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:32/input[2]:14/input[3]:14/filter_count:128/filter_height:5/filter_width:5/pad_height:2/pad_width:2/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__14381471328508771823<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:32/input[2]:14/input[3]:14/filter_count:128/filter_height:5/filter_width:5/pad_height:2/pad_width:2/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__14381471328508771823<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:32/input[2]:14/input[3]:14/filter_count:128/filter_height:5/filter_width:5/pad_height:2/pad_width:2/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__14381471328508771823<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:32/input[2]:14/input[3]:14/filter_count:128/filter_height:5/filter_width:5/pad_height:2/pad_width:2/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__14381471328508771823<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:32/input[2]:14/input[3]:14/filter_count:128/filter_height:5/filter_width:5/pad_height:2/pad_width:2/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__14381471328508771823<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:32/input[2]:14/input[3]:14/filter_count:128/filter_height:5/filter_width:5/pad_height:2/pad_width:2/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__16425765489206416313<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:832/input[2]:7/input[3]:7/filter_count:160/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__16425765489206416313<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:832/input[2]:7/input[3]:7/filter_count:160/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__16425765489206416313<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:832/input[2]:7/input[3]:7/filter_count:160/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__16425765489206416313<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:832/input[2]:7/input[3]:7/filter_count:160/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__16425765489206416313<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:832/input[2]:7/input[3]:7/filter_count:160/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__16425765489206416313<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:832/input[2]:7/input[3]:7/filter_count:160/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__16425765489206416313<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:832/input[2]:7/input[3]:7/filter_count:160/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__16425765489206416313<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:832/input[2]:7/input[3]:7/filter_count:160/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__7054182596056114367<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:32/input[2]:28/input[3]:28/filter_count:192/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__7054182596056114367<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:32/input[2]:28/input[3]:28/filter_count:192/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__7054182596056114367<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:32/input[2]:28/input[3]:28/filter_count:192/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__7054182596056114367<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:32/input[2]:28/input[3]:28/filter_count:192/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__7054182596056114367<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:32/input[2]:28/input[3]:28/filter_count:192/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__7054182596056114367<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:32/input[2]:28/input[3]:28/filter_count:192/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__7054182596056114367<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:32/input[2]:28/input[3]:28/filter_count:192/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__7054182596056114367<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:32/input[2]:28/input[3]:28/filter_count:192/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__1928653545434803107<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:1/input[1]:864/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__1928653545434803107<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:1/input[1]:864/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__1928653545434803107<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:1/input[1]:864/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__1928653545434803107<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:1/input[1]:864/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__1928653545434803107<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:1/input[1]:864/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__1928653545434803107<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:1/input[1]:864/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__1928653545434803107<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:1/input[1]:864/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__1928653545434803107<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:1/input[1]:864/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__13843182093923952381<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:144/input[2]:28/input[3]:28/filter_count:32/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__13843182093923952381<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:144/input[2]:28/input[3]:28/filter_count:32/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__13843182093923952381<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:144/input[2]:28/input[3]:28/filter_count:32/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__13843182093923952381<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:144/input[2]:28/input[3]:28/filter_count:32/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__13843182093923952381<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:144/input[2]:28/input[3]:28/filter_count:32/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__13843182093923952381<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:144/input[2]:28/input[3]:28/filter_count:32/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__13843182093923952381<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:144/input[2]:28/input[3]:28/filter_count:32/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__13843182093923952381<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:144/input[2]:28/input[3]:28/filter_count:32/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__4227617969350582405<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:192/input[2]:28/input[3]:28/filter_count:192/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:192/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__4227617969350582405<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:192/input[2]:28/input[3]:28/filter_count:192/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:192/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__4227617969350582405<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:192/input[2]:28/input[3]:28/filter_count:192/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:192/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__4227617969350582405<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:192/input[2]:28/input[3]:28/filter_count:192/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:192/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__4227617969350582405<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:192/input[2]:28/input[3]:28/filter_count:192/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:192/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__4227617969350582405<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:192/input[2]:28/input[3]:28/filter_count:192/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:192/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__4227617969350582405<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:192/input[2]:28/input[3]:28/filter_count:192/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:192/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__4227617969350582405<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:192/input[2]:28/input[3]:28/filter_count:192/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:192/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__3538666090942584914<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:576/input[2]:14/input[3]:14/filter_count:576/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:576/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__3538666090942584914<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:576/input[2]:14/input[3]:14/filter_count:576/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:576/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__3538666090942584914<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:576/input[2]:14/input[3]:14/filter_count:576/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:576/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__3538666090942584914<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:576/input[2]:14/input[3]:14/filter_count:576/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:576/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__3538666090942584914<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:576/input[2]:14/input[3]:14/filter_count:576/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:576/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__3538666090942584914<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:576/input[2]:14/input[3]:14/filter_count:576/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:576/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__3538666090942584914<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:576/input[2]:14/input[3]:14/filter_count:576/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:576/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__3538666090942584914<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:576/input[2]:14/input[3]:14/filter_count:576/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:576/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__15270365293401413008<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:1/input[1]:896/input[2]:7/input[3]:7/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__15270365293401413008<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:1/input[1]:896/input[2]:7/input[3]:7/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__15270365293401413008<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:1/input[1]:896/input[2]:7/input[3]:7/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__15270365293401413008<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:1/input[1]:896/input[2]:7/input[3]:7/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__15270365293401413008<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:1/input[1]:896/input[2]:7/input[3]:7/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__15270365293401413008<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:1/input[1]:896/input[2]:7/input[3]:7/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__15270365293401413008<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:1/input[1]:896/input[2]:7/input[3]:7/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__15270365293401413008<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:1/input[1]:896/input[2]:7/input[3]:7/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__14432469205306730518<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:576/input[2]:14/input[3]:14/filter_count:576/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:576/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__14432469205306730518<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:576/input[2]:14/input[3]:14/filter_count:576/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:576/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__14432469205306730518<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:576/input[2]:14/input[3]:14/filter_count:576/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:576/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__14432469205306730518<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:576/input[2]:14/input[3]:14/filter_count:576/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:576/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__14432469205306730518<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:576/input[2]:14/input[3]:14/filter_count:576/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:576/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__14432469205306730518<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:576/input[2]:14/input[3]:14/filter_count:576/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:576/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__14432469205306730518<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:576/input[2]:14/input[3]:14/filter_count:576/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:576/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__14432469205306730518<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:576/input[2]:14/input[3]:14/filter_count:576/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:576/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__3430837407541565976<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:1/input[2]:64/input[3]:64/filter_count:64/filter_height:3/filter_width:3/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__3430837407541565976<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:1/input[2]:64/input[3]:64/filter_count:64/filter_height:3/filter_width:3/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__3430837407541565976<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:1/input[2]:64/input[3]:64/filter_count:64/filter_height:3/filter_width:3/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__3430837407541565976<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:1/input[2]:64/input[3]:64/filter_count:64/filter_height:3/filter_width:3/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__3430837407541565976<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:1/input[2]:64/input[3]:64/filter_count:64/filter_height:3/filter_width:3/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__3430837407541565976<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:1/input[2]:64/input[3]:64/filter_count:64/filter_height:3/filter_width:3/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__3430837407541565976<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:1/input[2]:64/input[3]:64/filter_count:64/filter_height:3/filter_width:3/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__3430837407541565976<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:1/input[2]:64/input[3]:64/filter_count:64/filter_height:3/filter_width:3/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__230646304257146060<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:96/input[2]:28/input[3]:28/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__230646304257146060<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:96/input[2]:28/input[3]:28/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__230646304257146060<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:96/input[2]:28/input[3]:28/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__230646304257146060<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:96/input[2]:28/input[3]:28/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__230646304257146060<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:96/input[2]:28/input[3]:28/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__230646304257146060<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:96/input[2]:28/input[3]:28/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__230646304257146060<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:96/input[2]:28/input[3]:28/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__230646304257146060<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:96/input[2]:28/input[3]:28/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__2281153969545101356<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:1/input[1]:1024/input[2]:1/input[3]:1/filter_count:1000/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__2281153969545101356<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:1/input[1]:1024/input[2]:1/input[3]:1/filter_count:1000/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__2281153969545101356<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:1/input[1]:1024/input[2]:1/input[3]:1/filter_count:1000/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__2281153969545101356<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:1/input[1]:1024/input[2]:1/input[3]:1/filter_count:1000/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__2281153969545101356<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:1/input[1]:1024/input[2]:1/input[3]:1/filter_count:1000/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__2281153969545101356<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:1/input[1]:1024/input[2]:1/input[3]:1/filter_count:1000/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__2281153969545101356<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:1/input[1]:1024/input[2]:1/input[3]:1/filter_count:1000/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__2281153969545101356<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:1/input[1]:1024/input[2]:1/input[3]:1/filter_count:1000/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__12401635154024824820<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:128/input[2]:16/input[3]:16/filter_count:256/filter_height:3/filter_width:3/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__12401635154024824820<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:128/input[2]:16/input[3]:16/filter_count:256/filter_height:3/filter_width:3/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__12401635154024824820<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:128/input[2]:16/input[3]:16/filter_count:256/filter_height:3/filter_width:3/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__12401635154024824820<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:128/input[2]:16/input[3]:16/filter_count:256/filter_height:3/filter_width:3/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__12401635154024824820<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:128/input[2]:16/input[3]:16/filter_count:256/filter_height:3/filter_width:3/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__12401635154024824820<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:128/input[2]:16/input[3]:16/filter_count:256/filter_height:3/filter_width:3/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__12401635154024824820<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:128/input[2]:16/input[3]:16/filter_count:256/filter_height:3/filter_width:3/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__12401635154024824820<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:128/input[2]:16/input[3]:16/filter_count:256/filter_height:3/filter_width:3/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__12812158252801400378<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:1/input[1]:32/input[2]:13/input[3]:13/filter_count:128/filter_height:5/filter_width:5/pad_height:2/pad_width:2/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__12812158252801400378<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:1/input[1]:32/input[2]:13/input[3]:13/filter_count:128/filter_height:5/filter_width:5/pad_height:2/pad_width:2/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__12812158252801400378<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:1/input[1]:32/input[2]:13/input[3]:13/filter_count:128/filter_height:5/filter_width:5/pad_height:2/pad_width:2/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__12812158252801400378<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:1/input[1]:32/input[2]:13/input[3]:13/filter_count:128/filter_height:5/filter_width:5/pad_height:2/pad_width:2/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__12812158252801400378<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:1/input[1]:32/input[2]:13/input[3]:13/filter_count:128/filter_height:5/filter_width:5/pad_height:2/pad_width:2/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__12812158252801400378<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:1/input[1]:32/input[2]:13/input[3]:13/filter_count:128/filter_height:5/filter_width:5/pad_height:2/pad_width:2/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__12812158252801400378<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:1/input[1]:32/input[2]:13/input[3]:13/filter_count:128/filter_height:5/filter_width:5/pad_height:2/pad_width:2/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__12812158252801400378<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:1/input[1]:32/input[2]:13/input[3]:13/filter_count:128/filter_height:5/filter_width:5/pad_height:2/pad_width:2/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__8849673836353494804<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:256/input[2]:16/input[3]:16/filter_count:256/filter_height:3/filter_width:3/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__8849673836353494804<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:256/input[2]:16/input[3]:16/filter_count:256/filter_height:3/filter_width:3/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__8849673836353494804<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:256/input[2]:16/input[3]:16/filter_count:256/filter_height:3/filter_width:3/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__8849673836353494804<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:256/input[2]:16/input[3]:16/filter_count:256/filter_height:3/filter_width:3/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__8849673836353494804<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:256/input[2]:16/input[3]:16/filter_count:256/filter_height:3/filter_width:3/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__8849673836353494804<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:256/input[2]:16/input[3]:16/filter_count:256/filter_height:3/filter_width:3/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__8849673836353494804<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:256/input[2]:16/input[3]:16/filter_count:256/filter_height:3/filter_width:3/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__8849673836353494804<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:256/input[2]:16/input[3]:16/filter_count:256/filter_height:3/filter_width:3/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__5283300838216404682<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:128/input[2]:14/input[3]:14/filter_count:160/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__5283300838216404682<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:128/input[2]:14/input[3]:14/filter_count:160/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__5283300838216404682<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:128/input[2]:14/input[3]:14/filter_count:160/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__5283300838216404682<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:128/input[2]:14/input[3]:14/filter_count:160/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__5283300838216404682<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:128/input[2]:14/input[3]:14/filter_count:160/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__5283300838216404682<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:128/input[2]:14/input[3]:14/filter_count:160/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__5283300838216404682<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:128/input[2]:14/input[3]:14/filter_count:160/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__5283300838216404682<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:128/input[2]:14/input[3]:14/filter_count:160/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__8549384043421900094<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:1/input[1]:528/input[2]:13/input[3]:13/filter_count:160/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__8549384043421900094<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:1/input[1]:528/input[2]:13/input[3]:13/filter_count:160/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__8549384043421900094<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:1/input[1]:528/input[2]:13/input[3]:13/filter_count:160/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__8549384043421900094<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:1/input[1]:528/input[2]:13/input[3]:13/filter_count:160/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__8549384043421900094<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:1/input[1]:528/input[2]:13/input[3]:13/filter_count:160/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__8549384043421900094<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:1/input[1]:528/input[2]:13/input[3]:13/filter_count:160/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__8549384043421900094<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:1/input[1]:528/input[2]:13/input[3]:13/filter_count:160/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__8549384043421900094<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:1/input[1]:528/input[2]:13/input[3]:13/filter_count:160/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__16789593852747237241<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:256/input[2]:28/input[3]:28/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__16789593852747237241<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:256/input[2]:28/input[3]:28/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__16789593852747237241<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:256/input[2]:28/input[3]:28/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__16789593852747237241<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:256/input[2]:28/input[3]:28/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__16789593852747237241<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:256/input[2]:28/input[3]:28/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__16789593852747237241<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:256/input[2]:28/input[3]:28/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__16789593852747237241<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:256/input[2]:28/input[3]:28/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__16789593852747237241<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:256/input[2]:28/input[3]:28/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__12214396263859311657<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:1/input[1]:832/input[2]:6/input[3]:6/filter_count:32/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__12214396263859311657<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:1/input[1]:832/input[2]:6/input[3]:6/filter_count:32/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__12214396263859311657<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:1/input[1]:832/input[2]:6/input[3]:6/filter_count:32/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__12214396263859311657<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:1/input[1]:832/input[2]:6/input[3]:6/filter_count:32/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__12214396263859311657<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:1/input[1]:832/input[2]:6/input[3]:6/filter_count:32/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__12214396263859311657<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:1/input[1]:832/input[2]:6/input[3]:6/filter_count:32/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__12214396263859311657<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:1/input[1]:832/input[2]:6/input[3]:6/filter_count:32/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__12214396263859311657<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:1/input[1]:832/input[2]:6/input[3]:6/filter_count:32/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__13579049267917411946<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:512/input[2]:100/input[3]:100/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__13579049267917411946<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:512/input[2]:100/input[3]:100/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__13579049267917411946<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:512/input[2]:100/input[3]:100/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__13579049267917411946<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:512/input[2]:100/input[3]:100/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__13579049267917411946<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:512/input[2]:100/input[3]:100/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__13579049267917411946<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:512/input[2]:100/input[3]:100/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__13579049267917411946<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:512/input[2]:100/input[3]:100/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__13579049267917411946<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:512/input[2]:100/input[3]:100/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__6162321340479005012<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:256/input[2]:100/input[3]:100/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__6162321340479005012<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:256/input[2]:100/input[3]:100/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__6162321340479005012<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:256/input[2]:100/input[3]:100/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__6162321340479005012<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:256/input[2]:100/input[3]:100/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__6162321340479005012<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:256/input[2]:100/input[3]:100/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__6162321340479005012<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:256/input[2]:100/input[3]:100/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__6162321340479005012<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:256/input[2]:100/input[3]:100/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__6162321340479005012<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:256/input[2]:100/input[3]:100/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__14582320161453482827<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:576/input[2]:14/input[3]:14/filter_count:96/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__14582320161453482827<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:576/input[2]:14/input[3]:14/filter_count:96/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__14582320161453482827<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:576/input[2]:14/input[3]:14/filter_count:96/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__14582320161453482827<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:576/input[2]:14/input[3]:14/filter_count:96/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__14582320161453482827<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:576/input[2]:14/input[3]:14/filter_count:96/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__14582320161453482827<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:576/input[2]:14/input[3]:14/filter_count:96/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__14582320161453482827<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:576/input[2]:14/input[3]:14/filter_count:96/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__14582320161453482827<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:576/input[2]:14/input[3]:14/filter_count:96/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__4907009221597460180<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:512/input[2]:100/input[3]:100/filter_count:512/filter_height:3/filter_width:3/pad_height:5/pad_width:5/stride_height:1/stride_width:1/dilation_height:5/dilation_width:5/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__4907009221597460180<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:512/input[2]:100/input[3]:100/filter_count:512/filter_height:3/filter_width:3/pad_height:5/pad_width:5/stride_height:1/stride_width:1/dilation_height:5/dilation_width:5/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__4907009221597460180<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:512/input[2]:100/input[3]:100/filter_count:512/filter_height:3/filter_width:3/pad_height:5/pad_width:5/stride_height:1/stride_width:1/dilation_height:5/dilation_width:5/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__4907009221597460180<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:512/input[2]:100/input[3]:100/filter_count:512/filter_height:3/filter_width:3/pad_height:5/pad_width:5/stride_height:1/stride_width:1/dilation_height:5/dilation_width:5/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__4907009221597460180<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:512/input[2]:100/input[3]:100/filter_count:512/filter_height:3/filter_width:3/pad_height:5/pad_width:5/stride_height:1/stride_width:1/dilation_height:5/dilation_width:5/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__4907009221597460180<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:512/input[2]:100/input[3]:100/filter_count:512/filter_height:3/filter_width:3/pad_height:5/pad_width:5/stride_height:1/stride_width:1/dilation_height:5/dilation_width:5/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__4907009221597460180<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:512/input[2]:100/input[3]:100/filter_count:512/filter_height:3/filter_width:3/pad_height:5/pad_width:5/stride_height:1/stride_width:1/dilation_height:5/dilation_width:5/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__4907009221597460180<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:512/input[2]:100/input[3]:100/filter_count:512/filter_height:3/filter_width:3/pad_height:5/pad_width:5/stride_height:1/stride_width:1/dilation_height:5/dilation_width:5/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__14175138174942404156<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:256/input[2]:8/input[3]:8/filter_count:256/filter_height:3/filter_width:3/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__14175138174942404156<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:256/input[2]:8/input[3]:8/filter_count:256/filter_height:3/filter_width:3/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__14175138174942404156<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:256/input[2]:8/input[3]:8/filter_count:256/filter_height:3/filter_width:3/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__14175138174942404156<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:256/input[2]:8/input[3]:8/filter_count:256/filter_height:3/filter_width:3/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__14175138174942404156<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:256/input[2]:8/input[3]:8/filter_count:256/filter_height:3/filter_width:3/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__14175138174942404156<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:256/input[2]:8/input[3]:8/filter_count:256/filter_height:3/filter_width:3/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__14175138174942404156<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:256/input[2]:8/input[3]:8/filter_count:256/filter_height:3/filter_width:3/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__14175138174942404156<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:256/input[2]:8/input[3]:8/filter_count:256/filter_height:3/filter_width:3/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__16961530857230821012<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:512/input[2]:100/input[3]:100/filter_count:512/filter_height:3/filter_width:3/pad_height:17/pad_width:17/stride_height:1/stride_width:1/dilation_height:17/dilation_width:17/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__16961530857230821012<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:512/input[2]:100/input[3]:100/filter_count:512/filter_height:3/filter_width:3/pad_height:17/pad_width:17/stride_height:1/stride_width:1/dilation_height:17/dilation_width:17/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__16961530857230821012<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:512/input[2]:100/input[3]:100/filter_count:512/filter_height:3/filter_width:3/pad_height:17/pad_width:17/stride_height:1/stride_width:1/dilation_height:17/dilation_width:17/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__16961530857230821012<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:512/input[2]:100/input[3]:100/filter_count:512/filter_height:3/filter_width:3/pad_height:17/pad_width:17/stride_height:1/stride_width:1/dilation_height:17/dilation_width:17/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__16961530857230821012<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:512/input[2]:100/input[3]:100/filter_count:512/filter_height:3/filter_width:3/pad_height:17/pad_width:17/stride_height:1/stride_width:1/dilation_height:17/dilation_width:17/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__16961530857230821012<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:512/input[2]:100/input[3]:100/filter_count:512/filter_height:3/filter_width:3/pad_height:17/pad_width:17/stride_height:1/stride_width:1/dilation_height:17/dilation_width:17/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__16961530857230821012<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:512/input[2]:100/input[3]:100/filter_count:512/filter_height:3/filter_width:3/pad_height:17/pad_width:17/stride_height:1/stride_width:1/dilation_height:17/dilation_width:17/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__16961530857230821012<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:512/input[2]:100/input[3]:100/filter_count:512/filter_height:3/filter_width:3/pad_height:17/pad_width:17/stride_height:1/stride_width:1/dilation_height:17/dilation_width:17/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__13529055723686234354<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:128/input[2]:28/input[3]:28/filter_count:160/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__13529055723686234354<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:128/input[2]:28/input[3]:28/filter_count:160/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__13529055723686234354<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:128/input[2]:28/input[3]:28/filter_count:160/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__13529055723686234354<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:128/input[2]:28/input[3]:28/filter_count:160/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__13529055723686234354<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:128/input[2]:28/input[3]:28/filter_count:160/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__13529055723686234354<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:128/input[2]:28/input[3]:28/filter_count:160/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__13529055723686234354<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:128/input[2]:28/input[3]:28/filter_count:160/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__13529055723686234354<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:128/input[2]:28/input[3]:28/filter_count:160/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__4867954812249902477<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:64/input[2]:52/input[3]:52/filter_count:128/filter_height:3/filter_width:3/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__4867954812249902477<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:64/input[2]:52/input[3]:52/filter_count:128/filter_height:3/filter_width:3/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__4867954812249902477<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:64/input[2]:52/input[3]:52/filter_count:128/filter_height:3/filter_width:3/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__4867954812249902477<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:64/input[2]:52/input[3]:52/filter_count:128/filter_height:3/filter_width:3/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__4867954812249902477<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:64/input[2]:52/input[3]:52/filter_count:128/filter_height:3/filter_width:3/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__4867954812249902477<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:64/input[2]:52/input[3]:52/filter_count:128/filter_height:3/filter_width:3/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__4867954812249902477<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:64/input[2]:52/input[3]:52/filter_count:128/filter_height:3/filter_width:3/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__4867954812249902477<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:64/input[2]:52/input[3]:52/filter_count:128/filter_height:3/filter_width:3/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__17058904980315095466<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:256/input[2]:14/input[3]:14/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__17058904980315095466<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:256/input[2]:14/input[3]:14/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__17058904980315095466<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:256/input[2]:14/input[3]:14/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__17058904980315095466<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:256/input[2]:14/input[3]:14/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__17058904980315095466<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:256/input[2]:14/input[3]:14/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__17058904980315095466<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:256/input[2]:14/input[3]:14/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__17058904980315095466<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:256/input[2]:14/input[3]:14/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__17058904980315095466<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:256/input[2]:14/input[3]:14/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__2928005750715271384<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:128/input[2]:28/input[3]:28/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__2928005750715271384<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:128/input[2]:28/input[3]:28/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__2928005750715271384<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:128/input[2]:28/input[3]:28/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__2928005750715271384<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:128/input[2]:28/input[3]:28/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__2928005750715271384<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:128/input[2]:28/input[3]:28/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__2928005750715271384<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:128/input[2]:28/input[3]:28/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__2928005750715271384<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:128/input[2]:28/input[3]:28/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__2928005750715271384<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:128/input[2]:28/input[3]:28/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__11367813071859073765<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:64/input[2]:13/input[3]:13/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__11367813071859073765<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:64/input[2]:13/input[3]:13/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__11367813071859073765<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:64/input[2]:13/input[3]:13/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__11367813071859073765<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:64/input[2]:13/input[3]:13/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__11367813071859073765<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:64/input[2]:13/input[3]:13/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__11367813071859073765<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:64/input[2]:13/input[3]:13/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__11367813071859073765<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:64/input[2]:13/input[3]:13/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__11367813071859073765<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:64/input[2]:13/input[3]:13/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__14588263526202482829<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:1/input[1]:512/input[2]:13/input[3]:13/filter_count:144/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__14588263526202482829<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:1/input[1]:512/input[2]:13/input[3]:13/filter_count:144/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__14588263526202482829<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:1/input[1]:512/input[2]:13/input[3]:13/filter_count:144/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__14588263526202482829<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:1/input[1]:512/input[2]:13/input[3]:13/filter_count:144/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__14588263526202482829<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:1/input[1]:512/input[2]:13/input[3]:13/filter_count:144/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__14588263526202482829<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:1/input[1]:512/input[2]:13/input[3]:13/filter_count:144/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__14588263526202482829<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:1/input[1]:512/input[2]:13/input[3]:13/filter_count:144/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__14588263526202482829<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:1/input[1]:512/input[2]:13/input[3]:13/filter_count:144/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__6298249107325714156<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:128/input[2]:56/input[3]:56/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__6298249107325714156<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:128/input[2]:56/input[3]:56/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__6298249107325714156<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:128/input[2]:56/input[3]:56/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__6298249107325714156<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:128/input[2]:56/input[3]:56/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__6298249107325714156<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:128/input[2]:56/input[3]:56/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__6298249107325714156<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:128/input[2]:56/input[3]:56/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__6298249107325714156<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:128/input[2]:56/input[3]:56/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__6298249107325714156<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:128/input[2]:56/input[3]:56/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__9562225249255800104<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__9562225249255800104<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__9562225249255800104<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__9562225249255800104<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__9562225249255800104<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__9562225249255800104<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__9562225249255800104<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__9562225249255800104<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__14385595200097480636<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:512/input[2]:7/input[3]:7/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__14385595200097480636<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:512/input[2]:7/input[3]:7/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__14385595200097480636<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:512/input[2]:7/input[3]:7/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__14385595200097480636<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:512/input[2]:7/input[3]:7/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__14385595200097480636<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:512/input[2]:7/input[3]:7/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__14385595200097480636<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:512/input[2]:7/input[3]:7/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__14385595200097480636<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:512/input[2]:7/input[3]:7/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__14385595200097480636<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:512/input[2]:7/input[3]:7/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__17943835395491718644<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:512/input[2]:14/input[3]:14/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__17943835395491718644<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:512/input[2]:14/input[3]:14/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__17943835395491718644<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:512/input[2]:14/input[3]:14/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__17943835395491718644<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:512/input[2]:14/input[3]:14/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__17943835395491718644<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:512/input[2]:14/input[3]:14/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__17943835395491718644<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:512/input[2]:14/input[3]:14/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__17943835395491718644<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:512/input[2]:14/input[3]:14/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__17943835395491718644<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:512/input[2]:14/input[3]:14/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__9070928575328259436<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__9070928575328259436<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__9070928575328259436<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__9070928575328259436<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__9070928575328259436<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__9070928575328259436<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__9070928575328259436<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__9070928575328259436<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__2872861084407136926<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:2048/input[2]:7/input[3]:7/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__2872861084407136926<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:2048/input[2]:7/input[3]:7/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__2872861084407136926<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:2048/input[2]:7/input[3]:7/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__2872861084407136926<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:2048/input[2]:7/input[3]:7/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__2872861084407136926<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:2048/input[2]:7/input[3]:7/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__2872861084407136926<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:2048/input[2]:7/input[3]:7/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__2872861084407136926<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:2048/input[2]:7/input[3]:7/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__2872861084407136926<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:2048/input[2]:7/input[3]:7/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__6263338175559636724<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__6263338175559636724<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__6263338175559636724<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__6263338175559636724<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__6263338175559636724<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__6263338175559636724<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__6263338175559636724<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__6263338175559636724<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__14640196378248879381<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__14640196378248879381<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__14640196378248879381<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__14640196378248879381<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__14640196378248879381<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__14640196378248879381<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__14640196378248879381<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__14640196378248879381<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__10351068418695972412<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:128/input[2]:112/input[3]:112/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__10351068418695972412<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:128/input[2]:112/input[3]:112/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__10351068418695972412<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:128/input[2]:112/input[3]:112/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__10351068418695972412<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:128/input[2]:112/input[3]:112/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__10351068418695972412<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:128/input[2]:112/input[3]:112/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__10351068418695972412<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:128/input[2]:112/input[3]:112/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__10351068418695972412<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:128/input[2]:112/input[3]:112/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__10351068418695972412<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:128/input[2]:112/input[3]:112/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__8242993018864188740<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:64/input[2]:112/input[3]:112/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__8242993018864188740<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:64/input[2]:112/input[3]:112/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__8242993018864188740<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:64/input[2]:112/input[3]:112/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__8242993018864188740<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:64/input[2]:112/input[3]:112/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__8242993018864188740<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:64/input[2]:112/input[3]:112/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__8242993018864188740<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:64/input[2]:112/input[3]:112/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__8242993018864188740<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:64/input[2]:112/input[3]:112/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__8242993018864188740<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:64/input[2]:112/input[3]:112/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__3128501535788430015<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:1024/input[2]:14/input[3]:14/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__3128501535788430015<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:1024/input[2]:14/input[3]:14/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__3128501535788430015<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:1024/input[2]:14/input[3]:14/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__3128501535788430015<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:1024/input[2]:14/input[3]:14/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__3128501535788430015<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:1024/input[2]:14/input[3]:14/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__3128501535788430015<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:1024/input[2]:14/input[3]:14/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__3128501535788430015<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:1024/input[2]:14/input[3]:14/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__3128501535788430015<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:1024/input[2]:14/input[3]:14/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__15128697251547281564<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:128/input[2]:28/input[3]:28/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__15128697251547281564<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:128/input[2]:28/input[3]:28/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__15128697251547281564<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:128/input[2]:28/input[3]:28/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__15128697251547281564<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:128/input[2]:28/input[3]:28/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__15128697251547281564<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:128/input[2]:28/input[3]:28/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__15128697251547281564<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:128/input[2]:28/input[3]:28/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__15128697251547281564<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:128/input[2]:28/input[3]:28/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_FLOAT32__BatchSize_128__15128697251547281564<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:128/input[2]:28/input[3]:28/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__16169773638883887620<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:16/input[2]:55/input[3]:55/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__16169773638883887620<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:16/input[2]:55/input[3]:55/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__16169773638883887620<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:16/input[2]:55/input[3]:55/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__16169773638883887620<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:16/input[2]:55/input[3]:55/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__16169773638883887620<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:16/input[2]:55/input[3]:55/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__16169773638883887620<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:16/input[2]:55/input[3]:55/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__16169773638883887620<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:16/input[2]:55/input[3]:55/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__16169773638883887620<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:16/input[2]:55/input[3]:55/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__972010337835526156<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:1/input[1]:136/input[2]:14/input[3]:14/filter_count:136/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:4/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__972010337835526156<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:1/input[1]:136/input[2]:14/input[3]:14/filter_count:136/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:4/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__972010337835526156<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:1/input[1]:136/input[2]:14/input[3]:14/filter_count:136/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:4/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__972010337835526156<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:1/input[1]:136/input[2]:14/input[3]:14/filter_count:136/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:4/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__972010337835526156<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:1/input[1]:136/input[2]:14/input[3]:14/filter_count:136/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:4/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__972010337835526156<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:1/input[1]:136/input[2]:14/input[3]:14/filter_count:136/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:4/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__972010337835526156<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:1/input[1]:136/input[2]:14/input[3]:14/filter_count:136/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:4/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__972010337835526156<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:1/input[1]:136/input[2]:14/input[3]:14/filter_count:136/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:4/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__6359866969157171536<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:1/input[1]:272/input[2]:14/input[3]:14/filter_count:272/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:4/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__6359866969157171536<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:1/input[1]:272/input[2]:14/input[3]:14/filter_count:272/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:4/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__6359866969157171536<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:1/input[1]:272/input[2]:14/input[3]:14/filter_count:272/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:4/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__6359866969157171536<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:1/input[1]:272/input[2]:14/input[3]:14/filter_count:272/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:4/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__6359866969157171536<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:1/input[1]:272/input[2]:14/input[3]:14/filter_count:272/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:4/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__6359866969157171536<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:1/input[1]:272/input[2]:14/input[3]:14/filter_count:272/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:4/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__6359866969157171536<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:1/input[1]:272/input[2]:14/input[3]:14/filter_count:272/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:4/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__6359866969157171536<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:1/input[1]:272/input[2]:14/input[3]:14/filter_count:272/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:4/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__7688604381410044393<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:1/input[1]:272/input[2]:14/input[3]:14/filter_count:272/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:272/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__7688604381410044393<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:1/input[1]:272/input[2]:14/input[3]:14/filter_count:272/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:272/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__7688604381410044393<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:1/input[1]:272/input[2]:14/input[3]:14/filter_count:272/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:272/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__7688604381410044393<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:1/input[1]:272/input[2]:14/input[3]:14/filter_count:272/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:272/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__7688604381410044393<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:1/input[1]:272/input[2]:14/input[3]:14/filter_count:272/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:272/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__7688604381410044393<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:1/input[1]:272/input[2]:14/input[3]:14/filter_count:272/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:272/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__7688604381410044393<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:1/input[1]:272/input[2]:14/input[3]:14/filter_count:272/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:272/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__7688604381410044393<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:1/input[1]:272/input[2]:14/input[3]:14/filter_count:272/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:272/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__10089576711009153973<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:24/input[2]:56/input[3]:56/filter_count:112/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:4/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__10089576711009153973<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:24/input[2]:56/input[3]:56/filter_count:112/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:4/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__10089576711009153973<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:24/input[2]:56/input[3]:56/filter_count:112/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:4/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__10089576711009153973<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:24/input[2]:56/input[3]:56/filter_count:112/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:4/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__10089576711009153973<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:24/input[2]:56/input[3]:56/filter_count:112/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:4/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__10089576711009153973<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:24/input[2]:56/input[3]:56/filter_count:112/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:4/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__10089576711009153973<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:24/input[2]:56/input[3]:56/filter_count:112/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:4/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__10089576711009153973<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:24/input[2]:56/input[3]:56/filter_count:112/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:4/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__15914800424517040869<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:384/input[2]:13/input[3]:13/filter_count:48/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__15914800424517040869<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:384/input[2]:13/input[3]:13/filter_count:48/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__15914800424517040869<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:384/input[2]:13/input[3]:13/filter_count:48/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__15914800424517040869<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:384/input[2]:13/input[3]:13/filter_count:48/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__15914800424517040869<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:384/input[2]:13/input[3]:13/filter_count:48/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__15914800424517040869<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:384/input[2]:13/input[3]:13/filter_count:48/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__15914800424517040869<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:384/input[2]:13/input[3]:13/filter_count:48/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__15914800424517040869<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:384/input[2]:13/input[3]:13/filter_count:48/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__4337218548239653944<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:1/input[1]:48/input[2]:6/input[3]:6/filter_count:128/filter_height:5/filter_width:5/pad_height:2/pad_width:2/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__4337218548239653944<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:1/input[1]:48/input[2]:6/input[3]:6/filter_count:128/filter_height:5/filter_width:5/pad_height:2/pad_width:2/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__4337218548239653944<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:1/input[1]:48/input[2]:6/input[3]:6/filter_count:128/filter_height:5/filter_width:5/pad_height:2/pad_width:2/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__4337218548239653944<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:1/input[1]:48/input[2]:6/input[3]:6/filter_count:128/filter_height:5/filter_width:5/pad_height:2/pad_width:2/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__4337218548239653944<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:1/input[1]:48/input[2]:6/input[3]:6/filter_count:128/filter_height:5/filter_width:5/pad_height:2/pad_width:2/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__4337218548239653944<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:1/input[1]:48/input[2]:6/input[3]:6/filter_count:128/filter_height:5/filter_width:5/pad_height:2/pad_width:2/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__4337218548239653944<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:1/input[1]:48/input[2]:6/input[3]:6/filter_count:128/filter_height:5/filter_width:5/pad_height:2/pad_width:2/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__4337218548239653944<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:1/input[1]:48/input[2]:6/input[3]:6/filter_count:128/filter_height:5/filter_width:5/pad_height:2/pad_width:2/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__2562839765583816880<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:512/input[2]:13/input[3]:13/filter_count:1000/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__2562839765583816880<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:512/input[2]:13/input[3]:13/filter_count:1000/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__2562839765583816880<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:512/input[2]:13/input[3]:13/filter_count:1000/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__2562839765583816880<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:512/input[2]:13/input[3]:13/filter_count:1000/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__2562839765583816880<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:512/input[2]:13/input[3]:13/filter_count:1000/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__2562839765583816880<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:512/input[2]:13/input[3]:13/filter_count:1000/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__2562839765583816880<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:512/input[2]:13/input[3]:13/filter_count:1000/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__2562839765583816880<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:512/input[2]:13/input[3]:13/filter_count:1000/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__6830662759055045042<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:1/input[1]:832/input[2]:6/input[3]:6/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__6830662759055045042<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:1/input[1]:832/input[2]:6/input[3]:6/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__6830662759055045042<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:1/input[1]:832/input[2]:6/input[3]:6/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__6830662759055045042<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:1/input[1]:832/input[2]:6/input[3]:6/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__6830662759055045042<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:1/input[1]:832/input[2]:6/input[3]:6/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__6830662759055045042<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:1/input[1]:832/input[2]:6/input[3]:6/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__6830662759055045042<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:1/input[1]:832/input[2]:6/input[3]:6/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__6830662759055045042<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:1/input[1]:832/input[2]:6/input[3]:6/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__15540098221680123473<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:1/input[1]:128/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__15540098221680123473<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:1/input[1]:128/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__15540098221680123473<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:1/input[1]:128/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__15540098221680123473<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:1/input[1]:128/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__15540098221680123473<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:1/input[1]:128/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__15540098221680123473<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:1/input[1]:128/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__15540098221680123473<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:1/input[1]:128/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__15540098221680123473<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:1/input[1]:128/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__3043237967567955884<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:1/input[1]:192/input[2]:27/input[3]:27/filter_count:16/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__3043237967567955884<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:1/input[1]:192/input[2]:27/input[3]:27/filter_count:16/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__3043237967567955884<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:1/input[1]:192/input[2]:27/input[3]:27/filter_count:16/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__3043237967567955884<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:1/input[1]:192/input[2]:27/input[3]:27/filter_count:16/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__3043237967567955884<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:1/input[1]:192/input[2]:27/input[3]:27/filter_count:16/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__3043237967567955884<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:1/input[1]:192/input[2]:27/input[3]:27/filter_count:16/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__3043237967567955884<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:1/input[1]:192/input[2]:27/input[3]:27/filter_count:16/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__3043237967567955884<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:1/input[1]:192/input[2]:27/input[3]:27/filter_count:16/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__3930636241252563940<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:1/input[1]:224/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__3930636241252563940<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:1/input[1]:224/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__3930636241252563940<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:1/input[1]:224/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__3930636241252563940<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:1/input[1]:224/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__3930636241252563940<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:1/input[1]:224/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__3930636241252563940<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:1/input[1]:224/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__3930636241252563940<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:1/input[1]:224/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__3930636241252563940<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:1/input[1]:224/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__18283338308808173294<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:1/input[1]:128/input[2]:28/input[3]:28/filter_count:32/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__18283338308808173294<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:1/input[1]:128/input[2]:28/input[3]:28/filter_count:32/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__18283338308808173294<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:1/input[1]:128/input[2]:28/input[3]:28/filter_count:32/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__18283338308808173294<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:1/input[1]:128/input[2]:28/input[3]:28/filter_count:32/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__18283338308808173294<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:1/input[1]:128/input[2]:28/input[3]:28/filter_count:32/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__18283338308808173294<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:1/input[1]:128/input[2]:28/input[3]:28/filter_count:32/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__18283338308808173294<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:1/input[1]:128/input[2]:28/input[3]:28/filter_count:32/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__18283338308808173294<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:1/input[1]:128/input[2]:28/input[3]:28/filter_count:32/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__6309800528572562598<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:1/input[1]:256/input[2]:27/input[3]:27/filter_count:32/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__6309800528572562598<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:1/input[1]:256/input[2]:27/input[3]:27/filter_count:32/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__6309800528572562598<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:1/input[1]:256/input[2]:27/input[3]:27/filter_count:32/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__6309800528572562598<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:1/input[1]:256/input[2]:27/input[3]:27/filter_count:32/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__6309800528572562598<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:1/input[1]:256/input[2]:27/input[3]:27/filter_count:32/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__6309800528572562598<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:1/input[1]:256/input[2]:27/input[3]:27/filter_count:32/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__6309800528572562598<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:1/input[1]:256/input[2]:27/input[3]:27/filter_count:32/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__6309800528572562598<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:1/input[1]:256/input[2]:27/input[3]:27/filter_count:32/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__14674577036701251069<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:1/input[1]:256/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__14674577036701251069<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:1/input[1]:256/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__14674577036701251069<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:1/input[1]:256/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__14674577036701251069<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:1/input[1]:256/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__14674577036701251069<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:1/input[1]:256/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__14674577036701251069<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:1/input[1]:256/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__14674577036701251069<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:1/input[1]:256/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__14674577036701251069<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:1/input[1]:256/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__4180845995860635516<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:512/input[2]:12/input[3]:12/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__4180845995860635516<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:512/input[2]:12/input[3]:12/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__4180845995860635516<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:512/input[2]:12/input[3]:12/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__4180845995860635516<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:512/input[2]:12/input[3]:12/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__4180845995860635516<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:512/input[2]:12/input[3]:12/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__4180845995860635516<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:512/input[2]:12/input[3]:12/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__4180845995860635516<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:512/input[2]:12/input[3]:12/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__4180845995860635516<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:512/input[2]:12/input[3]:12/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__2120557780659131677<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:1/input[1]:128/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__2120557780659131677<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:1/input[1]:128/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__2120557780659131677<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:1/input[1]:128/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__2120557780659131677<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:1/input[1]:128/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__2120557780659131677<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:1/input[1]:128/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__2120557780659131677<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:1/input[1]:128/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__2120557780659131677<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:1/input[1]:128/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__2120557780659131677<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:1/input[1]:128/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__17271315264594299431<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:1/input[1]:480/input[2]:13/input[3]:13/filter_count:192/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__17271315264594299431<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:1/input[1]:480/input[2]:13/input[3]:13/filter_count:192/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__17271315264594299431<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:1/input[1]:480/input[2]:13/input[3]:13/filter_count:192/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__17271315264594299431<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:1/input[1]:480/input[2]:13/input[3]:13/filter_count:192/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__17271315264594299431<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:1/input[1]:480/input[2]:13/input[3]:13/filter_count:192/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__17271315264594299431<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:1/input[1]:480/input[2]:13/input[3]:13/filter_count:192/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__17271315264594299431<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:1/input[1]:480/input[2]:13/input[3]:13/filter_count:192/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__17271315264594299431<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:1/input[1]:480/input[2]:13/input[3]:13/filter_count:192/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__1351179328154132865<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:144/input[2]:14/input[3]:14/filter_count:288/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__1351179328154132865<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:144/input[2]:14/input[3]:14/filter_count:288/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__1351179328154132865<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:144/input[2]:14/input[3]:14/filter_count:288/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__1351179328154132865<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:144/input[2]:14/input[3]:14/filter_count:288/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__1351179328154132865<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:144/input[2]:14/input[3]:14/filter_count:288/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__1351179328154132865<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:144/input[2]:14/input[3]:14/filter_count:288/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__1351179328154132865<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:144/input[2]:14/input[3]:14/filter_count:288/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__1351179328154132865<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:144/input[2]:14/input[3]:14/filter_count:288/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__13051816163919761267<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:480/input[2]:14/input[3]:14/filter_count:16/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__13051816163919761267<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:480/input[2]:14/input[3]:14/filter_count:16/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__13051816163919761267<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:480/input[2]:14/input[3]:14/filter_count:16/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__13051816163919761267<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:480/input[2]:14/input[3]:14/filter_count:16/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__13051816163919761267<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:480/input[2]:14/input[3]:14/filter_count:16/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__13051816163919761267<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:480/input[2]:14/input[3]:14/filter_count:16/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__13051816163919761267<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:480/input[2]:14/input[3]:14/filter_count:16/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__13051816163919761267<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:480/input[2]:14/input[3]:14/filter_count:16/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__3830852759700652469<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:16/input[2]:112/input[3]:112/filter_count:96/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__3830852759700652469<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:16/input[2]:112/input[3]:112/filter_count:96/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__3830852759700652469<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:16/input[2]:112/input[3]:112/filter_count:96/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__3830852759700652469<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:16/input[2]:112/input[3]:112/filter_count:96/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__3830852759700652469<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:16/input[2]:112/input[3]:112/filter_count:96/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__3830852759700652469<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:16/input[2]:112/input[3]:112/filter_count:96/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__3830852759700652469<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:16/input[2]:112/input[3]:112/filter_count:96/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__3830852759700652469<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:16/input[2]:112/input[3]:112/filter_count:96/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__6932479544753593227<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:96/input[2]:26/input[3]:26/filter_count:256/filter_height:5/filter_width:5/pad_height:2/pad_width:2/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:2/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__6932479544753593227<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:96/input[2]:26/input[3]:26/filter_count:256/filter_height:5/filter_width:5/pad_height:2/pad_width:2/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:2/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__6932479544753593227<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:96/input[2]:26/input[3]:26/filter_count:256/filter_height:5/filter_width:5/pad_height:2/pad_width:2/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:2/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__6932479544753593227<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:96/input[2]:26/input[3]:26/filter_count:256/filter_height:5/filter_width:5/pad_height:2/pad_width:2/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:2/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__6932479544753593227<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:96/input[2]:26/input[3]:26/filter_count:256/filter_height:5/filter_width:5/pad_height:2/pad_width:2/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:2/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__6932479544753593227<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:96/input[2]:26/input[3]:26/filter_count:256/filter_height:5/filter_width:5/pad_height:2/pad_width:2/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:2/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__6932479544753593227<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:96/input[2]:26/input[3]:26/filter_count:256/filter_height:5/filter_width:5/pad_height:2/pad_width:2/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:2/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__6932479544753593227<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:96/input[2]:26/input[3]:26/filter_count:256/filter_height:5/filter_width:5/pad_height:2/pad_width:2/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:2/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__12335377408300587202<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:1/input[1]:288/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__12335377408300587202<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:1/input[1]:288/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__12335377408300587202<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:1/input[1]:288/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__12335377408300587202<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:1/input[1]:288/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__12335377408300587202<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:1/input[1]:288/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__12335377408300587202<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:1/input[1]:288/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__12335377408300587202<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:1/input[1]:288/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__12335377408300587202<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:1/input[1]:288/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__6237919692003755528<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:160/input[2]:14/input[3]:14/filter_count:320/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__6237919692003755528<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:160/input[2]:14/input[3]:14/filter_count:320/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__6237919692003755528<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:160/input[2]:14/input[3]:14/filter_count:320/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__6237919692003755528<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:160/input[2]:14/input[3]:14/filter_count:320/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__6237919692003755528<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:160/input[2]:14/input[3]:14/filter_count:320/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__6237919692003755528<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:160/input[2]:14/input[3]:14/filter_count:320/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__6237919692003755528<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:160/input[2]:14/input[3]:14/filter_count:320/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__6237919692003755528<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:160/input[2]:14/input[3]:14/filter_count:320/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__18023355759516697796<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:64/input[2]:55/input[3]:55/filter_count:16/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__18023355759516697796<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:64/input[2]:55/input[3]:55/filter_count:16/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__18023355759516697796<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:64/input[2]:55/input[3]:55/filter_count:16/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__18023355759516697796<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:64/input[2]:55/input[3]:55/filter_count:16/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__18023355759516697796<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:64/input[2]:55/input[3]:55/filter_count:16/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__18023355759516697796<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:64/input[2]:55/input[3]:55/filter_count:16/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__18023355759516697796<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:64/input[2]:55/input[3]:55/filter_count:16/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__18023355759516697796<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:64/input[2]:55/input[3]:55/filter_count:16/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__6339505475346237008<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:512/input[2]:14/input[3]:14/filter_count:144/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__6339505475346237008<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:512/input[2]:14/input[3]:14/filter_count:144/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__6339505475346237008<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:512/input[2]:14/input[3]:14/filter_count:144/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__6339505475346237008<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:512/input[2]:14/input[3]:14/filter_count:144/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__6339505475346237008<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:512/input[2]:14/input[3]:14/filter_count:144/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__6339505475346237008<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:512/input[2]:14/input[3]:14/filter_count:144/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__6339505475346237008<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:512/input[2]:14/input[3]:14/filter_count:144/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__6339505475346237008<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:512/input[2]:14/input[3]:14/filter_count:144/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__4514867126541267301<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:96/input[2]:112/input[3]:112/filter_count:96/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:96/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__4514867126541267301<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:96/input[2]:112/input[3]:112/filter_count:96/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:96/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__4514867126541267301<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:96/input[2]:112/input[3]:112/filter_count:96/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:96/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__4514867126541267301<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:96/input[2]:112/input[3]:112/filter_count:96/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:96/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__4514867126541267301<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:96/input[2]:112/input[3]:112/filter_count:96/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:96/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__4514867126541267301<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:96/input[2]:112/input[3]:112/filter_count:96/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:96/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__4514867126541267301<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:96/input[2]:112/input[3]:112/filter_count:96/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:96/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__4514867126541267301<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:96/input[2]:112/input[3]:112/filter_count:96/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:96/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__670533858076067383<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:1/input[1]:320/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__670533858076067383<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:1/input[1]:320/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__670533858076067383<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:1/input[1]:320/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__670533858076067383<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:1/input[1]:320/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__670533858076067383<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:1/input[1]:320/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__670533858076067383<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:1/input[1]:320/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__670533858076067383<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:1/input[1]:320/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__670533858076067383<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:1/input[1]:320/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__5168181768677779517<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:1/input[1]:128/input[2]:13/input[3]:13/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__5168181768677779517<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:1/input[1]:128/input[2]:13/input[3]:13/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__5168181768677779517<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:1/input[1]:128/input[2]:13/input[3]:13/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__5168181768677779517<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:1/input[1]:128/input[2]:13/input[3]:13/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__5168181768677779517<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:1/input[1]:128/input[2]:13/input[3]:13/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__5168181768677779517<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:1/input[1]:128/input[2]:13/input[3]:13/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__5168181768677779517<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:1/input[1]:128/input[2]:13/input[3]:13/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__5168181768677779517<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:1/input[1]:128/input[2]:13/input[3]:13/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__14393016835965374467<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:1/input[1]:704/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__14393016835965374467<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:1/input[1]:704/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__14393016835965374467<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:1/input[1]:704/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__14393016835965374467<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:1/input[1]:704/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__14393016835965374467<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:1/input[1]:704/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__14393016835965374467<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:1/input[1]:704/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__14393016835965374467<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:1/input[1]:704/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__14393016835965374467<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:1/input[1]:704/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__13009955720426689851<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:1/input[1]:768/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__13009955720426689851<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:1/input[1]:768/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__13009955720426689851<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:1/input[1]:768/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__13009955720426689851<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:1/input[1]:768/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__13009955720426689851<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:1/input[1]:768/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__13009955720426689851<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:1/input[1]:768/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__13009955720426689851<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:1/input[1]:768/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__13009955720426689851<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:1/input[1]:768/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__5452294292262303092<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:128/input[2]:199/input[3]:199/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__5452294292262303092<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:128/input[2]:199/input[3]:199/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__5452294292262303092<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:128/input[2]:199/input[3]:199/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__5452294292262303092<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:128/input[2]:199/input[3]:199/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__5452294292262303092<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:128/input[2]:199/input[3]:199/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__5452294292262303092<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:128/input[2]:199/input[3]:199/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__5452294292262303092<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:128/input[2]:199/input[3]:199/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__5452294292262303092<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:128/input[2]:199/input[3]:199/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__1494202957548002979<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:832/input[2]:7/input[3]:7/filter_count:192/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__1494202957548002979<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:832/input[2]:7/input[3]:7/filter_count:192/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__1494202957548002979<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:832/input[2]:7/input[3]:7/filter_count:192/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__1494202957548002979<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:832/input[2]:7/input[3]:7/filter_count:192/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__1494202957548002979<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:832/input[2]:7/input[3]:7/filter_count:192/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__1494202957548002979<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:832/input[2]:7/input[3]:7/filter_count:192/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__1494202957548002979<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:832/input[2]:7/input[3]:7/filter_count:192/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__1494202957548002979<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:832/input[2]:7/input[3]:7/filter_count:192/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__10477223231936199684<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:160/input[2]:7/input[3]:7/filter_count:320/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__10477223231936199684<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:160/input[2]:7/input[3]:7/filter_count:320/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__10477223231936199684<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:160/input[2]:7/input[3]:7/filter_count:320/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__10477223231936199684<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:160/input[2]:7/input[3]:7/filter_count:320/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__10477223231936199684<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:160/input[2]:7/input[3]:7/filter_count:320/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__10477223231936199684<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:160/input[2]:7/input[3]:7/filter_count:320/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__10477223231936199684<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:160/input[2]:7/input[3]:7/filter_count:320/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__10477223231936199684<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:160/input[2]:7/input[3]:7/filter_count:320/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__8221520561120285748<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:1/input[1]:544/input[2]:7/input[3]:7/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__8221520561120285748<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:1/input[1]:544/input[2]:7/input[3]:7/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__8221520561120285748<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:1/input[1]:544/input[2]:7/input[3]:7/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__8221520561120285748<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:1/input[1]:544/input[2]:7/input[3]:7/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__8221520561120285748<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:1/input[1]:544/input[2]:7/input[3]:7/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__8221520561120285748<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:1/input[1]:544/input[2]:7/input[3]:7/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__8221520561120285748<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:1/input[1]:544/input[2]:7/input[3]:7/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__8221520561120285748<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:1/input[1]:544/input[2]:7/input[3]:7/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__995781860295843966<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:1/input[1]:448/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__995781860295843966<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:1/input[1]:448/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__995781860295843966<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:1/input[1]:448/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__995781860295843966<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:1/input[1]:448/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__995781860295843966<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:1/input[1]:448/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__995781860295843966<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:1/input[1]:448/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__995781860295843966<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:1/input[1]:448/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__995781860295843966<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:1/input[1]:448/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__16403170060639865380<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:1/input[1]:928/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__16403170060639865380<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:1/input[1]:928/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__16403170060639865380<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:1/input[1]:928/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__16403170060639865380<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:1/input[1]:928/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__16403170060639865380<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:1/input[1]:928/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__16403170060639865380<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:1/input[1]:928/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__16403170060639865380<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:1/input[1]:928/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__16403170060639865380<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:1/input[1]:928/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__18432505984245721748<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:1/input[1]:896/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__18432505984245721748<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:1/input[1]:896/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__18432505984245721748<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:1/input[1]:896/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__18432505984245721748<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:1/input[1]:896/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__18432505984245721748<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:1/input[1]:896/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__18432505984245721748<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:1/input[1]:896/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__18432505984245721748<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:1/input[1]:896/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__18432505984245721748<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:1/input[1]:896/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__16909330632506389045<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:384/input[2]:28/input[3]:28/filter_count:384/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:384/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__16909330632506389045<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:384/input[2]:28/input[3]:28/filter_count:384/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:384/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__16909330632506389045<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:384/input[2]:28/input[3]:28/filter_count:384/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:384/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__16909330632506389045<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:384/input[2]:28/input[3]:28/filter_count:384/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:384/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__16909330632506389045<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:384/input[2]:28/input[3]:28/filter_count:384/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:384/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__16909330632506389045<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:384/input[2]:28/input[3]:28/filter_count:384/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:384/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__16909330632506389045<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:384/input[2]:28/input[3]:28/filter_count:384/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:384/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__16909330632506389045<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:384/input[2]:28/input[3]:28/filter_count:384/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:384/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__15068298120463786504<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:1/input[1]:512/input[2]:13/input[3]:13/filter_count:32/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__15068298120463786504<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:1/input[1]:512/input[2]:13/input[3]:13/filter_count:32/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__15068298120463786504<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:1/input[1]:512/input[2]:13/input[3]:13/filter_count:32/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__15068298120463786504<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:1/input[1]:512/input[2]:13/input[3]:13/filter_count:32/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__15068298120463786504<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:1/input[1]:512/input[2]:13/input[3]:13/filter_count:32/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__15068298120463786504<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:1/input[1]:512/input[2]:13/input[3]:13/filter_count:32/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__15068298120463786504<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:1/input[1]:512/input[2]:13/input[3]:13/filter_count:32/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__15068298120463786504<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:1/input[1]:512/input[2]:13/input[3]:13/filter_count:32/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__14326440837465517151<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:1/input[1]:480/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__14326440837465517151<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:1/input[1]:480/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__14326440837465517151<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:1/input[1]:480/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__14326440837465517151<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:1/input[1]:480/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__14326440837465517151<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:1/input[1]:480/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__14326440837465517151<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:1/input[1]:480/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__14326440837465517151<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:1/input[1]:480/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__14326440837465517151<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:1/input[1]:480/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__7240335983645887293<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:1/input[1]:960/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__7240335983645887293<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:1/input[1]:960/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__7240335983645887293<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:1/input[1]:960/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__7240335983645887293<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:1/input[1]:960/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__7240335983645887293<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:1/input[1]:960/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__7240335983645887293<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:1/input[1]:960/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__7240335983645887293<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:1/input[1]:960/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__7240335983645887293<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:1/input[1]:960/input[2]:14/input[3]:14/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__3508945788052142604<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:1/input[1]:112/input[2]:13/input[3]:13/filter_count:224/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__3508945788052142604<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:1/input[1]:112/input[2]:13/input[3]:13/filter_count:224/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__3508945788052142604<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:1/input[1]:112/input[2]:13/input[3]:13/filter_count:224/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__3508945788052142604<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:1/input[1]:112/input[2]:13/input[3]:13/filter_count:224/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__3508945788052142604<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:1/input[1]:112/input[2]:13/input[3]:13/filter_count:224/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__3508945788052142604<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:1/input[1]:112/input[2]:13/input[3]:13/filter_count:224/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__3508945788052142604<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:1/input[1]:112/input[2]:13/input[3]:13/filter_count:224/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__3508945788052142604<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:1/input[1]:112/input[2]:13/input[3]:13/filter_count:224/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__15290371352394127559<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:1/input[1]:512/input[2]:13/input[3]:13/filter_count:24/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__15290371352394127559<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:1/input[1]:512/input[2]:13/input[3]:13/filter_count:24/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__15290371352394127559<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:1/input[1]:512/input[2]:13/input[3]:13/filter_count:24/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__15290371352394127559<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:1/input[1]:512/input[2]:13/input[3]:13/filter_count:24/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__15290371352394127559<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:1/input[1]:512/input[2]:13/input[3]:13/filter_count:24/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__15290371352394127559<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:1/input[1]:512/input[2]:13/input[3]:13/filter_count:24/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__15290371352394127559<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:1/input[1]:512/input[2]:13/input[3]:13/filter_count:24/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__15290371352394127559<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:1/input[1]:512/input[2]:13/input[3]:13/filter_count:24/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__11884789225813939908<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:192/input[2]:7/input[3]:7/filter_count:384/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__11884789225813939908<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:192/input[2]:7/input[3]:7/filter_count:384/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__11884789225813939908<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:192/input[2]:7/input[3]:7/filter_count:384/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__11884789225813939908<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:192/input[2]:7/input[3]:7/filter_count:384/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__11884789225813939908<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:192/input[2]:7/input[3]:7/filter_count:384/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__11884789225813939908<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:192/input[2]:7/input[3]:7/filter_count:384/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__11884789225813939908<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:192/input[2]:7/input[3]:7/filter_count:384/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__11884789225813939908<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:192/input[2]:7/input[3]:7/filter_count:384/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__5529794847985927785<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:48/input[2]:7/input[3]:7/filter_count:128/filter_height:5/filter_width:5/pad_height:2/pad_width:2/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__5529794847985927785<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:48/input[2]:7/input[3]:7/filter_count:128/filter_height:5/filter_width:5/pad_height:2/pad_width:2/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__5529794847985927785<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:48/input[2]:7/input[3]:7/filter_count:128/filter_height:5/filter_width:5/pad_height:2/pad_width:2/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__5529794847985927785<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:48/input[2]:7/input[3]:7/filter_count:128/filter_height:5/filter_width:5/pad_height:2/pad_width:2/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__5529794847985927785<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:48/input[2]:7/input[3]:7/filter_count:128/filter_height:5/filter_width:5/pad_height:2/pad_width:2/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__5529794847985927785<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:48/input[2]:7/input[3]:7/filter_count:128/filter_height:5/filter_width:5/pad_height:2/pad_width:2/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__5529794847985927785<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:48/input[2]:7/input[3]:7/filter_count:128/filter_height:5/filter_width:5/pad_height:2/pad_width:2/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__5529794847985927785<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:48/input[2]:7/input[3]:7/filter_count:128/filter_height:5/filter_width:5/pad_height:2/pad_width:2/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__3665417485103352688<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:832/input[2]:7/input[3]:7/filter_count:32/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__3665417485103352688<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:832/input[2]:7/input[3]:7/filter_count:32/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__3665417485103352688<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:832/input[2]:7/input[3]:7/filter_count:32/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__3665417485103352688<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:832/input[2]:7/input[3]:7/filter_count:32/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__3665417485103352688<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:832/input[2]:7/input[3]:7/filter_count:32/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__3665417485103352688<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:832/input[2]:7/input[3]:7/filter_count:32/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__3665417485103352688<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:832/input[2]:7/input[3]:7/filter_count:32/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__3665417485103352688<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:832/input[2]:7/input[3]:7/filter_count:32/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__10195652698245888212<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:1/input[1]:672/input[2]:7/input[3]:7/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__10195652698245888212<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:1/input[1]:672/input[2]:7/input[3]:7/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__10195652698245888212<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:1/input[1]:672/input[2]:7/input[3]:7/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__10195652698245888212<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:1/input[1]:672/input[2]:7/input[3]:7/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__10195652698245888212<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:1/input[1]:672/input[2]:7/input[3]:7/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__10195652698245888212<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:1/input[1]:672/input[2]:7/input[3]:7/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__10195652698245888212<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:1/input[1]:672/input[2]:7/input[3]:7/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__10195652698245888212<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:1/input[1]:672/input[2]:7/input[3]:7/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__11642544894090319085<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:960/input[2]:7/input[3]:7/filter_count:960/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:960/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__11642544894090319085<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:960/input[2]:7/input[3]:7/filter_count:960/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:960/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__11642544894090319085<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:960/input[2]:7/input[3]:7/filter_count:960/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:960/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__11642544894090319085<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:960/input[2]:7/input[3]:7/filter_count:960/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:960/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__11642544894090319085<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:960/input[2]:7/input[3]:7/filter_count:960/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:960/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__11642544894090319085<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:960/input[2]:7/input[3]:7/filter_count:960/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:960/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__11642544894090319085<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:960/input[2]:7/input[3]:7/filter_count:960/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:960/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__11642544894090319085<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:960/input[2]:7/input[3]:7/filter_count:960/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:960/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__10445561953826416545<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:64/input[2]:32/input[3]:32/filter_count:128/filter_height:3/filter_width:3/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__10445561953826416545<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:64/input[2]:32/input[3]:32/filter_count:128/filter_height:3/filter_width:3/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__10445561953826416545<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:64/input[2]:32/input[3]:32/filter_count:128/filter_height:3/filter_width:3/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__10445561953826416545<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:64/input[2]:32/input[3]:32/filter_count:128/filter_height:3/filter_width:3/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__10445561953826416545<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:64/input[2]:32/input[3]:32/filter_count:128/filter_height:3/filter_width:3/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__10445561953826416545<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:64/input[2]:32/input[3]:32/filter_count:128/filter_height:3/filter_width:3/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__10445561953826416545<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:64/input[2]:32/input[3]:32/filter_count:128/filter_height:3/filter_width:3/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__10445561953826416545<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:64/input[2]:32/input[3]:32/filter_count:128/filter_height:3/filter_width:3/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__5436253109781300155<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:1/input[1]:512/input[2]:13/input[3]:13/filter_count:112/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__5436253109781300155<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:1/input[1]:512/input[2]:13/input[3]:13/filter_count:112/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__5436253109781300155<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:1/input[1]:512/input[2]:13/input[3]:13/filter_count:112/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__5436253109781300155<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:1/input[1]:512/input[2]:13/input[3]:13/filter_count:112/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__5436253109781300155<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:1/input[1]:512/input[2]:13/input[3]:13/filter_count:112/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__5436253109781300155<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:1/input[1]:512/input[2]:13/input[3]:13/filter_count:112/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__5436253109781300155<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:1/input[1]:512/input[2]:13/input[3]:13/filter_count:112/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__5436253109781300155<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:1/input[1]:512/input[2]:13/input[3]:13/filter_count:112/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__18121406941540699140<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:1/input[1]:736/input[2]:7/input[3]:7/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__18121406941540699140<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:1/input[1]:736/input[2]:7/input[3]:7/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__18121406941540699140<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:1/input[1]:736/input[2]:7/input[3]:7/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__18121406941540699140<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:1/input[1]:736/input[2]:7/input[3]:7/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__18121406941540699140<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:1/input[1]:736/input[2]:7/input[3]:7/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__18121406941540699140<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:1/input[1]:736/input[2]:7/input[3]:7/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__18121406941540699140<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:1/input[1]:736/input[2]:7/input[3]:7/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__18121406941540699140<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:1/input[1]:736/input[2]:7/input[3]:7/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__11090351917531343346<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:480/input[2]:14/input[3]:14/filter_count:192/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__11090351917531343346<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:480/input[2]:14/input[3]:14/filter_count:192/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__11090351917531343346<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:480/input[2]:14/input[3]:14/filter_count:192/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__11090351917531343346<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:480/input[2]:14/input[3]:14/filter_count:192/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__11090351917531343346<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:480/input[2]:14/input[3]:14/filter_count:192/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__11090351917531343346<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:480/input[2]:14/input[3]:14/filter_count:192/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__11090351917531343346<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:480/input[2]:14/input[3]:14/filter_count:192/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__11090351917531343346<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:480/input[2]:14/input[3]:14/filter_count:192/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__8489613993998248489<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:192/input[2]:28/input[3]:28/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__8489613993998248489<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:192/input[2]:28/input[3]:28/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__8489613993998248489<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:192/input[2]:28/input[3]:28/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__8489613993998248489<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:192/input[2]:28/input[3]:28/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__8489613993998248489<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:192/input[2]:28/input[3]:28/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__8489613993998248489<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:192/input[2]:28/input[3]:28/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__8489613993998248489<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:192/input[2]:28/input[3]:28/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__8489613993998248489<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:192/input[2]:28/input[3]:28/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__5560699537725816344<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:96/input[2]:28/input[3]:28/filter_count:96/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__5560699537725816344<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:96/input[2]:28/input[3]:28/filter_count:96/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__5560699537725816344<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:96/input[2]:28/input[3]:28/filter_count:96/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__5560699537725816344<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:96/input[2]:28/input[3]:28/filter_count:96/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__5560699537725816344<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:96/input[2]:28/input[3]:28/filter_count:96/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__5560699537725816344<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:96/input[2]:28/input[3]:28/filter_count:96/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__5560699537725816344<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:96/input[2]:28/input[3]:28/filter_count:96/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__5560699537725816344<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:96/input[2]:28/input[3]:28/filter_count:96/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__9116135508566071309<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:64/input[2]:14/input[3]:14/filter_count:96/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__9116135508566071309<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:64/input[2]:14/input[3]:14/filter_count:96/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__9116135508566071309<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:64/input[2]:14/input[3]:14/filter_count:96/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__9116135508566071309<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:64/input[2]:14/input[3]:14/filter_count:96/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__9116135508566071309<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:64/input[2]:14/input[3]:14/filter_count:96/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__9116135508566071309<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:64/input[2]:14/input[3]:14/filter_count:96/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__9116135508566071309<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:64/input[2]:14/input[3]:14/filter_count:96/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__9116135508566071309<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:64/input[2]:14/input[3]:14/filter_count:96/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__4963210424433599508<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:160/input[2]:14/input[3]:14/filter_count:160/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__4963210424433599508<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:160/input[2]:14/input[3]:14/filter_count:160/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__4963210424433599508<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:160/input[2]:14/input[3]:14/filter_count:160/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__4963210424433599508<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:160/input[2]:14/input[3]:14/filter_count:160/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__4963210424433599508<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:160/input[2]:14/input[3]:14/filter_count:160/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__4963210424433599508<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:160/input[2]:14/input[3]:14/filter_count:160/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__4963210424433599508<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:160/input[2]:14/input[3]:14/filter_count:160/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__4963210424433599508<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:160/input[2]:14/input[3]:14/filter_count:160/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__12257998807915311908<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:512/input[2]:100/input[3]:100/filter_count:512/filter_height:3/filter_width:3/pad_height:9/pad_width:9/stride_height:1/stride_width:1/dilation_height:9/dilation_width:9/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__12257998807915311908<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:512/input[2]:100/input[3]:100/filter_count:512/filter_height:3/filter_width:3/pad_height:9/pad_width:9/stride_height:1/stride_width:1/dilation_height:9/dilation_width:9/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__12257998807915311908<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:512/input[2]:100/input[3]:100/filter_count:512/filter_height:3/filter_width:3/pad_height:9/pad_width:9/stride_height:1/stride_width:1/dilation_height:9/dilation_width:9/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__12257998807915311908<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:512/input[2]:100/input[3]:100/filter_count:512/filter_height:3/filter_width:3/pad_height:9/pad_width:9/stride_height:1/stride_width:1/dilation_height:9/dilation_width:9/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__12257998807915311908<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:512/input[2]:100/input[3]:100/filter_count:512/filter_height:3/filter_width:3/pad_height:9/pad_width:9/stride_height:1/stride_width:1/dilation_height:9/dilation_width:9/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__12257998807915311908<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:512/input[2]:100/input[3]:100/filter_count:512/filter_height:3/filter_width:3/pad_height:9/pad_width:9/stride_height:1/stride_width:1/dilation_height:9/dilation_width:9/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__12257998807915311908<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:512/input[2]:100/input[3]:100/filter_count:512/filter_height:3/filter_width:3/pad_height:9/pad_width:9/stride_height:1/stride_width:1/dilation_height:9/dilation_width:9/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__12257998807915311908<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:512/input[2]:100/input[3]:100/filter_count:512/filter_height:3/filter_width:3/pad_height:9/pad_width:9/stride_height:1/stride_width:1/dilation_height:9/dilation_width:9/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "Exception in CUDNN/CONV_FWDstd::bad_alloc",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__10388139115557651280<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:192/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__10388139115557651280<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:192/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__10388139115557651280<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:192/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__10388139115557651280<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:192/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__10388139115557651280<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:192/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__10388139115557651280<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:192/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__10388139115557651280<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:192/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__10388139115557651280<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:192/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__12198960507689519729<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:192/input[2]:7/input[3]:7/filter_count:224/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__12198960507689519729<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:192/input[2]:7/input[3]:7/filter_count:224/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__12198960507689519729<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:192/input[2]:7/input[3]:7/filter_count:224/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__12198960507689519729<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:192/input[2]:7/input[3]:7/filter_count:224/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__12198960507689519729<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:192/input[2]:7/input[3]:7/filter_count:224/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__12198960507689519729<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:192/input[2]:7/input[3]:7/filter_count:224/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__12198960507689519729<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:192/input[2]:7/input[3]:7/filter_count:224/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__12198960507689519729<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:192/input[2]:7/input[3]:7/filter_count:224/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__13348320634927797247<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:256/input[2]:28/input[3]:28/filter_count:32/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__13348320634927797247<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:256/input[2]:28/input[3]:28/filter_count:32/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__13348320634927797247<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:256/input[2]:28/input[3]:28/filter_count:32/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__13348320634927797247<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:256/input[2]:28/input[3]:28/filter_count:32/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__13348320634927797247<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:256/input[2]:28/input[3]:28/filter_count:32/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__13348320634927797247<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:256/input[2]:28/input[3]:28/filter_count:32/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__13348320634927797247<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:256/input[2]:28/input[3]:28/filter_count:32/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__13348320634927797247<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:256/input[2]:28/input[3]:28/filter_count:32/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__12848057424107778243<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:1024/input[2]:7/input[3]:7/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__12848057424107778243<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:1024/input[2]:7/input[3]:7/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__12848057424107778243<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:1024/input[2]:7/input[3]:7/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__12848057424107778243<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:1024/input[2]:7/input[3]:7/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__12848057424107778243<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:1024/input[2]:7/input[3]:7/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__12848057424107778243<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:1024/input[2]:7/input[3]:7/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__12848057424107778243<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:1024/input[2]:7/input[3]:7/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__12848057424107778243<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:1024/input[2]:7/input[3]:7/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__8480388862092924848<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:3/input[2]:416/input[3]:416/filter_count:16/filter_height:3/filter_width:3/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__8480388862092924848<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:3/input[2]:416/input[3]:416/filter_count:16/filter_height:3/filter_width:3/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__8480388862092924848<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:3/input[2]:416/input[3]:416/filter_count:16/filter_height:3/filter_width:3/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__8480388862092924848<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:3/input[2]:416/input[3]:416/filter_count:16/filter_height:3/filter_width:3/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__8480388862092924848<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:3/input[2]:416/input[3]:416/filter_count:16/filter_height:3/filter_width:3/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__8480388862092924848<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:3/input[2]:416/input[3]:416/filter_count:16/filter_height:3/filter_width:3/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__8480388862092924848<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:3/input[2]:416/input[3]:416/filter_count:16/filter_height:3/filter_width:3/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__8480388862092924848<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:3/input[2]:416/input[3]:416/filter_count:16/filter_height:3/filter_width:3/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__75158071466409667<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:384/input[2]:13/input[3]:13/filter_count:384/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:2/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__75158071466409667<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:384/input[2]:13/input[3]:13/filter_count:384/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:2/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__75158071466409667<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:384/input[2]:13/input[3]:13/filter_count:384/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:2/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__75158071466409667<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:384/input[2]:13/input[3]:13/filter_count:384/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:2/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__75158071466409667<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:384/input[2]:13/input[3]:13/filter_count:384/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:2/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__75158071466409667<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:384/input[2]:13/input[3]:13/filter_count:384/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:2/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__75158071466409667<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:384/input[2]:13/input[3]:13/filter_count:384/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:2/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__75158071466409667<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:384/input[2]:13/input[3]:13/filter_count:384/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:2/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__17213637575625633055<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:160/input[2]:7/input[3]:7/filter_count:224/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__17213637575625633055<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:160/input[2]:7/input[3]:7/filter_count:224/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__17213637575625633055<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:160/input[2]:7/input[3]:7/filter_count:224/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__17213637575625633055<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:160/input[2]:7/input[3]:7/filter_count:224/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__17213637575625633055<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:160/input[2]:7/input[3]:7/filter_count:224/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__17213637575625633055<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:160/input[2]:7/input[3]:7/filter_count:224/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__17213637575625633055<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:160/input[2]:7/input[3]:7/filter_count:224/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__17213637575625633055<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:160/input[2]:7/input[3]:7/filter_count:224/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__13564343922843240531<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:2048/input[2]:100/input[3]:100/filter_count:304/filter_height:3/filter_width:3/pad_height:6/pad_width:6/stride_height:1/stride_width:1/dilation_height:6/dilation_width:6/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD failed to cudnnSetTensor4dDescriptor",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__13564343922843240531<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:2048/input[2]:100/input[3]:100/filter_count:304/filter_height:3/filter_width:3/pad_height:6/pad_width:6/stride_height:1/stride_width:1/dilation_height:6/dilation_width:6/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD failed to cudnnSetTensor4dDescriptor",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__13564343922843240531<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:2048/input[2]:100/input[3]:100/filter_count:304/filter_height:3/filter_width:3/pad_height:6/pad_width:6/stride_height:1/stride_width:1/dilation_height:6/dilation_width:6/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD failed to cudnnSetTensor4dDescriptor",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__13564343922843240531<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:2048/input[2]:100/input[3]:100/filter_count:304/filter_height:3/filter_width:3/pad_height:6/pad_width:6/stride_height:1/stride_width:1/dilation_height:6/dilation_width:6/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD failed to cudnnSetTensor4dDescriptor",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__13564343922843240531<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:2048/input[2]:100/input[3]:100/filter_count:304/filter_height:3/filter_width:3/pad_height:6/pad_width:6/stride_height:1/stride_width:1/dilation_height:6/dilation_width:6/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD failed to cudnnSetTensor4dDescriptor",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__13564343922843240531<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:2048/input[2]:100/input[3]:100/filter_count:304/filter_height:3/filter_width:3/pad_height:6/pad_width:6/stride_height:1/stride_width:1/dilation_height:6/dilation_width:6/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD failed to cudnnSetTensor4dDescriptor",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__13564343922843240531<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:2048/input[2]:100/input[3]:100/filter_count:304/filter_height:3/filter_width:3/pad_height:6/pad_width:6/stride_height:1/stride_width:1/dilation_height:6/dilation_width:6/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD failed to cudnnSetTensor4dDescriptor",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__13564343922843240531<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:2048/input[2]:100/input[3]:100/filter_count:304/filter_height:3/filter_width:3/pad_height:6/pad_width:6/stride_height:1/stride_width:1/dilation_height:6/dilation_width:6/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD failed to cudnnSetTensor4dDescriptor",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__5166164685744749187<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:144/input[2]:56/input[3]:56/filter_count:144/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:144/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__5166164685744749187<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:144/input[2]:56/input[3]:56/filter_count:144/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:144/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__5166164685744749187<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:144/input[2]:56/input[3]:56/filter_count:144/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:144/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__5166164685744749187<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:144/input[2]:56/input[3]:56/filter_count:144/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:144/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__5166164685744749187<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:144/input[2]:56/input[3]:56/filter_count:144/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:144/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__5166164685744749187<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:144/input[2]:56/input[3]:56/filter_count:144/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:144/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__5166164685744749187<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:144/input[2]:56/input[3]:56/filter_count:144/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:144/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__5166164685744749187<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:144/input[2]:56/input[3]:56/filter_count:144/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:144/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to cudnnGetConvolution2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__16657387963186277128<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:256/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__16657387963186277128<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:256/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__16657387963186277128<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:256/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__16657387963186277128<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:256/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__16657387963186277128<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:256/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__16657387963186277128<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:256/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__16657387963186277128<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:256/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__16657387963186277128<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:256/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__14716849201188773238<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:512/input[2]:7/input[3]:7/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__14716849201188773238<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:512/input[2]:7/input[3]:7/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__14716849201188773238<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:512/input[2]:7/input[3]:7/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__14716849201188773238<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:512/input[2]:7/input[3]:7/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__14716849201188773238<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:512/input[2]:7/input[3]:7/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__14716849201188773238<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:512/input[2]:7/input[3]:7/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__14716849201188773238<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:512/input[2]:7/input[3]:7/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__14716849201188773238<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:512/input[2]:7/input[3]:7/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__4394929117217488063<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:1024/input[2]:14/input[3]:14/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__4394929117217488063<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:1024/input[2]:14/input[3]:14/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__4394929117217488063<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:1024/input[2]:14/input[3]:14/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__4394929117217488063<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:1024/input[2]:14/input[3]:14/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__4394929117217488063<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:1024/input[2]:14/input[3]:14/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__4394929117217488063<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:1024/input[2]:14/input[3]:14/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__4394929117217488063<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:1024/input[2]:14/input[3]:14/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__4394929117217488063<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:1024/input[2]:14/input[3]:14/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__15969503444992457156<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:128/input[2]:100/input[3]:100/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__15969503444992457156<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:128/input[2]:100/input[3]:100/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__15969503444992457156<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:128/input[2]:100/input[3]:100/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__15969503444992457156<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:128/input[2]:100/input[3]:100/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__15969503444992457156<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:128/input[2]:100/input[3]:100/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__15969503444992457156<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:128/input[2]:100/input[3]:100/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__15969503444992457156<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:128/input[2]:100/input[3]:100/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__15969503444992457156<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:128/input[2]:100/input[3]:100/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__5981565955212840185<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:64/input[2]:56/input[3]:56/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__5981565955212840185<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:64/input[2]:56/input[3]:56/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__5981565955212840185<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:64/input[2]:56/input[3]:56/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__5981565955212840185<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:64/input[2]:56/input[3]:56/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__5981565955212840185<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:64/input[2]:56/input[3]:56/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__5981565955212840185<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:64/input[2]:56/input[3]:56/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__5981565955212840185<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:64/input[2]:56/input[3]:56/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__5981565955212840185<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:64/input[2]:56/input[3]:56/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__16971164566866137272<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:512/input[2]:14/input[3]:14/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__16971164566866137272<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:512/input[2]:14/input[3]:14/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__16971164566866137272<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:512/input[2]:14/input[3]:14/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__16971164566866137272<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:512/input[2]:14/input[3]:14/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__16971164566866137272<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:512/input[2]:14/input[3]:14/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__16971164566866137272<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:512/input[2]:14/input[3]:14/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__16971164566866137272<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:512/input[2]:14/input[3]:14/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__16971164566866137272<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:512/input[2]:14/input[3]:14/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__3471640941490868128<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:128/input[1]:3/input[2]:112/input[3]:112/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__3471640941490868128<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:128/input[1]:3/input[2]:112/input[3]:112/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__3471640941490868128<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:128/input[1]:3/input[2]:112/input[3]:112/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__3471640941490868128<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:128/input[1]:3/input[2]:112/input[3]:112/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__3471640941490868128<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:128/input[1]:3/input[2]:112/input[3]:112/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__3471640941490868128<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:128/input[1]:3/input[2]:112/input[3]:112/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__3471640941490868128<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:128/input[1]:3/input[2]:112/input[3]:112/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_FLOAT32__BatchSize_128__3471640941490868128<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:128/input[1]:3/input[2]:112/input[3]:112/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:128/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_DROPOUT_FWD_FLOAT32__BatchSize_128__14874554712254526533/input[0]:1/input[1]:1024/input[2]:1/input[3]:1/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_DROPOUT_FWD_FLOAT32__BatchSize_128__7059844864622109039/input[0]:128/input[1]:512/input[2]:13/input[3]:13/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_DROPOUT_FWD_FLOAT32__BatchSize_128__402683540774037342/input[0]:128/input[1]:1024/input[2]:1/input[3]:1/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_DROPOUT_FWD_FLOAT32__BatchSize_128__18341856093365895807/input[0]:128/input[1]:64/input[2]:32/input[3]:32/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_DROPOUT_FWD_FLOAT32__BatchSize_128__13705821161794981523/input[0]:128/input[1]:128/input[2]:16/input[3]:16/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_DROPOUT_FWD_FLOAT32__BatchSize_128__16930707074709615899/input[0]:128/input[1]:256/input[2]:8/input[3]:8/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_DROPOUT_FWD_FLOAT32__BatchSize_128__5528603025886191828/input[0]:1/input[1]:4096/input[2]:-1/input[3]:-1/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_DROPOUT_FWD_FLOAT32__BatchSize_128__663994574542691333/input[0]:128/input[1]:256/input[2]:4/input[3]:4/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_DROPOUT_FWD_FLOAT32__BatchSize_128__9538753626685623055/input[0]:128/input[1]:512/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_DROPOUT_FWD_FLOAT32__BatchSize_128__17983908109240499243/input[0]:128/input[1]:4096/input[2]:-1/input[3]:-1/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_ADD_FWD_FLOAT32__BatchSize_128__8602742229904642917/input[0]:1/input[1]:272/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_ADD_FWD_FLOAT32__BatchSize_128__4889074840031823528/input[0]:1/input[1]:136/input[2]:28/input[3]:28/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_MUL_FWD_FLOAT32__BatchSize_128__16222927563893588573/input[0]:1/input[1]:224/input[2]:28/input[3]:28/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_ADD_FWD_FLOAT32__BatchSize_128__11859752660777327245/input[0]:1/input[1]:512/input[2]:28/input[3]:28/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_MUL_FWD_FLOAT32__BatchSize_128__4000415970715328467/input[0]:1/input[1]:64/input[2]:112/input[3]:112/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_ADD_FWD_FLOAT32__BatchSize_128__9318785962376274809/input[0]:1/input[1]:64/input[2]:112/input[3]:112/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_MUL_FWD_FLOAT32__BatchSize_128__15696134578862174127/input[0]:1/input[1]:64/input[2]:56/input[3]:56/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_MUL_FWD_FLOAT32__BatchSize_128__12115055749141559869/input[0]:1/input[1]:96/input[2]:56/input[3]:56/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_ADD_FWD_FLOAT32__BatchSize_128__7999923905992250117/input[0]:1/input[1]:64/input[2]:56/input[3]:56/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_ADD_FWD_FLOAT32__BatchSize_128__2231529591258613399/input[0]:1/input[1]:96/input[2]:56/input[3]:56/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_MUL_FWD_FLOAT32__BatchSize_128__957349887576585773/input[0]:1/input[1]:160/input[2]:56/input[3]:56/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_ADD_FWD_FLOAT32__BatchSize_128__13519700469997357703/input[0]:1/input[1]:160/input[2]:56/input[3]:56/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_MUL_FWD_FLOAT32__BatchSize_128__4654115189533878229/input[0]:1/input[1]:192/input[2]:56/input[3]:56/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_ADD_FWD_FLOAT32__BatchSize_128__6520963700839004131/input[0]:1/input[1]:224/input[2]:56/input[3]:56/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_MUL_FWD_FLOAT32__BatchSize_128__17053357981798058825/input[0]:1/input[1]:224/input[2]:56/input[3]:56/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_MUL_FWD_FLOAT32__BatchSize_128__9643064084508125139/input[0]:1/input[1]:256/input[2]:28/input[3]:28/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_ADD_FWD_FLOAT32__BatchSize_128__9782505467313199890/input[0]:1/input[1]:128/input[2]:56/input[3]:56/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_MUL_FWD_FLOAT32__BatchSize_128__3536697556171614136/input[0]:1/input[1]:128/input[2]:56/input[3]:56/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_ADD_FWD_FLOAT32__BatchSize_128__2753412083357664843/input[0]:1/input[1]:192/input[2]:28/input[3]:28/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_MUL_FWD_FLOAT32__BatchSize_128__9725536377354172375/input[0]:1/input[1]:256/input[2]:56/input[3]:56/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_ADD_FWD_FLOAT32__BatchSize_128__3471893346082442109/input[0]:1/input[1]:256/input[2]:56/input[3]:56/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_ADD_FWD_FLOAT32__BatchSize_128__6338189746645876471/input[0]:1/input[1]:224/input[2]:28/input[3]:28/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_MUL_FWD_FLOAT32__BatchSize_128__12777339716578591577/input[0]:1/input[1]:160/input[2]:28/input[3]:28/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_ADD_FWD_FLOAT32__BatchSize_128__17744202666092157823/input[0]:1/input[1]:192/input[2]:56/input[3]:56/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_ADD_FWD_FLOAT32__BatchSize_128__541722311841333235/input[0]:1/input[1]:160/input[2]:28/input[3]:28/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_ADD_FWD_FLOAT32__BatchSize_128__3393339380923550428/input[0]:1/input[1]:544/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_MUL_FWD_FLOAT32__BatchSize_128__6022924009766559957/input[0]:1/input[1]:288/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_MUL_FWD_FLOAT32__BatchSize_128__3116659330295674489/input[0]:1/input[1]:288/input[2]:28/input[3]:28/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_ADD_FWD_FLOAT32__BatchSize_128__3676525976393866105/input[0]:1/input[1]:256/input[2]:28/input[3]:28/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_ADD_FWD_FLOAT32__BatchSize_128__8842715452079885173/input[0]:128/input[1]:8/input[2]:28/input[3]:28/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_ADD_FWD_FLOAT32__BatchSize_128__4867194204076968481/input[0]:1/input[1]:256/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_ADD_FWD_FLOAT32__BatchSize_128__9717580908195891373/input[0]:1/input[1]:576/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_MUL_FWD_FLOAT32__BatchSize_128__1295899415286569345/input[0]:1/input[1]:320/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_ADD_FWD_FLOAT32__BatchSize_128__18197114862367277709/input[0]:128/input[1]:16/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_MUL_FWD_FLOAT32__BatchSize_128__17082498959024507477/input[0]:1/input[1]:320/input[2]:28/input[3]:28/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_ADD_FWD_FLOAT32__BatchSize_128__867762959831255308/input[0]:1/input[1]:608/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_ADD_FWD_FLOAT32__BatchSize_128__3076969826191117192/input[0]:1/input[1]:10/input[2]:-1/input[3]:-1/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD failed to cudnnSetTensor4dDescriptor",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_ADD_FWD_FLOAT32__BatchSize_128__16520072241565817983/input[0]:1/input[1]:288/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_MUL_FWD_FLOAT32__BatchSize_128__13464714521111639462/input[0]:1/input[1]:608/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_ADD_FWD_FLOAT32__BatchSize_128__12046384574013777195/input[0]:1/input[1]:320/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_MUL_FWD_FLOAT32__BatchSize_128__7606112692828955931/input[0]:1/input[1]:352/input[2]:28/input[3]:28/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_ADD_FWD_FLOAT32__BatchSize_128__6613418539027937023/input[0]:1/input[1]:320/input[2]:28/input[3]:28/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_MUL_FWD_FLOAT32__BatchSize_128__9273318575461893565/input[0]:1/input[1]:640/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_ADD_FWD_FLOAT32__BatchSize_128__16093886381364091313/input[0]:1/input[1]:352/input[2]:28/input[3]:28/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_ADD_FWD_FLOAT32__BatchSize_128__10988244649517747641/input[0]:1/input[1]:352/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_MUL_FWD_FLOAT32__BatchSize_128__7002485435070303673/input[0]:1/input[1]:384/input[2]:28/input[3]:28/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_ADD_FWD_FLOAT32__BatchSize_128__3920345303339563287/input[0]:1/input[1]:640/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_ADD_FWD_FLOAT32__BatchSize_128__9903594805643085694/input[0]:1/input[1]:672/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_MUL_FWD_FLOAT32__BatchSize_128__3362140663394824467/input[0]:1/input[1]:352/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_MUL_FWD_FLOAT32__BatchSize_128__4586366833977621460/input[0]:1/input[1]:672/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_ADD_FWD_FLOAT32__BatchSize_128__202845539991917333/input[0]:1/input[1]:512/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_ADD_FWD_FLOAT32__BatchSize_128__15563169499806609683/input[0]:1/input[1]:384/input[2]:28/input[3]:28/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_MUL_FWD_FLOAT32__BatchSize_128__14529507170416616086/input[0]:1/input[1]:864/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_MUL_FWD_FLOAT32__BatchSize_128__11280536348425139756/input[0]:1/input[1]:704/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_ADD_FWD_FLOAT32__BatchSize_128__3051799380943161990/input[0]:1/input[1]:704/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_ADD_FWD_FLOAT32__BatchSize_128__8506393240186216314/input[0]:128/input[1]:24/input[2]:56/input[3]:56/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_MUL_FWD_FLOAT32__BatchSize_128__15963677223175319307/input[0]:1/input[1]:736/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_ADD_FWD_FLOAT32__BatchSize_128__9184390632879201852/input[0]:1/input[1]:864/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_MUL_FWD_FLOAT32__BatchSize_128__17738657224718187953/input[0]:1/input[1]:384/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_ADD_FWD_FLOAT32__BatchSize_128__4682320396779946267/input[0]:1/input[1]:384/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_ADD_FWD_FLOAT32__BatchSize_128__13809155009492560943/input[0]:1/input[1]:416/input[2]:28/input[3]:28/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_MUL_FWD_FLOAT32__BatchSize_128__18049707595352205496/input[0]:1/input[1]:896/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_ADD_FWD_FLOAT32__BatchSize_128__7736322753082889121/input[0]:1/input[1]:736/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_MUL_FWD_FLOAT32__BatchSize_128__681545501379711109/input[0]:1/input[1]:416/input[2]:28/input[3]:28/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_ADD_FWD_FLOAT32__BatchSize_128__5524753707947758610/input[0]:1/input[1]:896/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_MUL_FWD_FLOAT32__BatchSize_128__9023139260052505180/input[0]:1/input[1]:832/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_MUL_FWD_FLOAT32__BatchSize_128__3672828123752986197/input[0]:1/input[1]:416/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_MUL_FWD_FLOAT32__BatchSize_128__16589866989282454139/input[0]:1/input[1]:768/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_ADD_FWD_FLOAT32__BatchSize_128__136229250273447514/input[0]:1/input[1]:448/input[2]:28/input[3]:28/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_MUL_FWD_FLOAT32__BatchSize_128__17680305320347694731/input[0]:1/input[1]:256/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_MUL_FWD_FLOAT32__BatchSize_128__10200186871024356796/input[0]:1/input[1]:448/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_ADD_FWD_FLOAT32__BatchSize_128__9524601857314425599/input[0]:1/input[1]:416/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_ADD_FWD_FLOAT32__BatchSize_128__5831496819014899409/input[0]:1/input[1]:768/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_ADD_FWD_FLOAT32__BatchSize_128__16596821321162573344/input[0]:1/input[1]:800/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_MUL_FWD_FLOAT32__BatchSize_128__35955332915386683/input[0]:1/input[1]:928/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_ADD_FWD_FLOAT32__BatchSize_128__429691266213522750/input[0]:1/input[1]:480/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_MUL_FWD_FLOAT32__BatchSize_128__5802165028729305738/input[0]:1/input[1]:800/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_ADD_FWD_FLOAT32__BatchSize_128__4276441343181353238/input[0]:1/input[1]:448/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_ADD_FWD_FLOAT32__BatchSize_128__14694698084686069494/input[0]:1/input[1]:832/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_MUL_FWD_FLOAT32__BatchSize_128__12907385504867176852/input[0]:1/input[1]:480/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_MUL_FWD_FLOAT32__BatchSize_128__11730708899326371868/input[0]:1/input[1]:128/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_MUL_FWD_FLOAT32__BatchSize_128__885802583756205794/input[0]:1/input[1]:544/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_MUL_FWD_FLOAT32__BatchSize_128__10553069481933062347/input[0]:1/input[1]:576/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_ADD_FWD_FLOAT32__BatchSize_128__13162071708262147473/input[0]:1/input[1]:928/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_ADD_FWD_FLOAT32__BatchSize_128__11633705738314619348/input[0]:1/input[1]:608/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_ADD_FWD_FLOAT32__BatchSize_128__1449445236630639798/input[0]:1/input[1]:128/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_MUL_FWD_FLOAT32__BatchSize_128__3213557803215457016/input[0]:1/input[1]:480/input[2]:28/input[3]:28/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_MUL_FWD_FLOAT32__BatchSize_128__1703933990638347646/input[0]:1/input[1]:608/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_ADD_FWD_FLOAT32__BatchSize_128__11118954956718831186/input[0]:1/input[1]:480/input[2]:28/input[3]:28/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_MUL_FWD_FLOAT32__BatchSize_128__7977493492987359641/input[0]:1/input[1]:960/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_ADD_FWD_FLOAT32__BatchSize_128__2639856623970827361/input[0]:1/input[1]:576/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_ADD_FWD_FLOAT32__BatchSize_128__13447097118241428040/input[0]:1/input[1]:544/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_MUL_FWD_FLOAT32__BatchSize_128__12972066382209445823/input[0]:1/input[1]:512/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_ADD_FWD_FLOAT32__BatchSize_128__15592428674322566451/input[0]:1/input[1]:960/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_MUL_FWD_FLOAT32__BatchSize_128__15405744767238863032/input[0]:1/input[1]:128/input[2]:28/input[3]:28/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_ADD_FWD_FLOAT32__BatchSize_128__6295362665763949595/input[0]:1/input[1]:992/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_MUL_FWD_FLOAT32__BatchSize_128__11079206260717270646/input[0]:1/input[1]:544/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_ADD_FWD_FLOAT32__BatchSize_128__7141192142365787154/input[0]:1/input[1]:128/input[2]:28/input[3]:28/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_MUL_FWD_FLOAT32__BatchSize_128__3462536996000281607/input[0]:1/input[1]:576/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_MUL_FWD_FLOAT32__BatchSize_128__15993571055945074656/input[0]:1/input[1]:672/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_MUL_FWD_FLOAT32__BatchSize_128__16252138283960709297/input[0]:1/input[1]:992/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_MUL_FWD_FLOAT32__BatchSize_128__18306965781554308883/input[0]:1/input[1]:768/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_MUL_FWD_FLOAT32__BatchSize_128__2456163856224280729/input[0]:1/input[1]:640/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_ADD_FWD_FLOAT32__BatchSize_128__14081531414377019306/input[0]:128/input[1]:256/input[2]:199/input[3]:199/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_ADD_FWD_FLOAT32__BatchSize_128__11355323369507703507/input[0]:1/input[1]:288/input[2]:28/input[3]:28/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_MUL_FWD_FLOAT32__BatchSize_128__14207999948591134031/input[0]:1/input[1]:1024/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_ADD_FWD_FLOAT32__BatchSize_128__15016216026979619901/input[0]:1/input[1]:928/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_ADD_FWD_FLOAT32__BatchSize_128__10718746709237308467/input[0]:1/input[1]:640/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_ADD_FWD_FLOAT32__BatchSize_128__8357093187731720677/input[0]:1/input[1]:1024/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_MUL_FWD_FLOAT32__BatchSize_128__5436105508891870305/input[0]:1/input[1]:960/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_MUL_FWD_FLOAT32__BatchSize_128__5268318793114351851/input[0]:1/input[1]:512/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_ADD_FWD_FLOAT32__BatchSize_128__14249126530000944711/input[0]:128/input[1]:1/input[2]:64/input[3]:64/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_ADD_FWD_FLOAT32__BatchSize_128__18277369239987271883/input[0]:1/input[1]:960/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_MUL_FWD_FLOAT32__BatchSize_128__2303855167187015924/input[0]:1/input[1]:704/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_MUL_FWD_FLOAT32__BatchSize_128__8316387375803532013/input[0]:128/input[1]:1/input[2]:64/input[3]:64/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_MUL_FWD_FLOAT32__BatchSize_128__7464402879249980934/input[0]:128/input[1]:192/input[2]:56/input[3]:56/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_ADD_FWD_FLOAT32__BatchSize_128__11542783995717599641/input[0]:128/input[1]:128/input[2]:32/input[3]:32/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_ADD_FWD_FLOAT32__BatchSize_128__11709550072729247979/input[0]:1/input[1]:992/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_MUL_FWD_FLOAT32__BatchSize_128__14935327387696276264/input[0]:1/input[1]:128/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_MUL_FWD_FLOAT32__BatchSize_128__1465361566616640577/input[0]:1/input[1]:992/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_ADD_FWD_FLOAT32__BatchSize_128__3036678588698513765/input[0]:128/input[1]:256/input[2]:16/input[3]:16/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_ADD_FWD_FLOAT32__BatchSize_128__5249445878335953849/input[0]:1/input[1]:768/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_MUL_FWD_FLOAT32__BatchSize_128__3676653527546892447/input[0]:1/input[1]:1024/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_MUL_FWD_FLOAT32__BatchSize_128__6035594608291911650/input[0]:1/input[1]:800/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_ADD_FWD_FLOAT32__BatchSize_128__9642408784420826165/input[0]:1/input[1]:1024/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_ADD_FWD_FLOAT32__BatchSize_128__12190785993967510622/input[0]:1/input[1]:704/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_ADD_FWD_FLOAT32__BatchSize_128__16506838349363571528/input[0]:1/input[1]:800/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_ADD_FWD_FLOAT32__BatchSize_128__7719798096482253642/input[0]:1/input[1]:672/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_MUL_FWD_FLOAT32__BatchSize_128__9514650020721788819/input[0]:1/input[1]:736/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_ADD_FWD_FLOAT32__BatchSize_128__3664941208885918521/input[0]:1/input[1]:736/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_ADD_FWD_FLOAT32__BatchSize_128__16123732482287921214/input[0]:1/input[1]:832/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_MUL_FWD_FLOAT32__BatchSize_128__2973173839693035756/input[0]:128/input[1]:64/input[2]:112/input[3]:112/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_ADD_FWD_FLOAT32__BatchSize_128__18431680023426794561/input[0]:1/input[1]:512/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_ADD_FWD_FLOAT32__BatchSize_128__11498950499483239494/input[0]:128/input[1]:64/input[2]:112/input[3]:112/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_ADD_FWD_FLOAT32__BatchSize_128__15078136808460378796/input[0]:128/input[1]:192/input[2]:56/input[3]:56/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_MUL_FWD_FLOAT32__BatchSize_128__4996319056361291910/input[0]:1/input[1]:864/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_MUL_FWD_FLOAT32__BatchSize_128__1315298900013000231/input[0]:1/input[1]:512/input[2]:28/input[3]:28/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_ADD_FWD_FLOAT32__BatchSize_128__17546256012648053804/input[0]:1/input[1]:864/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_MUL_FWD_FLOAT32__BatchSize_128__3312400187810042696/input[0]:128/input[1]:64/input[2]:56/input[3]:56/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_MUL_FWD_FLOAT32__BatchSize_128__4902696826534833950/input[0]:128/input[1]:96/input[2]:28/input[3]:28/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_MUL_FWD_FLOAT32__BatchSize_128__16000812086280587588/input[0]:128/input[1]:64/input[2]:28/input[3]:28/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_ADD_FWD_FLOAT32__BatchSize_128__1738219589844204087/input[0]:128/input[1]:512/input[2]:100/input[3]:100/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_MUL_FWD_FLOAT32__BatchSize_128__7572149762790397076/input[0]:1/input[1]:832/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_ADD_FWD_FLOAT32__BatchSize_128__1728045460296915495/input[0]:128/input[1]:32/input[2]:28/input[3]:28/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_MUL_FWD_FLOAT32__BatchSize_128__8551381917492099420/input[0]:1/input[1]:896/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_ADD_FWD_FLOAT32__BatchSize_128__17500794213419701172/input[0]:128/input[1]:96/input[2]:28/input[3]:28/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_MUL_FWD_FLOAT32__BatchSize_128__3515896971825751394/input[0]:128/input[1]:224/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_MUL_FWD_FLOAT32__BatchSize_128__4859044290618184826/input[0]:128/input[1]:160/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_MUL_FWD_FLOAT32__BatchSize_128__17573577638705566123/input[0]:128/input[1]:128/input[2]:28/input[3]:28/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_ADD_FWD_FLOAT32__BatchSize_128__13869455035643741686/input[0]:1/input[1]:896/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_MUL_FWD_FLOAT32__BatchSize_128__7400258329898461335/input[0]:1/input[1]:928/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_MUL_FWD_FLOAT32__BatchSize_128__17386149515984404592/input[0]:128/input[1]:64/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_MUL_FWD_FLOAT32__BatchSize_128__11410442627855547934/input[0]:128/input[1]:96/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_ADD_FWD_FLOAT32__BatchSize_128__14065550617447867365/input[0]:128/input[1]:128/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_ADD_FWD_FLOAT32__BatchSize_128__8760168078350770050/input[0]:1/input[1]:128/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_MUL_FWD_FLOAT32__BatchSize_128__7659037478881594386/input[0]:128/input[1]:192/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_ADD_FWD_FLOAT32__BatchSize_128__5160753033663511770/input[0]:128/input[1]:64/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_ADD_FWD_FLOAT32__BatchSize_128__11726883026593476671/input[0]:128/input[1]:1024/input[2]:100/input[3]:100/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_ADD_FWD_FLOAT32__BatchSize_128__15896846132408021176/input[0]:128/input[1]:192/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_ADD_FWD_FLOAT32__BatchSize_128__9663694549647055304/input[0]:128/input[1]:224/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_ADD_FWD_FLOAT32__BatchSize_128__17706012286997702864/input[0]:128/input[1]:160/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_ADD_FWD_FLOAT32__BatchSize_128__2921893092905779892/input[0]:128/input[1]:96/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_MUL_FWD_FLOAT32__BatchSize_128__9245566870541569488/input[0]:128/input[1]:256/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_MUL_FWD_FLOAT32__BatchSize_128__16257068218681899274/input[0]:128/input[1]:160/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_MUL_FWD_FLOAT32__BatchSize_128__16131387623150485132/input[0]:128/input[1]:256/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_ADD_FWD_FLOAT32__BatchSize_128__6289868681804465568/input[0]:128/input[1]:160/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_ADD_FWD_FLOAT32__BatchSize_128__12328870842149517530/input[0]:128/input[1]:256/input[2]:8/input[3]:8/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_ADD_FWD_FLOAT32__BatchSize_128__3934023198703415674/input[0]:128/input[1]:256/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_MUL_FWD_FLOAT32__BatchSize_128__8495038592888692559/input[0]:128/input[1]:128/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_ADD_FWD_FLOAT32__BatchSize_128__10769968453352262078/input[0]:128/input[1]:352/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_MUL_FWD_FLOAT32__BatchSize_128__1139113796806332166/input[0]:128/input[1]:320/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_MUL_FWD_FLOAT32__BatchSize_128__10374336630329007463/input[0]:128/input[1]:128/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_ADD_FWD_FLOAT32__BatchSize_128__14193041908497393068/input[0]:128/input[1]:192/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_ADD_FWD_FLOAT32__BatchSize_128__4120691850972078541/input[0]:128/input[1]:128/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_ADD_FWD_FLOAT32__BatchSize_128__17218676028722520310/input[0]:1/input[1]:8/input[2]:-1/input[3]:-1/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD failed to cudnnSetTensor4dDescriptor",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_MUL_FWD_FLOAT32__BatchSize_128__14085589548115980342/input[0]:128/input[1]:224/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_ADD_FWD_FLOAT32__BatchSize_128__7555037439557170670/input[0]:128/input[1]:64/input[2]:28/input[3]:28/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_MUL_FWD_FLOAT32__BatchSize_128__2567107226118747412/input[0]:128/input[1]:352/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_MUL_FWD_FLOAT32__BatchSize_128__11614202227398649485/input[0]:128/input[1]:32/input[2]:28/input[3]:28/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_ADD_FWD_FLOAT32__BatchSize_128__13337514348088636332/input[0]:128/input[1]:320/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_ADD_FWD_FLOAT32__BatchSize_128__11978317872429573260/input[0]:128/input[1]:2048/input[2]:100/input[3]:100/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD failed to cudnnSetTensor4dDescriptor",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_ADD_FWD_FLOAT32__BatchSize_128__9894607138728858300/input[0]:128/input[1]:64/input[2]:64/input[3]:64/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_MUL_FWD_FLOAT32__BatchSize_128__10439549439521700577/input[0]:1/input[1]:192/input[2]:28/input[3]:28/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_MUL_FWD_FLOAT32__BatchSize_128__13201550915717165808/input[0]:1/input[1]:448/input[2]:28/input[3]:28/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_ADD_FWD_FLOAT32__BatchSize_128__8479361399082224796/input[0]:128/input[1]:224/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_MUL_FWD_FLOAT32__BatchSize_128__8223994299342444806/input[0]:128/input[1]:192/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_ADD_FWD_FLOAT32__BatchSize_128__950618074392442140/input[0]:128/input[1]:304/input[2]:100/input[3]:100/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_ADD_FWD_FLOAT32__BatchSize_128__1852862554614835749/input[0]:128/input[1]:2048/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_ADD_FWD_FLOAT32__BatchSize_128__4885645646132727830/input[0]:128/input[1]:1024/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_ADD_FWD_FLOAT32__BatchSize_128__16388021820960134678/input[0]:128/input[1]:512/input[2]:28/input[3]:28/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_ADD_FWD_FLOAT32__BatchSize_128__4987539310922689793/input[0]:128/input[1]:128/input[2]:28/input[3]:28/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_ADD_FWD_FLOAT32__BatchSize_128__7568471555481043494/input[0]:128/input[1]:256/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_ADD_FWD_FLOAT32__BatchSize_128__8418180691010534597/input[0]:128/input[1]:3/input[2]:112/input[3]:112/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_MUL_FWD_FLOAT32__BatchSize_128__13980807015759396975/input[0]:128/input[1]:3/input[2]:112/input[3]:112/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_ADD_FWD_FLOAT32__BatchSize_128__14235160675187721934/input[0]:128/input[1]:512/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_ADD_FWD_FLOAT32__BatchSize_128__11182065411661639650/input[0]:128/input[1]:64/input[2]:56/input[3]:56/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_ADD_FWD_FLOAT32__BatchSize_128__3883187674744536966/input[0]:128/input[1]:256/input[2]:56/input[3]:56/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_POOLING_FWD_FLOAT32__BatchSize_128__4987670874941180316<CUDNN_POOLING_MAX>/input[0]:128/input[1]:128/input[2]:55/input[3]:55/filter_height:3/filter_width:3/pad_height:0/pad_width:0/stride_height:2/stride_width:2/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_POOLING_FWD_FLOAT32__BatchSize_128__4987670874941180316<CUDNN_POOLING_MAX_DETERMINISTIC>/input[0]:128/input[1]:128/input[2]:55/input[3]:55/filter_height:3/filter_width:3/pad_height:0/pad_width:0/stride_height:2/stride_width:2/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_POOLING_FWD_FLOAT32__BatchSize_128__6554634258335844894<CUDNN_POOLING_MAX>/input[0]:128/input[1]:480/input[2]:14/input[3]:14/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_POOLING_FWD_FLOAT32__BatchSize_128__6554634258335844894<CUDNN_POOLING_MAX_DETERMINISTIC>/input[0]:128/input[1]:480/input[2]:14/input[3]:14/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_POOLING_FWD_FLOAT32__BatchSize_128__10014929859010889653<CUDNN_POOLING_MAX>/input[0]:1/input[1]:192/input[2]:55/input[3]:55/filter_height:3/filter_width:3/pad_height:0/pad_width:0/stride_height:2/stride_width:2/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_POOLING_FWD_FLOAT32__BatchSize_128__10014929859010889653<CUDNN_POOLING_MAX_DETERMINISTIC>/input[0]:1/input[1]:192/input[2]:55/input[3]:55/filter_height:3/filter_width:3/pad_height:0/pad_width:0/stride_height:2/stride_width:2/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_POOLING_FWD_FLOAT32__BatchSize_128__15146903995428275415<CUDNN_POOLING_AVERAGE_COUNT_INCLUDE_PADDING>/input[0]:128/input[1]:24/input[2]:56/input[3]:56/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_POOLING_FWD_FLOAT32__BatchSize_128__15146903995428275415<CUDNN_POOLING_AVERAGE_COUNT_EXCLUDE_PADDING>/input[0]:128/input[1]:24/input[2]:56/input[3]:56/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_POOLING_FWD_FLOAT32__BatchSize_128__2472086423123290291<CUDNN_POOLING_AVERAGE_COUNT_INCLUDE_PADDING>/input[0]:1/input[1]:136/input[2]:28/input[3]:28/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_POOLING_FWD_FLOAT32__BatchSize_128__2472086423123290291<CUDNN_POOLING_AVERAGE_COUNT_EXCLUDE_PADDING>/input[0]:1/input[1]:136/input[2]:28/input[3]:28/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_POOLING_FWD_FLOAT32__BatchSize_128__7573435973572634799<CUDNN_POOLING_AVERAGE_COUNT_INCLUDE_PADDING>/input[0]:1/input[1]:272/input[2]:14/input[3]:14/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_POOLING_FWD_FLOAT32__BatchSize_128__7573435973572634799<CUDNN_POOLING_AVERAGE_COUNT_EXCLUDE_PADDING>/input[0]:1/input[1]:272/input[2]:14/input[3]:14/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_POOLING_FWD_FLOAT32__BatchSize_128__12046916340716316446<CUDNN_POOLING_MAX>/input[0]:1/input[1]:832/input[2]:6/input[3]:6/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_POOLING_FWD_FLOAT32__BatchSize_128__12046916340716316446<CUDNN_POOLING_MAX_DETERMINISTIC>/input[0]:1/input[1]:832/input[2]:6/input[3]:6/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_POOLING_FWD_FLOAT32__BatchSize_128__12188622744918645100<CUDNN_POOLING_MAX>/input[0]:1/input[1]:64/input[2]:112/input[3]:112/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_POOLING_FWD_FLOAT32__BatchSize_128__12188622744918645100<CUDNN_POOLING_MAX_DETERMINISTIC>/input[0]:1/input[1]:64/input[2]:112/input[3]:112/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_POOLING_FWD_FLOAT32__BatchSize_128__9583991673165301151<CUDNN_POOLING_AVERAGE_COUNT_INCLUDE_PADDING>/input[0]:1/input[1]:1024/input[2]:6/input[3]:6/filter_height:7/filter_width:7/pad_height:0/pad_width:1/stride_height:1/stride_width:1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/POOLING_FWD failed to cudnnGetPooling2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_POOLING_FWD_FLOAT32__BatchSize_128__9583991673165301151<CUDNN_POOLING_AVERAGE_COUNT_EXCLUDE_PADDING>/input[0]:1/input[1]:1024/input[2]:6/input[3]:6/filter_height:7/filter_width:7/pad_height:0/pad_width:1/stride_height:1/stride_width:1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/POOLING_FWD failed to cudnnGetPooling2dForwardOutputDim",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_POOLING_FWD_FLOAT32__BatchSize_128__14261809621156750017<CUDNN_POOLING_MAX>/input[0]:1/input[1]:192/input[2]:27/input[3]:27/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_POOLING_FWD_FLOAT32__BatchSize_128__14261809621156750017<CUDNN_POOLING_MAX_DETERMINISTIC>/input[0]:1/input[1]:192/input[2]:27/input[3]:27/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_POOLING_FWD_FLOAT32__BatchSize_128__1901401565630734524<CUDNN_POOLING_MAX>/input[0]:128/input[1]:96/input[2]:109/input[3]:109/filter_height:3/filter_width:3/pad_height:0/pad_width:0/stride_height:2/stride_width:2/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_POOLING_FWD_FLOAT32__BatchSize_128__1901401565630734524<CUDNN_POOLING_MAX_DETERMINISTIC>/input[0]:128/input[1]:96/input[2]:109/input[3]:109/filter_height:3/filter_width:3/pad_height:0/pad_width:0/stride_height:2/stride_width:2/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_POOLING_FWD_FLOAT32__BatchSize_128__13223476246407754740<CUDNN_POOLING_MAX>/input[0]:128/input[1]:256/input[2]:25/input[3]:25/filter_height:3/filter_width:3/pad_height:0/pad_width:0/stride_height:2/stride_width:2/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_POOLING_FWD_FLOAT32__BatchSize_128__13223476246407754740<CUDNN_POOLING_MAX_DETERMINISTIC>/input[0]:128/input[1]:256/input[2]:25/input[3]:25/filter_height:3/filter_width:3/pad_height:0/pad_width:0/stride_height:2/stride_width:2/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_POOLING_FWD_FLOAT32__BatchSize_128__18025819889999712314<CUDNN_POOLING_AVERAGE_COUNT_INCLUDE_PADDING>/input[0]:1/input[1]:128/input[2]:56/input[3]:56/filter_height:2/filter_width:2/pad_height:0/pad_width:0/stride_height:2/stride_width:2/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_POOLING_FWD_FLOAT32__BatchSize_128__18025819889999712314<CUDNN_POOLING_AVERAGE_COUNT_EXCLUDE_PADDING>/input[0]:1/input[1]:128/input[2]:56/input[3]:56/filter_height:2/filter_width:2/pad_height:0/pad_width:0/stride_height:2/stride_width:2/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_POOLING_FWD_FLOAT32__BatchSize_128__12892920817041115801<CUDNN_POOLING_MAX>/input[0]:1/input[1]:256/input[2]:27/input[3]:27/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_POOLING_FWD_FLOAT32__BatchSize_128__12892920817041115801<CUDNN_POOLING_MAX_DETERMINISTIC>/input[0]:1/input[1]:256/input[2]:27/input[3]:27/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_POOLING_FWD_FLOAT32__BatchSize_128__11897532277767615078<CUDNN_POOLING_MAX>/input[0]:128/input[1]:512/input[2]:12/input[3]:12/filter_height:2/filter_width:2/pad_height:0/pad_width:0/stride_height:2/stride_width:2/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_POOLING_FWD_FLOAT32__BatchSize_128__11897532277767615078<CUDNN_POOLING_MAX_DETERMINISTIC>/input[0]:128/input[1]:512/input[2]:12/input[3]:12/filter_height:2/filter_width:2/pad_height:0/pad_width:0/stride_height:2/stride_width:2/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_POOLING_FWD_FLOAT32__BatchSize_128__12740391965218566735<CUDNN_POOLING_MAX>/input[0]:1/input[1]:480/input[2]:27/input[3]:27/filter_height:3/filter_width:3/pad_height:0/pad_width:0/stride_height:2/stride_width:2/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_POOLING_FWD_FLOAT32__BatchSize_128__12740391965218566735<CUDNN_POOLING_MAX_DETERMINISTIC>/input[0]:1/input[1]:480/input[2]:27/input[3]:27/filter_height:3/filter_width:3/pad_height:0/pad_width:0/stride_height:2/stride_width:2/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_POOLING_FWD_FLOAT32__BatchSize_128__16584370666109172630<CUDNN_POOLING_AVERAGE_COUNT_INCLUDE_PADDING>/input[0]:1/input[1]:256/input[2]:28/input[3]:28/filter_height:2/filter_width:2/pad_height:0/pad_width:0/stride_height:2/stride_width:2/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_POOLING_FWD_FLOAT32__BatchSize_128__16584370666109172630<CUDNN_POOLING_AVERAGE_COUNT_EXCLUDE_PADDING>/input[0]:1/input[1]:256/input[2]:28/input[3]:28/filter_height:2/filter_width:2/pad_height:0/pad_width:0/stride_height:2/stride_width:2/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_POOLING_FWD_FLOAT32__BatchSize_128__2688241428392343040<CUDNN_POOLING_MAX>/input[0]:128/input[1]:96/input[2]:54/input[3]:54/filter_height:3/filter_width:3/pad_height:0/pad_width:0/stride_height:2/stride_width:2/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_POOLING_FWD_FLOAT32__BatchSize_128__2688241428392343040<CUDNN_POOLING_MAX_DETERMINISTIC>/input[0]:128/input[1]:96/input[2]:54/input[3]:54/filter_height:3/filter_width:3/pad_height:0/pad_width:0/stride_height:2/stride_width:2/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_POOLING_FWD_FLOAT32__BatchSize_128__15272039671985705637<CUDNN_POOLING_MAX>/input[0]:128/input[1]:8/input[2]:28/input[3]:28/filter_height:2/filter_width:2/pad_height:0/pad_width:0/stride_height:2/stride_width:2/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_POOLING_FWD_FLOAT32__BatchSize_128__15272039671985705637<CUDNN_POOLING_MAX_DETERMINISTIC>/input[0]:128/input[1]:8/input[2]:28/input[3]:28/filter_height:2/filter_width:2/pad_height:0/pad_width:0/stride_height:2/stride_width:2/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_POOLING_FWD_FLOAT32__BatchSize_128__30349846265042425<CUDNN_POOLING_MAX>/input[0]:128/input[1]:16/input[2]:14/input[3]:14/filter_height:3/filter_width:3/pad_height:0/pad_width:0/stride_height:3/stride_width:3/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_POOLING_FWD_FLOAT32__BatchSize_128__30349846265042425<CUDNN_POOLING_MAX_DETERMINISTIC>/input[0]:128/input[1]:16/input[2]:14/input[3]:14/filter_height:3/filter_width:3/pad_height:0/pad_width:0/stride_height:3/stride_width:3/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_POOLING_FWD_FLOAT32__BatchSize_128__14568780168263494705<CUDNN_POOLING_AVERAGE_COUNT_INCLUDE_PADDING>/input[0]:128/input[1]:1000/input[2]:13/input[3]:13/filter_height:13/filter_width:13/pad_height:0/pad_width:0/stride_height:13/stride_width:13/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_POOLING_FWD_FLOAT32__BatchSize_128__14568780168263494705<CUDNN_POOLING_AVERAGE_COUNT_EXCLUDE_PADDING>/input[0]:128/input[1]:1000/input[2]:13/input[3]:13/filter_height:13/filter_width:13/pad_height:0/pad_width:0/stride_height:13/stride_width:13/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_POOLING_FWD_FLOAT32__BatchSize_128__10732800990514878085<CUDNN_POOLING_MAX>/input[0]:128/input[1]:64/input[2]:111/input[3]:111/filter_height:3/filter_width:3/pad_height:0/pad_width:0/stride_height:2/stride_width:2/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_POOLING_FWD_FLOAT32__BatchSize_128__10732800990514878085<CUDNN_POOLING_MAX_DETERMINISTIC>/input[0]:128/input[1]:64/input[2]:111/input[3]:111/filter_height:3/filter_width:3/pad_height:0/pad_width:0/stride_height:2/stride_width:2/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_POOLING_FWD_FLOAT32__BatchSize_128__4772049457172707298<CUDNN_POOLING_MAX>/input[0]:128/input[1]:512/input[2]:14/input[3]:14/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_POOLING_FWD_FLOAT32__BatchSize_128__4772049457172707298<CUDNN_POOLING_MAX_DETERMINISTIC>/input[0]:128/input[1]:512/input[2]:14/input[3]:14/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_POOLING_FWD_FLOAT32__BatchSize_128__954531217519849600<CUDNN_POOLING_MAX>/input[0]:128/input[1]:256/input[2]:26/input[3]:26/filter_height:3/filter_width:3/pad_height:0/pad_width:0/stride_height:2/stride_width:2/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_POOLING_FWD_FLOAT32__BatchSize_128__954531217519849600<CUDNN_POOLING_MAX_DETERMINISTIC>/input[0]:128/input[1]:256/input[2]:26/input[3]:26/filter_height:3/filter_width:3/pad_height:0/pad_width:0/stride_height:2/stride_width:2/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_POOLING_FWD_FLOAT32__BatchSize_128__11544484622659589566<CUDNN_POOLING_MAX>/input[0]:128/input[1]:256/input[2]:12/input[3]:12/filter_height:3/filter_width:3/pad_height:0/pad_width:1/stride_height:2/stride_width:2/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_POOLING_FWD_FLOAT32__BatchSize_128__11544484622659589566<CUDNN_POOLING_MAX_DETERMINISTIC>/input[0]:128/input[1]:256/input[2]:12/input[3]:12/filter_height:3/filter_width:3/pad_height:0/pad_width:1/stride_height:2/stride_width:2/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_POOLING_FWD_FLOAT32__BatchSize_128__3219630457710520779<CUDNN_POOLING_MAX>/input[0]:1/input[1]:480/input[2]:13/input[3]:13/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_POOLING_FWD_FLOAT32__BatchSize_128__3219630457710520779<CUDNN_POOLING_MAX_DETERMINISTIC>/input[0]:1/input[1]:480/input[2]:13/input[3]:13/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_POOLING_FWD_FLOAT32__BatchSize_128__2213622606922862094<CUDNN_POOLING_MAX>/input[0]:128/input[1]:832/input[2]:14/input[3]:14/filter_height:3/filter_width:3/pad_height:0/pad_width:2/stride_height:2/stride_width:2/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_POOLING_FWD_FLOAT32__BatchSize_128__2213622606922862094<CUDNN_POOLING_MAX_DETERMINISTIC>/input[0]:128/input[1]:832/input[2]:14/input[3]:14/filter_height:3/filter_width:3/pad_height:0/pad_width:2/stride_height:2/stride_width:2/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_POOLING_FWD_FLOAT32__BatchSize_128__3795202866414374941<CUDNN_POOLING_MAX>/input[0]:128/input[1]:528/input[2]:14/input[3]:14/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_POOLING_FWD_FLOAT32__BatchSize_128__3795202866414374941<CUDNN_POOLING_MAX_DETERMINISTIC>/input[0]:128/input[1]:528/input[2]:14/input[3]:14/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_POOLING_FWD_FLOAT32__BatchSize_128__16320534206257659956<CUDNN_POOLING_MAX>/input[0]:128/input[1]:128/input[2]:400/input[3]:400/filter_height:3/filter_width:3/pad_height:0/pad_width:0/stride_height:2/stride_width:2/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD failed to cudnnSetTensor4dDescriptor",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_POOLING_FWD_FLOAT32__BatchSize_128__16320534206257659956<CUDNN_POOLING_MAX_DETERMINISTIC>/input[0]:128/input[1]:128/input[2]:400/input[3]:400/filter_height:3/filter_width:3/pad_height:0/pad_width:0/stride_height:2/stride_width:2/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD failed to cudnnSetTensor4dDescriptor",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_POOLING_FWD_FLOAT32__BatchSize_128__3774412604688307255<CUDNN_POOLING_MAX>/input[0]:1/input[1]:512/input[2]:13/input[3]:13/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_POOLING_FWD_FLOAT32__BatchSize_128__3774412604688307255<CUDNN_POOLING_MAX_DETERMINISTIC>/input[0]:1/input[1]:512/input[2]:13/input[3]:13/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_POOLING_FWD_FLOAT32__BatchSize_128__15538013285487836495<CUDNN_POOLING_MAX>/input[0]:128/input[1]:832/input[2]:7/input[3]:7/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_POOLING_FWD_FLOAT32__BatchSize_128__15538013285487836495<CUDNN_POOLING_MAX_DETERMINISTIC>/input[0]:128/input[1]:832/input[2]:7/input[3]:7/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_POOLING_FWD_FLOAT32__BatchSize_128__17896406744012089780<CUDNN_POOLING_AVERAGE_COUNT_INCLUDE_PADDING>/input[0]:1/input[1]:512/input[2]:14/input[3]:14/filter_height:2/filter_width:2/pad_height:0/pad_width:0/stride_height:2/stride_width:2/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_POOLING_FWD_FLOAT32__BatchSize_128__17896406744012089780<CUDNN_POOLING_AVERAGE_COUNT_EXCLUDE_PADDING>/input[0]:1/input[1]:512/input[2]:14/input[3]:14/filter_height:2/filter_width:2/pad_height:0/pad_width:0/stride_height:2/stride_width:2/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_POOLING_FWD_FLOAT32__BatchSize_128__745201977981313116<CUDNN_POOLING_MAX>/input[0]:128/input[1]:128/input[2]:32/input[3]:32/filter_height:2/filter_width:2/pad_height:0/pad_width:0/stride_height:2/stride_width:2/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_POOLING_FWD_FLOAT32__BatchSize_128__745201977981313116<CUDNN_POOLING_MAX_DETERMINISTIC>/input[0]:128/input[1]:128/input[2]:32/input[3]:32/filter_height:2/filter_width:2/pad_height:0/pad_width:0/stride_height:2/stride_width:2/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_POOLING_FWD_FLOAT32__BatchSize_128__12756378019358793297<CUDNN_POOLING_MAX>/input[0]:128/input[1]:64/input[2]:64/input[3]:64/filter_height:2/filter_width:2/pad_height:0/pad_width:0/stride_height:2/stride_width:2/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_POOLING_FWD_FLOAT32__BatchSize_128__12756378019358793297<CUDNN_POOLING_MAX_DETERMINISTIC>/input[0]:128/input[1]:64/input[2]:64/input[3]:64/filter_height:2/filter_width:2/pad_height:0/pad_width:0/stride_height:2/stride_width:2/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_POOLING_FWD_FLOAT32__BatchSize_128__17252000733506113433<CUDNN_POOLING_MAX>/input[0]:128/input[1]:192/input[2]:56/input[3]:56/filter_height:3/filter_width:3/pad_height:0/pad_width:2/stride_height:2/stride_width:2/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_POOLING_FWD_FLOAT32__BatchSize_128__17252000733506113433<CUDNN_POOLING_MAX_DETERMINISTIC>/input[0]:128/input[1]:192/input[2]:56/input[3]:56/filter_height:3/filter_width:3/pad_height:0/pad_width:2/stride_height:2/stride_width:2/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_POOLING_FWD_FLOAT32__BatchSize_128__16216068964442360280<CUDNN_POOLING_MAX>/input[0]:128/input[1]:256/input[2]:16/input[3]:16/filter_height:2/filter_width:2/pad_height:0/pad_width:0/stride_height:2/stride_width:2/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_POOLING_FWD_FLOAT32__BatchSize_128__16216068964442360280<CUDNN_POOLING_MAX_DETERMINISTIC>/input[0]:128/input[1]:256/input[2]:16/input[3]:16/filter_height:2/filter_width:2/pad_height:0/pad_width:0/stride_height:2/stride_width:2/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_POOLING_FWD_FLOAT32__BatchSize_128__3502244002183751412<CUDNN_POOLING_MAX>/input[0]:128/input[1]:64/input[2]:112/input[3]:112/filter_height:3/filter_width:3/pad_height:0/pad_width:2/stride_height:2/stride_width:2/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_POOLING_FWD_FLOAT32__BatchSize_128__3502244002183751412<CUDNN_POOLING_MAX_DETERMINISTIC>/input[0]:128/input[1]:64/input[2]:112/input[3]:112/filter_height:3/filter_width:3/pad_height:0/pad_width:2/stride_height:2/stride_width:2/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_POOLING_FWD_FLOAT32__BatchSize_128__14389414007329128210<CUDNN_POOLING_MAX>/input[0]:128/input[1]:192/input[2]:56/input[3]:56/filter_height:3/filter_width:3/pad_height:0/pad_width:1/stride_height:2/stride_width:2/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_POOLING_FWD_FLOAT32__BatchSize_128__14389414007329128210<CUDNN_POOLING_MAX_DETERMINISTIC>/input[0]:128/input[1]:192/input[2]:56/input[3]:56/filter_height:3/filter_width:3/pad_height:0/pad_width:1/stride_height:2/stride_width:2/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_POOLING_FWD_FLOAT32__BatchSize_128__4824363524686328776<CUDNN_POOLING_MAX>/input[0]:1/input[1]:528/input[2]:13/input[3]:13/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_POOLING_FWD_FLOAT32__BatchSize_128__4824363524686328776<CUDNN_POOLING_MAX_DETERMINISTIC>/input[0]:1/input[1]:528/input[2]:13/input[3]:13/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_POOLING_FWD_FLOAT32__BatchSize_128__14520331911326150431<CUDNN_POOLING_AVERAGE_COUNT_INCLUDE_PADDING>/input[0]:128/input[1]:192/input[2]:28/input[3]:28/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_POOLING_FWD_FLOAT32__BatchSize_128__14520331911326150431<CUDNN_POOLING_AVERAGE_COUNT_EXCLUDE_PADDING>/input[0]:128/input[1]:192/input[2]:28/input[3]:28/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_POOLING_FWD_FLOAT32__BatchSize_128__7591051439236236770<CUDNN_POOLING_MAX>/input[0]:1/input[1]:832/input[2]:13/input[3]:13/filter_height:3/filter_width:3/pad_height:0/pad_width:0/stride_height:2/stride_width:2/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_POOLING_FWD_FLOAT32__BatchSize_128__7591051439236236770<CUDNN_POOLING_MAX_DETERMINISTIC>/input[0]:1/input[1]:832/input[2]:13/input[3]:13/filter_height:3/filter_width:3/pad_height:0/pad_width:0/stride_height:2/stride_width:2/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_POOLING_FWD_FLOAT32__BatchSize_128__13727657301277361991<CUDNN_POOLING_AVERAGE_COUNT_INCLUDE_PADDING>/input[0]:128/input[1]:256/input[2]:28/input[3]:28/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_POOLING_FWD_FLOAT32__BatchSize_128__13727657301277361991<CUDNN_POOLING_AVERAGE_COUNT_EXCLUDE_PADDING>/input[0]:128/input[1]:256/input[2]:28/input[3]:28/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_POOLING_FWD_FLOAT32__BatchSize_128__11485013337624778164<CUDNN_POOLING_AVERAGE_COUNT_INCLUDE_PADDING>/input[0]:128/input[1]:576/input[2]:14/input[3]:14/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_POOLING_FWD_FLOAT32__BatchSize_128__11485013337624778164<CUDNN_POOLING_AVERAGE_COUNT_EXCLUDE_PADDING>/input[0]:128/input[1]:576/input[2]:14/input[3]:14/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_POOLING_FWD_FLOAT32__BatchSize_128__12924893865057950128<CUDNN_POOLING_MAX>/input[0]:128/input[1]:320/input[2]:28/input[3]:28/filter_height:3/filter_width:3/pad_height:0/pad_width:1/stride_height:2/stride_width:2/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_POOLING_FWD_FLOAT32__BatchSize_128__12924893865057950128<CUDNN_POOLING_MAX_DETERMINISTIC>/input[0]:128/input[1]:320/input[2]:28/input[3]:28/filter_height:3/filter_width:3/pad_height:0/pad_width:1/stride_height:2/stride_width:2/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_POOLING_FWD_FLOAT32__BatchSize_128__6873445933493553392<CUDNN_POOLING_MAX>/input[0]:128/input[1]:256/input[2]:8/input[3]:8/filter_height:2/filter_width:2/pad_height:0/pad_width:0/stride_height:2/stride_width:2/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_POOLING_FWD_FLOAT32__BatchSize_128__6873445933493553392<CUDNN_POOLING_MAX_DETERMINISTIC>/input[0]:128/input[1]:256/input[2]:8/input[3]:8/filter_height:2/filter_width:2/pad_height:0/pad_width:0/stride_height:2/stride_width:2/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_POOLING_FWD_FLOAT32__BatchSize_128__6599230399380967157<CUDNN_POOLING_MAX>/input[0]:128/input[1]:576/input[2]:14/input[3]:14/filter_height:3/filter_width:3/pad_height:0/pad_width:1/stride_height:2/stride_width:2/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_POOLING_FWD_FLOAT32__BatchSize_128__6599230399380967157<CUDNN_POOLING_MAX_DETERMINISTIC>/input[0]:128/input[1]:576/input[2]:14/input[3]:14/filter_height:3/filter_width:3/pad_height:0/pad_width:1/stride_height:2/stride_width:2/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_POOLING_FWD_FLOAT32__BatchSize_128__5451929663193097839<CUDNN_POOLING_MAX>/input[0]:128/input[1]:1024/input[2]:7/input[3]:7/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_POOLING_FWD_FLOAT32__BatchSize_128__5451929663193097839<CUDNN_POOLING_MAX_DETERMINISTIC>/input[0]:128/input[1]:1024/input[2]:7/input[3]:7/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_POOLING_FWD_FLOAT32__BatchSize_128__15919742622928504700<CUDNN_POOLING_AVERAGE_COUNT_INCLUDE_PADDING>/input[0]:128/input[1]:1024/input[2]:7/input[3]:7/filter_height:7/filter_width:7/pad_height:0/pad_width:0/stride_height:1/stride_width:1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_POOLING_FWD_FLOAT32__BatchSize_128__15919742622928504700<CUDNN_POOLING_AVERAGE_COUNT_EXCLUDE_PADDING>/input[0]:128/input[1]:1024/input[2]:7/input[3]:7/filter_height:7/filter_width:7/pad_height:0/pad_width:0/stride_height:1/stride_width:1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_POOLING_FWD_FLOAT32__BatchSize_128__6736393049128911225<CUDNN_POOLING_MAX>/input[0]:128/input[1]:16/input[2]:416/input[3]:416/filter_height:2/filter_width:2/pad_height:0/pad_width:0/stride_height:2/stride_width:2/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_POOLING_FWD_FLOAT32__BatchSize_128__6736393049128911225<CUDNN_POOLING_MAX_DETERMINISTIC>/input[0]:128/input[1]:16/input[2]:416/input[3]:416/filter_height:2/filter_width:2/pad_height:0/pad_width:0/stride_height:2/stride_width:2/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_POOLING_FWD_FLOAT32__BatchSize_128__6906416060005709103<CUDNN_POOLING_MAX>/input[0]:128/input[1]:480/input[2]:28/input[3]:28/filter_height:3/filter_width:3/pad_height:0/pad_width:2/stride_height:2/stride_width:2/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_POOLING_FWD_FLOAT32__BatchSize_128__6906416060005709103<CUDNN_POOLING_MAX_DETERMINISTIC>/input[0]:128/input[1]:480/input[2]:28/input[3]:28/filter_height:3/filter_width:3/pad_height:0/pad_width:2/stride_height:2/stride_width:2/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_POOLING_FWD_FLOAT32__BatchSize_128__7663263071795423919<CUDNN_POOLING_MAX>/input[0]:128/input[1]:32/input[2]:208/input[3]:208/filter_height:2/filter_width:2/pad_height:0/pad_width:0/stride_height:2/stride_width:2/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_POOLING_FWD_FLOAT32__BatchSize_128__7663263071795423919<CUDNN_POOLING_MAX_DETERMINISTIC>/input[0]:128/input[1]:32/input[2]:208/input[3]:208/filter_height:2/filter_width:2/pad_height:0/pad_width:0/stride_height:2/stride_width:2/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_POOLING_FWD_FLOAT32__BatchSize_128__3674469098584854392<CUDNN_POOLING_MAX>/input[0]:128/input[1]:128/input[2]:52/input[3]:52/filter_height:2/filter_width:2/pad_height:0/pad_width:0/stride_height:2/stride_width:2/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_POOLING_FWD_FLOAT32__BatchSize_128__3674469098584854392<CUDNN_POOLING_MAX_DETERMINISTIC>/input[0]:128/input[1]:128/input[2]:52/input[3]:52/filter_height:2/filter_width:2/pad_height:0/pad_width:0/stride_height:2/stride_width:2/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_POOLING_FWD_FLOAT32__BatchSize_128__3805536138759449524<CUDNN_POOLING_MAX>/input[0]:128/input[1]:256/input[2]:26/input[3]:26/filter_height:2/filter_width:2/pad_height:0/pad_width:0/stride_height:2/stride_width:2/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_POOLING_FWD_FLOAT32__BatchSize_128__3805536138759449524<CUDNN_POOLING_MAX_DETERMINISTIC>/input[0]:128/input[1]:256/input[2]:26/input[3]:26/filter_height:2/filter_width:2/pad_height:0/pad_width:0/stride_height:2/stride_width:2/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_POOLING_FWD_FLOAT32__BatchSize_128__18076217970140493262<CUDNN_POOLING_MAX>/input[0]:128/input[1]:256/input[2]:27/input[3]:27/filter_height:3/filter_width:3/pad_height:0/pad_width:1/stride_height:2/stride_width:2/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_POOLING_FWD_FLOAT32__BatchSize_128__18076217970140493262<CUDNN_POOLING_MAX_DETERMINISTIC>/input[0]:128/input[1]:256/input[2]:27/input[3]:27/filter_height:3/filter_width:3/pad_height:0/pad_width:1/stride_height:2/stride_width:2/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_POOLING_FWD_FLOAT32__BatchSize_128__10778577188711766178<CUDNN_POOLING_MAX>/input[0]:128/input[1]:512/input[2]:13/input[3]:13/filter_height:2/filter_width:2/pad_height:0/pad_width:0/stride_height:1/stride_width:1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_POOLING_FWD_FLOAT32__BatchSize_128__10778577188711766178<CUDNN_POOLING_MAX_DETERMINISTIC>/input[0]:128/input[1]:512/input[2]:13/input[3]:13/filter_height:2/filter_width:2/pad_height:0/pad_width:0/stride_height:1/stride_width:1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_POOLING_FWD_FLOAT32__BatchSize_128__7633103954448191294<CUDNN_POOLING_MAX>/input[0]:128/input[1]:256/input[2]:13/input[3]:13/filter_height:3/filter_width:3/pad_height:0/pad_width:1/stride_height:2/stride_width:2/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_POOLING_FWD_FLOAT32__BatchSize_128__7633103954448191294<CUDNN_POOLING_MAX_DETERMINISTIC>/input[0]:128/input[1]:256/input[2]:13/input[3]:13/filter_height:3/filter_width:3/pad_height:0/pad_width:1/stride_height:2/stride_width:2/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_POOLING_FWD_FLOAT32__BatchSize_128__2663553416683724345<CUDNN_POOLING_MAX>/input[0]:128/input[1]:96/input[2]:54/input[3]:54/filter_height:3/filter_width:3/pad_height:0/pad_width:2/stride_height:2/stride_width:2/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_POOLING_FWD_FLOAT32__BatchSize_128__2663553416683724345<CUDNN_POOLING_MAX_DETERMINISTIC>/input[0]:128/input[1]:96/input[2]:54/input[3]:54/filter_height:3/filter_width:3/pad_height:0/pad_width:2/stride_height:2/stride_width:2/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_POOLING_FWD_FLOAT32__BatchSize_128__1253180533452451524<CUDNN_POOLING_MAX>/input[0]:128/input[1]:24/input[2]:112/input[3]:112/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_POOLING_FWD_FLOAT32__BatchSize_128__1253180533452451524<CUDNN_POOLING_MAX_DETERMINISTIC>/input[0]:128/input[1]:24/input[2]:112/input[3]:112/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_POOLING_FWD_FLOAT32__BatchSize_128__9178069187549969374<CUDNN_POOLING_MAX>/input[0]:128/input[1]:512/input[2]:28/input[3]:28/filter_height:2/filter_width:2/pad_height:0/pad_width:0/stride_height:2/stride_width:2/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_POOLING_FWD_FLOAT32__BatchSize_128__9178069187549969374<CUDNN_POOLING_MAX_DETERMINISTIC>/input[0]:128/input[1]:512/input[2]:28/input[3]:28/filter_height:2/filter_width:2/pad_height:0/pad_width:0/stride_height:2/stride_width:2/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_POOLING_FWD_FLOAT32__BatchSize_128__2070394493293175691<CUDNN_POOLING_AVERAGE_COUNT_INCLUDE_PADDING>/input[0]:1/input[1]:544/input[2]:7/input[3]:7/filter_height:7/filter_width:7/pad_height:0/pad_width:0/stride_height:1/stride_width:1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_POOLING_FWD_FLOAT32__BatchSize_128__2070394493293175691<CUDNN_POOLING_AVERAGE_COUNT_EXCLUDE_PADDING>/input[0]:1/input[1]:544/input[2]:7/input[3]:7/filter_height:7/filter_width:7/pad_height:0/pad_width:0/stride_height:1/stride_width:1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_POOLING_FWD_FLOAT32__BatchSize_128__17248544316990788801<CUDNN_POOLING_MAX>/input[0]:128/input[1]:64/input[2]:104/input[3]:104/filter_height:2/filter_width:2/pad_height:0/pad_width:0/stride_height:2/stride_width:2/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_POOLING_FWD_FLOAT32__BatchSize_128__17248544316990788801<CUDNN_POOLING_MAX_DETERMINISTIC>/input[0]:128/input[1]:64/input[2]:104/input[3]:104/filter_height:2/filter_width:2/pad_height:0/pad_width:0/stride_height:2/stride_width:2/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_POOLING_FWD_FLOAT32__BatchSize_128__10093265983642525405<CUDNN_POOLING_MAX>/input[0]:128/input[1]:64/input[2]:224/input[3]:224/filter_height:2/filter_width:2/pad_height:0/pad_width:0/stride_height:2/stride_width:2/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_POOLING_FWD_FLOAT32__BatchSize_128__10093265983642525405<CUDNN_POOLING_MAX_DETERMINISTIC>/input[0]:128/input[1]:64/input[2]:224/input[3]:224/filter_height:2/filter_width:2/pad_height:0/pad_width:0/stride_height:2/stride_width:2/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_POOLING_FWD_FLOAT32__BatchSize_128__6302790647592549560<CUDNN_POOLING_MAX>/input[0]:128/input[1]:128/input[2]:112/input[3]:112/filter_height:2/filter_width:2/pad_height:0/pad_width:0/stride_height:2/stride_width:2/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_POOLING_FWD_FLOAT32__BatchSize_128__6302790647592549560<CUDNN_POOLING_MAX_DETERMINISTIC>/input[0]:128/input[1]:128/input[2]:112/input[3]:112/filter_height:2/filter_width:2/pad_height:0/pad_width:0/stride_height:2/stride_width:2/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_POOLING_FWD_FLOAT32__BatchSize_128__14350319107604291581<CUDNN_POOLING_MAX>/input[0]:128/input[1]:64/input[2]:112/input[3]:112/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_POOLING_FWD_FLOAT32__BatchSize_128__14350319107604291581<CUDNN_POOLING_MAX_DETERMINISTIC>/input[0]:128/input[1]:64/input[2]:112/input[3]:112/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_POOLING_FWD_FLOAT32__BatchSize_128__11539098735059178700<CUDNN_POOLING_MAX>/input[0]:128/input[1]:256/input[2]:56/input[3]:56/filter_height:2/filter_width:2/pad_height:0/pad_width:0/stride_height:2/stride_width:2/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_POOLING_FWD_FLOAT32__BatchSize_128__11539098735059178700<CUDNN_POOLING_MAX_DETERMINISTIC>/input[0]:128/input[1]:256/input[2]:56/input[3]:56/filter_height:2/filter_width:2/pad_height:0/pad_width:0/stride_height:2/stride_width:2/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_POOLING_FWD_FLOAT32__BatchSize_128__8402713719283813794<CUDNN_POOLING_MAX>/input[0]:128/input[1]:512/input[2]:14/input[3]:14/filter_height:2/filter_width:2/pad_height:0/pad_width:0/stride_height:2/stride_width:2/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_POOLING_FWD_FLOAT32__BatchSize_128__8402713719283813794<CUDNN_POOLING_MAX_DETERMINISTIC>/input[0]:128/input[1]:512/input[2]:14/input[3]:14/filter_height:2/filter_width:2/pad_height:0/pad_width:0/stride_height:2/stride_width:2/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_SOFTMAX_FWD_FLOAT32__BatchSize_128__10869317846957800128<CUDNN_SOFTMAX_FAST, CUDNN_SOFTMAX_MODE_INSTANCE>/input[0]:1/input[1]:1000/input[2]:-1/input[3]:-1/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_SOFTMAX_FWD_FLOAT32__BatchSize_128__10869317846957800128<CUDNN_SOFTMAX_FAST, CUDNN_SOFTMAX_MODE_CHANNEL>/input[0]:1/input[1]:1000/input[2]:-1/input[3]:-1/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_SOFTMAX_FWD_FLOAT32__BatchSize_128__10869317846957800128<CUDNN_SOFTMAX_ACCURATE, CUDNN_SOFTMAX_MODE_INSTANCE>/input[0]:1/input[1]:1000/input[2]:-1/input[3]:-1/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_SOFTMAX_FWD_FLOAT32__BatchSize_128__10869317846957800128<CUDNN_SOFTMAX_ACCURATE, CUDNN_SOFTMAX_MODE_CHANNEL>/input[0]:1/input[1]:1000/input[2]:-1/input[3]:-1/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_SOFTMAX_FWD_FLOAT32__BatchSize_128__10869317846957800128<CUDNN_SOFTMAX_LOG, CUDNN_SOFTMAX_MODE_INSTANCE>/input[0]:1/input[1]:1000/input[2]:-1/input[3]:-1/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_SOFTMAX_FWD_FLOAT32__BatchSize_128__10869317846957800128<CUDNN_SOFTMAX_LOG, CUDNN_SOFTMAX_MODE_CHANNEL>/input[0]:1/input[1]:1000/input[2]:-1/input[3]:-1/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_SOFTMAX_FWD_FLOAT32__BatchSize_128__15296824738350132482<CUDNN_SOFTMAX_FAST, CUDNN_SOFTMAX_MODE_INSTANCE>/input[0]:128/input[1]:19/input[2]:10000/input[3]:-1/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_SOFTMAX_FWD_FLOAT32__BatchSize_128__15296824738350132482<CUDNN_SOFTMAX_FAST, CUDNN_SOFTMAX_MODE_CHANNEL>/input[0]:128/input[1]:19/input[2]:10000/input[3]:-1/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_SOFTMAX_FWD_FLOAT32__BatchSize_128__15296824738350132482<CUDNN_SOFTMAX_ACCURATE, CUDNN_SOFTMAX_MODE_INSTANCE>/input[0]:128/input[1]:19/input[2]:10000/input[3]:-1/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_SOFTMAX_FWD_FLOAT32__BatchSize_128__15296824738350132482<CUDNN_SOFTMAX_ACCURATE, CUDNN_SOFTMAX_MODE_CHANNEL>/input[0]:128/input[1]:19/input[2]:10000/input[3]:-1/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_SOFTMAX_FWD_FLOAT32__BatchSize_128__15296824738350132482<CUDNN_SOFTMAX_LOG, CUDNN_SOFTMAX_MODE_INSTANCE>/input[0]:128/input[1]:19/input[2]:10000/input[3]:-1/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_SOFTMAX_FWD_FLOAT32__BatchSize_128__15296824738350132482<CUDNN_SOFTMAX_LOG, CUDNN_SOFTMAX_MODE_CHANNEL>/input[0]:128/input[1]:19/input[2]:10000/input[3]:-1/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:128/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/ACTIVATION_FWD device memory allocation failed",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    }
  ]
}
