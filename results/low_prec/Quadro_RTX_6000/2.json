{
  "context": {
    "date": "2019-10-14 00:04:49",
    "executable": "./scope",
    "num_cpus": 10,
    "mhz_per_cpu": 3100,
    "cpu_scaling_enabled": false,
    "caches": [
      {
        "type": "Data",
        "level": 1,
        "size": 32000000,
        "num_sharing": 1
      },
      {
        "type": "Instruction",
        "level": 1,
        "size": 32000000,
        "num_sharing": 1
      },
      {
        "type": "Unified",
        "level": 2,
        "size": 256000000,
        "num_sharing": 1
      },
      {
        "type": "Unified",
        "level": 3,
        "size": 25600000000,
        "num_sharing": 10
      }
    ],
    "library_build_type": "release"
  },
  "benchmarks": [
    {
      "name": "LAYER_CUBLAS_GEMM_FWD_TENSORCOREHALF__BatchSize_2__16156577666090785135/input[0]:2/input[1]:1000/input[2]:2048/input[3]:0/input[4]:1/input[5]:1/input[6]:1/input[7]:-1/batch_size:2/manual_time",
      "iterations": 9869,
      "real_time": 7.1227262402557302e+04,
      "cpu_time": 7.6994789644336764e+04,
      "time_unit": "ns",
      "items_per_second": 5.7506070875650276e+10,
      "K": 2.0480000000000000e+03,
      "M": 2.0000000000000000e+00,
      "N": 1.0000000000000000e+03,
      "alpha": 1.0000000000000000e+00,
      "batch_size": 2.0000000000000000e+00,
      "benchmark_file:/home/dakkak/scope/scopes/cudnn_scope/src/cublas_gemm_fwd.cpp": 9.7453394616956928e+18,
      "benchmark_func:void iLAYER_CUBLAS_GEMM_FWD_Impl(benchmark::State&) [with T = __half]": 1.8015355583317387e+19,
      "beta": 1.0000000000000000e+00,
      "compute_capability:7.5": 3.8315628306456499e+18,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUBLAS_GEMM_FWD_Impl": 1.7610984762236383e+19,
      "gpu_name:Quadro RTX 6000": 5.1174270964049613e+18,
      "host_name:aleph": 3.2334478980185999e+18,
      "input[0]": 2.0000000000000000e+00,
      "input[1]": 1.0000000000000000e+03,
      "input[2]": 2.0480000000000000e+03,
      "input[3]": 0.0000000000000000e+00,
      "input[4]": 1.0000000000000000e+00,
      "input[5]": 1.0000000000000000e+00,
      "input[6]": 1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "lda": 2.0000000000000000e+00,
      "ldb": 1.0000000000000000e+03,
      "num_iterations": 9.8690000000000000e+03,
      "predicted_flops": 1.1501214175130055e+11,
      "predicted_flops_count": 8.1920000000000000e+06,
      "transA": 0.0000000000000000e+00,
      "transB": 1.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_TENSORCOREHALF__BatchSize_2__5889151137839384926<CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:64/input[2]:112/input[3]:112/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:2/manual_time",
      "iterations": 35417,
      "real_time": 1.9868162772036241e+04,
      "cpu_time": 2.5887199226360390e+04,
      "time_unit": "ns",
      "items_per_second": 8.0814316775171188e+10,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 2.0000000000000000e+00,
      "benchmark_file:/home/dakkak/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 3.5332582243186171e+18,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 7.3033908785557658e+18,
      "compute_capability:7.5": 3.8315628306456499e+18,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:Quadro RTX 6000": 5.1174270964049613e+18,
      "host_name:aleph": 3.2334478980185999e+18,
      "input[0]": 2.0000000000000000e+00,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 1.1200000000000000e+02,
      "input[3]": 1.1200000000000000e+02,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 2.0000000000000000e+00,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 1.1200000000000000e+02,
      "input_size": 1.6056320000000000e+06,
      "input_width": 1.1200000000000000e+02,
      "num_iterations": 3.5417000000000000e+04,
      "output_batch_size": 2.0000000000000000e+00,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 1.1200000000000000e+02,
      "output_size": 1.6056320000000000e+06,
      "output_width": 1.1200000000000000e+02,
      "predicted_flops": 8.0814316775171188e+10,
      "predicted_flops_count": 1.6056320000000000e+06,
      "x_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_TENSORCOREHALF__BatchSize_2__5889151137839384926<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:2/input[1]:64/input[2]:112/input[3]:112/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:2/manual_time",
      "iterations": 34576,
      "real_time": 2.0227407688965261e+04,
      "cpu_time": 2.6153109729292486e+04,
      "time_unit": "ns",
      "items_per_second": 7.9379029912761734e+10,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 2.0000000000000000e+00,
      "benchmark_file:/home/dakkak/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 3.5332582243186171e+18,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 7.3051544952070380e+18,
      "compute_capability:7.5": 3.8315628306456499e+18,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:Quadro RTX 6000": 5.1174270964049613e+18,
      "host_name:aleph": 3.2334478980185999e+18,
      "input[0]": 2.0000000000000000e+00,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 1.1200000000000000e+02,
      "input[3]": 1.1200000000000000e+02,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 2.0000000000000000e+00,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 1.1200000000000000e+02,
      "input_size": 1.6056320000000000e+06,
      "input_width": 1.1200000000000000e+02,
      "num_iterations": 3.4576000000000000e+04,
      "output_batch_size": 2.0000000000000000e+00,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 1.1200000000000000e+02,
      "output_size": 1.6056320000000000e+06,
      "output_width": 1.1200000000000000e+02,
      "predicted_flops": 7.9379029912761734e+10,
      "predicted_flops_count": 1.6056320000000000e+06,
      "x_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_TENSORCOREHALF__BatchSize_2__6236170619363862634<CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:64/input[2]:56/input[3]:56/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:2/manual_time",
      "iterations": 91623,
      "real_time": 7.6261874950904466e+03,
      "cpu_time": 1.3327514739746563e+04,
      "time_unit": "ns",
      "items_per_second": 5.2635474836989868e+10,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 2.0000000000000000e+00,
      "benchmark_file:/home/dakkak/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 3.5332582243186171e+18,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 7.3033908785557658e+18,
      "compute_capability:7.5": 3.8315628306456499e+18,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:Quadro RTX 6000": 5.1174270964049613e+18,
      "host_name:aleph": 3.2334478980185999e+18,
      "input[0]": 2.0000000000000000e+00,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 2.0000000000000000e+00,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 4.0140800000000000e+05,
      "input_width": 5.6000000000000000e+01,
      "num_iterations": 9.1623000000000000e+04,
      "output_batch_size": 2.0000000000000000e+00,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 5.6000000000000000e+01,
      "output_size": 4.0140800000000000e+05,
      "output_width": 5.6000000000000000e+01,
      "predicted_flops": 5.2635474836989868e+10,
      "predicted_flops_count": 4.0140800000000000e+05,
      "x_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_TENSORCOREHALF__BatchSize_2__6236170619363862634<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:2/input[1]:64/input[2]:56/input[3]:56/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:2/manual_time",
      "iterations": 92249,
      "real_time": 7.5264920080399197e+03,
      "cpu_time": 1.3179735292525005e+04,
      "time_unit": "ns",
      "items_per_second": 5.3332681356893692e+10,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 2.0000000000000000e+00,
      "benchmark_file:/home/dakkak/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 3.5332582243186171e+18,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 7.3051544952070380e+18,
      "compute_capability:7.5": 3.8315628306456499e+18,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:Quadro RTX 6000": 5.1174270964049613e+18,
      "host_name:aleph": 3.2334478980185999e+18,
      "input[0]": 2.0000000000000000e+00,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 2.0000000000000000e+00,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 4.0140800000000000e+05,
      "input_width": 5.6000000000000000e+01,
      "num_iterations": 9.2249000000000000e+04,
      "output_batch_size": 2.0000000000000000e+00,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 5.6000000000000000e+01,
      "output_size": 4.0140800000000000e+05,
      "output_width": 5.6000000000000000e+01,
      "predicted_flops": 5.3332681356893692e+10,
      "predicted_flops_count": 4.0140800000000000e+05,
      "x_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_TENSORCOREHALF__BatchSize_2__11596198000963992557<CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:128/input[2]:28/input[3]:28/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:2/manual_time",
      "iterations": 99104,
      "real_time": 6.8671737247986594e+03,
      "cpu_time": 1.2551244530998641e+04,
      "time_unit": "ns",
      "items_per_second": 2.9226579673559155e+10,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 2.0000000000000000e+00,
      "benchmark_file:/home/dakkak/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 3.5332582243186171e+18,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 7.3033908785557658e+18,
      "compute_capability:7.5": 3.8315628306456499e+18,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:Quadro RTX 6000": 5.1174270964049613e+18,
      "host_name:aleph": 3.2334478980185999e+18,
      "input[0]": 2.0000000000000000e+00,
      "input[1]": 1.2800000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 2.0000000000000000e+00,
      "input_channels": 1.2800000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 2.0070400000000000e+05,
      "input_width": 2.8000000000000000e+01,
      "num_iterations": 9.9104000000000000e+04,
      "output_batch_size": 2.0000000000000000e+00,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 2.0070400000000000e+05,
      "output_width": 2.8000000000000000e+01,
      "predicted_flops": 2.9226579673559155e+10,
      "predicted_flops_count": 2.0070400000000000e+05,
      "x_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_TENSORCOREHALF__BatchSize_2__11596198000963992557<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:2/input[1]:128/input[2]:28/input[3]:28/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:2/manual_time",
      "iterations": 102949,
      "real_time": 6.8168047586299399e+03,
      "cpu_time": 1.2484385783254078e+04,
      "time_unit": "ns",
      "items_per_second": 2.9442533137818375e+10,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 2.0000000000000000e+00,
      "benchmark_file:/home/dakkak/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 3.5332582243186171e+18,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 7.3051544952070380e+18,
      "compute_capability:7.5": 3.8315628306456499e+18,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:Quadro RTX 6000": 5.1174270964049613e+18,
      "host_name:aleph": 3.2334478980185999e+18,
      "input[0]": 2.0000000000000000e+00,
      "input[1]": 1.2800000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 2.0000000000000000e+00,
      "input_channels": 1.2800000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 2.0070400000000000e+05,
      "input_width": 2.8000000000000000e+01,
      "num_iterations": 1.0294900000000000e+05,
      "output_batch_size": 2.0000000000000000e+00,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 2.0070400000000000e+05,
      "output_width": 2.8000000000000000e+01,
      "predicted_flops": 2.9442533137818375e+10,
      "predicted_flops_count": 2.0070400000000000e+05,
      "x_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_TENSORCOREHALF__BatchSize_2__3814746841111338822<CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:256/input[2]:56/input[3]:56/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:2/manual_time",
      "iterations": 35124,
      "real_time": 1.9781813499783133e+04,
      "cpu_time": 2.5724360209540697e+04,
      "time_unit": "ns",
      "items_per_second": 8.1167078034458405e+10,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 2.0000000000000000e+00,
      "benchmark_file:/home/dakkak/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 3.5332582243186171e+18,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 7.3033908785557658e+18,
      "compute_capability:7.5": 3.8315628306456499e+18,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:Quadro RTX 6000": 5.1174270964049613e+18,
      "host_name:aleph": 3.2334478980185999e+18,
      "input[0]": 2.0000000000000000e+00,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 2.0000000000000000e+00,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 5.6000000000000000e+01,
      "input_size": 1.6056320000000000e+06,
      "input_width": 5.6000000000000000e+01,
      "num_iterations": 3.5124000000000000e+04,
      "output_batch_size": 2.0000000000000000e+00,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 5.6000000000000000e+01,
      "output_size": 1.6056320000000000e+06,
      "output_width": 5.6000000000000000e+01,
      "predicted_flops": 8.1167078034458405e+10,
      "predicted_flops_count": 1.6056320000000000e+06,
      "x_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_TENSORCOREHALF__BatchSize_2__3814746841111338822<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:2/input[1]:256/input[2]:56/input[3]:56/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:2/manual_time",
      "iterations": 34454,
      "real_time": 2.0286922626487063e+04,
      "cpu_time": 2.6222107911997817e+04,
      "time_unit": "ns",
      "items_per_second": 7.9146158811866837e+10,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 2.0000000000000000e+00,
      "benchmark_file:/home/dakkak/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 3.5332582243186171e+18,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 7.3051544952070380e+18,
      "compute_capability:7.5": 3.8315628306456499e+18,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:Quadro RTX 6000": 5.1174270964049613e+18,
      "host_name:aleph": 3.2334478980185999e+18,
      "input[0]": 2.0000000000000000e+00,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 2.0000000000000000e+00,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 5.6000000000000000e+01,
      "input_size": 1.6056320000000000e+06,
      "input_width": 5.6000000000000000e+01,
      "num_iterations": 3.4454000000000000e+04,
      "output_batch_size": 2.0000000000000000e+00,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 5.6000000000000000e+01,
      "output_size": 1.6056320000000000e+06,
      "output_width": 5.6000000000000000e+01,
      "predicted_flops": 7.9146158811866837e+10,
      "predicted_flops_count": 1.6056320000000000e+06,
      "x_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_TENSORCOREHALF__BatchSize_2__3269583333310659682<CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:512/input[2]:28/input[3]:28/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:2/manual_time",
      "iterations": 76457,
      "real_time": 9.1978300740916147e+03,
      "cpu_time": 1.4819686268100357e+04,
      "time_unit": "ns",
      "items_per_second": 8.7283195442082214e+10,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 2.0000000000000000e+00,
      "benchmark_file:/home/dakkak/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 3.5332582243186171e+18,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 7.3033908785557658e+18,
      "compute_capability:7.5": 3.8315628306456499e+18,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:Quadro RTX 6000": 5.1174270964049613e+18,
      "host_name:aleph": 3.2334478980185999e+18,
      "input[0]": 2.0000000000000000e+00,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 2.0000000000000000e+00,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 8.0281600000000000e+05,
      "input_width": 2.8000000000000000e+01,
      "num_iterations": 7.6457000000000000e+04,
      "output_batch_size": 2.0000000000000000e+00,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 8.0281600000000000e+05,
      "output_width": 2.8000000000000000e+01,
      "predicted_flops": 8.7283195442082214e+10,
      "predicted_flops_count": 8.0281600000000000e+05,
      "x_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_TENSORCOREHALF__BatchSize_2__3269583333310659682<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:2/input[1]:512/input[2]:28/input[3]:28/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:2/manual_time",
      "iterations": 75907,
      "real_time": 9.1699824010029442e+03,
      "cpu_time": 1.4803877547522454e+04,
      "time_unit": "ns",
      "items_per_second": 8.7548259625034164e+10,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 2.0000000000000000e+00,
      "benchmark_file:/home/dakkak/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 3.5332582243186171e+18,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 7.3051544952070380e+18,
      "compute_capability:7.5": 3.8315628306456499e+18,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:Quadro RTX 6000": 5.1174270964049613e+18,
      "host_name:aleph": 3.2334478980185999e+18,
      "input[0]": 2.0000000000000000e+00,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 2.0000000000000000e+00,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 8.0281600000000000e+05,
      "input_width": 2.8000000000000000e+01,
      "num_iterations": 7.5907000000000000e+04,
      "output_batch_size": 2.0000000000000000e+00,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 8.0281600000000000e+05,
      "output_width": 2.8000000000000000e+01,
      "predicted_flops": 8.7548259625034164e+10,
      "predicted_flops_count": 8.0281600000000000e+05,
      "x_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_TENSORCOREHALF__BatchSize_2__17300768728678995562<CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:1024/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:2/manual_time",
      "iterations": 92823,
      "real_time": 7.5967727083702675e+03,
      "cpu_time": 1.3308881634944148e+04,
      "time_unit": "ns",
      "items_per_second": 5.2839279969206009e+10,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 2.0000000000000000e+00,
      "benchmark_file:/home/dakkak/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 3.5332582243186171e+18,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 7.3033908785557658e+18,
      "compute_capability:7.5": 3.8315628306456499e+18,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:Quadro RTX 6000": 5.1174270964049613e+18,
      "host_name:aleph": 3.2334478980185999e+18,
      "input[0]": 2.0000000000000000e+00,
      "input[1]": 1.0240000000000000e+03,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 2.0000000000000000e+00,
      "input_channels": 1.0240000000000000e+03,
      "input_height": 1.4000000000000000e+01,
      "input_size": 4.0140800000000000e+05,
      "input_width": 1.4000000000000000e+01,
      "num_iterations": 9.2823000000000000e+04,
      "output_batch_size": 2.0000000000000000e+00,
      "output_channels": 1.0240000000000000e+03,
      "output_height": 1.4000000000000000e+01,
      "output_size": 4.0140800000000000e+05,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 5.2839279969206009e+10,
      "predicted_flops_count": 4.0140800000000000e+05,
      "x_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_TENSORCOREHALF__BatchSize_2__17300768728678995562<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:2/input[1]:1024/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:2/manual_time",
      "iterations": 89638,
      "real_time": 7.6417048274084646e+03,
      "cpu_time": 1.3325138434594102e+04,
      "time_unit": "ns",
      "items_per_second": 5.2528592646011650e+10,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 2.0000000000000000e+00,
      "benchmark_file:/home/dakkak/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 3.5332582243186171e+18,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 7.3051544952070380e+18,
      "compute_capability:7.5": 3.8315628306456499e+18,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:Quadro RTX 6000": 5.1174270964049613e+18,
      "host_name:aleph": 3.2334478980185999e+18,
      "input[0]": 2.0000000000000000e+00,
      "input[1]": 1.0240000000000000e+03,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 2.0000000000000000e+00,
      "input_channels": 1.0240000000000000e+03,
      "input_height": 1.4000000000000000e+01,
      "input_size": 4.0140800000000000e+05,
      "input_width": 1.4000000000000000e+01,
      "num_iterations": 8.9638000000000000e+04,
      "output_batch_size": 2.0000000000000000e+00,
      "output_channels": 1.0240000000000000e+03,
      "output_height": 1.4000000000000000e+01,
      "output_size": 4.0140800000000000e+05,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 5.2528592646011650e+10,
      "predicted_flops_count": 4.0140800000000000e+05,
      "x_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_TENSORCOREHALF__BatchSize_2__321446366007769006<CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:256/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:2/manual_time",
      "iterations": 108595,
      "real_time": 6.4441116263986096e+03,
      "cpu_time": 1.1843802817803386e+04,
      "time_unit": "ns",
      "items_per_second": 1.5572666306539951e+10,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 2.0000000000000000e+00,
      "benchmark_file:/home/dakkak/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 3.5332582243186171e+18,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 7.3033908785557658e+18,
      "compute_capability:7.5": 3.8315628306456499e+18,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:Quadro RTX 6000": 5.1174270964049613e+18,
      "host_name:aleph": 3.2334478980185999e+18,
      "input[0]": 2.0000000000000000e+00,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 2.0000000000000000e+00,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 1.0035200000000000e+05,
      "input_width": 1.4000000000000000e+01,
      "num_iterations": 1.0859500000000000e+05,
      "output_batch_size": 2.0000000000000000e+00,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 1.0035200000000000e+05,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 1.5572666306539951e+10,
      "predicted_flops_count": 1.0035200000000000e+05,
      "x_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_TENSORCOREHALF__BatchSize_2__321446366007769006<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:2/input[1]:256/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:2/manual_time",
      "iterations": 105048,
      "real_time": 6.5262462687912785e+03,
      "cpu_time": 1.1999226686849615e+04,
      "time_unit": "ns",
      "items_per_second": 1.5376679927002834e+10,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 2.0000000000000000e+00,
      "benchmark_file:/home/dakkak/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 3.5332582243186171e+18,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 7.3051544952070380e+18,
      "compute_capability:7.5": 3.8315628306456499e+18,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:Quadro RTX 6000": 5.1174270964049613e+18,
      "host_name:aleph": 3.2334478980185999e+18,
      "input[0]": 2.0000000000000000e+00,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 2.0000000000000000e+00,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 1.0035200000000000e+05,
      "input_width": 1.4000000000000000e+01,
      "num_iterations": 1.0504800000000000e+05,
      "output_batch_size": 2.0000000000000000e+00,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 1.0035200000000000e+05,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 1.5376679927002834e+10,
      "predicted_flops_count": 1.0035200000000000e+05,
      "x_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_TENSORCOREHALF__BatchSize_2__4457267625156160462<CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:512/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:2/manual_time",
      "iterations": 113594,
      "real_time": 6.2790930983174221e+03,
      "cpu_time": 1.1838228524394572e+04,
      "time_unit": "ns",
      "items_per_second": 7.9909629009076824e+09,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 2.0000000000000000e+00,
      "benchmark_file:/home/dakkak/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 3.5332582243186171e+18,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 7.3033908785557658e+18,
      "compute_capability:7.5": 3.8315628306456499e+18,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:Quadro RTX 6000": 5.1174270964049613e+18,
      "host_name:aleph": 3.2334478980185999e+18,
      "input[0]": 2.0000000000000000e+00,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 2.0000000000000000e+00,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 5.0176000000000000e+04,
      "input_width": 7.0000000000000000e+00,
      "num_iterations": 1.1359400000000000e+05,
      "output_batch_size": 2.0000000000000000e+00,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 5.0176000000000000e+04,
      "output_width": 7.0000000000000000e+00,
      "predicted_flops": 7.9909629009076824e+09,
      "predicted_flops_count": 5.0176000000000000e+04,
      "x_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_TENSORCOREHALF__BatchSize_2__4457267625156160462<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:2/input[1]:512/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:2/manual_time",
      "iterations": 112379,
      "real_time": 6.2704125633895965e+03,
      "cpu_time": 1.1827279473922128e+04,
      "time_unit": "ns",
      "items_per_second": 8.0020253041972666e+09,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 2.0000000000000000e+00,
      "benchmark_file:/home/dakkak/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 3.5332582243186171e+18,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 7.3051544952070380e+18,
      "compute_capability:7.5": 3.8315628306456499e+18,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:Quadro RTX 6000": 5.1174270964049613e+18,
      "host_name:aleph": 3.2334478980185999e+18,
      "input[0]": 2.0000000000000000e+00,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 2.0000000000000000e+00,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 5.0176000000000000e+04,
      "input_width": 7.0000000000000000e+00,
      "num_iterations": 1.1237900000000000e+05,
      "output_batch_size": 2.0000000000000000e+00,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 5.0176000000000000e+04,
      "output_width": 7.0000000000000000e+00,
      "predicted_flops": 8.0020253041972666e+09,
      "predicted_flops_count": 5.0176000000000000e+04,
      "x_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_TENSORCOREHALF__BatchSize_2__8355125013597722013<CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:2048/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:2/manual_time",
      "iterations": 102185,
      "real_time": 6.9233576135717940e+03,
      "cpu_time": 1.2606285413706446e+04,
      "time_unit": "ns",
      "items_per_second": 2.8989402426152569e+10,
      "activation_mode": 1.0000000000000000e+00,
      "batch_size": 2.0000000000000000e+00,
      "benchmark_file:/home/dakkak/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 3.5332582243186171e+18,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1]": 7.3033908785557658e+18,
      "compute_capability:7.5": 3.8315628306456499e+18,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:Quadro RTX 6000": 5.1174270964049613e+18,
      "host_name:aleph": 3.2334478980185999e+18,
      "input[0]": 2.0000000000000000e+00,
      "input[1]": 2.0480000000000000e+03,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 2.0000000000000000e+00,
      "input_channels": 2.0480000000000000e+03,
      "input_height": 7.0000000000000000e+00,
      "input_size": 2.0070400000000000e+05,
      "input_width": 7.0000000000000000e+00,
      "num_iterations": 1.0218500000000000e+05,
      "output_batch_size": 2.0000000000000000e+00,
      "output_channels": 2.0480000000000000e+03,
      "output_height": 7.0000000000000000e+00,
      "output_size": 2.0070400000000000e+05,
      "output_width": 7.0000000000000000e+00,
      "predicted_flops": 2.8989402426152569e+10,
      "predicted_flops_count": 2.0070400000000000e+05,
      "x_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_ACTIVATION_FWD_TENSORCOREHALF__BatchSize_2__8355125013597722013<CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:2/input[1]:2048/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:2/manual_time",
      "iterations": 101125,
      "real_time": 6.8568267953377481e+03,
      "cpu_time": 1.2549693260805132e+04,
      "time_unit": "ns",
      "items_per_second": 2.9270682487775146e+10,
      "activation_mode": 3.0000000000000000e+00,
      "batch_size": 2.0000000000000000e+00,
      "benchmark_file:/home/dakkak/scope/scopes/cudnn_scope/src/cudnn_activation_fwd.cpp": 3.5332582243186171e+18,
      "benchmark_func:void iLAYER_CUDNN_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3]": 7.3051544952070380e+18,
      "compute_capability:7.5": 3.8315628306456499e+18,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ACTIVATION_FWD_Impl": 1.7018446903751907e+19,
      "gpu_name:Quadro RTX 6000": 5.1174270964049613e+18,
      "host_name:aleph": 3.2334478980185999e+18,
      "input[0]": 2.0000000000000000e+00,
      "input[1]": 2.0480000000000000e+03,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 2.0000000000000000e+00,
      "input_channels": 2.0480000000000000e+03,
      "input_height": 7.0000000000000000e+00,
      "input_size": 2.0070400000000000e+05,
      "input_width": 7.0000000000000000e+00,
      "num_iterations": 1.0112500000000000e+05,
      "output_batch_size": 2.0000000000000000e+00,
      "output_channels": 2.0480000000000000e+03,
      "output_height": 7.0000000000000000e+00,
      "output_size": 2.0070400000000000e+05,
      "output_width": 7.0000000000000000e+00,
      "predicted_flops": 2.9270682487775146e+10,
      "predicted_flops_count": 2.0070400000000000e+05,
      "x_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_ADD_TENSOR_TENSORCOREHALF__BatchSize_2__10755788372172763879/input[0]:2/input[1]:64/input[2]:56/input[3]:56/bias[0]:1/bias[1]:64/bias[2]:1/bias[3]:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 73703,
      "real_time": 9.4599299196383217e+03,
      "cpu_time": 1.5135985333031573e+04,
      "time_unit": "ns",
      "items_per_second": 4.2432449649198555e+10,
      "a_desc_0": 1.0000000000000000e+00,
      "a_desc_1": 6.4000000000000000e+01,
      "a_desc_2": 1.0000000000000000e+00,
      "a_desc_3": 1.0000000000000000e+00,
      "alpha": 0.0000000000000000e+00,
      "batch_size": 2.0000000000000000e+00,
      "benchmark_file:/home/dakkak/scope/scopes/cudnn_scope/src/cudnn_add_tensor.cpp": 3.4177723063645414e+18,
      "benchmark_func:void iLAYER_CUDNN_ADD_TENSOR_Impl(benchmark::State&) [with T = __half]": 1.3682207389025487e+19,
      "beta": 0.0000000000000000e+00,
      "bias[0]": 1.0000000000000000e+00,
      "bias[1]": 6.4000000000000000e+01,
      "bias[2]": 1.0000000000000000e+00,
      "bias[3]": 1.0000000000000000e+00,
      "c_desc_0": 2.0000000000000000e+00,
      "c_desc_1": 6.4000000000000000e+01,
      "c_desc_2": 5.6000000000000000e+01,
      "c_desc_3": 5.6000000000000000e+01,
      "compute_capability:7.5": 3.8315628306456499e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ADD_TENSOR_Impl": 1.3211678748143176e+19,
      "gpu_name:Quadro RTX 6000": 5.1174270964049613e+18,
      "host_name:aleph": 3.2334478980185999e+18,
      "input[0]": 2.0000000000000000e+00,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_tensor_layout": 0.0000000000000000e+00,
      "num_iterations": 7.3703000000000000e+04,
      "output_tensor_layout": 0.0000000000000000e+00,
      "predicted_flops": 4.2432449649198555e+10,
      "predicted_flops_count": 4.0140800000000000e+05
    },
    {
      "name": "LAYER_CUDNN_ADD_TENSOR_TENSORCOREHALF__BatchSize_2__7283883811879959857/input[0]:2/input[1]:128/input[2]:28/input[3]:28/bias[0]:1/bias[1]:128/bias[2]:1/bias[3]:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 90630,
      "real_time": 7.5364300642512026e+03,
      "cpu_time": 1.3211216650104017e+04,
      "time_unit": "ns",
      "items_per_second": 2.6631176603367229e+10,
      "a_desc_0": 1.0000000000000000e+00,
      "a_desc_1": 1.2800000000000000e+02,
      "a_desc_2": 1.0000000000000000e+00,
      "a_desc_3": 1.0000000000000000e+00,
      "alpha": 0.0000000000000000e+00,
      "batch_size": 2.0000000000000000e+00,
      "benchmark_file:/home/dakkak/scope/scopes/cudnn_scope/src/cudnn_add_tensor.cpp": 3.4177723063645414e+18,
      "benchmark_func:void iLAYER_CUDNN_ADD_TENSOR_Impl(benchmark::State&) [with T = __half]": 1.3682207389025487e+19,
      "beta": 0.0000000000000000e+00,
      "bias[0]": 1.0000000000000000e+00,
      "bias[1]": 1.2800000000000000e+02,
      "bias[2]": 1.0000000000000000e+00,
      "bias[3]": 1.0000000000000000e+00,
      "c_desc_0": 2.0000000000000000e+00,
      "c_desc_1": 1.2800000000000000e+02,
      "c_desc_2": 2.8000000000000000e+01,
      "c_desc_3": 2.8000000000000000e+01,
      "compute_capability:7.5": 3.8315628306456499e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ADD_TENSOR_Impl": 1.3211678748143176e+19,
      "gpu_name:Quadro RTX 6000": 5.1174270964049613e+18,
      "host_name:aleph": 3.2334478980185999e+18,
      "input[0]": 2.0000000000000000e+00,
      "input[1]": 1.2800000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_tensor_layout": 0.0000000000000000e+00,
      "num_iterations": 9.0630000000000000e+04,
      "output_tensor_layout": 0.0000000000000000e+00,
      "predicted_flops": 2.6631176603367229e+10,
      "predicted_flops_count": 2.0070400000000000e+05
    },
    {
      "name": "LAYER_CUDNN_ADD_TENSOR_TENSORCOREHALF__BatchSize_2__12950653399528576388/input[0]:2/input[1]:512/input[2]:7/input[3]:7/bias[0]:1/bias[1]:512/bias[2]:1/bias[3]:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 109789,
      "real_time": 6.4094651566198290e+03,
      "cpu_time": 1.1859603357347491e+04,
      "time_unit": "ns",
      "items_per_second": 7.8284223057484264e+09,
      "a_desc_0": 1.0000000000000000e+00,
      "a_desc_1": 5.1200000000000000e+02,
      "a_desc_2": 1.0000000000000000e+00,
      "a_desc_3": 1.0000000000000000e+00,
      "alpha": 0.0000000000000000e+00,
      "batch_size": 2.0000000000000000e+00,
      "benchmark_file:/home/dakkak/scope/scopes/cudnn_scope/src/cudnn_add_tensor.cpp": 3.4177723063645414e+18,
      "benchmark_func:void iLAYER_CUDNN_ADD_TENSOR_Impl(benchmark::State&) [with T = __half]": 1.3682207389025487e+19,
      "beta": 0.0000000000000000e+00,
      "bias[0]": 1.0000000000000000e+00,
      "bias[1]": 5.1200000000000000e+02,
      "bias[2]": 1.0000000000000000e+00,
      "bias[3]": 1.0000000000000000e+00,
      "c_desc_0": 2.0000000000000000e+00,
      "c_desc_1": 5.1200000000000000e+02,
      "c_desc_2": 7.0000000000000000e+00,
      "c_desc_3": 7.0000000000000000e+00,
      "compute_capability:7.5": 3.8315628306456499e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ADD_TENSOR_Impl": 1.3211678748143176e+19,
      "gpu_name:Quadro RTX 6000": 5.1174270964049613e+18,
      "host_name:aleph": 3.2334478980185999e+18,
      "input[0]": 2.0000000000000000e+00,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input_tensor_layout": 0.0000000000000000e+00,
      "num_iterations": 1.0978900000000000e+05,
      "output_tensor_layout": 0.0000000000000000e+00,
      "predicted_flops": 7.8284223057484264e+09,
      "predicted_flops_count": 5.0176000000000000e+04
    },
    {
      "name": "LAYER_CUDNN_ADD_TENSOR_TENSORCOREHALF__BatchSize_2__2462633704059891400/input[0]:2/input[1]:128/input[2]:28/input[3]:28/bias[0]:1/bias[1]:128/bias[2]:1/bias[3]:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 89692,
      "real_time": 7.5267844714563480e+03,
      "cpu_time": 1.3185393424145153e+04,
      "time_unit": "ns",
      "items_per_second": 2.6665304521622101e+10,
      "a_desc_0": 1.0000000000000000e+00,
      "a_desc_1": 1.2800000000000000e+02,
      "a_desc_2": 1.0000000000000000e+00,
      "a_desc_3": 1.0000000000000000e+00,
      "alpha": 0.0000000000000000e+00,
      "batch_size": 2.0000000000000000e+00,
      "benchmark_file:/home/dakkak/scope/scopes/cudnn_scope/src/cudnn_add_tensor.cpp": 3.4177723063645414e+18,
      "benchmark_func:void iLAYER_CUDNN_ADD_TENSOR_Impl(benchmark::State&) [with T = __half]": 1.3682207389025487e+19,
      "beta": 0.0000000000000000e+00,
      "bias[0]": 1.0000000000000000e+00,
      "bias[1]": 1.2800000000000000e+02,
      "bias[2]": 1.0000000000000000e+00,
      "bias[3]": 1.0000000000000000e+00,
      "c_desc_0": 2.0000000000000000e+00,
      "c_desc_1": 1.2800000000000000e+02,
      "c_desc_2": 2.8000000000000000e+01,
      "c_desc_3": 2.8000000000000000e+01,
      "compute_capability:7.5": 3.8315628306456499e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ADD_TENSOR_Impl": 1.3211678748143176e+19,
      "gpu_name:Quadro RTX 6000": 5.1174270964049613e+18,
      "host_name:aleph": 3.2334478980185999e+18,
      "input[0]": 2.0000000000000000e+00,
      "input[1]": 1.2800000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_tensor_layout": 0.0000000000000000e+00,
      "num_iterations": 8.9692000000000000e+04,
      "output_tensor_layout": 0.0000000000000000e+00,
      "predicted_flops": 2.6665304521622101e+10,
      "predicted_flops_count": 2.0070400000000000e+05
    },
    {
      "name": "LAYER_CUDNN_ADD_TENSOR_TENSORCOREHALF__BatchSize_2__11740883119364384098/input[0]:2/input[1]:64/input[2]:56/input[3]:56/bias[0]:1/bias[1]:64/bias[2]:1/bias[3]:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 73308,
      "real_time": 9.5274224807029586e+03,
      "cpu_time": 1.5147412301529990e+04,
      "time_unit": "ns",
      "items_per_second": 4.2131856838827103e+10,
      "a_desc_0": 1.0000000000000000e+00,
      "a_desc_1": 6.4000000000000000e+01,
      "a_desc_2": 1.0000000000000000e+00,
      "a_desc_3": 1.0000000000000000e+00,
      "alpha": 0.0000000000000000e+00,
      "batch_size": 2.0000000000000000e+00,
      "benchmark_file:/home/dakkak/scope/scopes/cudnn_scope/src/cudnn_add_tensor.cpp": 3.4177723063645414e+18,
      "benchmark_func:void iLAYER_CUDNN_ADD_TENSOR_Impl(benchmark::State&) [with T = __half]": 1.3682207389025487e+19,
      "beta": 0.0000000000000000e+00,
      "bias[0]": 1.0000000000000000e+00,
      "bias[1]": 6.4000000000000000e+01,
      "bias[2]": 1.0000000000000000e+00,
      "bias[3]": 1.0000000000000000e+00,
      "c_desc_0": 2.0000000000000000e+00,
      "c_desc_1": 6.4000000000000000e+01,
      "c_desc_2": 5.6000000000000000e+01,
      "c_desc_3": 5.6000000000000000e+01,
      "compute_capability:7.5": 3.8315628306456499e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ADD_TENSOR_Impl": 1.3211678748143176e+19,
      "gpu_name:Quadro RTX 6000": 5.1174270964049613e+18,
      "host_name:aleph": 3.2334478980185999e+18,
      "input[0]": 2.0000000000000000e+00,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_tensor_layout": 0.0000000000000000e+00,
      "num_iterations": 7.3308000000000000e+04,
      "output_tensor_layout": 0.0000000000000000e+00,
      "predicted_flops": 4.2131856838827103e+10,
      "predicted_flops_count": 4.0140800000000000e+05
    },
    {
      "name": "LAYER_CUDNN_ADD_TENSOR_TENSORCOREHALF__BatchSize_2__12681374900741332879/input[0]:2/input[1]:256/input[2]:56/input[3]:56/bias[0]:1/bias[1]:256/bias[2]:1/bias[3]:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 34460,
      "real_time": 2.0278536504381336e+04,
      "cpu_time": 2.5838747098058757e+04,
      "time_unit": "ns",
      "items_per_second": 7.9178889445650620e+10,
      "a_desc_0": 1.0000000000000000e+00,
      "a_desc_1": 2.5600000000000000e+02,
      "a_desc_2": 1.0000000000000000e+00,
      "a_desc_3": 1.0000000000000000e+00,
      "alpha": 0.0000000000000000e+00,
      "batch_size": 2.0000000000000000e+00,
      "benchmark_file:/home/dakkak/scope/scopes/cudnn_scope/src/cudnn_add_tensor.cpp": 3.4177723063645414e+18,
      "benchmark_func:void iLAYER_CUDNN_ADD_TENSOR_Impl(benchmark::State&) [with T = __half]": 1.3682207389025487e+19,
      "beta": 0.0000000000000000e+00,
      "bias[0]": 1.0000000000000000e+00,
      "bias[1]": 2.5600000000000000e+02,
      "bias[2]": 1.0000000000000000e+00,
      "bias[3]": 1.0000000000000000e+00,
      "c_desc_0": 2.0000000000000000e+00,
      "c_desc_1": 2.5600000000000000e+02,
      "c_desc_2": 5.6000000000000000e+01,
      "c_desc_3": 5.6000000000000000e+01,
      "compute_capability:7.5": 3.8315628306456499e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ADD_TENSOR_Impl": 1.3211678748143176e+19,
      "gpu_name:Quadro RTX 6000": 5.1174270964049613e+18,
      "host_name:aleph": 3.2334478980185999e+18,
      "input[0]": 2.0000000000000000e+00,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_tensor_layout": 0.0000000000000000e+00,
      "num_iterations": 3.4460000000000000e+04,
      "output_tensor_layout": 0.0000000000000000e+00,
      "predicted_flops": 7.9178889445650620e+10,
      "predicted_flops_count": 1.6056320000000000e+06
    },
    {
      "name": "LAYER_CUDNN_ADD_TENSOR_TENSORCOREHALF__BatchSize_2__5444423172410412989/input[0]:2/input[1]:256/input[2]:14/input[3]:14/bias[0]:1/bias[1]:256/bias[2]:1/bias[3]:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 102620,
      "real_time": 6.8590263228528802e+03,
      "cpu_time": 1.2526941356460125e+04,
      "time_unit": "ns",
      "items_per_second": 1.4630648036099171e+10,
      "a_desc_0": 1.0000000000000000e+00,
      "a_desc_1": 2.5600000000000000e+02,
      "a_desc_2": 1.0000000000000000e+00,
      "a_desc_3": 1.0000000000000000e+00,
      "alpha": 0.0000000000000000e+00,
      "batch_size": 2.0000000000000000e+00,
      "benchmark_file:/home/dakkak/scope/scopes/cudnn_scope/src/cudnn_add_tensor.cpp": 3.4177723063645414e+18,
      "benchmark_func:void iLAYER_CUDNN_ADD_TENSOR_Impl(benchmark::State&) [with T = __half]": 1.3682207389025487e+19,
      "beta": 0.0000000000000000e+00,
      "bias[0]": 1.0000000000000000e+00,
      "bias[1]": 2.5600000000000000e+02,
      "bias[2]": 1.0000000000000000e+00,
      "bias[3]": 1.0000000000000000e+00,
      "c_desc_0": 2.0000000000000000e+00,
      "c_desc_1": 2.5600000000000000e+02,
      "c_desc_2": 1.4000000000000000e+01,
      "c_desc_3": 1.4000000000000000e+01,
      "compute_capability:7.5": 3.8315628306456499e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ADD_TENSOR_Impl": 1.3211678748143176e+19,
      "gpu_name:Quadro RTX 6000": 5.1174270964049613e+18,
      "host_name:aleph": 3.2334478980185999e+18,
      "input[0]": 2.0000000000000000e+00,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_tensor_layout": 0.0000000000000000e+00,
      "num_iterations": 1.0262000000000000e+05,
      "output_tensor_layout": 0.0000000000000000e+00,
      "predicted_flops": 1.4630648036099171e+10,
      "predicted_flops_count": 1.0035200000000000e+05
    },
    {
      "name": "LAYER_CUDNN_ADD_TENSOR_TENSORCOREHALF__BatchSize_2__18093698911605223805/input[0]:2/input[1]:2048/input[2]:7/input[3]:7/bias[0]:1/bias[1]:2048/bias[2]:1/bias[3]:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 92390,
      "real_time": 7.6229534855538550e+03,
      "cpu_time": 1.3287467150123326e+04,
      "time_unit": "ns",
      "items_per_second": 2.6328902620270626e+10,
      "a_desc_0": 1.0000000000000000e+00,
      "a_desc_1": 2.0480000000000000e+03,
      "a_desc_2": 1.0000000000000000e+00,
      "a_desc_3": 1.0000000000000000e+00,
      "alpha": 0.0000000000000000e+00,
      "batch_size": 2.0000000000000000e+00,
      "benchmark_file:/home/dakkak/scope/scopes/cudnn_scope/src/cudnn_add_tensor.cpp": 3.4177723063645414e+18,
      "benchmark_func:void iLAYER_CUDNN_ADD_TENSOR_Impl(benchmark::State&) [with T = __half]": 1.3682207389025487e+19,
      "beta": 0.0000000000000000e+00,
      "bias[0]": 1.0000000000000000e+00,
      "bias[1]": 2.0480000000000000e+03,
      "bias[2]": 1.0000000000000000e+00,
      "bias[3]": 1.0000000000000000e+00,
      "c_desc_0": 2.0000000000000000e+00,
      "c_desc_1": 2.0480000000000000e+03,
      "c_desc_2": 7.0000000000000000e+00,
      "c_desc_3": 7.0000000000000000e+00,
      "compute_capability:7.5": 3.8315628306456499e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ADD_TENSOR_Impl": 1.3211678748143176e+19,
      "gpu_name:Quadro RTX 6000": 5.1174270964049613e+18,
      "host_name:aleph": 3.2334478980185999e+18,
      "input[0]": 2.0000000000000000e+00,
      "input[1]": 2.0480000000000000e+03,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input_tensor_layout": 0.0000000000000000e+00,
      "num_iterations": 9.2390000000000000e+04,
      "output_tensor_layout": 0.0000000000000000e+00,
      "predicted_flops": 2.6328902620270626e+10,
      "predicted_flops_count": 2.0070400000000000e+05
    },
    {
      "name": "LAYER_CUDNN_ADD_TENSOR_TENSORCOREHALF__BatchSize_2__6496234762121407974/input[0]:2/input[1]:512/input[2]:28/input[3]:28/bias[0]:1/bias[1]:512/bias[2]:1/bias[3]:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 53291,
      "real_time": 1.3194870441626852e+04,
      "cpu_time": 1.8782092567246273e+04,
      "time_unit": "ns",
      "items_per_second": 6.0843037720726372e+10,
      "a_desc_0": 1.0000000000000000e+00,
      "a_desc_1": 5.1200000000000000e+02,
      "a_desc_2": 1.0000000000000000e+00,
      "a_desc_3": 1.0000000000000000e+00,
      "alpha": 0.0000000000000000e+00,
      "batch_size": 2.0000000000000000e+00,
      "benchmark_file:/home/dakkak/scope/scopes/cudnn_scope/src/cudnn_add_tensor.cpp": 3.4177723063645414e+18,
      "benchmark_func:void iLAYER_CUDNN_ADD_TENSOR_Impl(benchmark::State&) [with T = __half]": 1.3682207389025487e+19,
      "beta": 0.0000000000000000e+00,
      "bias[0]": 1.0000000000000000e+00,
      "bias[1]": 5.1200000000000000e+02,
      "bias[2]": 1.0000000000000000e+00,
      "bias[3]": 1.0000000000000000e+00,
      "c_desc_0": 2.0000000000000000e+00,
      "c_desc_1": 5.1200000000000000e+02,
      "c_desc_2": 2.8000000000000000e+01,
      "c_desc_3": 2.8000000000000000e+01,
      "compute_capability:7.5": 3.8315628306456499e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ADD_TENSOR_Impl": 1.3211678748143176e+19,
      "gpu_name:Quadro RTX 6000": 5.1174270964049613e+18,
      "host_name:aleph": 3.2334478980185999e+18,
      "input[0]": 2.0000000000000000e+00,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_tensor_layout": 0.0000000000000000e+00,
      "num_iterations": 5.3291000000000000e+04,
      "output_tensor_layout": 0.0000000000000000e+00,
      "predicted_flops": 6.0843037720726372e+10,
      "predicted_flops_count": 8.0281600000000000e+05
    },
    {
      "name": "LAYER_CUDNN_ADD_TENSOR_TENSORCOREHALF__BatchSize_2__12937909549470835540/input[0]:2/input[1]:256/input[2]:14/input[3]:14/bias[0]:1/bias[1]:256/bias[2]:1/bias[3]:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 100967,
      "real_time": 6.8541675718567576e+03,
      "cpu_time": 1.2513611982134498e+04,
      "time_unit": "ns",
      "items_per_second": 1.4641019343041124e+10,
      "a_desc_0": 1.0000000000000000e+00,
      "a_desc_1": 2.5600000000000000e+02,
      "a_desc_2": 1.0000000000000000e+00,
      "a_desc_3": 1.0000000000000000e+00,
      "alpha": 0.0000000000000000e+00,
      "batch_size": 2.0000000000000000e+00,
      "benchmark_file:/home/dakkak/scope/scopes/cudnn_scope/src/cudnn_add_tensor.cpp": 3.4177723063645414e+18,
      "benchmark_func:void iLAYER_CUDNN_ADD_TENSOR_Impl(benchmark::State&) [with T = __half]": 1.3682207389025487e+19,
      "beta": 0.0000000000000000e+00,
      "bias[0]": 1.0000000000000000e+00,
      "bias[1]": 2.5600000000000000e+02,
      "bias[2]": 1.0000000000000000e+00,
      "bias[3]": 1.0000000000000000e+00,
      "c_desc_0": 2.0000000000000000e+00,
      "c_desc_1": 2.5600000000000000e+02,
      "c_desc_2": 1.4000000000000000e+01,
      "c_desc_3": 1.4000000000000000e+01,
      "compute_capability:7.5": 3.8315628306456499e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ADD_TENSOR_Impl": 1.3211678748143176e+19,
      "gpu_name:Quadro RTX 6000": 5.1174270964049613e+18,
      "host_name:aleph": 3.2334478980185999e+18,
      "input[0]": 2.0000000000000000e+00,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_tensor_layout": 0.0000000000000000e+00,
      "num_iterations": 1.0096700000000000e+05,
      "output_tensor_layout": 0.0000000000000000e+00,
      "predicted_flops": 1.4641019343041124e+10,
      "predicted_flops_count": 1.0035200000000000e+05
    },
    {
      "name": "LAYER_CUDNN_ADD_TENSOR_TENSORCOREHALF__BatchSize_2__1624363149426811201/input[0]:2/input[1]:512/input[2]:7/input[3]:7/bias[0]:1/bias[1]:512/bias[2]:1/bias[3]:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 107812,
      "real_time": 6.4186695282695946e+03,
      "cpu_time": 1.1849956247915854e+04,
      "time_unit": "ns",
      "items_per_second": 7.8171963487154188e+09,
      "a_desc_0": 1.0000000000000000e+00,
      "a_desc_1": 5.1200000000000000e+02,
      "a_desc_2": 1.0000000000000000e+00,
      "a_desc_3": 1.0000000000000000e+00,
      "alpha": 0.0000000000000000e+00,
      "batch_size": 2.0000000000000000e+00,
      "benchmark_file:/home/dakkak/scope/scopes/cudnn_scope/src/cudnn_add_tensor.cpp": 3.4177723063645414e+18,
      "benchmark_func:void iLAYER_CUDNN_ADD_TENSOR_Impl(benchmark::State&) [with T = __half]": 1.3682207389025487e+19,
      "beta": 0.0000000000000000e+00,
      "bias[0]": 1.0000000000000000e+00,
      "bias[1]": 5.1200000000000000e+02,
      "bias[2]": 1.0000000000000000e+00,
      "bias[3]": 1.0000000000000000e+00,
      "c_desc_0": 2.0000000000000000e+00,
      "c_desc_1": 5.1200000000000000e+02,
      "c_desc_2": 7.0000000000000000e+00,
      "c_desc_3": 7.0000000000000000e+00,
      "compute_capability:7.5": 3.8315628306456499e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ADD_TENSOR_Impl": 1.3211678748143176e+19,
      "gpu_name:Quadro RTX 6000": 5.1174270964049613e+18,
      "host_name:aleph": 3.2334478980185999e+18,
      "input[0]": 2.0000000000000000e+00,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input_tensor_layout": 0.0000000000000000e+00,
      "num_iterations": 1.0781200000000000e+05,
      "output_tensor_layout": 0.0000000000000000e+00,
      "predicted_flops": 7.8171963487154188e+09,
      "predicted_flops_count": 5.0176000000000000e+04
    },
    {
      "name": "LAYER_CUDNN_ADD_TENSOR_TENSORCOREHALF__BatchSize_2__10942011518612648461/input[0]:2/input[1]:1024/input[2]:14/input[3]:14/bias[0]:1/bias[1]:1024/bias[2]:1/bias[3]:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 73871,
      "real_time": 9.5197537231043207e+03,
      "cpu_time": 1.5144326257905155e+04,
      "time_unit": "ns",
      "items_per_second": 4.2165796687133606e+10,
      "a_desc_0": 1.0000000000000000e+00,
      "a_desc_1": 1.0240000000000000e+03,
      "a_desc_2": 1.0000000000000000e+00,
      "a_desc_3": 1.0000000000000000e+00,
      "alpha": 0.0000000000000000e+00,
      "batch_size": 2.0000000000000000e+00,
      "benchmark_file:/home/dakkak/scope/scopes/cudnn_scope/src/cudnn_add_tensor.cpp": 3.4177723063645414e+18,
      "benchmark_func:void iLAYER_CUDNN_ADD_TENSOR_Impl(benchmark::State&) [with T = __half]": 1.3682207389025487e+19,
      "beta": 0.0000000000000000e+00,
      "bias[0]": 1.0000000000000000e+00,
      "bias[1]": 1.0240000000000000e+03,
      "bias[2]": 1.0000000000000000e+00,
      "bias[3]": 1.0000000000000000e+00,
      "c_desc_0": 2.0000000000000000e+00,
      "c_desc_1": 1.0240000000000000e+03,
      "c_desc_2": 1.4000000000000000e+01,
      "c_desc_3": 1.4000000000000000e+01,
      "compute_capability:7.5": 3.8315628306456499e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_ADD_TENSOR_Impl": 1.3211678748143176e+19,
      "gpu_name:Quadro RTX 6000": 5.1174270964049613e+18,
      "host_name:aleph": 3.2334478980185999e+18,
      "input[0]": 2.0000000000000000e+00,
      "input[1]": 1.0240000000000000e+03,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_tensor_layout": 0.0000000000000000e+00,
      "num_iterations": 7.3871000000000000e+04,
      "output_tensor_layout": 0.0000000000000000e+00,
      "predicted_flops": 4.2165796687133606e+10,
      "predicted_flops_count": 4.0140800000000000e+05
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_TENSORCOREHALF__BatchSize_2__7881150944354432580<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:2/input[1]:64/input[2]:112/input[3]:112/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:2/manual_time",
      "iterations": 17491,
      "real_time": 4.0022786620278042e+04,
      "cpu_time": 4.6025157395244038e+04,
      "time_unit": "ns",
      "items_per_second": 4.0117946189845924e+10,
      "batch_size": 2.0000000000000000e+00,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/dakkak/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 4.4931805600426099e+17,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = __half; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = false]": 1.2934699958013073e+19,
      "compute_capability:7.5": 3.8315628306456499e+18,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:Quadro RTX 6000": 5.1174270964049613e+18,
      "host_name:aleph": 3.2334478980185999e+18,
      "input[0]": 2.0000000000000000e+00,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 1.1200000000000000e+02,
      "input[3]": 1.1200000000000000e+02,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 2.0000000000000000e+00,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 1.1200000000000000e+02,
      "input_size": 1.6056320000000000e+06,
      "input_width": 1.1200000000000000e+02,
      "is_training": 0.0000000000000000e+00,
      "num_iterations": 1.7491000000000000e+04,
      "output_batch_size": 2.0000000000000000e+00,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 1.1200000000000000e+02,
      "output_size": 1.6056320000000000e+06,
      "output_width": 1.1200000000000000e+02,
      "predicted_flops": 4.0117946189845924e+10,
      "predicted_flops_count": 1.6056320000000000e+06,
      "x_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_TENSORCOREHALF__BatchSize_2__16539550092941432647<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:2/input[1]:64/input[2]:112/input[3]:112/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:2/manual_time",
      "iterations": 8030,
      "real_time": 8.7246720954086588e+04,
      "cpu_time": 9.3362410336209810e+04,
      "time_unit": "ns",
      "items_per_second": 1.8403350663974644e+10,
      "batch_size": 2.0000000000000000e+00,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/dakkak/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 4.4931805600426099e+17,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = __half; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = true]": 1.7107992421717466e+18,
      "compute_capability:7.5": 3.8315628306456499e+18,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:Quadro RTX 6000": 5.1174270964049613e+18,
      "host_name:aleph": 3.2334478980185999e+18,
      "input[0]": 2.0000000000000000e+00,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 1.1200000000000000e+02,
      "input[3]": 1.1200000000000000e+02,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 2.0000000000000000e+00,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 1.1200000000000000e+02,
      "input_size": 1.6056320000000000e+06,
      "input_width": 1.1200000000000000e+02,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 8.0300000000000000e+03,
      "output_batch_size": 2.0000000000000000e+00,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 1.1200000000000000e+02,
      "output_size": 1.6056320000000000e+06,
      "output_width": 1.1200000000000000e+02,
      "predicted_flops": 1.8403350663974644e+10,
      "predicted_flops_count": 1.6056320000000000e+06,
      "x_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_TENSORCOREHALF__BatchSize_2__11243507372183143671<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:2/input[1]:128/input[2]:28/input[3]:28/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:2/manual_time",
      "iterations": 98514,
      "real_time": 7.1140377951583541e+03,
      "cpu_time": 1.2578026341442986e+04,
      "time_unit": "ns",
      "items_per_second": 2.8212388769791805e+10,
      "batch_size": 2.0000000000000000e+00,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/dakkak/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 4.4931805600426099e+17,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = __half; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = false]": 1.2934699958013073e+19,
      "compute_capability:7.5": 3.8315628306456499e+18,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:Quadro RTX 6000": 5.1174270964049613e+18,
      "host_name:aleph": 3.2334478980185999e+18,
      "input[0]": 2.0000000000000000e+00,
      "input[1]": 1.2800000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 2.0000000000000000e+00,
      "input_channels": 1.2800000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 2.0070400000000000e+05,
      "input_width": 2.8000000000000000e+01,
      "is_training": 0.0000000000000000e+00,
      "num_iterations": 9.8514000000000000e+04,
      "output_batch_size": 2.0000000000000000e+00,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 2.0070400000000000e+05,
      "output_width": 2.8000000000000000e+01,
      "predicted_flops": 2.8212388769791805e+10,
      "predicted_flops_count": 2.0070400000000000e+05,
      "x_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_TENSORCOREHALF__BatchSize_2__1504138815747466740<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:2/input[1]:128/input[2]:28/input[3]:28/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:2/manual_time",
      "iterations": 51763,
      "real_time": 1.3449691533384315e+04,
      "cpu_time": 1.9065333636019557e+04,
      "time_unit": "ns",
      "items_per_second": 1.4922572722342377e+10,
      "batch_size": 2.0000000000000000e+00,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/dakkak/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 4.4931805600426099e+17,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = __half; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = true]": 1.7107992421717466e+18,
      "compute_capability:7.5": 3.8315628306456499e+18,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:Quadro RTX 6000": 5.1174270964049613e+18,
      "host_name:aleph": 3.2334478980185999e+18,
      "input[0]": 2.0000000000000000e+00,
      "input[1]": 1.2800000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 2.0000000000000000e+00,
      "input_channels": 1.2800000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 2.0070400000000000e+05,
      "input_width": 2.8000000000000000e+01,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 5.1763000000000000e+04,
      "output_batch_size": 2.0000000000000000e+00,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 2.0070400000000000e+05,
      "output_width": 2.8000000000000000e+01,
      "predicted_flops": 1.4922572722342377e+10,
      "predicted_flops_count": 2.0070400000000000e+05,
      "x_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_TENSORCOREHALF__BatchSize_2__7669167158694434672<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:2/input[1]:64/input[2]:56/input[3]:56/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:2/manual_time",
      "iterations": 78631,
      "real_time": 8.8823076483714485e+03,
      "cpu_time": 1.4524784537909234e+04,
      "time_unit": "ns",
      "items_per_second": 4.5191859580949921e+10,
      "batch_size": 2.0000000000000000e+00,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/dakkak/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 4.4931805600426099e+17,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = __half; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = false]": 1.2934699958013073e+19,
      "compute_capability:7.5": 3.8315628306456499e+18,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:Quadro RTX 6000": 5.1174270964049613e+18,
      "host_name:aleph": 3.2334478980185999e+18,
      "input[0]": 2.0000000000000000e+00,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 2.0000000000000000e+00,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 4.0140800000000000e+05,
      "input_width": 5.6000000000000000e+01,
      "is_training": 0.0000000000000000e+00,
      "num_iterations": 7.8631000000000000e+04,
      "output_batch_size": 2.0000000000000000e+00,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 5.6000000000000000e+01,
      "output_size": 4.0140800000000000e+05,
      "output_width": 5.6000000000000000e+01,
      "predicted_flops": 4.5191859580949921e+10,
      "predicted_flops_count": 4.0140800000000000e+05,
      "x_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_TENSORCOREHALF__BatchSize_2__16337206561105884787<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:2/input[1]:64/input[2]:56/input[3]:56/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:2/manual_time",
      "iterations": 31853,
      "real_time": 2.2043633897708853e+04,
      "cpu_time": 2.7916972216116934e+04,
      "time_unit": "ns",
      "items_per_second": 1.8209701806094734e+10,
      "batch_size": 2.0000000000000000e+00,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/dakkak/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 4.4931805600426099e+17,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = __half; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = true]": 1.7107992421717466e+18,
      "compute_capability:7.5": 3.8315628306456499e+18,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:Quadro RTX 6000": 5.1174270964049613e+18,
      "host_name:aleph": 3.2334478980185999e+18,
      "input[0]": 2.0000000000000000e+00,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 2.0000000000000000e+00,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 4.0140800000000000e+05,
      "input_width": 5.6000000000000000e+01,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 3.1853000000000000e+04,
      "output_batch_size": 2.0000000000000000e+00,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 5.6000000000000000e+01,
      "output_size": 4.0140800000000000e+05,
      "output_width": 5.6000000000000000e+01,
      "predicted_flops": 1.8209701806094734e+10,
      "predicted_flops_count": 4.0140800000000000e+05,
      "x_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_TENSORCOREHALF__BatchSize_2__582577114306830428<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:2/input[1]:256/input[2]:56/input[3]:56/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:2/manual_time",
      "iterations": 17488,
      "real_time": 4.0006770354392786e+04,
      "cpu_time": 4.5978241365524285e+04,
      "time_unit": "ns",
      "items_per_second": 4.0134006963741325e+10,
      "batch_size": 2.0000000000000000e+00,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/dakkak/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 4.4931805600426099e+17,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = __half; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = false]": 1.2934699958013073e+19,
      "compute_capability:7.5": 3.8315628306456499e+18,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:Quadro RTX 6000": 5.1174270964049613e+18,
      "host_name:aleph": 3.2334478980185999e+18,
      "input[0]": 2.0000000000000000e+00,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 2.0000000000000000e+00,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 5.6000000000000000e+01,
      "input_size": 1.6056320000000000e+06,
      "input_width": 5.6000000000000000e+01,
      "is_training": 0.0000000000000000e+00,
      "num_iterations": 1.7488000000000000e+04,
      "output_batch_size": 2.0000000000000000e+00,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 5.6000000000000000e+01,
      "output_size": 1.6056320000000000e+06,
      "output_width": 5.6000000000000000e+01,
      "predicted_flops": 4.0134006963741325e+10,
      "predicted_flops_count": 1.6056320000000000e+06,
      "x_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_TENSORCOREHALF__BatchSize_2__9278130904821170527<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:2/input[1]:256/input[2]:56/input[3]:56/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:2/manual_time",
      "iterations": 8026,
      "real_time": 8.7208169638141815e+04,
      "cpu_time": 9.3297942686259485e+04,
      "time_unit": "ns",
      "items_per_second": 1.8411486064463306e+10,
      "batch_size": 2.0000000000000000e+00,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/dakkak/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 4.4931805600426099e+17,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = __half; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = true]": 1.7107992421717466e+18,
      "compute_capability:7.5": 3.8315628306456499e+18,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:Quadro RTX 6000": 5.1174270964049613e+18,
      "host_name:aleph": 3.2334478980185999e+18,
      "input[0]": 2.0000000000000000e+00,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 2.0000000000000000e+00,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 5.6000000000000000e+01,
      "input_size": 1.6056320000000000e+06,
      "input_width": 5.6000000000000000e+01,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 8.0260000000000000e+03,
      "output_batch_size": 2.0000000000000000e+00,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 5.6000000000000000e+01,
      "output_size": 1.6056320000000000e+06,
      "output_width": 5.6000000000000000e+01,
      "predicted_flops": 1.8411486064463306e+10,
      "predicted_flops_count": 1.6056320000000000e+06,
      "x_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_TENSORCOREHALF__BatchSize_2__89627295906780372<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:2/input[1]:512/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:2/manual_time",
      "iterations": 126551,
      "real_time": 5.5819625762144733e+03,
      "cpu_time": 1.1059987736174289e+04,
      "time_unit": "ns",
      "items_per_second": 8.9889531351942387e+09,
      "batch_size": 2.0000000000000000e+00,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/dakkak/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 4.4931805600426099e+17,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = __half; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = false]": 1.2934699958013073e+19,
      "compute_capability:7.5": 3.8315628306456499e+18,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:Quadro RTX 6000": 5.1174270964049613e+18,
      "host_name:aleph": 3.2334478980185999e+18,
      "input[0]": 2.0000000000000000e+00,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 2.0000000000000000e+00,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 5.0176000000000000e+04,
      "input_width": 7.0000000000000000e+00,
      "is_training": 0.0000000000000000e+00,
      "num_iterations": 1.2655100000000000e+05,
      "output_batch_size": 2.0000000000000000e+00,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 5.0176000000000000e+04,
      "output_width": 7.0000000000000000e+00,
      "predicted_flops": 8.9889531351942387e+09,
      "predicted_flops_count": 5.0176000000000000e+04,
      "x_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_TENSORCOREHALF__BatchSize_2__9937574821414352343<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:2/input[1]:512/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:2/manual_time",
      "iterations": 75136,
      "real_time": 9.3304957147695295e+03,
      "cpu_time": 1.4870069394161124e+04,
      "time_unit": "ns",
      "items_per_second": 5.3776349653721895e+09,
      "batch_size": 2.0000000000000000e+00,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/dakkak/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 4.4931805600426099e+17,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = __half; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = true]": 1.7107992421717466e+18,
      "compute_capability:7.5": 3.8315628306456499e+18,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:Quadro RTX 6000": 5.1174270964049613e+18,
      "host_name:aleph": 3.2334478980185999e+18,
      "input[0]": 2.0000000000000000e+00,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 2.0000000000000000e+00,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 5.0176000000000000e+04,
      "input_width": 7.0000000000000000e+00,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 7.5136000000000000e+04,
      "output_batch_size": 2.0000000000000000e+00,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 5.0176000000000000e+04,
      "output_width": 7.0000000000000000e+00,
      "predicted_flops": 5.3776349653721895e+09,
      "predicted_flops_count": 5.0176000000000000e+04,
      "x_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_TENSORCOREHALF__BatchSize_2__14771142364233918832<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:2/input[1]:1024/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:2/manual_time",
      "iterations": 78971,
      "real_time": 8.8599952465148726e+03,
      "cpu_time": 1.4510712907267527e+04,
      "time_unit": "ns",
      "items_per_second": 4.5305667647834923e+10,
      "batch_size": 2.0000000000000000e+00,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/dakkak/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 4.4931805600426099e+17,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = __half; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = false]": 1.2934699958013073e+19,
      "compute_capability:7.5": 3.8315628306456499e+18,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:Quadro RTX 6000": 5.1174270964049613e+18,
      "host_name:aleph": 3.2334478980185999e+18,
      "input[0]": 2.0000000000000000e+00,
      "input[1]": 1.0240000000000000e+03,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 2.0000000000000000e+00,
      "input_channels": 1.0240000000000000e+03,
      "input_height": 1.4000000000000000e+01,
      "input_size": 4.0140800000000000e+05,
      "input_width": 1.4000000000000000e+01,
      "is_training": 0.0000000000000000e+00,
      "num_iterations": 7.8971000000000000e+04,
      "output_batch_size": 2.0000000000000000e+00,
      "output_channels": 1.0240000000000000e+03,
      "output_height": 1.4000000000000000e+01,
      "output_size": 4.0140800000000000e+05,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 4.5305667647834923e+10,
      "predicted_flops_count": 4.0140800000000000e+05,
      "x_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_TENSORCOREHALF__BatchSize_2__4911900602416859251<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:2/input[1]:1024/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:2/manual_time",
      "iterations": 31795,
      "real_time": 2.2055834147111418e+04,
      "cpu_time": 2.7965844440923658e+04,
      "time_unit": "ns",
      "items_per_second": 1.8199629056086781e+10,
      "batch_size": 2.0000000000000000e+00,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/dakkak/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 4.4931805600426099e+17,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = __half; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = true]": 1.7107992421717466e+18,
      "compute_capability:7.5": 3.8315628306456499e+18,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:Quadro RTX 6000": 5.1174270964049613e+18,
      "host_name:aleph": 3.2334478980185999e+18,
      "input[0]": 2.0000000000000000e+00,
      "input[1]": 1.0240000000000000e+03,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 2.0000000000000000e+00,
      "input_channels": 1.0240000000000000e+03,
      "input_height": 1.4000000000000000e+01,
      "input_size": 4.0140800000000000e+05,
      "input_width": 1.4000000000000000e+01,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 3.1795000000000000e+04,
      "output_batch_size": 2.0000000000000000e+00,
      "output_channels": 1.0240000000000000e+03,
      "output_height": 1.4000000000000000e+01,
      "output_size": 4.0140800000000000e+05,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 1.8199629056086781e+10,
      "predicted_flops_count": 4.0140800000000000e+05,
      "x_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_TENSORCOREHALF__BatchSize_2__4076618591795955892<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:2/input[1]:256/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:2/manual_time",
      "iterations": 117645,
      "real_time": 5.9880722019981895e+03,
      "cpu_time": 1.1666453491453729e+04,
      "time_unit": "ns",
      "items_per_second": 1.6758648963269522e+10,
      "batch_size": 2.0000000000000000e+00,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/dakkak/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 4.4931805600426099e+17,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = __half; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = false]": 1.2934699958013073e+19,
      "compute_capability:7.5": 3.8315628306456499e+18,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:Quadro RTX 6000": 5.1174270964049613e+18,
      "host_name:aleph": 3.2334478980185999e+18,
      "input[0]": 2.0000000000000000e+00,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 2.0000000000000000e+00,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 1.0035200000000000e+05,
      "input_width": 1.4000000000000000e+01,
      "is_training": 0.0000000000000000e+00,
      "num_iterations": 1.1764500000000000e+05,
      "output_batch_size": 2.0000000000000000e+00,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 1.0035200000000000e+05,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 1.6758648963269522e+10,
      "predicted_flops_count": 1.0035200000000000e+05,
      "x_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_TENSORCOREHALF__BatchSize_2__12701346291485452727<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:2/input[1]:256/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:2/manual_time",
      "iterations": 68343,
      "real_time": 1.0180392898838960e+04,
      "cpu_time": 1.5757847094825564e+04,
      "time_unit": "ns",
      "items_per_second": 9.8573798670820274e+09,
      "batch_size": 2.0000000000000000e+00,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/dakkak/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 4.4931805600426099e+17,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = __half; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = true]": 1.7107992421717466e+18,
      "compute_capability:7.5": 3.8315628306456499e+18,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:Quadro RTX 6000": 5.1174270964049613e+18,
      "host_name:aleph": 3.2334478980185999e+18,
      "input[0]": 2.0000000000000000e+00,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 2.0000000000000000e+00,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 1.0035200000000000e+05,
      "input_width": 1.4000000000000000e+01,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 6.8343000000000000e+04,
      "output_batch_size": 2.0000000000000000e+00,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 1.0035200000000000e+05,
      "output_width": 1.4000000000000000e+01,
      "predicted_flops": 9.8573798670820274e+09,
      "predicted_flops_count": 1.0035200000000000e+05,
      "x_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_TENSORCOREHALF__BatchSize_2__5698833811316599431<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:2/input[1]:2048/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:2/manual_time",
      "iterations": 99028,
      "real_time": 7.0777955253628625e+03,
      "cpu_time": 1.2528920678984923e+04,
      "time_unit": "ns",
      "items_per_second": 2.8356851971887157e+10,
      "batch_size": 2.0000000000000000e+00,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/dakkak/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 4.4931805600426099e+17,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = __half; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = false]": 1.2934699958013073e+19,
      "compute_capability:7.5": 3.8315628306456499e+18,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:Quadro RTX 6000": 5.1174270964049613e+18,
      "host_name:aleph": 3.2334478980185999e+18,
      "input[0]": 2.0000000000000000e+00,
      "input[1]": 2.0480000000000000e+03,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 2.0000000000000000e+00,
      "input_channels": 2.0480000000000000e+03,
      "input_height": 7.0000000000000000e+00,
      "input_size": 2.0070400000000000e+05,
      "input_width": 7.0000000000000000e+00,
      "is_training": 0.0000000000000000e+00,
      "num_iterations": 9.9028000000000000e+04,
      "output_batch_size": 2.0000000000000000e+00,
      "output_channels": 2.0480000000000000e+03,
      "output_height": 7.0000000000000000e+00,
      "output_size": 2.0070400000000000e+05,
      "output_width": 7.0000000000000000e+00,
      "predicted_flops": 2.8356851971887157e+10,
      "predicted_flops_count": 2.0070400000000000e+05,
      "x_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_TENSORCOREHALF__BatchSize_2__14393894747053067140<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:2/input[1]:2048/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:2/manual_time",
      "iterations": 51950,
      "real_time": 1.3429317710597301e+04,
      "cpu_time": 1.9041166294536273e+04,
      "time_unit": "ns",
      "items_per_second": 1.4945211985089987e+10,
      "batch_size": 2.0000000000000000e+00,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/dakkak/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 4.4931805600426099e+17,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = __half; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = true]": 1.7107992421717466e+18,
      "compute_capability:7.5": 3.8315628306456499e+18,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:Quadro RTX 6000": 5.1174270964049613e+18,
      "host_name:aleph": 3.2334478980185999e+18,
      "input[0]": 2.0000000000000000e+00,
      "input[1]": 2.0480000000000000e+03,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 2.0000000000000000e+00,
      "input_channels": 2.0480000000000000e+03,
      "input_height": 7.0000000000000000e+00,
      "input_size": 2.0070400000000000e+05,
      "input_width": 7.0000000000000000e+00,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 5.1950000000000000e+04,
      "output_batch_size": 2.0000000000000000e+00,
      "output_channels": 2.0480000000000000e+03,
      "output_height": 7.0000000000000000e+00,
      "output_size": 2.0070400000000000e+05,
      "output_width": 7.0000000000000000e+00,
      "predicted_flops": 1.4945211985089987e+10,
      "predicted_flops_count": 2.0070400000000000e+05,
      "x_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_INFERENCE_TENSORCOREHALF__BatchSize_2__1277591215860024184<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:2/input[1]:512/input[2]:28/input[3]:28/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:2/manual_time",
      "iterations": 30496,
      "real_time": 2.2881523676061432e+04,
      "cpu_time": 2.8709090208568345e+04,
      "time_unit": "ns",
      "items_per_second": 3.5085775377795464e+10,
      "batch_size": 2.0000000000000000e+00,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/dakkak/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 4.4931805600426099e+17,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = __half; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = false]": 1.2934699958013073e+19,
      "compute_capability:7.5": 3.8315628306456499e+18,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:Quadro RTX 6000": 5.1174270964049613e+18,
      "host_name:aleph": 3.2334478980185999e+18,
      "input[0]": 2.0000000000000000e+00,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 2.0000000000000000e+00,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 8.0281600000000000e+05,
      "input_width": 2.8000000000000000e+01,
      "is_training": 0.0000000000000000e+00,
      "num_iterations": 3.0496000000000000e+04,
      "output_batch_size": 2.0000000000000000e+00,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 8.0281600000000000e+05,
      "output_width": 2.8000000000000000e+01,
      "predicted_flops": 3.5085775377795464e+10,
      "predicted_flops_count": 8.0281600000000000e+05,
      "x_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_BATCHNORM_FWD_TRAINING_TENSORCOREHALF__BatchSize_2__11055732748475458171<CUDNN_BATCHNORM_PER_ACTIVATION>/input[0]:2/input[1]:512/input[2]:28/input[3]:28/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:2/manual_time",
      "iterations": 14657,
      "real_time": 4.7839781674206082e+04,
      "cpu_time": 5.3772449068705944e+04,
      "time_unit": "ns",
      "items_per_second": 1.6781347487479372e+10,
      "batch_size": 2.0000000000000000e+00,
      "batchnorm_mode": 0.0000000000000000e+00,
      "benchmark_file:/home/dakkak/scope/scopes/cudnn_scope/src/cudnn_batchnorm_fwd.cpp": 4.4931805600426099e+17,
      "benchmark_func:void iLAYER_CUDNN_BATCHNORM_FWD_Impl(benchmark::State&) [with T = __half; cudnnBatchNormMode_t batchnorm_mode = (cudnnBatchNormMode_t)0; bool is_training = true]": 1.7107992421717466e+18,
      "compute_capability:7.5": 3.8315628306456499e+18,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_BATCHNORM_FWD_Impl": 2.4394916016563661e+18,
      "gpu_name:Quadro RTX 6000": 5.1174270964049613e+18,
      "host_name:aleph": 3.2334478980185999e+18,
      "input[0]": 2.0000000000000000e+00,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_batch_size": 2.0000000000000000e+00,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 8.0281600000000000e+05,
      "input_width": 2.8000000000000000e+01,
      "is_training": 1.0000000000000000e+00,
      "num_iterations": 1.4657000000000000e+04,
      "output_batch_size": 2.0000000000000000e+00,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 8.0281600000000000e+05,
      "output_width": 2.8000000000000000e+01,
      "predicted_flops": 1.6781347487479372e+10,
      "predicted_flops_count": 8.0281600000000000e+05,
      "x_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_TENSORCOREHALF__BatchSize_2__17938446161332567201<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:2/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 3005,
      "real_time": 2.3292694629182399e+05,
      "cpu_time": 2.3939395108157318e+05,
      "time_unit": "ns",
      "items_per_second": 1.1029257202304959e+11,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 2.4195200204849243e-01,
      "batch_size": 2.0000000000000000e+00,
      "benchmark_file:/home/dakkak/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 7.5702145113912750e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.5012058362110720e+19,
      "compute_capability:7.5": 3.8315628306456499e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:Quadro RTX 6000": 5.1174270964049613e+18,
      "group": 1.0000000000000000e+00,
      "host_name:aleph": 3.2334478980185999e+18,
      "input[0]": 2.0000000000000000e+00,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 2.0000000000000000e+00,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 4.0140800000000000e+05,
      "input_width": 5.6000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 3.0050000000000000e+03,
      "output_batch_size": 2.0000000000000000e+00,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 5.6000000000000000e+01,
      "output_size": 4.0140800000000000e+05,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "predicted_advised_flops": 9.9263314820744629e+11,
      "predicted_advised_flops_count": 2.3121100800000000e+08,
      "predicted_flops": 9.9263314820744629e+11,
      "predicted_flops_count": 2.3121100800000000e+08,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00,
      "x_tensor_layout": 1.0000000000000000e+00,
      "y_tensor_layout": 1.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_TENSORCOREHALF__BatchSize_2__17938446161332567201<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:2/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 17533,
      "real_time": 3.9694728672510886e+04,
      "cpu_time": 4.5460150801337404e+04,
      "time_unit": "ns",
      "items_per_second": 6.4719202924772058e+11,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.8824000000000000e+04,
      "advised_time": 6.7680001258850098e-02,
      "batch_size": 2.0000000000000000e+00,
      "benchmark_file:/home/dakkak/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 7.5702145113912750e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.3877274157379230e+19,
      "compute_capability:7.5": 3.8315628306456499e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:Quadro RTX 6000": 5.1174270964049613e+18,
      "group": 1.0000000000000000e+00,
      "host_name:aleph": 3.2334478980185999e+18,
      "input[0]": 2.0000000000000000e+00,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 2.0000000000000000e+00,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 4.0140800000000000e+05,
      "input_width": 5.6000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 1.7533000000000000e+04,
      "output_batch_size": 2.0000000000000000e+00,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 5.6000000000000000e+01,
      "output_size": 4.0140800000000000e+05,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "predicted_advised_flops": 5.8247282632294854e+12,
      "predicted_advised_flops_count": 2.3121100800000000e+08,
      "predicted_flops": 5.8247282632294854e+12,
      "predicted_flops_count": 2.3121100800000000e+08,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 1.0000000000000000e+00,
      "workspace_bytes": 1.8824000000000000e+04,
      "workspace_megabytes": 1.7951965332031250e-02,
      "x_tensor_layout": 1.0000000000000000e+00,
      "y_tensor_layout": 1.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_TENSORCOREHALF__BatchSize_2__17938446161332567201<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:2/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_TENSORCOREHALF__BatchSize_2__17938446161332567201<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:2/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_TENSORCOREHALF__BatchSize_2__17938446161332567201<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:2/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_TENSORCOREHALF__BatchSize_2__17938446161332567201<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:2/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_TENSORCOREHALF__BatchSize_2__17938446161332567201<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:2/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_TENSORCOREHALF__BatchSize_2__17938446161332567201<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:2/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_TENSORCOREHALF__BatchSize_2__17714407797669034095<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:2/input[1]:512/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 6365,
      "real_time": 1.1083782964751111e+05,
      "cpu_time": 1.1682835161051228e+05,
      "time_unit": "ns",
      "items_per_second": 9.2712432503235596e+11,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 1.2015999853610992e-01,
      "batch_size": 2.0000000000000000e+00,
      "benchmark_file:/home/dakkak/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 7.5702145113912750e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.5012058362110720e+19,
      "compute_capability:7.5": 3.8315628306456499e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Quadro RTX 6000": 5.1174270964049613e+18,
      "group": 1.0000000000000000e+00,
      "host_name:aleph": 3.2334478980185999e+18,
      "input[0]": 2.0000000000000000e+00,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 2.0000000000000000e+00,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 8.0281600000000000e+05,
      "input_width": 2.8000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 6.3650000000000000e+03,
      "output_batch_size": 2.0000000000000000e+00,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 2.0070400000000000e+05,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 9.2712432503235596e+11,
      "predicted_advised_flops_count": 1.0276044800000000e+08,
      "predicted_flops": 9.2712432503235596e+11,
      "predicted_flops_count": 1.0276044800000000e+08,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00,
      "x_tensor_layout": 1.0000000000000000e+00,
      "y_tensor_layout": 1.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_TENSORCOREHALF__BatchSize_2__17714407797669034095<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:2/input[1]:512/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 19811,
      "real_time": 3.5212855734785786e+04,
      "cpu_time": 4.1065931603599987e+04,
      "time_unit": "ns",
      "items_per_second": 2.9182651010746011e+12,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 4.7120000000000000e+03,
      "advised_time": 4.0768001228570938e-02,
      "batch_size": 2.0000000000000000e+00,
      "benchmark_file:/home/dakkak/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 7.5702145113912750e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.3877274157379230e+19,
      "compute_capability:7.5": 3.8315628306456499e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Quadro RTX 6000": 5.1174270964049613e+18,
      "group": 1.0000000000000000e+00,
      "host_name:aleph": 3.2334478980185999e+18,
      "input[0]": 2.0000000000000000e+00,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 2.0000000000000000e+00,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 8.0281600000000000e+05,
      "input_width": 2.8000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 1.9811000000000000e+04,
      "output_batch_size": 2.0000000000000000e+00,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 2.0070400000000000e+05,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 2.9182651010746011e+12,
      "predicted_advised_flops_count": 1.0276044800000000e+08,
      "predicted_flops": 2.9182651010746011e+12,
      "predicted_flops_count": 1.0276044800000000e+08,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 1.0000000000000000e+00,
      "workspace_bytes": 4.7120000000000000e+03,
      "workspace_megabytes": 4.4937133789062500e-03,
      "x_tensor_layout": 1.0000000000000000e+00,
      "y_tensor_layout": 1.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_TENSORCOREHALF__BatchSize_2__17714407797669034095<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:2/input[1]:512/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_TENSORCOREHALF__BatchSize_2__17714407797669034095<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:2/input[1]:512/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_TENSORCOREHALF__BatchSize_2__17714407797669034095<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:2/input[1]:512/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_TENSORCOREHALF__BatchSize_2__17714407797669034095<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:2/input[1]:512/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_TENSORCOREHALF__BatchSize_2__17714407797669034095<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:2/input[1]:512/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_TENSORCOREHALF__BatchSize_2__17714407797669034095<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:2/input[1]:512/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_TENSORCOREHALF__BatchSize_2__8733978106764940258<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:2/input[1]:1024/input[2]:14/input[3]:14/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 2449,
      "real_time": 2.8541395641299005e+05,
      "cpu_time": 2.9233775704345247e+05,
      "time_unit": "ns",
      "items_per_second": 2.8803201999360415e+12,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 3.0070400238037109e-01,
      "batch_size": 2.0000000000000000e+00,
      "benchmark_file:/home/dakkak/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 7.5702145113912750e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.5012058362110720e+19,
      "compute_capability:7.5": 3.8315628306456499e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.0480000000000000e+03,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Quadro RTX 6000": 5.1174270964049613e+18,
      "group": 1.0000000000000000e+00,
      "host_name:aleph": 3.2334478980185999e+18,
      "input[0]": 2.0000000000000000e+00,
      "input[1]": 1.0240000000000000e+03,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 2.0000000000000000e+00,
      "input_channels": 1.0240000000000000e+03,
      "input_height": 1.4000000000000000e+01,
      "input_size": 4.0140800000000000e+05,
      "input_width": 1.4000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 2.0480000000000000e+03,
      "num_iterations": 2.4490000000000000e+03,
      "output_batch_size": 2.0000000000000000e+00,
      "output_channels": 2.0480000000000000e+03,
      "output_height": 7.0000000000000000e+00,
      "output_size": 2.0070400000000000e+05,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 7.2008004998401038e+11,
      "predicted_advised_flops_count": 2.0552089600000000e+08,
      "predicted_flops": 7.2008004998401038e+11,
      "predicted_flops_count": 2.0552089600000000e+08,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "w_filter_layout": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00,
      "x_tensor_layout": 1.0000000000000000e+00,
      "y_tensor_layout": 1.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_TENSORCOREHALF__BatchSize_2__8733978106764940258<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:2/input[1]:1024/input[2]:14/input[3]:14/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 15362,
      "real_time": 4.5183345783064717e+04,
      "cpu_time": 5.0902305428976848e+04,
      "time_unit": "ns",
      "items_per_second": 1.8194393747355633e+13,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 3.0000000000000000e+02,
      "advised_time": 5.3024001419544220e-02,
      "batch_size": 2.0000000000000000e+00,
      "benchmark_file:/home/dakkak/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 7.5702145113912750e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.3877274157379230e+19,
      "compute_capability:7.5": 3.8315628306456499e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.0480000000000000e+03,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Quadro RTX 6000": 5.1174270964049613e+18,
      "group": 1.0000000000000000e+00,
      "host_name:aleph": 3.2334478980185999e+18,
      "input[0]": 2.0000000000000000e+00,
      "input[1]": 1.0240000000000000e+03,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 2.0000000000000000e+00,
      "input_channels": 1.0240000000000000e+03,
      "input_height": 1.4000000000000000e+01,
      "input_size": 4.0140800000000000e+05,
      "input_width": 1.4000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 2.0480000000000000e+03,
      "num_iterations": 1.5362000000000000e+04,
      "output_batch_size": 2.0000000000000000e+00,
      "output_channels": 2.0480000000000000e+03,
      "output_height": 7.0000000000000000e+00,
      "output_size": 2.0070400000000000e+05,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 4.5485984368389082e+12,
      "predicted_advised_flops_count": 2.0552089600000000e+08,
      "predicted_flops": 4.5485984368389082e+12,
      "predicted_flops_count": 2.0552089600000000e+08,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "w_filter_layout": 1.0000000000000000e+00,
      "workspace_bytes": 3.0000000000000000e+02,
      "workspace_megabytes": 2.8610229492187500e-04,
      "x_tensor_layout": 1.0000000000000000e+00,
      "y_tensor_layout": 1.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_TENSORCOREHALF__BatchSize_2__8733978106764940258<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:2/input[1]:1024/input[2]:14/input[3]:14/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_TENSORCOREHALF__BatchSize_2__8733978106764940258<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:2/input[1]:1024/input[2]:14/input[3]:14/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_TENSORCOREHALF__BatchSize_2__8733978106764940258<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:2/input[1]:1024/input[2]:14/input[3]:14/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_TENSORCOREHALF__BatchSize_2__8733978106764940258<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:2/input[1]:1024/input[2]:14/input[3]:14/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_TENSORCOREHALF__BatchSize_2__8733978106764940258<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:2/input[1]:1024/input[2]:14/input[3]:14/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_TENSORCOREHALF__BatchSize_2__8733978106764940258<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:2/input[1]:1024/input[2]:14/input[3]:14/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_TENSORCOREHALF__BatchSize_2__15274969848148649785<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:2/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 11445,
      "real_time": 6.0817270799957128e+04,
      "cpu_time": 6.6621673132241107e+04,
      "time_unit": "ns",
      "items_per_second": 3.3793179683450195e+12,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 6.3487999141216278e-02,
      "batch_size": 2.0000000000000000e+00,
      "benchmark_file:/home/dakkak/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 7.5702145113912750e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.5012058362110720e+19,
      "compute_capability:7.5": 3.8315628306456499e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Quadro RTX 6000": 5.1174270964049613e+18,
      "group": 1.0000000000000000e+00,
      "host_name:aleph": 3.2334478980185999e+18,
      "input[0]": 2.0000000000000000e+00,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 2.0000000000000000e+00,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 5.6000000000000000e+01,
      "input_size": 1.6056320000000000e+06,
      "input_width": 5.6000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 1.1445000000000000e+04,
      "output_batch_size": 2.0000000000000000e+00,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 2.0070400000000000e+05,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 8.4482949208625488e+11,
      "predicted_advised_flops_count": 5.1380224000000000e+07,
      "predicted_flops": 8.4482949208625488e+11,
      "predicted_flops_count": 5.1380224000000000e+07,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "w_filter_layout": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00,
      "x_tensor_layout": 1.0000000000000000e+00,
      "y_tensor_layout": 1.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_TENSORCOREHALF__BatchSize_2__15274969848148649785<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:2/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 25228,
      "real_time": 2.7802706901530153e+04,
      "cpu_time": 3.3513916006018131e+04,
      "time_unit": "ns",
      "items_per_second": 7.3921182109317891e+12,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 4.7120000000000000e+03,
      "advised_time": 3.3119998872280121e-02,
      "batch_size": 2.0000000000000000e+00,
      "benchmark_file:/home/dakkak/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 7.5702145113912750e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.3877274157379230e+19,
      "compute_capability:7.5": 3.8315628306456499e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Quadro RTX 6000": 5.1174270964049613e+18,
      "group": 1.0000000000000000e+00,
      "host_name:aleph": 3.2334478980185999e+18,
      "input[0]": 2.0000000000000000e+00,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 2.0000000000000000e+00,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 5.6000000000000000e+01,
      "input_size": 1.6056320000000000e+06,
      "input_width": 5.6000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 2.5228000000000000e+04,
      "output_batch_size": 2.0000000000000000e+00,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 2.0070400000000000e+05,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 1.8480295527329473e+12,
      "predicted_advised_flops_count": 5.1380224000000000e+07,
      "predicted_flops": 1.8480295527329473e+12,
      "predicted_flops_count": 5.1380224000000000e+07,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "w_filter_layout": 1.0000000000000000e+00,
      "workspace_bytes": 4.7120000000000000e+03,
      "workspace_megabytes": 4.4937133789062500e-03,
      "x_tensor_layout": 1.0000000000000000e+00,
      "y_tensor_layout": 1.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_TENSORCOREHALF__BatchSize_2__15274969848148649785<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:2/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_TENSORCOREHALF__BatchSize_2__15274969848148649785<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:2/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_TENSORCOREHALF__BatchSize_2__15274969848148649785<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:2/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_TENSORCOREHALF__BatchSize_2__15274969848148649785<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:2/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_TENSORCOREHALF__BatchSize_2__15274969848148649785<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:2/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_TENSORCOREHALF__BatchSize_2__15274969848148649785<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:2/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_TENSORCOREHALF__BatchSize_2__1642253536799466404<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:2/input[1]:64/input[2]:56/input[3]:56/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 12579,
      "real_time": 5.5524917461296725e+04,
      "cpu_time": 6.1307175451093739e+04,
      "time_unit": "ns",
      "items_per_second": 1.8507087033785955e+12,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 5.7760000228881836e-02,
      "batch_size": 2.0000000000000000e+00,
      "benchmark_file:/home/dakkak/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 7.5702145113912750e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.5012058362110720e+19,
      "compute_capability:7.5": 3.8315628306456499e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.5600000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Quadro RTX 6000": 5.1174270964049613e+18,
      "group": 1.0000000000000000e+00,
      "host_name:aleph": 3.2334478980185999e+18,
      "input[0]": 2.0000000000000000e+00,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 2.0000000000000000e+00,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 4.0140800000000000e+05,
      "input_width": 5.6000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 2.5600000000000000e+02,
      "num_iterations": 1.2579000000000000e+04,
      "output_batch_size": 2.0000000000000000e+00,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 5.6000000000000000e+01,
      "output_size": 1.6056320000000000e+06,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 1.8507087033785955e+12,
      "predicted_advised_flops_count": 1.0276044800000000e+08,
      "predicted_flops": 1.8507087033785955e+12,
      "predicted_flops_count": 1.0276044800000000e+08,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00,
      "x_tensor_layout": 1.0000000000000000e+00,
      "y_tensor_layout": 1.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_TENSORCOREHALF__BatchSize_2__1642253536799466404<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:2/input[1]:64/input[2]:56/input[3]:56/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 26295,
      "real_time": 2.6433444541333247e+04,
      "cpu_time": 3.2046894999037329e+04,
      "time_unit": "ns",
      "items_per_second": 3.8875163560056021e+12,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.8824000000000000e+04,
      "advised_time": 3.2575998455286026e-02,
      "batch_size": 2.0000000000000000e+00,
      "benchmark_file:/home/dakkak/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 7.5702145113912750e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.3877274157379230e+19,
      "compute_capability:7.5": 3.8315628306456499e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.5600000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Quadro RTX 6000": 5.1174270964049613e+18,
      "group": 1.0000000000000000e+00,
      "host_name:aleph": 3.2334478980185999e+18,
      "input[0]": 2.0000000000000000e+00,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 2.0000000000000000e+00,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 4.0140800000000000e+05,
      "input_width": 5.6000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 2.5600000000000000e+02,
      "num_iterations": 2.6295000000000000e+04,
      "output_batch_size": 2.0000000000000000e+00,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 5.6000000000000000e+01,
      "output_size": 1.6056320000000000e+06,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 3.8875163560056021e+12,
      "predicted_advised_flops_count": 1.0276044800000000e+08,
      "predicted_flops": 3.8875163560056021e+12,
      "predicted_flops_count": 1.0276044800000000e+08,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 1.0000000000000000e+00,
      "workspace_bytes": 1.8824000000000000e+04,
      "workspace_megabytes": 1.7951965332031250e-02,
      "x_tensor_layout": 1.0000000000000000e+00,
      "y_tensor_layout": 1.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_TENSORCOREHALF__BatchSize_2__1642253536799466404<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:2/input[1]:64/input[2]:56/input[3]:56/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_TENSORCOREHALF__BatchSize_2__1642253536799466404<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:2/input[1]:64/input[2]:56/input[3]:56/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_TENSORCOREHALF__BatchSize_2__1642253536799466404<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:2/input[1]:64/input[2]:56/input[3]:56/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_TENSORCOREHALF__BatchSize_2__1642253536799466404<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:2/input[1]:64/input[2]:56/input[3]:56/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_TENSORCOREHALF__BatchSize_2__1642253536799466404<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:2/input[1]:64/input[2]:56/input[3]:56/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_TENSORCOREHALF__BatchSize_2__1642253536799466404<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:2/input[1]:64/input[2]:56/input[3]:56/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_TENSORCOREHALF__BatchSize_2__13368387017189291347<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:2/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 4694,
      "real_time": 1.4825697674999421e+05,
      "cpu_time": 1.5426573753732274e+05,
      "time_unit": "ns",
      "items_per_second": 1.3862477200420049e+12,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 1.5027199685573578e-01,
      "batch_size": 2.0000000000000000e+00,
      "benchmark_file:/home/dakkak/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 7.5702145113912750e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.5012058362110720e+19,
      "compute_capability:7.5": 3.8315628306456499e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.5600000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Quadro RTX 6000": 5.1174270964049613e+18,
      "group": 1.0000000000000000e+00,
      "host_name:aleph": 3.2334478980185999e+18,
      "input[0]": 2.0000000000000000e+00,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 2.0000000000000000e+00,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 8.0281600000000000e+05,
      "input_width": 2.8000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 2.5600000000000000e+02,
      "num_iterations": 4.6940000000000000e+03,
      "output_batch_size": 2.0000000000000000e+00,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 1.0035200000000000e+05,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 3.4656193001050122e+11,
      "predicted_advised_flops_count": 5.1380224000000000e+07,
      "predicted_flops": 3.4656193001050122e+11,
      "predicted_flops_count": 5.1380224000000000e+07,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "w_filter_layout": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00,
      "x_tensor_layout": 1.0000000000000000e+00,
      "y_tensor_layout": 1.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_TENSORCOREHALF__BatchSize_2__13368387017189291347<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:2/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 19783,
      "real_time": 3.5438347552512118e+04,
      "cpu_time": 4.1164130465631351e+04,
      "time_unit": "ns",
      "items_per_second": 5.7993927537242422e+12,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.1840000000000000e+03,
      "advised_time": 5.9647999703884125e-02,
      "batch_size": 2.0000000000000000e+00,
      "benchmark_file:/home/dakkak/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 7.5702145113912750e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.3877274157379230e+19,
      "compute_capability:7.5": 3.8315628306456499e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.5600000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Quadro RTX 6000": 5.1174270964049613e+18,
      "group": 1.0000000000000000e+00,
      "host_name:aleph": 3.2334478980185999e+18,
      "input[0]": 2.0000000000000000e+00,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 2.0000000000000000e+00,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 8.0281600000000000e+05,
      "input_width": 2.8000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 2.5600000000000000e+02,
      "num_iterations": 1.9783000000000000e+04,
      "output_batch_size": 2.0000000000000000e+00,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 1.0035200000000000e+05,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 1.4498481884310605e+12,
      "predicted_advised_flops_count": 5.1380224000000000e+07,
      "predicted_flops": 1.4498481884310605e+12,
      "predicted_flops_count": 5.1380224000000000e+07,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "w_filter_layout": 1.0000000000000000e+00,
      "workspace_bytes": 1.1840000000000000e+03,
      "workspace_megabytes": 1.1291503906250000e-03,
      "x_tensor_layout": 1.0000000000000000e+00,
      "y_tensor_layout": 1.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_TENSORCOREHALF__BatchSize_2__13368387017189291347<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:2/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_TENSORCOREHALF__BatchSize_2__13368387017189291347<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:2/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_TENSORCOREHALF__BatchSize_2__13368387017189291347<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:2/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_TENSORCOREHALF__BatchSize_2__13368387017189291347<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:2/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_TENSORCOREHALF__BatchSize_2__13368387017189291347<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:2/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_0_TENSORCOREHALF__BatchSize_2__13368387017189291347<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:2/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_TENSORCOREHALF__BatchSize_2__7136764562785026719<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:2/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:7/filter_width:7/pad_height:3/pad_width:3/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 6515,
      "real_time": 1.0815324651078999e+05,
      "cpu_time": 1.1398085234080906e+05,
      "time_unit": "ns",
      "items_per_second": 1.7815076866950781e+11,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 1.1081600189208984e-01,
      "batch_size": 2.0000000000000000e+00,
      "benchmark_file:/home/dakkak/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 7.5702145113912750e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.5012058362110720e+19,
      "compute_capability:7.5": 3.8315628306456499e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 7.0000000000000000e+00,
      "filter_width": 7.0000000000000000e+00,
      "gpu_name:Quadro RTX 6000": 5.1174270964049613e+18,
      "group": 1.0000000000000000e+00,
      "host_name:aleph": 3.2334478980185999e+18,
      "input[0]": 2.0000000000000000e+00,
      "input[1]": 3.0000000000000000e+00,
      "input[2]": 2.2400000000000000e+02,
      "input[3]": 2.2400000000000000e+02,
      "input_batch_size": 2.0000000000000000e+00,
      "input_channels": 3.0000000000000000e+00,
      "input_height": 2.2400000000000000e+02,
      "input_size": 3.0105600000000000e+05,
      "input_width": 2.2400000000000000e+02,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 6.5150000000000000e+03,
      "output_batch_size": 2.0000000000000000e+00,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 1.1200000000000000e+02,
      "output_size": 1.6056320000000000e+06,
      "output_width": 1.1200000000000000e+02,
      "pad_height": 3.0000000000000000e+00,
      "pad_width": 3.0000000000000000e+00,
      "predicted_advised_flops": 2.1823469162014709e+12,
      "predicted_advised_flops_count": 2.3602790400000000e+08,
      "predicted_flops": 2.1823469162014709e+12,
      "predicted_flops_count": 2.3602790400000000e+08,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "w_filter_layout": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00,
      "x_tensor_layout": 1.0000000000000000e+00,
      "y_tensor_layout": 1.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_TENSORCOREHALF__BatchSize_2__7136764562785026719<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:2/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:7/filter_width:7/pad_height:3/pad_width:3/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 6431,
      "real_time": 1.0749419515233557e+05,
      "cpu_time": 1.1348740180371946e+05,
      "time_unit": "ns",
      "items_per_second": 1.7924301840387671e+11,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 5.8800000000000000e+02,
      "advised_time": 1.1020799726247787e-01,
      "batch_size": 2.0000000000000000e+00,
      "benchmark_file:/home/dakkak/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 7.5702145113912750e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.3877274157379230e+19,
      "compute_capability:7.5": 3.8315628306456499e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 7.0000000000000000e+00,
      "filter_width": 7.0000000000000000e+00,
      "gpu_name:Quadro RTX 6000": 5.1174270964049613e+18,
      "group": 1.0000000000000000e+00,
      "host_name:aleph": 3.2334478980185999e+18,
      "input[0]": 2.0000000000000000e+00,
      "input[1]": 3.0000000000000000e+00,
      "input[2]": 2.2400000000000000e+02,
      "input[3]": 2.2400000000000000e+02,
      "input_batch_size": 2.0000000000000000e+00,
      "input_channels": 3.0000000000000000e+00,
      "input_height": 2.2400000000000000e+02,
      "input_size": 3.0105600000000000e+05,
      "input_width": 2.2400000000000000e+02,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 6.4310000000000000e+03,
      "output_batch_size": 2.0000000000000000e+00,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 1.1200000000000000e+02,
      "output_size": 1.6056320000000000e+06,
      "output_width": 1.1200000000000000e+02,
      "pad_height": 3.0000000000000000e+00,
      "pad_width": 3.0000000000000000e+00,
      "predicted_advised_flops": 2.1957269754474897e+12,
      "predicted_advised_flops_count": 2.3602790400000000e+08,
      "predicted_flops": 2.1957269754474897e+12,
      "predicted_flops_count": 2.3602790400000000e+08,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "w_filter_layout": 1.0000000000000000e+00,
      "workspace_bytes": 5.8800000000000000e+02,
      "workspace_megabytes": 5.6076049804687500e-04,
      "x_tensor_layout": 1.0000000000000000e+00,
      "y_tensor_layout": 1.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_TENSORCOREHALF__BatchSize_2__7136764562785026719<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:2/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:7/filter_width:7/pad_height:3/pad_width:3/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_TENSORCOREHALF__BatchSize_2__7136764562785026719<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:2/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:7/filter_width:7/pad_height:3/pad_width:3/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_TENSORCOREHALF__BatchSize_2__7136764562785026719<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:2/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:7/filter_width:7/pad_height:3/pad_width:3/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_TENSORCOREHALF__BatchSize_2__7136764562785026719<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:2/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:7/filter_width:7/pad_height:3/pad_width:3/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_TENSORCOREHALF__BatchSize_2__7136764562785026719<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:2/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:7/filter_width:7/pad_height:3/pad_width:3/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_TENSORCOREHALF__BatchSize_2__7136764562785026719<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:2/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:7/filter_width:7/pad_height:3/pad_width:3/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_TENSORCOREHALF__BatchSize_2__11957615293010273335<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:2/input[1]:256/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 1141,
      "real_time": 6.1118121021798591e+05,
      "cpu_time": 6.2234553637161944e+05,
      "time_unit": "ns",
      "items_per_second": 4.2033543522774979e+10,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 6.4716798067092896e-01,
      "batch_size": 2.0000000000000000e+00,
      "benchmark_file:/home/dakkak/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 7.5702145113912750e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.5012058362110720e+19,
      "compute_capability:7.5": 3.8315628306456499e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.5600000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:Quadro RTX 6000": 5.1174270964049613e+18,
      "group": 1.0000000000000000e+00,
      "host_name:aleph": 3.2334478980185999e+18,
      "input[0]": 2.0000000000000000e+00,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 2.0000000000000000e+00,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 1.0035200000000000e+05,
      "input_width": 1.4000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 2.5600000000000000e+02,
      "num_iterations": 1.1410000000000000e+03,
      "output_batch_size": 2.0000000000000000e+00,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 1.0035200000000000e+05,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "predicted_advised_flops": 3.7830189170497485e+11,
      "predicted_advised_flops_count": 2.3121100800000000e+08,
      "predicted_flops": 3.7830189170497485e+11,
      "predicted_flops_count": 2.3121100800000000e+08,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00,
      "x_tensor_layout": 1.0000000000000000e+00,
      "y_tensor_layout": 1.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_TENSORCOREHALF__BatchSize_2__11957615293010273335<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:2/input[1]:256/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 8544,
      "real_time": 8.2140726548568506e+04,
      "cpu_time": 8.8053517790266676e+04,
      "time_unit": "ns",
      "items_per_second": 3.1275730176077570e+11,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.1840000000000000e+03,
      "advised_time": 9.4655998051166534e-02,
      "batch_size": 2.0000000000000000e+00,
      "benchmark_file:/home/dakkak/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 7.5702145113912750e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.3877274157379230e+19,
      "compute_capability:7.5": 3.8315628306456499e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.5600000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:Quadro RTX 6000": 5.1174270964049613e+18,
      "group": 1.0000000000000000e+00,
      "host_name:aleph": 3.2334478980185999e+18,
      "input[0]": 2.0000000000000000e+00,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 2.0000000000000000e+00,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 1.0035200000000000e+05,
      "input_width": 1.4000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 2.5600000000000000e+02,
      "num_iterations": 8.5440000000000000e+03,
      "output_batch_size": 2.0000000000000000e+00,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 1.0035200000000000e+05,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "predicted_advised_flops": 2.8148157158469814e+12,
      "predicted_advised_flops_count": 2.3121100800000000e+08,
      "predicted_flops": 2.8148157158469814e+12,
      "predicted_flops_count": 2.3121100800000000e+08,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 1.0000000000000000e+00,
      "workspace_bytes": 1.1840000000000000e+03,
      "workspace_megabytes": 1.1291503906250000e-03,
      "x_tensor_layout": 1.0000000000000000e+00,
      "y_tensor_layout": 1.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_TENSORCOREHALF__BatchSize_2__11957615293010273335<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:2/input[1]:256/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_TENSORCOREHALF__BatchSize_2__11957615293010273335<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:2/input[1]:256/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_TENSORCOREHALF__BatchSize_2__11957615293010273335<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:2/input[1]:256/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_TENSORCOREHALF__BatchSize_2__11957615293010273335<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:2/input[1]:256/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_TENSORCOREHALF__BatchSize_2__11957615293010273335<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:2/input[1]:256/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_TENSORCOREHALF__BatchSize_2__11957615293010273335<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:2/input[1]:256/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_TENSORCOREHALF__BatchSize_2__14841668094294921171<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:2/input[1]:128/input[2]:28/input[3]:28/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 2983,
      "real_time": 2.3479997324506729e+05,
      "cpu_time": 2.4131765504525698e+05,
      "time_unit": "ns",
      "items_per_second": 1.0941275522713332e+11,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 2.3811200261116028e-01,
      "batch_size": 2.0000000000000000e+00,
      "benchmark_file:/home/dakkak/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 7.5702145113912750e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.5012058362110720e+19,
      "compute_capability:7.5": 3.8315628306456499e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:Quadro RTX 6000": 5.1174270964049613e+18,
      "group": 1.0000000000000000e+00,
      "host_name:aleph": 3.2334478980185999e+18,
      "input[0]": 2.0000000000000000e+00,
      "input[1]": 1.2800000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 2.0000000000000000e+00,
      "input_channels": 1.2800000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 2.0070400000000000e+05,
      "input_width": 2.8000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 2.9830000000000000e+03,
      "output_batch_size": 2.0000000000000000e+00,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 2.0070400000000000e+05,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "predicted_advised_flops": 9.8471479704419983e+11,
      "predicted_advised_flops_count": 2.3121100800000000e+08,
      "predicted_flops": 9.8471479704419983e+11,
      "predicted_flops_count": 2.3121100800000000e+08,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00,
      "x_tensor_layout": 1.0000000000000000e+00,
      "y_tensor_layout": 1.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_TENSORCOREHALF__BatchSize_2__14841668094294921171<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:2/input[1]:128/input[2]:28/input[3]:28/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 13570,
      "real_time": 5.1877472473260575e+04,
      "cpu_time": 5.7792252763364326e+04,
      "time_unit": "ns",
      "items_per_second": 4.9520747205333807e+11,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 4.7120000000000000e+03,
      "advised_time": 6.0991998761892319e-02,
      "batch_size": 2.0000000000000000e+00,
      "benchmark_file:/home/dakkak/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 7.5702145113912750e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.3877274157379230e+19,
      "compute_capability:7.5": 3.8315628306456499e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:Quadro RTX 6000": 5.1174270964049613e+18,
      "group": 1.0000000000000000e+00,
      "host_name:aleph": 3.2334478980185999e+18,
      "input[0]": 2.0000000000000000e+00,
      "input[1]": 1.2800000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 2.0000000000000000e+00,
      "input_channels": 1.2800000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 2.0070400000000000e+05,
      "input_width": 2.8000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 1.3570000000000000e+04,
      "output_batch_size": 2.0000000000000000e+00,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 2.0070400000000000e+05,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "predicted_advised_flops": 4.4568672484800430e+12,
      "predicted_advised_flops_count": 2.3121100800000000e+08,
      "predicted_flops": 4.4568672484800430e+12,
      "predicted_flops_count": 2.3121100800000000e+08,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 1.0000000000000000e+00,
      "workspace_bytes": 4.7120000000000000e+03,
      "workspace_megabytes": 4.4937133789062500e-03,
      "x_tensor_layout": 1.0000000000000000e+00,
      "y_tensor_layout": 1.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_TENSORCOREHALF__BatchSize_2__14841668094294921171<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:2/input[1]:128/input[2]:28/input[3]:28/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_TENSORCOREHALF__BatchSize_2__14841668094294921171<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:2/input[1]:128/input[2]:28/input[3]:28/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_TENSORCOREHALF__BatchSize_2__14841668094294921171<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:2/input[1]:128/input[2]:28/input[3]:28/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_TENSORCOREHALF__BatchSize_2__14841668094294921171<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:2/input[1]:128/input[2]:28/input[3]:28/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_TENSORCOREHALF__BatchSize_2__14841668094294921171<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:2/input[1]:128/input[2]:28/input[3]:28/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_TENSORCOREHALF__BatchSize_2__14841668094294921171<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:2/input[1]:128/input[2]:28/input[3]:28/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_TENSORCOREHALF__BatchSize_2__7974111828696901003<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:2/input[1]:512/input[2]:7/input[3]:7/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 582,
      "real_time": 1.2005326116883238e+06,
      "cpu_time": 1.2274511975950347e+06,
      "time_unit": "ns",
      "items_per_second": 2.1398928900291748e+10,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 1.2533760070800781e+00,
      "batch_size": 2.0000000000000000e+00,
      "benchmark_file:/home/dakkak/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 7.5702145113912750e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.5012058362110720e+19,
      "compute_capability:7.5": 3.8315628306456499e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:Quadro RTX 6000": 5.1174270964049613e+18,
      "group": 1.0000000000000000e+00,
      "host_name:aleph": 3.2334478980185999e+18,
      "input[0]": 2.0000000000000000e+00,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input_batch_size": 2.0000000000000000e+00,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 5.0176000000000000e+04,
      "input_width": 7.0000000000000000e+00,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 5.8200000000000000e+02,
      "output_batch_size": 2.0000000000000000e+00,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 5.0176000000000000e+04,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "predicted_advised_flops": 1.9259036010262573e+11,
      "predicted_advised_flops_count": 2.3121100800000000e+08,
      "predicted_flops": 1.9259036010262573e+11,
      "predicted_flops_count": 2.3121100800000000e+08,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00,
      "x_tensor_layout": 1.0000000000000000e+00,
      "y_tensor_layout": 1.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_TENSORCOREHALF__BatchSize_2__7974111828696901003<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:2/input[1]:512/input[2]:7/input[3]:7/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 5330,
      "real_time": 1.3152345243479277e+05,
      "cpu_time": 1.3767487166985174e+05,
      "time_unit": "ns",
      "items_per_second": 1.9532723270579251e+11,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 3.0000000000000000e+02,
      "advised_time": 1.4336000382900238e-01,
      "batch_size": 2.0000000000000000e+00,
      "benchmark_file:/home/dakkak/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 7.5702145113912750e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.3877274157379230e+19,
      "compute_capability:7.5": 3.8315628306456499e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:Quadro RTX 6000": 5.1174270964049613e+18,
      "group": 1.0000000000000000e+00,
      "host_name:aleph": 3.2334478980185999e+18,
      "input[0]": 2.0000000000000000e+00,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input_batch_size": 2.0000000000000000e+00,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 5.0176000000000000e+04,
      "input_width": 7.0000000000000000e+00,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 5.3300000000000000e+03,
      "output_batch_size": 2.0000000000000000e+00,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 5.0176000000000000e+04,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "predicted_advised_flops": 1.7579450943521326e+12,
      "predicted_advised_flops_count": 2.3121100800000000e+08,
      "predicted_flops": 1.7579450943521326e+12,
      "predicted_flops_count": 2.3121100800000000e+08,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 1.0000000000000000e+00,
      "workspace_bytes": 3.0000000000000000e+02,
      "workspace_megabytes": 2.8610229492187500e-04,
      "x_tensor_layout": 1.0000000000000000e+00,
      "y_tensor_layout": 1.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_TENSORCOREHALF__BatchSize_2__7974111828696901003<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:2/input[1]:512/input[2]:7/input[3]:7/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_TENSORCOREHALF__BatchSize_2__7974111828696901003<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:2/input[1]:512/input[2]:7/input[3]:7/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_TENSORCOREHALF__BatchSize_2__7974111828696901003<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:2/input[1]:512/input[2]:7/input[3]:7/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_TENSORCOREHALF__BatchSize_2__7974111828696901003<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:2/input[1]:512/input[2]:7/input[3]:7/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_TENSORCOREHALF__BatchSize_2__7974111828696901003<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:2/input[1]:512/input[2]:7/input[3]:7/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_TENSORCOREHALF__BatchSize_2__7974111828696901003<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:2/input[1]:512/input[2]:7/input[3]:7/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_TENSORCOREHALF__BatchSize_2__10291896158586816681<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:2/input[1]:2048/input[2]:7/input[3]:7/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 1253,
      "real_time": 5.5437218547439692e+05,
      "cpu_time": 5.6458425937736838e+05,
      "time_unit": "ns",
      "items_per_second": 1.8536364322114044e+11,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 5.8784002065658569e-01,
      "batch_size": 2.0000000000000000e+00,
      "benchmark_file:/home/dakkak/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 7.5702145113912750e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.5012058362110720e+19,
      "compute_capability:7.5": 3.8315628306456499e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Quadro RTX 6000": 5.1174270964049613e+18,
      "group": 1.0000000000000000e+00,
      "host_name:aleph": 3.2334478980185999e+18,
      "input[0]": 2.0000000000000000e+00,
      "input[1]": 2.0480000000000000e+03,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input_batch_size": 2.0000000000000000e+00,
      "input_channels": 2.0480000000000000e+03,
      "input_height": 7.0000000000000000e+00,
      "input_size": 2.0070400000000000e+05,
      "input_width": 7.0000000000000000e+00,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 1.2530000000000000e+03,
      "output_batch_size": 2.0000000000000000e+00,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 5.0176000000000000e+04,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 1.8536364322114044e+11,
      "predicted_advised_flops_count": 1.0276044800000000e+08,
      "predicted_flops": 1.8536364322114044e+11,
      "predicted_flops_count": 1.0276044800000000e+08,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00,
      "x_tensor_layout": 1.0000000000000000e+00,
      "y_tensor_layout": 1.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_TENSORCOREHALF__BatchSize_2__10291896158586816681<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:2/input[1]:2048/input[2]:7/input[3]:7/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 9924,
      "real_time": 7.0295484004168160e+04,
      "cpu_time": 7.6121836356375745e+04,
      "time_unit": "ns",
      "items_per_second": 1.4618356990600823e+12,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 3.0000000000000000e+02,
      "advised_time": 9.6032001078128815e-02,
      "batch_size": 2.0000000000000000e+00,
      "benchmark_file:/home/dakkak/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 7.5702145113912750e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.3877274157379230e+19,
      "compute_capability:7.5": 3.8315628306456499e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Quadro RTX 6000": 5.1174270964049613e+18,
      "group": 1.0000000000000000e+00,
      "host_name:aleph": 3.2334478980185999e+18,
      "input[0]": 2.0000000000000000e+00,
      "input[1]": 2.0480000000000000e+03,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input_batch_size": 2.0000000000000000e+00,
      "input_channels": 2.0480000000000000e+03,
      "input_height": 7.0000000000000000e+00,
      "input_size": 2.0070400000000000e+05,
      "input_width": 7.0000000000000000e+00,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 9.9240000000000000e+03,
      "output_batch_size": 2.0000000000000000e+00,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 5.0176000000000000e+04,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 1.4618356990600823e+12,
      "predicted_advised_flops_count": 1.0276044800000000e+08,
      "predicted_flops": 1.4618356990600823e+12,
      "predicted_flops_count": 1.0276044800000000e+08,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 1.0000000000000000e+00,
      "workspace_bytes": 3.0000000000000000e+02,
      "workspace_megabytes": 2.8610229492187500e-04,
      "x_tensor_layout": 1.0000000000000000e+00,
      "y_tensor_layout": 1.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_TENSORCOREHALF__BatchSize_2__10291896158586816681<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:2/input[1]:2048/input[2]:7/input[3]:7/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_TENSORCOREHALF__BatchSize_2__10291896158586816681<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:2/input[1]:2048/input[2]:7/input[3]:7/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_TENSORCOREHALF__BatchSize_2__10291896158586816681<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:2/input[1]:2048/input[2]:7/input[3]:7/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_TENSORCOREHALF__BatchSize_2__10291896158586816681<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:2/input[1]:2048/input[2]:7/input[3]:7/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_TENSORCOREHALF__BatchSize_2__10291896158586816681<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:2/input[1]:2048/input[2]:7/input[3]:7/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_1_TENSORCOREHALF__BatchSize_2__10291896158586816681<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:2/input[1]:2048/input[2]:7/input[3]:7/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_TENSORCOREHALF__BatchSize_2__1993613384533916958<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:2/input[1]:256/input[2]:56/input[3]:56/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 7376,
      "real_time": 9.4809279995909194e+04,
      "cpu_time": 1.0073545214204039e+05,
      "time_unit": "ns",
      "items_per_second": 8.6709189652687070e+12,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 9.6511997282505035e-02,
      "batch_size": 2.0000000000000000e+00,
      "benchmark_file:/home/dakkak/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 7.5702145113912750e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.5012058362110720e+19,
      "compute_capability:7.5": 3.8315628306456499e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Quadro RTX 6000": 5.1174270964049613e+18,
      "group": 1.0000000000000000e+00,
      "host_name:aleph": 3.2334478980185999e+18,
      "input[0]": 2.0000000000000000e+00,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 2.0000000000000000e+00,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 5.6000000000000000e+01,
      "input_size": 1.6056320000000000e+06,
      "input_width": 5.6000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 7.3760000000000000e+03,
      "output_batch_size": 2.0000000000000000e+00,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 8.0281600000000000e+05,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 2.1677297413171768e+12,
      "predicted_advised_flops_count": 2.0552089600000000e+08,
      "predicted_flops": 2.1677297413171768e+12,
      "predicted_flops_count": 2.0552089600000000e+08,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "w_filter_layout": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00,
      "x_tensor_layout": 1.0000000000000000e+00,
      "y_tensor_layout": 1.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_TENSORCOREHALF__BatchSize_2__1993613384533916958<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:2/input[1]:256/input[2]:56/input[3]:56/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 22889,
      "real_time": 3.0655882537098656e+04,
      "cpu_time": 3.6530966708856002e+04,
      "time_unit": "ns",
      "items_per_second": 2.6816503586388148e+13,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 4.7120000000000000e+03,
      "advised_time": 3.5808000713586807e-02,
      "batch_size": 2.0000000000000000e+00,
      "benchmark_file:/home/dakkak/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 7.5702145113912750e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.3877274157379230e+19,
      "compute_capability:7.5": 3.8315628306456499e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Quadro RTX 6000": 5.1174270964049613e+18,
      "group": 1.0000000000000000e+00,
      "host_name:aleph": 3.2334478980185999e+18,
      "input[0]": 2.0000000000000000e+00,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 2.0000000000000000e+00,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 5.6000000000000000e+01,
      "input_size": 1.6056320000000000e+06,
      "input_width": 5.6000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 2.2889000000000000e+04,
      "output_batch_size": 2.0000000000000000e+00,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 8.0281600000000000e+05,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 6.7041258965970371e+12,
      "predicted_advised_flops_count": 2.0552089600000000e+08,
      "predicted_flops": 6.7041258965970371e+12,
      "predicted_flops_count": 2.0552089600000000e+08,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "w_filter_layout": 1.0000000000000000e+00,
      "workspace_bytes": 4.7120000000000000e+03,
      "workspace_megabytes": 4.4937133789062500e-03,
      "x_tensor_layout": 1.0000000000000000e+00,
      "y_tensor_layout": 1.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_TENSORCOREHALF__BatchSize_2__1993613384533916958<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:2/input[1]:256/input[2]:56/input[3]:56/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_TENSORCOREHALF__BatchSize_2__1993613384533916958<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:2/input[1]:256/input[2]:56/input[3]:56/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_TENSORCOREHALF__BatchSize_2__1993613384533916958<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:2/input[1]:256/input[2]:56/input[3]:56/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_TENSORCOREHALF__BatchSize_2__1993613384533916958<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:2/input[1]:256/input[2]:56/input[3]:56/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_TENSORCOREHALF__BatchSize_2__1993613384533916958<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:2/input[1]:256/input[2]:56/input[3]:56/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_TENSORCOREHALF__BatchSize_2__1993613384533916958<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:2/input[1]:256/input[2]:56/input[3]:56/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_TENSORCOREHALF__BatchSize_2__104228237670797297<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:2/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 2457,
      "real_time": 2.8452383756618999e+05,
      "cpu_time": 2.9147313797309756e+05,
      "time_unit": "ns",
      "items_per_second": 7.2233278504191687e+11,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 2.9872000217437744e-01,
      "batch_size": 2.0000000000000000e+00,
      "benchmark_file:/home/dakkak/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 7.5702145113912750e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.5012058362110720e+19,
      "compute_capability:7.5": 3.8315628306456499e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Quadro RTX 6000": 5.1174270964049613e+18,
      "group": 1.0000000000000000e+00,
      "host_name:aleph": 3.2334478980185999e+18,
      "input[0]": 2.0000000000000000e+00,
      "input[1]": 1.0240000000000000e+03,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 2.0000000000000000e+00,
      "input_channels": 1.0240000000000000e+03,
      "input_height": 1.4000000000000000e+01,
      "input_size": 4.0140800000000000e+05,
      "input_width": 1.4000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 2.4570000000000000e+03,
      "output_batch_size": 2.0000000000000000e+00,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 5.0176000000000000e+04,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 1.8058319626047922e+11,
      "predicted_advised_flops_count": 5.1380224000000000e+07,
      "predicted_flops": 1.8058319626047922e+11,
      "predicted_flops_count": 5.1380224000000000e+07,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "w_filter_layout": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00,
      "x_tensor_layout": 1.0000000000000000e+00,
      "y_tensor_layout": 1.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_TENSORCOREHALF__BatchSize_2__104228237670797297<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:2/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 15521,
      "real_time": 4.4954897097589237e+04,
      "cpu_time": 5.0730935120175665e+04,
      "time_unit": "ns",
      "items_per_second": 4.5717131896409414e+12,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 3.0000000000000000e+02,
      "advised_time": 7.1263998746871948e-02,
      "batch_size": 2.0000000000000000e+00,
      "benchmark_file:/home/dakkak/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 7.5702145113912750e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.3877274157379230e+19,
      "compute_capability:7.5": 3.8315628306456499e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Quadro RTX 6000": 5.1174270964049613e+18,
      "group": 1.0000000000000000e+00,
      "host_name:aleph": 3.2334478980185999e+18,
      "input[0]": 2.0000000000000000e+00,
      "input[1]": 1.0240000000000000e+03,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 2.0000000000000000e+00,
      "input_channels": 1.0240000000000000e+03,
      "input_height": 1.4000000000000000e+01,
      "input_size": 4.0140800000000000e+05,
      "input_width": 1.4000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 1.5521000000000000e+04,
      "output_batch_size": 2.0000000000000000e+00,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 5.0176000000000000e+04,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 1.1429282974102354e+12,
      "predicted_advised_flops_count": 5.1380224000000000e+07,
      "predicted_flops": 1.1429282974102354e+12,
      "predicted_flops_count": 5.1380224000000000e+07,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "w_filter_layout": 1.0000000000000000e+00,
      "workspace_bytes": 3.0000000000000000e+02,
      "workspace_megabytes": 2.8610229492187500e-04,
      "x_tensor_layout": 1.0000000000000000e+00,
      "y_tensor_layout": 1.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_TENSORCOREHALF__BatchSize_2__104228237670797297<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:2/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_TENSORCOREHALF__BatchSize_2__104228237670797297<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:2/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_TENSORCOREHALF__BatchSize_2__104228237670797297<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:2/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_TENSORCOREHALF__BatchSize_2__104228237670797297<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:2/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_TENSORCOREHALF__BatchSize_2__104228237670797297<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:2/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_TENSORCOREHALF__BatchSize_2__104228237670797297<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:2/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_TENSORCOREHALF__BatchSize_2__18371337818687497974<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:2/input[1]:128/input[2]:28/input[3]:28/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 12019,
      "real_time": 5.7728663139401076e+04,
      "cpu_time": 6.3485632914537528e+04,
      "time_unit": "ns",
      "items_per_second": 1.7800593745234980e+12,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 6.1087999492883682e-02,
      "batch_size": 2.0000000000000000e+00,
      "benchmark_file:/home/dakkak/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 7.5702145113912750e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.5012058362110720e+19,
      "compute_capability:7.5": 3.8315628306456499e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Quadro RTX 6000": 5.1174270964049613e+18,
      "group": 1.0000000000000000e+00,
      "host_name:aleph": 3.2334478980185999e+18,
      "input[0]": 2.0000000000000000e+00,
      "input[1]": 1.2800000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 2.0000000000000000e+00,
      "input_channels": 1.2800000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 2.0070400000000000e+05,
      "input_width": 2.8000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 1.2019000000000000e+04,
      "output_batch_size": 2.0000000000000000e+00,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 8.0281600000000000e+05,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 1.7800593745234980e+12,
      "predicted_advised_flops_count": 1.0276044800000000e+08,
      "predicted_flops": 1.7800593745234980e+12,
      "predicted_flops_count": 1.0276044800000000e+08,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00,
      "x_tensor_layout": 1.0000000000000000e+00,
      "y_tensor_layout": 1.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_TENSORCOREHALF__BatchSize_2__18371337818687497974<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:2/input[1]:128/input[2]:28/input[3]:28/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 26935,
      "real_time": 2.5866287278740318e+04,
      "cpu_time": 3.1743768145557780e+04,
      "time_unit": "ns",
      "items_per_second": 3.9727560006054497e+12,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 4.7120000000000000e+03,
      "advised_time": 3.1039999797940254e-02,
      "batch_size": 2.0000000000000000e+00,
      "benchmark_file:/home/dakkak/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 7.5702145113912750e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.3877274157379230e+19,
      "compute_capability:7.5": 3.8315628306456499e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Quadro RTX 6000": 5.1174270964049613e+18,
      "group": 1.0000000000000000e+00,
      "host_name:aleph": 3.2334478980185999e+18,
      "input[0]": 2.0000000000000000e+00,
      "input[1]": 1.2800000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 2.0000000000000000e+00,
      "input_channels": 1.2800000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 2.0070400000000000e+05,
      "input_width": 2.8000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 2.6935000000000000e+04,
      "output_batch_size": 2.0000000000000000e+00,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 8.0281600000000000e+05,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 3.9727560006054497e+12,
      "predicted_advised_flops_count": 1.0276044800000000e+08,
      "predicted_flops": 3.9727560006054497e+12,
      "predicted_flops_count": 1.0276044800000000e+08,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 1.0000000000000000e+00,
      "workspace_bytes": 4.7120000000000000e+03,
      "workspace_megabytes": 4.4937133789062500e-03,
      "x_tensor_layout": 1.0000000000000000e+00,
      "y_tensor_layout": 1.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_TENSORCOREHALF__BatchSize_2__18371337818687497974<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:2/input[1]:128/input[2]:28/input[3]:28/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_TENSORCOREHALF__BatchSize_2__18371337818687497974<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:2/input[1]:128/input[2]:28/input[3]:28/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_TENSORCOREHALF__BatchSize_2__18371337818687497974<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:2/input[1]:128/input[2]:28/input[3]:28/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_TENSORCOREHALF__BatchSize_2__18371337818687497974<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:2/input[1]:128/input[2]:28/input[3]:28/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_TENSORCOREHALF__BatchSize_2__18371337818687497974<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:2/input[1]:128/input[2]:28/input[3]:28/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_TENSORCOREHALF__BatchSize_2__18371337818687497974<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:2/input[1]:128/input[2]:28/input[3]:28/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_TENSORCOREHALF__BatchSize_2__13074516066256786069<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:2/input[1]:512/input[2]:28/input[3]:28/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 4695,
      "real_time": 1.4834126688914892e+05,
      "cpu_time": 1.5443641512249381e+05,
      "time_unit": "ns",
      "items_per_second": 5.5418401179917051e+12,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 1.5155200660228729e-01,
      "batch_size": 2.0000000000000000e+00,
      "benchmark_file:/home/dakkak/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 7.5702145113912750e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.5012058362110720e+19,
      "compute_capability:7.5": 3.8315628306456499e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.0240000000000000e+03,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Quadro RTX 6000": 5.1174270964049613e+18,
      "group": 1.0000000000000000e+00,
      "host_name:aleph": 3.2334478980185999e+18,
      "input[0]": 2.0000000000000000e+00,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 2.0000000000000000e+00,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 8.0281600000000000e+05,
      "input_width": 2.8000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 1.0240000000000000e+03,
      "num_iterations": 4.6950000000000000e+03,
      "output_batch_size": 2.0000000000000000e+00,
      "output_channels": 1.0240000000000000e+03,
      "output_height": 1.4000000000000000e+01,
      "output_size": 4.0140800000000000e+05,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 1.3854600294979263e+12,
      "predicted_advised_flops_count": 2.0552089600000000e+08,
      "predicted_flops": 1.3854600294979263e+12,
      "predicted_flops_count": 2.0552089600000000e+08,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "w_filter_layout": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00,
      "x_tensor_layout": 1.0000000000000000e+00,
      "y_tensor_layout": 1.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_TENSORCOREHALF__BatchSize_2__13074516066256786069<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:2/input[1]:512/input[2]:28/input[3]:28/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 19686,
      "real_time": 3.5406375922853840e+04,
      "cpu_time": 4.1024218175381458e+04,
      "time_unit": "ns",
      "items_per_second": 2.3218518206755176e+13,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.1840000000000000e+03,
      "advised_time": 4.0863998234272003e-02,
      "batch_size": 2.0000000000000000e+00,
      "benchmark_file:/home/dakkak/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 7.5702145113912750e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.3877274157379230e+19,
      "compute_capability:7.5": 3.8315628306456499e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.0240000000000000e+03,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Quadro RTX 6000": 5.1174270964049613e+18,
      "group": 1.0000000000000000e+00,
      "host_name:aleph": 3.2334478980185999e+18,
      "input[0]": 2.0000000000000000e+00,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 2.0000000000000000e+00,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 8.0281600000000000e+05,
      "input_width": 2.8000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 1.0240000000000000e+03,
      "num_iterations": 1.9686000000000000e+04,
      "output_batch_size": 2.0000000000000000e+00,
      "output_channels": 1.0240000000000000e+03,
      "output_height": 1.4000000000000000e+01,
      "output_size": 4.0140800000000000e+05,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 5.8046295516887939e+12,
      "predicted_advised_flops_count": 2.0552089600000000e+08,
      "predicted_flops": 5.8046295516887939e+12,
      "predicted_flops_count": 2.0552089600000000e+08,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "w_filter_layout": 1.0000000000000000e+00,
      "workspace_bytes": 1.1840000000000000e+03,
      "workspace_megabytes": 1.1291503906250000e-03,
      "x_tensor_layout": 1.0000000000000000e+00,
      "y_tensor_layout": 1.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_TENSORCOREHALF__BatchSize_2__13074516066256786069<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:2/input[1]:512/input[2]:28/input[3]:28/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_TENSORCOREHALF__BatchSize_2__13074516066256786069<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:2/input[1]:512/input[2]:28/input[3]:28/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_TENSORCOREHALF__BatchSize_2__13074516066256786069<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:2/input[1]:512/input[2]:28/input[3]:28/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_TENSORCOREHALF__BatchSize_2__13074516066256786069<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:2/input[1]:512/input[2]:28/input[3]:28/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_TENSORCOREHALF__BatchSize_2__13074516066256786069<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:2/input[1]:512/input[2]:28/input[3]:28/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_2_TENSORCOREHALF__BatchSize_2__13074516066256786069<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:2/input[1]:512/input[2]:28/input[3]:28/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_TENSORCOREHALF__BatchSize_2__16087794718906805034<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:2/input[1]:256/input[2]:14/input[3]:14/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 8568,
      "real_time": 8.1431133695645738e+04,
      "cpu_time": 8.7334176470563456e+04,
      "time_unit": "ns",
      "items_per_second": 1.2619307055710901e+12,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 8.5887998342514038e-02,
      "batch_size": 2.0000000000000000e+00,
      "benchmark_file:/home/dakkak/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 7.5702145113912750e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.5012058362110720e+19,
      "compute_capability:7.5": 3.8315628306456499e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.0240000000000000e+03,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Quadro RTX 6000": 5.1174270964049613e+18,
      "group": 1.0000000000000000e+00,
      "host_name:aleph": 3.2334478980185999e+18,
      "input[0]": 2.0000000000000000e+00,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 2.0000000000000000e+00,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 1.0035200000000000e+05,
      "input_width": 1.4000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 1.0240000000000000e+03,
      "num_iterations": 8.5680000000000000e+03,
      "output_batch_size": 2.0000000000000000e+00,
      "output_channels": 1.0240000000000000e+03,
      "output_height": 1.4000000000000000e+01,
      "output_size": 4.0140800000000000e+05,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 1.2619307055710901e+12,
      "predicted_advised_flops_count": 1.0276044800000000e+08,
      "predicted_flops": 1.2619307055710901e+12,
      "predicted_flops_count": 1.0276044800000000e+08,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00,
      "x_tensor_layout": 1.0000000000000000e+00,
      "y_tensor_layout": 1.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_TENSORCOREHALF__BatchSize_2__16087794718906805034<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:2/input[1]:256/input[2]:14/input[3]:14/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 24997,
      "real_time": 2.8260083679918313e+04,
      "cpu_time": 3.4075164899796815e+04,
      "time_unit": "ns",
      "items_per_second": 3.6362400466995723e+12,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.1840000000000000e+03,
      "advised_time": 3.3023998141288757e-02,
      "batch_size": 2.0000000000000000e+00,
      "benchmark_file:/home/dakkak/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 7.5702145113912750e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.3877274157379230e+19,
      "compute_capability:7.5": 3.8315628306456499e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.0240000000000000e+03,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Quadro RTX 6000": 5.1174270964049613e+18,
      "group": 1.0000000000000000e+00,
      "host_name:aleph": 3.2334478980185999e+18,
      "input[0]": 2.0000000000000000e+00,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 2.0000000000000000e+00,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 1.0035200000000000e+05,
      "input_width": 1.4000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 1.0240000000000000e+03,
      "num_iterations": 2.4997000000000000e+04,
      "output_batch_size": 2.0000000000000000e+00,
      "output_channels": 1.0240000000000000e+03,
      "output_height": 1.4000000000000000e+01,
      "output_size": 4.0140800000000000e+05,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 3.6362400466995723e+12,
      "predicted_advised_flops_count": 1.0276044800000000e+08,
      "predicted_flops": 3.6362400466995723e+12,
      "predicted_flops_count": 1.0276044800000000e+08,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 1.0000000000000000e+00,
      "workspace_bytes": 1.1840000000000000e+03,
      "workspace_megabytes": 1.1291503906250000e-03,
      "x_tensor_layout": 1.0000000000000000e+00,
      "y_tensor_layout": 1.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_TENSORCOREHALF__BatchSize_2__16087794718906805034<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:2/input[1]:256/input[2]:14/input[3]:14/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_TENSORCOREHALF__BatchSize_2__16087794718906805034<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:2/input[1]:256/input[2]:14/input[3]:14/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_TENSORCOREHALF__BatchSize_2__16087794718906805034<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:2/input[1]:256/input[2]:14/input[3]:14/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_TENSORCOREHALF__BatchSize_2__16087794718906805034<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:2/input[1]:256/input[2]:14/input[3]:14/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_TENSORCOREHALF__BatchSize_2__16087794718906805034<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:2/input[1]:256/input[2]:14/input[3]:14/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_3_TENSORCOREHALF__BatchSize_2__16087794718906805034<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:2/input[1]:256/input[2]:14/input[3]:14/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_TENSORCOREHALF__BatchSize_2__2046605619055912169<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:2/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 19264,
      "real_time": 3.6430900591243328e+04,
      "cpu_time": 4.2222446272856272e+04,
      "time_unit": "ns",
      "items_per_second": 7.0517367353183081e+11,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 4.0543999522924423e-02,
      "batch_size": 2.0000000000000000e+00,
      "benchmark_file:/home/dakkak/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 7.5702145113912750e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.5012058362110720e+19,
      "compute_capability:7.5": 3.8315628306456499e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Quadro RTX 6000": 5.1174270964049613e+18,
      "group": 1.0000000000000000e+00,
      "host_name:aleph": 3.2334478980185999e+18,
      "input[0]": 2.0000000000000000e+00,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 2.0000000000000000e+00,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 4.0140800000000000e+05,
      "input_width": 5.6000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 1.9264000000000000e+04,
      "output_batch_size": 2.0000000000000000e+00,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 5.6000000000000000e+01,
      "output_size": 4.0140800000000000e+05,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 7.0517367353183081e+11,
      "predicted_advised_flops_count": 2.5690112000000000e+07,
      "predicted_flops": 7.0517367353183081e+11,
      "predicted_flops_count": 2.5690112000000000e+07,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00,
      "x_tensor_layout": 1.0000000000000000e+00,
      "y_tensor_layout": 1.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_TENSORCOREHALF__BatchSize_2__2046605619055912169<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:2/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 32158,
      "real_time": 2.1988967444505437e+04,
      "cpu_time": 2.7533036413962076e+04,
      "time_unit": "ns",
      "items_per_second": 1.1683182516339302e+12,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.8824000000000000e+04,
      "advised_time": 2.6559999212622643e-02,
      "batch_size": 2.0000000000000000e+00,
      "benchmark_file:/home/dakkak/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 7.5702145113912750e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.3877274157379230e+19,
      "compute_capability:7.5": 3.8315628306456499e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Quadro RTX 6000": 5.1174270964049613e+18,
      "group": 1.0000000000000000e+00,
      "host_name:aleph": 3.2334478980185999e+18,
      "input[0]": 2.0000000000000000e+00,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 2.0000000000000000e+00,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 4.0140800000000000e+05,
      "input_width": 5.6000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 3.2158000000000000e+04,
      "output_batch_size": 2.0000000000000000e+00,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 5.6000000000000000e+01,
      "output_size": 4.0140800000000000e+05,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 1.1683182516339302e+12,
      "predicted_advised_flops_count": 2.5690112000000000e+07,
      "predicted_flops": 1.1683182516339302e+12,
      "predicted_flops_count": 2.5690112000000000e+07,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 1.0000000000000000e+00,
      "workspace_bytes": 1.8824000000000000e+04,
      "workspace_megabytes": 1.7951965332031250e-02,
      "x_tensor_layout": 1.0000000000000000e+00,
      "y_tensor_layout": 1.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_TENSORCOREHALF__BatchSize_2__2046605619055912169<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:2/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_TENSORCOREHALF__BatchSize_2__2046605619055912169<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:2/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_TENSORCOREHALF__BatchSize_2__2046605619055912169<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:2/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_TENSORCOREHALF__BatchSize_2__2046605619055912169<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:2/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_TENSORCOREHALF__BatchSize_2__2046605619055912169<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:2/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_TENSORCOREHALF__BatchSize_2__2046605619055912169<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:2/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_TENSORCOREHALF__BatchSize_2__10738509053033655624<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:2/input[1]:256/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 6312,
      "real_time": 1.1052224596970485e+05,
      "cpu_time": 1.1648592664762413e+05,
      "time_unit": "ns",
      "items_per_second": 9.2977162288366431e+11,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 1.1638399958610535e-01,
      "batch_size": 2.0000000000000000e+00,
      "benchmark_file:/home/dakkak/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 7.5702145113912750e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.5012058362110720e+19,
      "compute_capability:7.5": 3.8315628306456499e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Quadro RTX 6000": 5.1174270964049613e+18,
      "group": 1.0000000000000000e+00,
      "host_name:aleph": 3.2334478980185999e+18,
      "input[0]": 2.0000000000000000e+00,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 2.0000000000000000e+00,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 5.6000000000000000e+01,
      "input_size": 1.6056320000000000e+06,
      "input_width": 5.6000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 6.3120000000000000e+03,
      "output_batch_size": 2.0000000000000000e+00,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 5.6000000000000000e+01,
      "output_size": 4.0140800000000000e+05,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 9.2977162288366431e+11,
      "predicted_advised_flops_count": 1.0276044800000000e+08,
      "predicted_flops": 9.2977162288366431e+11,
      "predicted_flops_count": 1.0276044800000000e+08,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00,
      "x_tensor_layout": 1.0000000000000000e+00,
      "y_tensor_layout": 1.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_TENSORCOREHALF__BatchSize_2__10738509053033655624<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:2/input[1]:256/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 23620,
      "real_time": 2.9925415112577986e+04,
      "cpu_time": 3.5772565156627265e+04,
      "time_unit": "ns",
      "items_per_second": 3.4338854653618032e+12,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.8824000000000000e+04,
      "advised_time": 3.6031998693943024e-02,
      "batch_size": 2.0000000000000000e+00,
      "benchmark_file:/home/dakkak/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 7.5702145113912750e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.3877274157379230e+19,
      "compute_capability:7.5": 3.8315628306456499e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Quadro RTX 6000": 5.1174270964049613e+18,
      "group": 1.0000000000000000e+00,
      "host_name:aleph": 3.2334478980185999e+18,
      "input[0]": 2.0000000000000000e+00,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 2.0000000000000000e+00,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 5.6000000000000000e+01,
      "input_size": 1.6056320000000000e+06,
      "input_width": 5.6000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 2.3620000000000000e+04,
      "output_batch_size": 2.0000000000000000e+00,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 5.6000000000000000e+01,
      "output_size": 4.0140800000000000e+05,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 3.4338854653618032e+12,
      "predicted_advised_flops_count": 1.0276044800000000e+08,
      "predicted_flops": 3.4338854653618032e+12,
      "predicted_flops_count": 1.0276044800000000e+08,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 1.0000000000000000e+00,
      "workspace_bytes": 1.8824000000000000e+04,
      "workspace_megabytes": 1.7951965332031250e-02,
      "x_tensor_layout": 1.0000000000000000e+00,
      "y_tensor_layout": 1.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_TENSORCOREHALF__BatchSize_2__10738509053033655624<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:2/input[1]:256/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_TENSORCOREHALF__BatchSize_2__10738509053033655624<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:2/input[1]:256/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_TENSORCOREHALF__BatchSize_2__10738509053033655624<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:2/input[1]:256/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_TENSORCOREHALF__BatchSize_2__10738509053033655624<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:2/input[1]:256/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_TENSORCOREHALF__BatchSize_2__10738509053033655624<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:2/input[1]:256/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_TENSORCOREHALF__BatchSize_2__10738509053033655624<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:2/input[1]:256/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_TENSORCOREHALF__BatchSize_2__11360564034770670530<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:2/input[1]:1024/input[2]:14/input[3]:14/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 2477,
      "real_time": 2.8198429833207285e+05,
      "cpu_time": 2.8890903431555122e+05,
      "time_unit": "ns",
      "items_per_second": 3.6441904250635376e+11,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 2.9491201043128967e-01,
      "batch_size": 2.0000000000000000e+00,
      "benchmark_file:/home/dakkak/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 7.5702145113912750e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.5012058362110720e+19,
      "compute_capability:7.5": 3.8315628306456499e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.5600000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Quadro RTX 6000": 5.1174270964049613e+18,
      "group": 1.0000000000000000e+00,
      "host_name:aleph": 3.2334478980185999e+18,
      "input[0]": 2.0000000000000000e+00,
      "input[1]": 1.0240000000000000e+03,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 2.0000000000000000e+00,
      "input_channels": 1.0240000000000000e+03,
      "input_height": 1.4000000000000000e+01,
      "input_size": 4.0140800000000000e+05,
      "input_width": 1.4000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 2.5600000000000000e+02,
      "num_iterations": 2.4770000000000000e+03,
      "output_batch_size": 2.0000000000000000e+00,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 1.0035200000000000e+05,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 3.6441904250635376e+11,
      "predicted_advised_flops_count": 1.0276044800000000e+08,
      "predicted_flops": 3.6441904250635376e+11,
      "predicted_flops_count": 1.0276044800000000e+08,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00,
      "x_tensor_layout": 1.0000000000000000e+00,
      "y_tensor_layout": 1.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_TENSORCOREHALF__BatchSize_2__11360564034770670530<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:2/input[1]:1024/input[2]:14/input[3]:14/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 14129,
      "real_time": 4.9465321121644403e+04,
      "cpu_time": 5.5223865807842638e+04,
      "time_unit": "ns",
      "items_per_second": 2.0774240552748660e+12,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.1840000000000000e+03,
      "advised_time": 7.5584001839160919e-02,
      "batch_size": 2.0000000000000000e+00,
      "benchmark_file:/home/dakkak/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 7.5702145113912750e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.3877274157379230e+19,
      "compute_capability:7.5": 3.8315628306456499e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.5600000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Quadro RTX 6000": 5.1174270964049613e+18,
      "group": 1.0000000000000000e+00,
      "host_name:aleph": 3.2334478980185999e+18,
      "input[0]": 2.0000000000000000e+00,
      "input[1]": 1.0240000000000000e+03,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 2.0000000000000000e+00,
      "input_channels": 1.0240000000000000e+03,
      "input_height": 1.4000000000000000e+01,
      "input_size": 4.0140800000000000e+05,
      "input_width": 1.4000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 2.5600000000000000e+02,
      "num_iterations": 1.4129000000000000e+04,
      "output_batch_size": 2.0000000000000000e+00,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 1.0035200000000000e+05,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 2.0774240552748660e+12,
      "predicted_advised_flops_count": 1.0276044800000000e+08,
      "predicted_flops": 2.0774240552748660e+12,
      "predicted_flops_count": 1.0276044800000000e+08,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 1.0000000000000000e+00,
      "workspace_bytes": 1.1840000000000000e+03,
      "workspace_megabytes": 1.1291503906250000e-03,
      "x_tensor_layout": 1.0000000000000000e+00,
      "y_tensor_layout": 1.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_TENSORCOREHALF__BatchSize_2__11360564034770670530<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:2/input[1]:1024/input[2]:14/input[3]:14/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_TENSORCOREHALF__BatchSize_2__11360564034770670530<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:2/input[1]:1024/input[2]:14/input[3]:14/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_TENSORCOREHALF__BatchSize_2__11360564034770670530<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:2/input[1]:1024/input[2]:14/input[3]:14/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_TENSORCOREHALF__BatchSize_2__11360564034770670530<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:2/input[1]:1024/input[2]:14/input[3]:14/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_TENSORCOREHALF__BatchSize_2__11360564034770670530<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:2/input[1]:1024/input[2]:14/input[3]:14/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_TENSORCOREHALF__BatchSize_2__11360564034770670530<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:2/input[1]:1024/input[2]:14/input[3]:14/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_TENSORCOREHALF__BatchSize_2__10461844402551109891<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM>/input[0]:2/input[1]:512/input[2]:7/input[3]:7/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 4674,
      "real_time": 1.4871504426104721e+05,
      "cpu_time": 1.5485527000432197e+05,
      "time_unit": "ns",
      "items_per_second": 6.9098892119898291e+11,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 1.5119999647140503e-01,
      "batch_size": 2.0000000000000000e+00,
      "benchmark_file:/home/dakkak/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 7.5702145113912750e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.5012058362110720e+19,
      "compute_capability:7.5": 3.8315628306456499e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.0480000000000000e+03,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Quadro RTX 6000": 5.1174270964049613e+18,
      "group": 1.0000000000000000e+00,
      "host_name:aleph": 3.2334478980185999e+18,
      "input[0]": 2.0000000000000000e+00,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input_batch_size": 2.0000000000000000e+00,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 5.0176000000000000e+04,
      "input_width": 7.0000000000000000e+00,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 2.0480000000000000e+03,
      "num_iterations": 4.6740000000000000e+03,
      "output_batch_size": 2.0000000000000000e+00,
      "output_channels": 2.0480000000000000e+03,
      "output_height": 7.0000000000000000e+00,
      "output_size": 2.0070400000000000e+05,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 6.9098892119898291e+11,
      "predicted_advised_flops_count": 1.0276044800000000e+08,
      "predicted_flops": 6.9098892119898291e+11,
      "predicted_flops_count": 1.0276044800000000e+08,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00,
      "x_tensor_layout": 1.0000000000000000e+00,
      "y_tensor_layout": 1.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_TENSORCOREHALF__BatchSize_2__10461844402551109891<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM>/input[0]:2/input[1]:512/input[2]:7/input[3]:7/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "iterations": 21407,
      "real_time": 3.2751907936537576e+04,
      "cpu_time": 3.8655611482207329e+04,
      "time_unit": "ns",
      "items_per_second": 3.1375408174423286e+12,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 3.0000000000000000e+02,
      "advised_time": 3.8911998271942139e-02,
      "batch_size": 2.0000000000000000e+00,
      "benchmark_file:/home/dakkak/scope/scopes/cudnn_scope/src/cudnn_conv_fwd.inc": 7.5702145113912750e+18,
      "benchmark_func:void iLAYER_CUDNN_CONV_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.3877274157379230e+19,
      "compute_capability:7.5": 3.8315628306456499e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 1.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_FWD_Impl": 7.6772958670751939e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.0480000000000000e+03,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Quadro RTX 6000": 5.1174270964049613e+18,
      "group": 1.0000000000000000e+00,
      "host_name:aleph": 3.2334478980185999e+18,
      "input[0]": 2.0000000000000000e+00,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input_batch_size": 2.0000000000000000e+00,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 5.0176000000000000e+04,
      "input_width": 7.0000000000000000e+00,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 2.0480000000000000e+03,
      "num_iterations": 2.1407000000000000e+04,
      "output_batch_size": 2.0000000000000000e+00,
      "output_channels": 2.0480000000000000e+03,
      "output_height": 7.0000000000000000e+00,
      "output_size": 2.0070400000000000e+05,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "predicted_advised_flops": 3.1375408174423286e+12,
      "predicted_advised_flops_count": 1.0276044800000000e+08,
      "predicted_flops": 3.1375408174423286e+12,
      "predicted_flops_count": 1.0276044800000000e+08,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 1.0000000000000000e+00,
      "workspace_bytes": 3.0000000000000000e+02,
      "workspace_megabytes": 2.8610229492187500e-04,
      "x_tensor_layout": 1.0000000000000000e+00,
      "y_tensor_layout": 1.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_TENSORCOREHALF__BatchSize_2__10461844402551109891<CUDNN_CONVOLUTION_FWD_ALGO_GEMM>/input[0]:2/input[1]:512/input[2]:7/input[3]:7/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_TENSORCOREHALF__BatchSize_2__10461844402551109891<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT>/input[0]:2/input[1]:512/input[2]:7/input[3]:7/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_TENSORCOREHALF__BatchSize_2__10461844402551109891<CUDNN_CONVOLUTION_FWD_ALGO_FFT>/input[0]:2/input[1]:512/input[2]:7/input[3]:7/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_TENSORCOREHALF__BatchSize_2__10461844402551109891<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING>/input[0]:2/input[1]:512/input[2]:7/input[3]:7/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_TENSORCOREHALF__BatchSize_2__10461844402551109891<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD>/input[0]:2/input[1]:512/input[2]:7/input[3]:7/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_FWD_4_TENSORCOREHALF__BatchSize_2__10461844402551109891<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED>/input[0]:2/input[1]:512/input[2]:7/input[3]:7/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:1/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_ADD_FWD_TENSORCOREHALF__BatchSize_2__17895129860916377009/input[0]:2/input[1]:256/input[2]:56/input[3]:56/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:2/manual_time",
      "iterations": 22034,
      "real_time": 3.1980280550791471e+04,
      "cpu_time": 3.7954803213218896e+04,
      "time_unit": "ns",
      "items_per_second": 5.0206939162085075e+10,
      "alpha": 5.9604644775390625e-08,
      "batch_size": 2.0000000000000000e+00,
      "benchmark_file:/home/dakkak/scope/scopes/cudnn_scope/src/cudnn_op_tensor.cpp": 1.3651308370281311e+18,
      "benchmark_func:void iLAYER_CUDNN_OP_TENSOR_Impl(benchmark::State&) [with T = __half; cudnnOpTensorOp_t op_type = (cudnnOpTensorOp_t)0]": 1.5887120378050222e+19,
      "beta": 0.0000000000000000e+00,
      "compute_capability:7.5": 3.8315628306456499e+18,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_OP_TENSOR_Impl": 3.0075642356307840e+18,
      "gpu_name:Quadro RTX 6000": 5.1174270964049613e+18,
      "host_name:aleph": 3.2334478980185999e+18,
      "input[0]": 2.0000000000000000e+00,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_a_tensor_layout": 0.0000000000000000e+00,
      "input_b_tensor_layout": 0.0000000000000000e+00,
      "input_c": 2.5600000000000000e+02,
      "input_h": 5.6000000000000000e+01,
      "input_n": 2.0000000000000000e+00,
      "input_size": 1.6056320000000000e+06,
      "input_w": 5.6000000000000000e+01,
      "num_iterations": 2.2034000000000000e+04,
      "op_type": 0.0000000000000000e+00,
      "output_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_ADD_FWD_TENSORCOREHALF__BatchSize_2__16282506575751354005/input[0]:2/input[1]:512/input[2]:28/input[3]:28/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:2/manual_time",
      "iterations": 70867,
      "real_time": 9.8915771843712409e+03,
      "cpu_time": 1.5346865917860723e+04,
      "time_unit": "ns",
      "items_per_second": 8.1161576666302994e+10,
      "alpha": 5.9604644775390625e-08,
      "batch_size": 2.0000000000000000e+00,
      "benchmark_file:/home/dakkak/scope/scopes/cudnn_scope/src/cudnn_op_tensor.cpp": 1.3651308370281311e+18,
      "benchmark_func:void iLAYER_CUDNN_OP_TENSOR_Impl(benchmark::State&) [with T = __half; cudnnOpTensorOp_t op_type = (cudnnOpTensorOp_t)0]": 1.5887120378050222e+19,
      "beta": 0.0000000000000000e+00,
      "compute_capability:7.5": 3.8315628306456499e+18,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_OP_TENSOR_Impl": 3.0075642356307840e+18,
      "gpu_name:Quadro RTX 6000": 5.1174270964049613e+18,
      "host_name:aleph": 3.2334478980185999e+18,
      "input[0]": 2.0000000000000000e+00,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_a_tensor_layout": 0.0000000000000000e+00,
      "input_b_tensor_layout": 0.0000000000000000e+00,
      "input_c": 5.1200000000000000e+02,
      "input_h": 2.8000000000000000e+01,
      "input_n": 2.0000000000000000e+00,
      "input_size": 8.0281600000000000e+05,
      "input_w": 2.8000000000000000e+01,
      "num_iterations": 7.0867000000000000e+04,
      "op_type": 0.0000000000000000e+00,
      "output_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_ADD_FWD_TENSORCOREHALF__BatchSize_2__4373097215246400669/input[0]:2/input[1]:1024/input[2]:14/input[3]:14/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:2/manual_time",
      "iterations": 86970,
      "real_time": 8.0983312583034294e+03,
      "cpu_time": 1.3614384776370029e+04,
      "time_unit": "ns",
      "items_per_second": 4.9566754828462456e+10,
      "alpha": 5.9604644775390625e-08,
      "batch_size": 2.0000000000000000e+00,
      "benchmark_file:/home/dakkak/scope/scopes/cudnn_scope/src/cudnn_op_tensor.cpp": 1.3651308370281311e+18,
      "benchmark_func:void iLAYER_CUDNN_OP_TENSOR_Impl(benchmark::State&) [with T = __half; cudnnOpTensorOp_t op_type = (cudnnOpTensorOp_t)0]": 1.5887120378050222e+19,
      "beta": 0.0000000000000000e+00,
      "compute_capability:7.5": 3.8315628306456499e+18,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_OP_TENSOR_Impl": 3.0075642356307840e+18,
      "gpu_name:Quadro RTX 6000": 5.1174270964049613e+18,
      "host_name:aleph": 3.2334478980185999e+18,
      "input[0]": 2.0000000000000000e+00,
      "input[1]": 1.0240000000000000e+03,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_a_tensor_layout": 0.0000000000000000e+00,
      "input_b_tensor_layout": 0.0000000000000000e+00,
      "input_c": 1.0240000000000000e+03,
      "input_h": 1.4000000000000000e+01,
      "input_n": 2.0000000000000000e+00,
      "input_size": 4.0140800000000000e+05,
      "input_w": 1.4000000000000000e+01,
      "num_iterations": 8.6970000000000000e+04,
      "op_type": 0.0000000000000000e+00,
      "output_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_OP_TENSOR_ADD_FWD_TENSORCOREHALF__BatchSize_2__13788804002330378090/input[0]:2/input[1]:2048/input[2]:7/input[3]:7/input[4]:-1/input[5]:-1/input[6]:-1/input[7]:-1/batch_size:2/manual_time",
      "iterations": 93955,
      "real_time": 7.2771507971551127e+03,
      "cpu_time": 1.2838397977763725e+04,
      "time_unit": "ns",
      "items_per_second": 2.7580024874359077e+10,
      "alpha": 5.9604644775390625e-08,
      "batch_size": 2.0000000000000000e+00,
      "benchmark_file:/home/dakkak/scope/scopes/cudnn_scope/src/cudnn_op_tensor.cpp": 1.3651308370281311e+18,
      "benchmark_func:void iLAYER_CUDNN_OP_TENSOR_Impl(benchmark::State&) [with T = __half; cudnnOpTensorOp_t op_type = (cudnnOpTensorOp_t)0]": 1.5887120378050222e+19,
      "beta": 0.0000000000000000e+00,
      "compute_capability:7.5": 3.8315628306456499e+18,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_OP_TENSOR_Impl": 3.0075642356307840e+18,
      "gpu_name:Quadro RTX 6000": 5.1174270964049613e+18,
      "host_name:aleph": 3.2334478980185999e+18,
      "input[0]": 2.0000000000000000e+00,
      "input[1]": 2.0480000000000000e+03,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input[4]": -1.0000000000000000e+00,
      "input[5]": -1.0000000000000000e+00,
      "input[6]": -1.0000000000000000e+00,
      "input[7]": -1.0000000000000000e+00,
      "input_a_tensor_layout": 0.0000000000000000e+00,
      "input_b_tensor_layout": 0.0000000000000000e+00,
      "input_c": 2.0480000000000000e+03,
      "input_h": 7.0000000000000000e+00,
      "input_n": 2.0000000000000000e+00,
      "input_size": 2.0070400000000000e+05,
      "input_w": 7.0000000000000000e+00,
      "num_iterations": 9.3955000000000000e+04,
      "op_type": 0.0000000000000000e+00,
      "output_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_POOLING_FWD_TENSORCOREHALF__BatchSize_2__1843146210790374264<CUDNN_POOLING_MAX>/input[0]:2/input[1]:64/input[2]:112/input[3]:112/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/batch_size:2/manual_time",
      "iterations": 38461,
      "real_time": 1.8264751038523202e+04,
      "cpu_time": 2.4007402823636756e+04,
      "time_unit": "ns",
      "items_per_second": 8.7908781051188278e+10,
      "batch_size": 2.0000000000000000e+00,
      "benchmark_file:/home/dakkak/scope/scopes/cudnn_scope/src/cudnn_pooling_fwd.cpp": 1.4160123057735852e+19,
      "benchmark_func:void iLAYER_CUDNN_POOLING_FWD_Impl(benchmark::State&) [with T = __half; cudnnPoolingMode_t pooling_mode = (cudnnPoolingMode_t)0]": 5.4796999114253292e+18,
      "compute_capability:7.5": 3.8315628306456499e+18,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_POOLING_FWD_Impl": 1.4645785230092718e+19,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:Quadro RTX 6000": 5.1174270964049613e+18,
      "horizontal_padding": 1.0000000000000000e+00,
      "horizontal_stride": 2.0000000000000000e+00,
      "host_name:aleph": 3.2334478980185999e+18,
      "input[0]": 2.0000000000000000e+00,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 1.1200000000000000e+02,
      "input[3]": 1.1200000000000000e+02,
      "input_batch_size": 2.0000000000000000e+00,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 1.1200000000000000e+02,
      "input_size": 1.6056320000000000e+06,
      "input_width": 1.1200000000000000e+02,
      "num_iterations": 3.8461000000000000e+04,
      "output_batch_size": 2.0000000000000000e+00,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 5.6000000000000000e+01,
      "output_size": 4.0140800000000000e+05,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "pooling_mode": 0.0000000000000000e+00,
      "predicted_flops": 8.7908781051188278e+10,
      "predicted_flops_count": 1.6056320000000000e+06,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "vertical_padding": 1.0000000000000000e+00,
      "vertical_stride": 2.0000000000000000e+00,
      "window_height": 3.0000000000000000e+00,
      "window_width": 3.0000000000000000e+00,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_POOLING_FWD_TENSORCOREHALF__BatchSize_2__1843146210790374264<CUDNN_POOLING_MAX_DETERMINISTIC>/input[0]:2/input[1]:64/input[2]:112/input[3]:112/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:2/stride_width:2/batch_size:2/manual_time",
      "iterations": 38203,
      "real_time": 1.8286944528366443e+04,
      "cpu_time": 2.3988472737771317e+04,
      "time_unit": "ns",
      "items_per_second": 8.7802092772216095e+10,
      "batch_size": 2.0000000000000000e+00,
      "benchmark_file:/home/dakkak/scope/scopes/cudnn_scope/src/cudnn_pooling_fwd.cpp": 1.4160123057735852e+19,
      "benchmark_func:void iLAYER_CUDNN_POOLING_FWD_Impl(benchmark::State&) [with T = __half; cudnnPoolingMode_t pooling_mode = (cudnnPoolingMode_t)3]": 5.4769555304018821e+18,
      "compute_capability:7.5": 3.8315628306456499e+18,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_POOLING_FWD_Impl": 1.4645785230092718e+19,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:Quadro RTX 6000": 5.1174270964049613e+18,
      "horizontal_padding": 1.0000000000000000e+00,
      "horizontal_stride": 2.0000000000000000e+00,
      "host_name:aleph": 3.2334478980185999e+18,
      "input[0]": 2.0000000000000000e+00,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 1.1200000000000000e+02,
      "input[3]": 1.1200000000000000e+02,
      "input_batch_size": 2.0000000000000000e+00,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 1.1200000000000000e+02,
      "input_size": 1.6056320000000000e+06,
      "input_width": 1.1200000000000000e+02,
      "num_iterations": 3.8203000000000000e+04,
      "output_batch_size": 2.0000000000000000e+00,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 5.6000000000000000e+01,
      "output_size": 4.0140800000000000e+05,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "pooling_mode": 3.0000000000000000e+00,
      "predicted_flops": 8.7802092772216095e+10,
      "predicted_flops_count": 1.6056320000000000e+06,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "vertical_padding": 1.0000000000000000e+00,
      "vertical_stride": 2.0000000000000000e+00,
      "window_height": 3.0000000000000000e+00,
      "window_width": 3.0000000000000000e+00,
      "x_tensor_layout": 0.0000000000000000e+00,
      "y_tensor_layout": 0.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_2__8391465597707106997<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_SIGMOID>/input[0]:2/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_2__8391465597707106997<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_TANH>/input[0]:2/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_2__8391465597707106997<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 2988,
      "real_time": 2.3436396322125843e+05,
      "cpu_time": 2.4088257697458353e+05,
      "time_unit": "ns",
      "items_per_second": 1.0961630639325923e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 2.4985599517822266e-01,
      "batch_size": 2.0000000000000000e+00,
      "benchmark_file:/home/dakkak/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 1.5291677899427402e+19,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 2.3191971996820818e+18,
      "bias_tensor_layout": 1.0000000000000000e+00,
      "compute_capability:7.5": 3.8315628306456499e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:Quadro RTX 6000": 5.1174270964049613e+18,
      "group": 1.0000000000000000e+00,
      "host_name:aleph": 3.2334478980185999e+18,
      "input[0]": 2.0000000000000000e+00,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 2.0000000000000000e+00,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 4.0140800000000000e+05,
      "input_width": 5.6000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 2.9880000000000000e+03,
      "output_batch_size": 2.0000000000000000e+00,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 5.6000000000000000e+01,
      "output_size": 4.0140800000000000e+05,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00,
      "x_tensor_layout": 1.0000000000000000e+00,
      "y_tensor_layout": 1.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_2__8391465597707106997<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:2/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 2986,
      "real_time": 2.3426617098262170e+05,
      "cpu_time": 2.4075993904880102e+05,
      "time_unit": "ns",
      "items_per_second": 1.0966206470291325e+11,
      "activation_mode": 3.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 2.3878400027751923e-01,
      "batch_size": 2.0000000000000000e+00,
      "benchmark_file:/home/dakkak/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 1.5291677899427402e+19,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.9889882919049984e+18,
      "bias_tensor_layout": 1.0000000000000000e+00,
      "compute_capability:7.5": 3.8315628306456499e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:Quadro RTX 6000": 5.1174270964049613e+18,
      "group": 1.0000000000000000e+00,
      "host_name:aleph": 3.2334478980185999e+18,
      "input[0]": 2.0000000000000000e+00,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 2.0000000000000000e+00,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 4.0140800000000000e+05,
      "input_width": 5.6000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 2.9860000000000000e+03,
      "output_batch_size": 2.0000000000000000e+00,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 5.6000000000000000e+01,
      "output_size": 4.0140800000000000e+05,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00,
      "x_tensor_layout": 1.0000000000000000e+00,
      "y_tensor_layout": 1.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_2__8391465597707106997<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_ELU>/input[0]:2/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_2__8391465597707106997<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 2987,
      "real_time": 2.3434278208735594e+05,
      "cpu_time": 2.4081483227327530e+05,
      "time_unit": "ns",
      "items_per_second": 1.0962621409190021e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 2.3395200073719025e-01,
      "batch_size": 2.0000000000000000e+00,
      "benchmark_file:/home/dakkak/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 1.5291677899427402e+19,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 2.3191971996820818e+18,
      "bias_tensor_layout": 1.0000000000000000e+00,
      "compute_capability:7.5": 3.8315628306456499e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:Quadro RTX 6000": 5.1174270964049613e+18,
      "group": 1.0000000000000000e+00,
      "host_name:aleph": 3.2334478980185999e+18,
      "input[0]": 2.0000000000000000e+00,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 2.0000000000000000e+00,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 4.0140800000000000e+05,
      "input_width": 5.6000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 2.9870000000000000e+03,
      "output_batch_size": 2.0000000000000000e+00,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 5.6000000000000000e+01,
      "output_size": 4.0140800000000000e+05,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00,
      "x_tensor_layout": 1.0000000000000000e+00,
      "y_tensor_layout": 1.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_2__8391465597707106997<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 2988,
      "real_time": 2.3443355360162666e+05,
      "cpu_time": 2.4097549397600538e+05,
      "time_unit": "ns",
      "items_per_second": 1.0958376736316190e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 2.4096000194549561e-01,
      "batch_size": 2.0000000000000000e+00,
      "benchmark_file:/home/dakkak/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 1.5291677899427402e+19,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 2.3191971996820818e+18,
      "bias_tensor_layout": 1.0000000000000000e+00,
      "compute_capability:7.5": 3.8315628306456499e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:Quadro RTX 6000": 5.1174270964049613e+18,
      "group": 1.0000000000000000e+00,
      "host_name:aleph": 3.2334478980185999e+18,
      "input[0]": 2.0000000000000000e+00,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 2.0000000000000000e+00,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 4.0140800000000000e+05,
      "input_width": 5.6000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 2.9880000000000000e+03,
      "output_batch_size": 2.0000000000000000e+00,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 5.6000000000000000e+01,
      "output_size": 4.0140800000000000e+05,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00,
      "x_tensor_layout": 1.0000000000000000e+00,
      "y_tensor_layout": 1.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_2__8391465597707106997<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_IDENTITY>/input[0]:2/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 2985,
      "real_time": 2.3434206827678616e+05,
      "cpu_time": 2.4084190385252621e+05,
      "time_unit": "ns",
      "items_per_second": 1.0962654801551418e+11,
      "activation_mode": 5.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 2.4575999379158020e-01,
      "batch_size": 2.0000000000000000e+00,
      "benchmark_file:/home/dakkak/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 1.5291677899427402e+19,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)5; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.3342635194217454e+19,
      "bias_tensor_layout": 1.0000000000000000e+00,
      "compute_capability:7.5": 3.8315628306456499e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:Quadro RTX 6000": 5.1174270964049613e+18,
      "group": 1.0000000000000000e+00,
      "host_name:aleph": 3.2334478980185999e+18,
      "input[0]": 2.0000000000000000e+00,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 2.0000000000000000e+00,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 4.0140800000000000e+05,
      "input_width": 5.6000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 2.9850000000000000e+03,
      "output_batch_size": 2.0000000000000000e+00,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 5.6000000000000000e+01,
      "output_size": 4.0140800000000000e+05,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00,
      "x_tensor_layout": 1.0000000000000000e+00,
      "y_tensor_layout": 1.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_2__8391465597707106997<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_SIGMOID>/input[0]:2/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_2__8391465597707106997<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_TANH>/input[0]:2/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_2__8391465597707106997<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 17422,
      "real_time": 4.0070733437833092e+04,
      "cpu_time": 4.5803613477254832e+04,
      "time_unit": "ns",
      "items_per_second": 6.4111908607453845e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.8824000000000000e+04,
      "advised_time": 7.3087997734546661e-02,
      "batch_size": 2.0000000000000000e+00,
      "benchmark_file:/home/dakkak/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 1.5291677899427402e+19,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.5541522464702913e+19,
      "bias_tensor_layout": 1.0000000000000000e+00,
      "compute_capability:7.5": 3.8315628306456499e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:Quadro RTX 6000": 5.1174270964049613e+18,
      "group": 1.0000000000000000e+00,
      "host_name:aleph": 3.2334478980185999e+18,
      "input[0]": 2.0000000000000000e+00,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 2.0000000000000000e+00,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 4.0140800000000000e+05,
      "input_width": 5.6000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 1.7422000000000000e+04,
      "output_batch_size": 2.0000000000000000e+00,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 5.6000000000000000e+01,
      "output_size": 4.0140800000000000e+05,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 1.0000000000000000e+00,
      "workspace_bytes": 1.8824000000000000e+04,
      "workspace_megabytes": 1.7951965332031250e-02,
      "x_tensor_layout": 1.0000000000000000e+00,
      "y_tensor_layout": 1.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_2__8391465597707106997<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:2/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 17489,
      "real_time": 4.0076908571311658e+04,
      "cpu_time": 4.5855628509493559e+04,
      "time_unit": "ns",
      "items_per_second": 6.4102030111149365e+11,
      "activation_mode": 3.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.8824000000000000e+04,
      "advised_time": 8.1791996955871582e-02,
      "batch_size": 2.0000000000000000e+00,
      "benchmark_file:/home/dakkak/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 1.5291677899427402e+19,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.5547362882776177e+19,
      "bias_tensor_layout": 1.0000000000000000e+00,
      "compute_capability:7.5": 3.8315628306456499e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:Quadro RTX 6000": 5.1174270964049613e+18,
      "group": 1.0000000000000000e+00,
      "host_name:aleph": 3.2334478980185999e+18,
      "input[0]": 2.0000000000000000e+00,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 2.0000000000000000e+00,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 4.0140800000000000e+05,
      "input_width": 5.6000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 1.7489000000000000e+04,
      "output_batch_size": 2.0000000000000000e+00,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 5.6000000000000000e+01,
      "output_size": 4.0140800000000000e+05,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 1.0000000000000000e+00,
      "workspace_bytes": 1.8824000000000000e+04,
      "workspace_megabytes": 1.7951965332031250e-02,
      "x_tensor_layout": 1.0000000000000000e+00,
      "y_tensor_layout": 1.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_2__8391465597707106997<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_ELU>/input[0]:2/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_2__8391465597707106997<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 17402,
      "real_time": 3.9925898917065875e+04,
      "cpu_time": 4.5693555683264894e+04,
      "time_unit": "ns",
      "items_per_second": 6.4344479891018933e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.8824000000000000e+04,
      "advised_time": 4.7104001045227051e-02,
      "batch_size": 2.0000000000000000e+00,
      "benchmark_file:/home/dakkak/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 1.5291677899427402e+19,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.5541522464702913e+19,
      "bias_tensor_layout": 1.0000000000000000e+00,
      "compute_capability:7.5": 3.8315628306456499e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:Quadro RTX 6000": 5.1174270964049613e+18,
      "group": 1.0000000000000000e+00,
      "host_name:aleph": 3.2334478980185999e+18,
      "input[0]": 2.0000000000000000e+00,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 2.0000000000000000e+00,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 4.0140800000000000e+05,
      "input_width": 5.6000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 1.7402000000000000e+04,
      "output_batch_size": 2.0000000000000000e+00,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 5.6000000000000000e+01,
      "output_size": 4.0140800000000000e+05,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 1.0000000000000000e+00,
      "workspace_bytes": 1.8824000000000000e+04,
      "workspace_megabytes": 1.7951965332031250e-02,
      "x_tensor_layout": 1.0000000000000000e+00,
      "y_tensor_layout": 1.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_2__8391465597707106997<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 17503,
      "real_time": 4.0230541389914200e+04,
      "cpu_time": 4.6012135119766746e+04,
      "time_unit": "ns",
      "items_per_second": 6.3857236597965637e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.8824000000000000e+04,
      "advised_time": 4.5728001743555069e-02,
      "batch_size": 2.0000000000000000e+00,
      "benchmark_file:/home/dakkak/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 1.5291677899427402e+19,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.5541522464702913e+19,
      "bias_tensor_layout": 1.0000000000000000e+00,
      "compute_capability:7.5": 3.8315628306456499e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:Quadro RTX 6000": 5.1174270964049613e+18,
      "group": 1.0000000000000000e+00,
      "host_name:aleph": 3.2334478980185999e+18,
      "input[0]": 2.0000000000000000e+00,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 2.0000000000000000e+00,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 4.0140800000000000e+05,
      "input_width": 5.6000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 1.7503000000000000e+04,
      "output_batch_size": 2.0000000000000000e+00,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 5.6000000000000000e+01,
      "output_size": 4.0140800000000000e+05,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 1.0000000000000000e+00,
      "workspace_bytes": 1.8824000000000000e+04,
      "workspace_megabytes": 1.7951965332031250e-02,
      "x_tensor_layout": 1.0000000000000000e+00,
      "y_tensor_layout": 1.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_2__8391465597707106997<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_IDENTITY>/input[0]:2/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 17380,
      "real_time": 4.0054891489387250e+04,
      "cpu_time": 4.5780610644261018e+04,
      "time_unit": "ns",
      "items_per_second": 6.4137265249630566e+11,
      "activation_mode": 5.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.8824000000000000e+04,
      "advised_time": 8.1727996468544006e-02,
      "batch_size": 2.0000000000000000e+00,
      "benchmark_file:/home/dakkak/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 1.5291677899427402e+19,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)5; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 4.5833023350607309e+18,
      "bias_tensor_layout": 1.0000000000000000e+00,
      "compute_capability:7.5": 3.8315628306456499e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:Quadro RTX 6000": 5.1174270964049613e+18,
      "group": 1.0000000000000000e+00,
      "host_name:aleph": 3.2334478980185999e+18,
      "input[0]": 2.0000000000000000e+00,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 2.0000000000000000e+00,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 4.0140800000000000e+05,
      "input_width": 5.6000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 1.7380000000000000e+04,
      "output_batch_size": 2.0000000000000000e+00,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 5.6000000000000000e+01,
      "output_size": 4.0140800000000000e+05,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 1.0000000000000000e+00,
      "workspace_bytes": 1.8824000000000000e+04,
      "workspace_megabytes": 1.7951965332031250e-02,
      "x_tensor_layout": 1.0000000000000000e+00,
      "y_tensor_layout": 1.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_2__8391465597707106997<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_SIGMOID>/input[0]:2/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_2__8391465597707106997<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_TANH>/input[0]:2/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_2__8391465597707106997<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_2__8391465597707106997<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:2/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_2__8391465597707106997<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_ELU>/input[0]:2/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_2__8391465597707106997<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_2__8391465597707106997<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_2__8391465597707106997<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_IDENTITY>/input[0]:2/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_2__8391465597707106997<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_SIGMOID>/input[0]:2/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_2__8391465597707106997<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_TANH>/input[0]:2/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_2__8391465597707106997<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_2__8391465597707106997<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:2/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_2__8391465597707106997<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_ELU>/input[0]:2/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_2__8391465597707106997<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_2__8391465597707106997<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_2__8391465597707106997<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_IDENTITY>/input[0]:2/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_2__8391465597707106997<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_SIGMOID>/input[0]:2/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_2__8391465597707106997<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_TANH>/input[0]:2/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_2__8391465597707106997<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_2__8391465597707106997<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:2/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_2__8391465597707106997<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_ELU>/input[0]:2/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_2__8391465597707106997<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_2__8391465597707106997<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_2__8391465597707106997<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_IDENTITY>/input[0]:2/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_2__8391465597707106997<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_SIGMOID>/input[0]:2/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_2__8391465597707106997<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_TANH>/input[0]:2/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_2__8391465597707106997<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_2__8391465597707106997<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:2/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_2__8391465597707106997<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_ELU>/input[0]:2/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_2__8391465597707106997<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_2__8391465597707106997<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_2__8391465597707106997<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_IDENTITY>/input[0]:2/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_2__8391465597707106997<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_SIGMOID>/input[0]:2/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_2__8391465597707106997<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_TANH>/input[0]:2/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_2__8391465597707106997<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_2__8391465597707106997<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:2/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_2__8391465597707106997<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_ELU>/input[0]:2/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_2__8391465597707106997<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_2__8391465597707106997<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_2__8391465597707106997<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_IDENTITY>/input[0]:2/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_2__8391465597707106997<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_SIGMOID>/input[0]:2/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_2__8391465597707106997<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_TANH>/input[0]:2/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_2__8391465597707106997<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_2__8391465597707106997<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:2/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_2__8391465597707106997<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_ELU>/input[0]:2/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_2__8391465597707106997<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_2__8391465597707106997<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_2__8391465597707106997<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_IDENTITY>/input[0]:2/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_2__9816403302642887125<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_SIGMOID>/input[0]:2/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_2__9816403302642887125<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_TANH>/input[0]:2/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_2__9816403302642887125<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 18793,
      "real_time": 3.7117473800336928e+04,
      "cpu_time": 4.2839414941782830e+04,
      "time_unit": "ns",
      "items_per_second": 6.9212986148229736e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 4.8160001635551453e-02,
      "batch_size": 2.0000000000000000e+00,
      "benchmark_file:/home/dakkak/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 1.5291677899427402e+19,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 2.3191971996820818e+18,
      "bias_tensor_layout": 1.0000000000000000e+00,
      "compute_capability:7.5": 3.8315628306456499e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Quadro RTX 6000": 5.1174270964049613e+18,
      "group": 1.0000000000000000e+00,
      "host_name:aleph": 3.2334478980185999e+18,
      "input[0]": 2.0000000000000000e+00,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 2.0000000000000000e+00,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 4.0140800000000000e+05,
      "input_width": 5.6000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 1.8793000000000000e+04,
      "output_batch_size": 2.0000000000000000e+00,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 5.6000000000000000e+01,
      "output_size": 4.0140800000000000e+05,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00,
      "x_tensor_layout": 1.0000000000000000e+00,
      "y_tensor_layout": 1.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_2__9816403302642887125<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:2/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 18845,
      "real_time": 3.7164571482754785e+04,
      "cpu_time": 4.2883146351857795e+04,
      "time_unit": "ns",
      "items_per_second": 6.9125274354154211e+11,
      "activation_mode": 3.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 4.0288001298904419e-02,
      "batch_size": 2.0000000000000000e+00,
      "benchmark_file:/home/dakkak/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 1.5291677899427402e+19,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.9889882919049984e+18,
      "bias_tensor_layout": 1.0000000000000000e+00,
      "compute_capability:7.5": 3.8315628306456499e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Quadro RTX 6000": 5.1174270964049613e+18,
      "group": 1.0000000000000000e+00,
      "host_name:aleph": 3.2334478980185999e+18,
      "input[0]": 2.0000000000000000e+00,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 2.0000000000000000e+00,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 4.0140800000000000e+05,
      "input_width": 5.6000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 1.8845000000000000e+04,
      "output_batch_size": 2.0000000000000000e+00,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 5.6000000000000000e+01,
      "output_size": 4.0140800000000000e+05,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00,
      "x_tensor_layout": 1.0000000000000000e+00,
      "y_tensor_layout": 1.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_2__9816403302642887125<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_ELU>/input[0]:2/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_2__9816403302642887125<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 18843,
      "real_time": 3.7165243596442080e+04,
      "cpu_time": 4.2927680624263754e+04,
      "time_unit": "ns",
      "items_per_second": 6.9124024260288660e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 3.8623999804258347e-02,
      "batch_size": 2.0000000000000000e+00,
      "benchmark_file:/home/dakkak/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 1.5291677899427402e+19,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 2.3191971996820818e+18,
      "bias_tensor_layout": 1.0000000000000000e+00,
      "compute_capability:7.5": 3.8315628306456499e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Quadro RTX 6000": 5.1174270964049613e+18,
      "group": 1.0000000000000000e+00,
      "host_name:aleph": 3.2334478980185999e+18,
      "input[0]": 2.0000000000000000e+00,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 2.0000000000000000e+00,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 4.0140800000000000e+05,
      "input_width": 5.6000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 1.8843000000000000e+04,
      "output_batch_size": 2.0000000000000000e+00,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 5.6000000000000000e+01,
      "output_size": 4.0140800000000000e+05,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00,
      "x_tensor_layout": 1.0000000000000000e+00,
      "y_tensor_layout": 1.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_2__9816403302642887125<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 18778,
      "real_time": 3.7161056415952342e+04,
      "cpu_time": 4.2879389551605345e+04,
      "time_unit": "ns",
      "items_per_second": 6.9131812918461206e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 4.0320001542568207e-02,
      "batch_size": 2.0000000000000000e+00,
      "benchmark_file:/home/dakkak/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 1.5291677899427402e+19,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 2.3191971996820818e+18,
      "bias_tensor_layout": 1.0000000000000000e+00,
      "compute_capability:7.5": 3.8315628306456499e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Quadro RTX 6000": 5.1174270964049613e+18,
      "group": 1.0000000000000000e+00,
      "host_name:aleph": 3.2334478980185999e+18,
      "input[0]": 2.0000000000000000e+00,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 2.0000000000000000e+00,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 4.0140800000000000e+05,
      "input_width": 5.6000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 1.8778000000000000e+04,
      "output_batch_size": 2.0000000000000000e+00,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 5.6000000000000000e+01,
      "output_size": 4.0140800000000000e+05,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00,
      "x_tensor_layout": 1.0000000000000000e+00,
      "y_tensor_layout": 1.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_2__9816403302642887125<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_IDENTITY>/input[0]:2/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 18883,
      "real_time": 3.7172031407961069e+04,
      "cpu_time": 4.2914231689964792e+04,
      "time_unit": "ns",
      "items_per_second": 6.9111401844177905e+11,
      "activation_mode": 5.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 3.9007999002933502e-02,
      "batch_size": 2.0000000000000000e+00,
      "benchmark_file:/home/dakkak/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 1.5291677899427402e+19,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)5; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.3342635194217454e+19,
      "bias_tensor_layout": 1.0000000000000000e+00,
      "compute_capability:7.5": 3.8315628306456499e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Quadro RTX 6000": 5.1174270964049613e+18,
      "group": 1.0000000000000000e+00,
      "host_name:aleph": 3.2334478980185999e+18,
      "input[0]": 2.0000000000000000e+00,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 2.0000000000000000e+00,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 4.0140800000000000e+05,
      "input_width": 5.6000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 1.8883000000000000e+04,
      "output_batch_size": 2.0000000000000000e+00,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 5.6000000000000000e+01,
      "output_size": 4.0140800000000000e+05,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00,
      "x_tensor_layout": 1.0000000000000000e+00,
      "y_tensor_layout": 1.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_2__9816403302642887125<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_SIGMOID>/input[0]:2/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_2__9816403302642887125<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_TANH>/input[0]:2/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_2__9816403302642887125<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 31616,
      "real_time": 2.2166037445130467e+04,
      "cpu_time": 2.7945967548132910e+04,
      "time_unit": "ns",
      "items_per_second": 1.1589853199333882e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.8824000000000000e+04,
      "advised_time": 2.8255999088287354e-02,
      "batch_size": 2.0000000000000000e+00,
      "benchmark_file:/home/dakkak/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 1.5291677899427402e+19,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.5541522464702913e+19,
      "bias_tensor_layout": 1.0000000000000000e+00,
      "compute_capability:7.5": 3.8315628306456499e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Quadro RTX 6000": 5.1174270964049613e+18,
      "group": 1.0000000000000000e+00,
      "host_name:aleph": 3.2334478980185999e+18,
      "input[0]": 2.0000000000000000e+00,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 2.0000000000000000e+00,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 4.0140800000000000e+05,
      "input_width": 5.6000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 3.1616000000000000e+04,
      "output_batch_size": 2.0000000000000000e+00,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 5.6000000000000000e+01,
      "output_size": 4.0140800000000000e+05,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 1.0000000000000000e+00,
      "workspace_bytes": 1.8824000000000000e+04,
      "workspace_megabytes": 1.7951965332031250e-02,
      "x_tensor_layout": 1.0000000000000000e+00,
      "y_tensor_layout": 1.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_2__9816403302642887125<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:2/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 31666,
      "real_time": 2.2191981793539533e+04,
      "cpu_time": 2.7941252415903618e+04,
      "time_unit": "ns",
      "items_per_second": 1.1576303657332141e+12,
      "activation_mode": 3.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.8824000000000000e+04,
      "advised_time": 2.6623999699950218e-02,
      "batch_size": 2.0000000000000000e+00,
      "benchmark_file:/home/dakkak/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 1.5291677899427402e+19,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.5547362882776177e+19,
      "bias_tensor_layout": 1.0000000000000000e+00,
      "compute_capability:7.5": 3.8315628306456499e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Quadro RTX 6000": 5.1174270964049613e+18,
      "group": 1.0000000000000000e+00,
      "host_name:aleph": 3.2334478980185999e+18,
      "input[0]": 2.0000000000000000e+00,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 2.0000000000000000e+00,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 4.0140800000000000e+05,
      "input_width": 5.6000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 3.1666000000000000e+04,
      "output_batch_size": 2.0000000000000000e+00,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 5.6000000000000000e+01,
      "output_size": 4.0140800000000000e+05,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 1.0000000000000000e+00,
      "workspace_bytes": 1.8824000000000000e+04,
      "workspace_megabytes": 1.7951965332031250e-02,
      "x_tensor_layout": 1.0000000000000000e+00,
      "y_tensor_layout": 1.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_2__9816403302642887125<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_ELU>/input[0]:2/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_2__9816403302642887125<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 30940,
      "real_time": 2.2225760301845523e+04,
      "cpu_time": 2.8022060891954159e+04,
      "time_unit": "ns",
      "items_per_second": 1.1558710096350142e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.8824000000000000e+04,
      "advised_time": 2.8351999819278717e-02,
      "batch_size": 2.0000000000000000e+00,
      "benchmark_file:/home/dakkak/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 1.5291677899427402e+19,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.5541522464702913e+19,
      "bias_tensor_layout": 1.0000000000000000e+00,
      "compute_capability:7.5": 3.8315628306456499e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Quadro RTX 6000": 5.1174270964049613e+18,
      "group": 1.0000000000000000e+00,
      "host_name:aleph": 3.2334478980185999e+18,
      "input[0]": 2.0000000000000000e+00,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 2.0000000000000000e+00,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 4.0140800000000000e+05,
      "input_width": 5.6000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 3.0940000000000000e+04,
      "output_batch_size": 2.0000000000000000e+00,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 5.6000000000000000e+01,
      "output_size": 4.0140800000000000e+05,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 1.0000000000000000e+00,
      "workspace_bytes": 1.8824000000000000e+04,
      "workspace_megabytes": 1.7951965332031250e-02,
      "x_tensor_layout": 1.0000000000000000e+00,
      "y_tensor_layout": 1.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_2__9816403302642887125<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 31577,
      "real_time": 2.2240528990509451e+04,
      "cpu_time": 2.8025481236305255e+04,
      "time_unit": "ns",
      "items_per_second": 1.1551034604870488e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.8824000000000000e+04,
      "advised_time": 2.8351999819278717e-02,
      "batch_size": 2.0000000000000000e+00,
      "benchmark_file:/home/dakkak/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 1.5291677899427402e+19,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.5541522464702913e+19,
      "bias_tensor_layout": 1.0000000000000000e+00,
      "compute_capability:7.5": 3.8315628306456499e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Quadro RTX 6000": 5.1174270964049613e+18,
      "group": 1.0000000000000000e+00,
      "host_name:aleph": 3.2334478980185999e+18,
      "input[0]": 2.0000000000000000e+00,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 2.0000000000000000e+00,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 4.0140800000000000e+05,
      "input_width": 5.6000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 3.1577000000000000e+04,
      "output_batch_size": 2.0000000000000000e+00,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 5.6000000000000000e+01,
      "output_size": 4.0140800000000000e+05,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 1.0000000000000000e+00,
      "workspace_bytes": 1.8824000000000000e+04,
      "workspace_megabytes": 1.7951965332031250e-02,
      "x_tensor_layout": 1.0000000000000000e+00,
      "y_tensor_layout": 1.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_2__9816403302642887125<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_IDENTITY>/input[0]:2/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 30981,
      "real_time": 2.2196198163753805e+04,
      "cpu_time": 2.7933672670219363e+04,
      "time_unit": "ns",
      "items_per_second": 1.1574104632905884e+12,
      "activation_mode": 5.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.8824000000000000e+04,
      "advised_time": 2.7680000290274620e-02,
      "batch_size": 2.0000000000000000e+00,
      "benchmark_file:/home/dakkak/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 1.5291677899427402e+19,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)5; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 4.5833023350607309e+18,
      "bias_tensor_layout": 1.0000000000000000e+00,
      "compute_capability:7.5": 3.8315628306456499e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Quadro RTX 6000": 5.1174270964049613e+18,
      "group": 1.0000000000000000e+00,
      "host_name:aleph": 3.2334478980185999e+18,
      "input[0]": 2.0000000000000000e+00,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 2.0000000000000000e+00,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 4.0140800000000000e+05,
      "input_width": 5.6000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 3.0981000000000000e+04,
      "output_batch_size": 2.0000000000000000e+00,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 5.6000000000000000e+01,
      "output_size": 4.0140800000000000e+05,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 1.0000000000000000e+00,
      "workspace_bytes": 1.8824000000000000e+04,
      "workspace_megabytes": 1.7951965332031250e-02,
      "x_tensor_layout": 1.0000000000000000e+00,
      "y_tensor_layout": 1.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_2__9816403302642887125<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_SIGMOID>/input[0]:2/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_2__9816403302642887125<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_TANH>/input[0]:2/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_2__9816403302642887125<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_2__9816403302642887125<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:2/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_2__9816403302642887125<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_ELU>/input[0]:2/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_2__9816403302642887125<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_2__9816403302642887125<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_2__9816403302642887125<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_IDENTITY>/input[0]:2/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_2__9816403302642887125<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_SIGMOID>/input[0]:2/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_2__9816403302642887125<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_TANH>/input[0]:2/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_2__9816403302642887125<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_2__9816403302642887125<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:2/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_2__9816403302642887125<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_ELU>/input[0]:2/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_2__9816403302642887125<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_2__9816403302642887125<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_2__9816403302642887125<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_IDENTITY>/input[0]:2/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_2__9816403302642887125<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_SIGMOID>/input[0]:2/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_2__9816403302642887125<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_TANH>/input[0]:2/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_2__9816403302642887125<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_2__9816403302642887125<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:2/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_2__9816403302642887125<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_ELU>/input[0]:2/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_2__9816403302642887125<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_2__9816403302642887125<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_2__9816403302642887125<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_IDENTITY>/input[0]:2/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_2__9816403302642887125<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_SIGMOID>/input[0]:2/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_2__9816403302642887125<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_TANH>/input[0]:2/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_2__9816403302642887125<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_2__9816403302642887125<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:2/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_2__9816403302642887125<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_ELU>/input[0]:2/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_2__9816403302642887125<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_2__9816403302642887125<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_2__9816403302642887125<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_IDENTITY>/input[0]:2/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_2__9816403302642887125<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_SIGMOID>/input[0]:2/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_2__9816403302642887125<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_TANH>/input[0]:2/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_2__9816403302642887125<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_2__9816403302642887125<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:2/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_2__9816403302642887125<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_ELU>/input[0]:2/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_2__9816403302642887125<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_2__9816403302642887125<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_2__9816403302642887125<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_IDENTITY>/input[0]:2/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_2__9816403302642887125<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_SIGMOID>/input[0]:2/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_2__9816403302642887125<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_TANH>/input[0]:2/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_2__9816403302642887125<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_2__9816403302642887125<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:2/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_2__9816403302642887125<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_ELU>/input[0]:2/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_2__9816403302642887125<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_2__9816403302642887125<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_2__9816403302642887125<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_IDENTITY>/input[0]:2/input[1]:64/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_2__8741601452745866875<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_SIGMOID>/input[0]:2/input[1]:512/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_2__8741601452745866875<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_TANH>/input[0]:2/input[1]:512/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_2__8741601452745866875<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:512/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 6225,
      "real_time": 1.1246980627274972e+05,
      "cpu_time": 1.1841759502001981e+05,
      "time_unit": "ns",
      "items_per_second": 9.1367142351784961e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 1.1427199840545654e-01,
      "batch_size": 2.0000000000000000e+00,
      "benchmark_file:/home/dakkak/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 1.5291677899427402e+19,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 2.3191971996820818e+18,
      "bias_tensor_layout": 1.0000000000000000e+00,
      "compute_capability:7.5": 3.8315628306456499e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Quadro RTX 6000": 5.1174270964049613e+18,
      "group": 1.0000000000000000e+00,
      "host_name:aleph": 3.2334478980185999e+18,
      "input[0]": 2.0000000000000000e+00,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 2.0000000000000000e+00,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 8.0281600000000000e+05,
      "input_width": 2.8000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 6.2250000000000000e+03,
      "output_batch_size": 2.0000000000000000e+00,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 2.0070400000000000e+05,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00,
      "x_tensor_layout": 1.0000000000000000e+00,
      "y_tensor_layout": 1.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_2__8741601452745866875<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:2/input[1]:512/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 6224,
      "real_time": 1.1238172247713969e+05,
      "cpu_time": 1.1826396031510770e+05,
      "time_unit": "ns",
      "items_per_second": 9.1438755106199048e+11,
      "activation_mode": 3.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 1.1475200206041336e-01,
      "batch_size": 2.0000000000000000e+00,
      "benchmark_file:/home/dakkak/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 1.5291677899427402e+19,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.9889882919049984e+18,
      "bias_tensor_layout": 1.0000000000000000e+00,
      "compute_capability:7.5": 3.8315628306456499e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Quadro RTX 6000": 5.1174270964049613e+18,
      "group": 1.0000000000000000e+00,
      "host_name:aleph": 3.2334478980185999e+18,
      "input[0]": 2.0000000000000000e+00,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 2.0000000000000000e+00,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 8.0281600000000000e+05,
      "input_width": 2.8000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 6.2240000000000000e+03,
      "output_batch_size": 2.0000000000000000e+00,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 2.0070400000000000e+05,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00,
      "x_tensor_layout": 1.0000000000000000e+00,
      "y_tensor_layout": 1.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_2__8741601452745866875<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_ELU>/input[0]:2/input[1]:512/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_2__8741601452745866875<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:512/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 6223,
      "real_time": 1.1239064377901128e+05,
      "cpu_time": 1.1831304869030767e+05,
      "time_unit": "ns",
      "items_per_second": 9.1431496915395642e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 1.1513599753379822e-01,
      "batch_size": 2.0000000000000000e+00,
      "benchmark_file:/home/dakkak/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 1.5291677899427402e+19,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 2.3191971996820818e+18,
      "bias_tensor_layout": 1.0000000000000000e+00,
      "compute_capability:7.5": 3.8315628306456499e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Quadro RTX 6000": 5.1174270964049613e+18,
      "group": 1.0000000000000000e+00,
      "host_name:aleph": 3.2334478980185999e+18,
      "input[0]": 2.0000000000000000e+00,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 2.0000000000000000e+00,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 8.0281600000000000e+05,
      "input_width": 2.8000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 6.2230000000000000e+03,
      "output_batch_size": 2.0000000000000000e+00,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 2.0070400000000000e+05,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00,
      "x_tensor_layout": 1.0000000000000000e+00,
      "y_tensor_layout": 1.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_2__8741601452745866875<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:512/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 6206,
      "real_time": 1.1231045052819046e+05,
      "cpu_time": 1.1823192732835021e+05,
      "time_unit": "ns",
      "items_per_second": 9.1496781926101025e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 1.1481600254774094e-01,
      "batch_size": 2.0000000000000000e+00,
      "benchmark_file:/home/dakkak/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 1.5291677899427402e+19,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 2.3191971996820818e+18,
      "bias_tensor_layout": 1.0000000000000000e+00,
      "compute_capability:7.5": 3.8315628306456499e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Quadro RTX 6000": 5.1174270964049613e+18,
      "group": 1.0000000000000000e+00,
      "host_name:aleph": 3.2334478980185999e+18,
      "input[0]": 2.0000000000000000e+00,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 2.0000000000000000e+00,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 8.0281600000000000e+05,
      "input_width": 2.8000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 6.2060000000000000e+03,
      "output_batch_size": 2.0000000000000000e+00,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 2.0070400000000000e+05,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00,
      "x_tensor_layout": 1.0000000000000000e+00,
      "y_tensor_layout": 1.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_2__8741601452745866875<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_IDENTITY>/input[0]:2/input[1]:512/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 6233,
      "real_time": 1.1242177052341813e+05,
      "cpu_time": 1.1839749414395503e+05,
      "time_unit": "ns",
      "items_per_second": 9.1406181846775293e+11,
      "activation_mode": 5.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 1.1468800157308578e-01,
      "batch_size": 2.0000000000000000e+00,
      "benchmark_file:/home/dakkak/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 1.5291677899427402e+19,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)5; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.3342635194217454e+19,
      "bias_tensor_layout": 1.0000000000000000e+00,
      "compute_capability:7.5": 3.8315628306456499e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Quadro RTX 6000": 5.1174270964049613e+18,
      "group": 1.0000000000000000e+00,
      "host_name:aleph": 3.2334478980185999e+18,
      "input[0]": 2.0000000000000000e+00,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 2.0000000000000000e+00,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 8.0281600000000000e+05,
      "input_width": 2.8000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 6.2330000000000000e+03,
      "output_batch_size": 2.0000000000000000e+00,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 2.0070400000000000e+05,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00,
      "x_tensor_layout": 1.0000000000000000e+00,
      "y_tensor_layout": 1.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_2__8741601452745866875<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_SIGMOID>/input[0]:2/input[1]:512/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_2__8741601452745866875<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_TANH>/input[0]:2/input[1]:512/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_2__8741601452745866875<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:512/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 19822,
      "real_time": 3.5680007933807261e+04,
      "cpu_time": 4.1469060841496132e+04,
      "time_unit": "ns",
      "items_per_second": 2.8800567586935195e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 4.7120000000000000e+03,
      "advised_time": 4.3007999658584595e-02,
      "batch_size": 2.0000000000000000e+00,
      "benchmark_file:/home/dakkak/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 1.5291677899427402e+19,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.5541522464702913e+19,
      "bias_tensor_layout": 1.0000000000000000e+00,
      "compute_capability:7.5": 3.8315628306456499e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Quadro RTX 6000": 5.1174270964049613e+18,
      "group": 1.0000000000000000e+00,
      "host_name:aleph": 3.2334478980185999e+18,
      "input[0]": 2.0000000000000000e+00,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 2.0000000000000000e+00,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 8.0281600000000000e+05,
      "input_width": 2.8000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 1.9822000000000000e+04,
      "output_batch_size": 2.0000000000000000e+00,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 2.0070400000000000e+05,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 1.0000000000000000e+00,
      "workspace_bytes": 4.7120000000000000e+03,
      "workspace_megabytes": 4.4937133789062500e-03,
      "x_tensor_layout": 1.0000000000000000e+00,
      "y_tensor_layout": 1.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_2__8741601452745866875<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:2/input[1]:512/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 19619,
      "real_time": 3.5471212802876769e+04,
      "cpu_time": 4.1182673275861853e+04,
      "time_unit": "ns",
      "items_per_second": 2.8970097123847422e+12,
      "activation_mode": 3.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 4.7120000000000000e+03,
      "advised_time": 4.1248001158237457e-02,
      "batch_size": 2.0000000000000000e+00,
      "benchmark_file:/home/dakkak/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 1.5291677899427402e+19,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.5547362882776177e+19,
      "bias_tensor_layout": 1.0000000000000000e+00,
      "compute_capability:7.5": 3.8315628306456499e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Quadro RTX 6000": 5.1174270964049613e+18,
      "group": 1.0000000000000000e+00,
      "host_name:aleph": 3.2334478980185999e+18,
      "input[0]": 2.0000000000000000e+00,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 2.0000000000000000e+00,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 8.0281600000000000e+05,
      "input_width": 2.8000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 1.9619000000000000e+04,
      "output_batch_size": 2.0000000000000000e+00,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 2.0070400000000000e+05,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 1.0000000000000000e+00,
      "workspace_bytes": 4.7120000000000000e+03,
      "workspace_megabytes": 4.4937133789062500e-03,
      "x_tensor_layout": 1.0000000000000000e+00,
      "y_tensor_layout": 1.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_2__8741601452745866875<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_ELU>/input[0]:2/input[1]:512/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_2__8741601452745866875<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:512/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 19815,
      "real_time": 3.5484490554174692e+04,
      "cpu_time": 4.1185275246003133e+04,
      "time_unit": "ns",
      "items_per_second": 2.8959256958505327e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 4.7120000000000000e+03,
      "advised_time": 5.1520001143217087e-02,
      "batch_size": 2.0000000000000000e+00,
      "benchmark_file:/home/dakkak/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 1.5291677899427402e+19,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.5541522464702913e+19,
      "bias_tensor_layout": 1.0000000000000000e+00,
      "compute_capability:7.5": 3.8315628306456499e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Quadro RTX 6000": 5.1174270964049613e+18,
      "group": 1.0000000000000000e+00,
      "host_name:aleph": 3.2334478980185999e+18,
      "input[0]": 2.0000000000000000e+00,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 2.0000000000000000e+00,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 8.0281600000000000e+05,
      "input_width": 2.8000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 1.9815000000000000e+04,
      "output_batch_size": 2.0000000000000000e+00,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 2.0070400000000000e+05,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 1.0000000000000000e+00,
      "workspace_bytes": 4.7120000000000000e+03,
      "workspace_megabytes": 4.4937133789062500e-03,
      "x_tensor_layout": 1.0000000000000000e+00,
      "y_tensor_layout": 1.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_2__8741601452745866875<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:512/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 19774,
      "real_time": 3.5366243126919886e+04,
      "cpu_time": 4.1014194042599789e+04,
      "time_unit": "ns",
      "items_per_second": 2.9056082556244531e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 4.7120000000000000e+03,
      "advised_time": 3.9583999663591385e-02,
      "batch_size": 2.0000000000000000e+00,
      "benchmark_file:/home/dakkak/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 1.5291677899427402e+19,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.5541522464702913e+19,
      "bias_tensor_layout": 1.0000000000000000e+00,
      "compute_capability:7.5": 3.8315628306456499e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Quadro RTX 6000": 5.1174270964049613e+18,
      "group": 1.0000000000000000e+00,
      "host_name:aleph": 3.2334478980185999e+18,
      "input[0]": 2.0000000000000000e+00,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 2.0000000000000000e+00,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 8.0281600000000000e+05,
      "input_width": 2.8000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 1.9774000000000000e+04,
      "output_batch_size": 2.0000000000000000e+00,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 2.0070400000000000e+05,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 1.0000000000000000e+00,
      "workspace_bytes": 4.7120000000000000e+03,
      "workspace_megabytes": 4.4937133789062500e-03,
      "x_tensor_layout": 1.0000000000000000e+00,
      "y_tensor_layout": 1.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_2__8741601452745866875<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_IDENTITY>/input[0]:2/input[1]:512/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 19357,
      "real_time": 3.5493761070284127e+04,
      "cpu_time": 4.1188934235567423e+04,
      "time_unit": "ns",
      "items_per_second": 2.8951693171235234e+12,
      "activation_mode": 5.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 4.7120000000000000e+03,
      "advised_time": 4.1216000914573669e-02,
      "batch_size": 2.0000000000000000e+00,
      "benchmark_file:/home/dakkak/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 1.5291677899427402e+19,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)5; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 4.5833023350607309e+18,
      "bias_tensor_layout": 1.0000000000000000e+00,
      "compute_capability:7.5": 3.8315628306456499e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Quadro RTX 6000": 5.1174270964049613e+18,
      "group": 1.0000000000000000e+00,
      "host_name:aleph": 3.2334478980185999e+18,
      "input[0]": 2.0000000000000000e+00,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 2.0000000000000000e+00,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 8.0281600000000000e+05,
      "input_width": 2.8000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 1.9357000000000000e+04,
      "output_batch_size": 2.0000000000000000e+00,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 2.0070400000000000e+05,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 1.0000000000000000e+00,
      "workspace_bytes": 4.7120000000000000e+03,
      "workspace_megabytes": 4.4937133789062500e-03,
      "x_tensor_layout": 1.0000000000000000e+00,
      "y_tensor_layout": 1.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_2__8741601452745866875<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_SIGMOID>/input[0]:2/input[1]:512/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_2__8741601452745866875<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_TANH>/input[0]:2/input[1]:512/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_2__8741601452745866875<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:512/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_2__8741601452745866875<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:2/input[1]:512/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_2__8741601452745866875<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_ELU>/input[0]:2/input[1]:512/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_2__8741601452745866875<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:512/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_2__8741601452745866875<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:512/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_2__8741601452745866875<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_IDENTITY>/input[0]:2/input[1]:512/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_2__8741601452745866875<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_SIGMOID>/input[0]:2/input[1]:512/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_2__8741601452745866875<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_TANH>/input[0]:2/input[1]:512/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_2__8741601452745866875<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:512/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_2__8741601452745866875<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:2/input[1]:512/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_2__8741601452745866875<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_ELU>/input[0]:2/input[1]:512/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_2__8741601452745866875<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:512/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_2__8741601452745866875<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:512/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_2__8741601452745866875<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_IDENTITY>/input[0]:2/input[1]:512/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_2__8741601452745866875<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_SIGMOID>/input[0]:2/input[1]:512/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_2__8741601452745866875<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_TANH>/input[0]:2/input[1]:512/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_2__8741601452745866875<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:512/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_2__8741601452745866875<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:2/input[1]:512/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_2__8741601452745866875<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_ELU>/input[0]:2/input[1]:512/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_2__8741601452745866875<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:512/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_2__8741601452745866875<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:512/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_2__8741601452745866875<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_IDENTITY>/input[0]:2/input[1]:512/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_2__8741601452745866875<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_SIGMOID>/input[0]:2/input[1]:512/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_2__8741601452745866875<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_TANH>/input[0]:2/input[1]:512/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_2__8741601452745866875<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:512/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_2__8741601452745866875<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:2/input[1]:512/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_2__8741601452745866875<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_ELU>/input[0]:2/input[1]:512/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_2__8741601452745866875<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:512/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_2__8741601452745866875<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:512/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_2__8741601452745866875<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_IDENTITY>/input[0]:2/input[1]:512/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_2__8741601452745866875<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_SIGMOID>/input[0]:2/input[1]:512/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_2__8741601452745866875<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_TANH>/input[0]:2/input[1]:512/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_2__8741601452745866875<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:512/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_2__8741601452745866875<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:2/input[1]:512/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_2__8741601452745866875<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_ELU>/input[0]:2/input[1]:512/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_2__8741601452745866875<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:512/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_2__8741601452745866875<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:512/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_2__8741601452745866875<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_IDENTITY>/input[0]:2/input[1]:512/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_2__8741601452745866875<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_SIGMOID>/input[0]:2/input[1]:512/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_2__8741601452745866875<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_TANH>/input[0]:2/input[1]:512/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_2__8741601452745866875<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:512/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_2__8741601452745866875<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:2/input[1]:512/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_2__8741601452745866875<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_ELU>/input[0]:2/input[1]:512/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_2__8741601452745866875<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:512/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_2__8741601452745866875<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:512/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_2__8741601452745866875<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_IDENTITY>/input[0]:2/input[1]:512/input[2]:28/input[3]:28/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_2__3342797149130588737<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_SIGMOID>/input[0]:2/input[1]:256/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_2__3342797149130588737<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_TANH>/input[0]:2/input[1]:256/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_2__3342797149130588737<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:256/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 1140,
      "real_time": 6.1401802257087349e+05,
      "cpu_time": 6.2510091052601277e+05,
      "time_unit": "ns",
      "items_per_second": 4.1839345191263832e+10,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 6.6560000181198120e-01,
      "batch_size": 2.0000000000000000e+00,
      "benchmark_file:/home/dakkak/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 1.5291677899427402e+19,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 2.3191971996820818e+18,
      "bias_tensor_layout": 1.0000000000000000e+00,
      "compute_capability:7.5": 3.8315628306456499e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.5600000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:Quadro RTX 6000": 5.1174270964049613e+18,
      "group": 1.0000000000000000e+00,
      "host_name:aleph": 3.2334478980185999e+18,
      "input[0]": 2.0000000000000000e+00,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 2.0000000000000000e+00,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 1.0035200000000000e+05,
      "input_width": 1.4000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 2.5600000000000000e+02,
      "num_iterations": 1.1400000000000000e+03,
      "output_batch_size": 2.0000000000000000e+00,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 1.0035200000000000e+05,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00,
      "x_tensor_layout": 1.0000000000000000e+00,
      "y_tensor_layout": 1.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_2__3342797149130588737<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:2/input[1]:256/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 1140,
      "real_time": 6.1396336904931162e+05,
      "cpu_time": 6.2508021929811290e+05,
      "time_unit": "ns",
      "items_per_second": 4.1843069627720169e+10,
      "activation_mode": 3.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 6.4512002468109131e-01,
      "batch_size": 2.0000000000000000e+00,
      "benchmark_file:/home/dakkak/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 1.5291677899427402e+19,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.9889882919049984e+18,
      "bias_tensor_layout": 1.0000000000000000e+00,
      "compute_capability:7.5": 3.8315628306456499e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.5600000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:Quadro RTX 6000": 5.1174270964049613e+18,
      "group": 1.0000000000000000e+00,
      "host_name:aleph": 3.2334478980185999e+18,
      "input[0]": 2.0000000000000000e+00,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 2.0000000000000000e+00,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 1.0035200000000000e+05,
      "input_width": 1.4000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 2.5600000000000000e+02,
      "num_iterations": 1.1400000000000000e+03,
      "output_batch_size": 2.0000000000000000e+00,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 1.0035200000000000e+05,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00,
      "x_tensor_layout": 1.0000000000000000e+00,
      "y_tensor_layout": 1.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_2__3342797149130588737<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_ELU>/input[0]:2/input[1]:256/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_2__3342797149130588737<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:256/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 1140,
      "real_time": 6.1402287846839614e+05,
      "cpu_time": 6.2510782192888111e+05,
      "time_unit": "ns",
      "items_per_second": 4.1839014311780693e+10,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 6.6431999206542969e-01,
      "batch_size": 2.0000000000000000e+00,
      "benchmark_file:/home/dakkak/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 1.5291677899427402e+19,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 2.3191971996820818e+18,
      "bias_tensor_layout": 1.0000000000000000e+00,
      "compute_capability:7.5": 3.8315628306456499e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.5600000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:Quadro RTX 6000": 5.1174270964049613e+18,
      "group": 1.0000000000000000e+00,
      "host_name:aleph": 3.2334478980185999e+18,
      "input[0]": 2.0000000000000000e+00,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 2.0000000000000000e+00,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 1.0035200000000000e+05,
      "input_width": 1.4000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 2.5600000000000000e+02,
      "num_iterations": 1.1400000000000000e+03,
      "output_batch_size": 2.0000000000000000e+00,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 1.0035200000000000e+05,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00,
      "x_tensor_layout": 1.0000000000000000e+00,
      "y_tensor_layout": 1.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_2__3342797149130588737<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:256/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 1140,
      "real_time": 6.1382082956761378e+05,
      "cpu_time": 6.2488330263207853e+05,
      "time_unit": "ns",
      "items_per_second": 4.1852786289602730e+10,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 6.4313602447509766e-01,
      "batch_size": 2.0000000000000000e+00,
      "benchmark_file:/home/dakkak/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 1.5291677899427402e+19,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 2.3191971996820818e+18,
      "bias_tensor_layout": 1.0000000000000000e+00,
      "compute_capability:7.5": 3.8315628306456499e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.5600000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:Quadro RTX 6000": 5.1174270964049613e+18,
      "group": 1.0000000000000000e+00,
      "host_name:aleph": 3.2334478980185999e+18,
      "input[0]": 2.0000000000000000e+00,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 2.0000000000000000e+00,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 1.0035200000000000e+05,
      "input_width": 1.4000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 2.5600000000000000e+02,
      "num_iterations": 1.1400000000000000e+03,
      "output_batch_size": 2.0000000000000000e+00,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 1.0035200000000000e+05,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00,
      "x_tensor_layout": 1.0000000000000000e+00,
      "y_tensor_layout": 1.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_2__3342797149130588737<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_IDENTITY>/input[0]:2/input[1]:256/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 1141,
      "real_time": 6.1401134596829035e+05,
      "cpu_time": 6.2513379929902859e+05,
      "time_unit": "ns",
      "items_per_second": 4.1839800141619415e+10,
      "activation_mode": 5.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 6.4591997861862183e-01,
      "batch_size": 2.0000000000000000e+00,
      "benchmark_file:/home/dakkak/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 1.5291677899427402e+19,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)5; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.3342635194217454e+19,
      "bias_tensor_layout": 1.0000000000000000e+00,
      "compute_capability:7.5": 3.8315628306456499e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.5600000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:Quadro RTX 6000": 5.1174270964049613e+18,
      "group": 1.0000000000000000e+00,
      "host_name:aleph": 3.2334478980185999e+18,
      "input[0]": 2.0000000000000000e+00,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 2.0000000000000000e+00,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 1.0035200000000000e+05,
      "input_width": 1.4000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 2.5600000000000000e+02,
      "num_iterations": 1.1410000000000000e+03,
      "output_batch_size": 2.0000000000000000e+00,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 1.0035200000000000e+05,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00,
      "x_tensor_layout": 1.0000000000000000e+00,
      "y_tensor_layout": 1.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_2__3342797149130588737<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_SIGMOID>/input[0]:2/input[1]:256/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_2__3342797149130588737<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_TANH>/input[0]:2/input[1]:256/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_2__3342797149130588737<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:256/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 8502,
      "real_time": 8.2531274075603331e+04,
      "cpu_time": 8.8489965655173553e+04,
      "time_unit": "ns",
      "items_per_second": 3.1127729806359705e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.1840000000000000e+03,
      "advised_time": 1.2707200646400452e-01,
      "batch_size": 2.0000000000000000e+00,
      "benchmark_file:/home/dakkak/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 1.5291677899427402e+19,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.5541522464702913e+19,
      "bias_tensor_layout": 1.0000000000000000e+00,
      "compute_capability:7.5": 3.8315628306456499e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.5600000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:Quadro RTX 6000": 5.1174270964049613e+18,
      "group": 1.0000000000000000e+00,
      "host_name:aleph": 3.2334478980185999e+18,
      "input[0]": 2.0000000000000000e+00,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 2.0000000000000000e+00,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 1.0035200000000000e+05,
      "input_width": 1.4000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 2.5600000000000000e+02,
      "num_iterations": 8.5020000000000000e+03,
      "output_batch_size": 2.0000000000000000e+00,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 1.0035200000000000e+05,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 1.0000000000000000e+00,
      "workspace_bytes": 1.1840000000000000e+03,
      "workspace_megabytes": 1.1291503906250000e-03,
      "x_tensor_layout": 1.0000000000000000e+00,
      "y_tensor_layout": 1.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_2__3342797149130588737<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:2/input[1]:256/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 8501,
      "real_time": 8.2298191334215415e+04,
      "cpu_time": 8.8219878955386084e+04,
      "time_unit": "ns",
      "items_per_second": 3.1215888932080762e+11,
      "activation_mode": 3.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.1840000000000000e+03,
      "advised_time": 1.3004800677299500e-01,
      "batch_size": 2.0000000000000000e+00,
      "benchmark_file:/home/dakkak/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 1.5291677899427402e+19,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.5547362882776177e+19,
      "bias_tensor_layout": 1.0000000000000000e+00,
      "compute_capability:7.5": 3.8315628306456499e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.5600000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:Quadro RTX 6000": 5.1174270964049613e+18,
      "group": 1.0000000000000000e+00,
      "host_name:aleph": 3.2334478980185999e+18,
      "input[0]": 2.0000000000000000e+00,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 2.0000000000000000e+00,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 1.0035200000000000e+05,
      "input_width": 1.4000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 2.5600000000000000e+02,
      "num_iterations": 8.5010000000000000e+03,
      "output_batch_size": 2.0000000000000000e+00,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 1.0035200000000000e+05,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 1.0000000000000000e+00,
      "workspace_bytes": 1.1840000000000000e+03,
      "workspace_megabytes": 1.1291503906250000e-03,
      "x_tensor_layout": 1.0000000000000000e+00,
      "y_tensor_layout": 1.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_2__3342797149130588737<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_ELU>/input[0]:2/input[1]:256/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_2__3342797149130588737<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:256/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 8527,
      "real_time": 8.2337943700125164e+04,
      "cpu_time": 8.8289724756566895e+04,
      "time_unit": "ns",
      "items_per_second": 3.1200818050015192e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.1840000000000000e+03,
      "advised_time": 9.6575997769832611e-02,
      "batch_size": 2.0000000000000000e+00,
      "benchmark_file:/home/dakkak/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 1.5291677899427402e+19,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.5541522464702913e+19,
      "bias_tensor_layout": 1.0000000000000000e+00,
      "compute_capability:7.5": 3.8315628306456499e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.5600000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:Quadro RTX 6000": 5.1174270964049613e+18,
      "group": 1.0000000000000000e+00,
      "host_name:aleph": 3.2334478980185999e+18,
      "input[0]": 2.0000000000000000e+00,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 2.0000000000000000e+00,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 1.0035200000000000e+05,
      "input_width": 1.4000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 2.5600000000000000e+02,
      "num_iterations": 8.5270000000000000e+03,
      "output_batch_size": 2.0000000000000000e+00,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 1.0035200000000000e+05,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 1.0000000000000000e+00,
      "workspace_bytes": 1.1840000000000000e+03,
      "workspace_megabytes": 1.1291503906250000e-03,
      "x_tensor_layout": 1.0000000000000000e+00,
      "y_tensor_layout": 1.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_2__3342797149130588737<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:256/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 8472,
      "real_time": 8.2505355465750894e+04,
      "cpu_time": 8.8432322119765813e+04,
      "time_unit": "ns",
      "items_per_second": 3.1137508413819653e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.1840000000000000e+03,
      "advised_time": 9.5807999372482300e-02,
      "batch_size": 2.0000000000000000e+00,
      "benchmark_file:/home/dakkak/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 1.5291677899427402e+19,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.5541522464702913e+19,
      "bias_tensor_layout": 1.0000000000000000e+00,
      "compute_capability:7.5": 3.8315628306456499e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.5600000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:Quadro RTX 6000": 5.1174270964049613e+18,
      "group": 1.0000000000000000e+00,
      "host_name:aleph": 3.2334478980185999e+18,
      "input[0]": 2.0000000000000000e+00,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 2.0000000000000000e+00,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 1.0035200000000000e+05,
      "input_width": 1.4000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 2.5600000000000000e+02,
      "num_iterations": 8.4720000000000000e+03,
      "output_batch_size": 2.0000000000000000e+00,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 1.0035200000000000e+05,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 1.0000000000000000e+00,
      "workspace_bytes": 1.1840000000000000e+03,
      "workspace_megabytes": 1.1291503906250000e-03,
      "x_tensor_layout": 1.0000000000000000e+00,
      "y_tensor_layout": 1.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_2__3342797149130588737<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_IDENTITY>/input[0]:2/input[1]:256/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 8508,
      "real_time": 8.2556008947824084e+04,
      "cpu_time": 8.8485108016009210e+04,
      "time_unit": "ns",
      "items_per_second": 3.1118403526793927e+11,
      "activation_mode": 5.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.1840000000000000e+03,
      "advised_time": 1.2508800625801086e-01,
      "batch_size": 2.0000000000000000e+00,
      "benchmark_file:/home/dakkak/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 1.5291677899427402e+19,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)5; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 4.5833023350607309e+18,
      "bias_tensor_layout": 1.0000000000000000e+00,
      "compute_capability:7.5": 3.8315628306456499e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.5600000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:Quadro RTX 6000": 5.1174270964049613e+18,
      "group": 1.0000000000000000e+00,
      "host_name:aleph": 3.2334478980185999e+18,
      "input[0]": 2.0000000000000000e+00,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 2.0000000000000000e+00,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 1.0035200000000000e+05,
      "input_width": 1.4000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 2.5600000000000000e+02,
      "num_iterations": 8.5080000000000000e+03,
      "output_batch_size": 2.0000000000000000e+00,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 1.0035200000000000e+05,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 1.0000000000000000e+00,
      "workspace_bytes": 1.1840000000000000e+03,
      "workspace_megabytes": 1.1291503906250000e-03,
      "x_tensor_layout": 1.0000000000000000e+00,
      "y_tensor_layout": 1.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_2__3342797149130588737<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_SIGMOID>/input[0]:2/input[1]:256/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_2__3342797149130588737<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_TANH>/input[0]:2/input[1]:256/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_2__3342797149130588737<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:256/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_2__3342797149130588737<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:2/input[1]:256/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_2__3342797149130588737<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_ELU>/input[0]:2/input[1]:256/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_2__3342797149130588737<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:256/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_2__3342797149130588737<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:256/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_2__3342797149130588737<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_IDENTITY>/input[0]:2/input[1]:256/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_2__3342797149130588737<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_SIGMOID>/input[0]:2/input[1]:256/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_2__3342797149130588737<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_TANH>/input[0]:2/input[1]:256/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_2__3342797149130588737<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:256/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_2__3342797149130588737<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:2/input[1]:256/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_2__3342797149130588737<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_ELU>/input[0]:2/input[1]:256/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_2__3342797149130588737<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:256/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_2__3342797149130588737<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:256/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_2__3342797149130588737<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_IDENTITY>/input[0]:2/input[1]:256/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_2__3342797149130588737<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_SIGMOID>/input[0]:2/input[1]:256/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_2__3342797149130588737<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_TANH>/input[0]:2/input[1]:256/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_2__3342797149130588737<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:256/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_2__3342797149130588737<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:2/input[1]:256/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_2__3342797149130588737<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_ELU>/input[0]:2/input[1]:256/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_2__3342797149130588737<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:256/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_2__3342797149130588737<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:256/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_2__3342797149130588737<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_IDENTITY>/input[0]:2/input[1]:256/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_2__3342797149130588737<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_SIGMOID>/input[0]:2/input[1]:256/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_2__3342797149130588737<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_TANH>/input[0]:2/input[1]:256/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_2__3342797149130588737<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:256/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_2__3342797149130588737<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:2/input[1]:256/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_2__3342797149130588737<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_ELU>/input[0]:2/input[1]:256/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_2__3342797149130588737<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:256/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_2__3342797149130588737<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:256/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_2__3342797149130588737<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_IDENTITY>/input[0]:2/input[1]:256/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_2__3342797149130588737<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_SIGMOID>/input[0]:2/input[1]:256/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_2__3342797149130588737<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_TANH>/input[0]:2/input[1]:256/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_2__3342797149130588737<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:256/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_2__3342797149130588737<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:2/input[1]:256/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_2__3342797149130588737<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_ELU>/input[0]:2/input[1]:256/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_2__3342797149130588737<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:256/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_2__3342797149130588737<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:256/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_2__3342797149130588737<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_IDENTITY>/input[0]:2/input[1]:256/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_2__3342797149130588737<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_SIGMOID>/input[0]:2/input[1]:256/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_2__3342797149130588737<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_TANH>/input[0]:2/input[1]:256/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_2__3342797149130588737<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:256/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_2__3342797149130588737<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:2/input[1]:256/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_2__3342797149130588737<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_ELU>/input[0]:2/input[1]:256/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_2__3342797149130588737<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:256/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_2__3342797149130588737<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:256/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_2__3342797149130588737<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_IDENTITY>/input[0]:2/input[1]:256/input[2]:14/input[3]:14/filter_count:256/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_2__16840028193500049748<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_SIGMOID>/input[0]:2/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_2__16840028193500049748<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_TANH>/input[0]:2/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_2__16840028193500049748<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 2445,
      "real_time": 2.8637180771204457e+05,
      "cpu_time": 2.9322662372165499e+05,
      "time_unit": "ns",
      "items_per_second": 7.1767153911553137e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 2.9750400781631470e-01,
      "batch_size": 2.0000000000000000e+00,
      "benchmark_file:/home/dakkak/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 1.5291677899427402e+19,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 2.3191971996820818e+18,
      "bias_tensor_layout": 1.0000000000000000e+00,
      "compute_capability:7.5": 3.8315628306456499e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Quadro RTX 6000": 5.1174270964049613e+18,
      "group": 1.0000000000000000e+00,
      "host_name:aleph": 3.2334478980185999e+18,
      "input[0]": 2.0000000000000000e+00,
      "input[1]": 1.0240000000000000e+03,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 2.0000000000000000e+00,
      "input_channels": 1.0240000000000000e+03,
      "input_height": 1.4000000000000000e+01,
      "input_size": 4.0140800000000000e+05,
      "input_width": 1.4000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 2.4450000000000000e+03,
      "output_batch_size": 2.0000000000000000e+00,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 5.0176000000000000e+04,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "w_filter_layout": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00,
      "x_tensor_layout": 1.0000000000000000e+00,
      "y_tensor_layout": 1.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_2__16840028193500049748<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:2/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 2444,
      "real_time": 2.8644027437065128e+05,
      "cpu_time": 2.9336184697212873e+05,
      "time_unit": "ns",
      "items_per_second": 7.1749999699433911e+11,
      "activation_mode": 3.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 2.9724800586700439e-01,
      "batch_size": 2.0000000000000000e+00,
      "benchmark_file:/home/dakkak/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 1.5291677899427402e+19,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.9889882919049984e+18,
      "bias_tensor_layout": 1.0000000000000000e+00,
      "compute_capability:7.5": 3.8315628306456499e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Quadro RTX 6000": 5.1174270964049613e+18,
      "group": 1.0000000000000000e+00,
      "host_name:aleph": 3.2334478980185999e+18,
      "input[0]": 2.0000000000000000e+00,
      "input[1]": 1.0240000000000000e+03,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 2.0000000000000000e+00,
      "input_channels": 1.0240000000000000e+03,
      "input_height": 1.4000000000000000e+01,
      "input_size": 4.0140800000000000e+05,
      "input_width": 1.4000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 2.4440000000000000e+03,
      "output_batch_size": 2.0000000000000000e+00,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 5.0176000000000000e+04,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "w_filter_layout": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00,
      "x_tensor_layout": 1.0000000000000000e+00,
      "y_tensor_layout": 1.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_2__16840028193500049748<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_ELU>/input[0]:2/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_2__16840028193500049748<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 2445,
      "real_time": 2.8648801547416119e+05,
      "cpu_time": 2.9343838772989507e+05,
      "time_unit": "ns",
      "items_per_second": 7.1738043094000305e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 2.9785600304603577e-01,
      "batch_size": 2.0000000000000000e+00,
      "benchmark_file:/home/dakkak/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 1.5291677899427402e+19,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 2.3191971996820818e+18,
      "bias_tensor_layout": 1.0000000000000000e+00,
      "compute_capability:7.5": 3.8315628306456499e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Quadro RTX 6000": 5.1174270964049613e+18,
      "group": 1.0000000000000000e+00,
      "host_name:aleph": 3.2334478980185999e+18,
      "input[0]": 2.0000000000000000e+00,
      "input[1]": 1.0240000000000000e+03,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 2.0000000000000000e+00,
      "input_channels": 1.0240000000000000e+03,
      "input_height": 1.4000000000000000e+01,
      "input_size": 4.0140800000000000e+05,
      "input_width": 1.4000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 2.4450000000000000e+03,
      "output_batch_size": 2.0000000000000000e+00,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 5.0176000000000000e+04,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "w_filter_layout": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00,
      "x_tensor_layout": 1.0000000000000000e+00,
      "y_tensor_layout": 1.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_2__16840028193500049748<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 2445,
      "real_time": 2.8658401542905043e+05,
      "cpu_time": 2.9354635419212945e+05,
      "time_unit": "ns",
      "items_per_second": 7.1714012273961182e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 2.9695999622344971e-01,
      "batch_size": 2.0000000000000000e+00,
      "benchmark_file:/home/dakkak/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 1.5291677899427402e+19,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 2.3191971996820818e+18,
      "bias_tensor_layout": 1.0000000000000000e+00,
      "compute_capability:7.5": 3.8315628306456499e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Quadro RTX 6000": 5.1174270964049613e+18,
      "group": 1.0000000000000000e+00,
      "host_name:aleph": 3.2334478980185999e+18,
      "input[0]": 2.0000000000000000e+00,
      "input[1]": 1.0240000000000000e+03,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 2.0000000000000000e+00,
      "input_channels": 1.0240000000000000e+03,
      "input_height": 1.4000000000000000e+01,
      "input_size": 4.0140800000000000e+05,
      "input_width": 1.4000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 2.4450000000000000e+03,
      "output_batch_size": 2.0000000000000000e+00,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 5.0176000000000000e+04,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "w_filter_layout": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00,
      "x_tensor_layout": 1.0000000000000000e+00,
      "y_tensor_layout": 1.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_2__16840028193500049748<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_IDENTITY>/input[0]:2/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 2444,
      "real_time": 2.8648564289581205e+05,
      "cpu_time": 2.9338804296229430e+05,
      "time_unit": "ns",
      "items_per_second": 7.1738637204497900e+11,
      "activation_mode": 5.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 3.1542399525642395e-01,
      "batch_size": 2.0000000000000000e+00,
      "benchmark_file:/home/dakkak/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 1.5291677899427402e+19,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)5; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.3342635194217454e+19,
      "bias_tensor_layout": 1.0000000000000000e+00,
      "compute_capability:7.5": 3.8315628306456499e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Quadro RTX 6000": 5.1174270964049613e+18,
      "group": 1.0000000000000000e+00,
      "host_name:aleph": 3.2334478980185999e+18,
      "input[0]": 2.0000000000000000e+00,
      "input[1]": 1.0240000000000000e+03,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 2.0000000000000000e+00,
      "input_channels": 1.0240000000000000e+03,
      "input_height": 1.4000000000000000e+01,
      "input_size": 4.0140800000000000e+05,
      "input_width": 1.4000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 2.4440000000000000e+03,
      "output_batch_size": 2.0000000000000000e+00,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 5.0176000000000000e+04,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "w_filter_layout": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00,
      "x_tensor_layout": 1.0000000000000000e+00,
      "y_tensor_layout": 1.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_2__16840028193500049748<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_SIGMOID>/input[0]:2/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_2__16840028193500049748<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_TANH>/input[0]:2/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_2__16840028193500049748<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 15423,
      "real_time": 4.5144381098991289e+04,
      "cpu_time": 5.0921384944444297e+04,
      "time_unit": "ns",
      "items_per_second": 4.5525243894547969e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 3.0000000000000000e+02,
      "advised_time": 8.6815997958183289e-02,
      "batch_size": 2.0000000000000000e+00,
      "benchmark_file:/home/dakkak/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 1.5291677899427402e+19,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.5541522464702913e+19,
      "bias_tensor_layout": 1.0000000000000000e+00,
      "compute_capability:7.5": 3.8315628306456499e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Quadro RTX 6000": 5.1174270964049613e+18,
      "group": 1.0000000000000000e+00,
      "host_name:aleph": 3.2334478980185999e+18,
      "input[0]": 2.0000000000000000e+00,
      "input[1]": 1.0240000000000000e+03,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 2.0000000000000000e+00,
      "input_channels": 1.0240000000000000e+03,
      "input_height": 1.4000000000000000e+01,
      "input_size": 4.0140800000000000e+05,
      "input_width": 1.4000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 1.5423000000000000e+04,
      "output_batch_size": 2.0000000000000000e+00,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 5.0176000000000000e+04,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "w_filter_layout": 1.0000000000000000e+00,
      "workspace_bytes": 3.0000000000000000e+02,
      "workspace_megabytes": 2.8610229492187500e-04,
      "x_tensor_layout": 1.0000000000000000e+00,
      "y_tensor_layout": 1.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_2__16840028193500049748<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:2/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 15468,
      "real_time": 4.5377191521051260e+04,
      "cpu_time": 5.1254669123373053e+04,
      "time_unit": "ns",
      "items_per_second": 4.5291673880842822e+12,
      "activation_mode": 3.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 3.0000000000000000e+02,
      "advised_time": 8.6047999560832977e-02,
      "batch_size": 2.0000000000000000e+00,
      "benchmark_file:/home/dakkak/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 1.5291677899427402e+19,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.5547362882776177e+19,
      "bias_tensor_layout": 1.0000000000000000e+00,
      "compute_capability:7.5": 3.8315628306456499e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Quadro RTX 6000": 5.1174270964049613e+18,
      "group": 1.0000000000000000e+00,
      "host_name:aleph": 3.2334478980185999e+18,
      "input[0]": 2.0000000000000000e+00,
      "input[1]": 1.0240000000000000e+03,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 2.0000000000000000e+00,
      "input_channels": 1.0240000000000000e+03,
      "input_height": 1.4000000000000000e+01,
      "input_size": 4.0140800000000000e+05,
      "input_width": 1.4000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 1.5468000000000000e+04,
      "output_batch_size": 2.0000000000000000e+00,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 5.0176000000000000e+04,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "w_filter_layout": 1.0000000000000000e+00,
      "workspace_bytes": 3.0000000000000000e+02,
      "workspace_megabytes": 2.8610229492187500e-04,
      "x_tensor_layout": 1.0000000000000000e+00,
      "y_tensor_layout": 1.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_2__16840028193500049748<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_ELU>/input[0]:2/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_2__16840028193500049748<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 15421,
      "real_time": 4.5203982997995881e+04,
      "cpu_time": 5.1027573892844499e+04,
      "time_unit": "ns",
      "items_per_second": 4.5465218409871484e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 3.0000000000000000e+02,
      "advised_time": 5.8143999427556992e-02,
      "batch_size": 2.0000000000000000e+00,
      "benchmark_file:/home/dakkak/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 1.5291677899427402e+19,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.5541522464702913e+19,
      "bias_tensor_layout": 1.0000000000000000e+00,
      "compute_capability:7.5": 3.8315628306456499e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Quadro RTX 6000": 5.1174270964049613e+18,
      "group": 1.0000000000000000e+00,
      "host_name:aleph": 3.2334478980185999e+18,
      "input[0]": 2.0000000000000000e+00,
      "input[1]": 1.0240000000000000e+03,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 2.0000000000000000e+00,
      "input_channels": 1.0240000000000000e+03,
      "input_height": 1.4000000000000000e+01,
      "input_size": 4.0140800000000000e+05,
      "input_width": 1.4000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 1.5421000000000000e+04,
      "output_batch_size": 2.0000000000000000e+00,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 5.0176000000000000e+04,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "w_filter_layout": 1.0000000000000000e+00,
      "workspace_bytes": 3.0000000000000000e+02,
      "workspace_megabytes": 2.8610229492187500e-04,
      "x_tensor_layout": 1.0000000000000000e+00,
      "y_tensor_layout": 1.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_2__16840028193500049748<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 15445,
      "real_time": 4.5286683746690520e+04,
      "cpu_time": 5.1127674004620923e+04,
      "time_unit": "ns",
      "items_per_second": 4.5382191628244170e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 3.0000000000000000e+02,
      "advised_time": 7.3119997978210449e-02,
      "batch_size": 2.0000000000000000e+00,
      "benchmark_file:/home/dakkak/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 1.5291677899427402e+19,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.5541522464702913e+19,
      "bias_tensor_layout": 1.0000000000000000e+00,
      "compute_capability:7.5": 3.8315628306456499e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Quadro RTX 6000": 5.1174270964049613e+18,
      "group": 1.0000000000000000e+00,
      "host_name:aleph": 3.2334478980185999e+18,
      "input[0]": 2.0000000000000000e+00,
      "input[1]": 1.0240000000000000e+03,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 2.0000000000000000e+00,
      "input_channels": 1.0240000000000000e+03,
      "input_height": 1.4000000000000000e+01,
      "input_size": 4.0140800000000000e+05,
      "input_width": 1.4000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 1.5445000000000000e+04,
      "output_batch_size": 2.0000000000000000e+00,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 5.0176000000000000e+04,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "w_filter_layout": 1.0000000000000000e+00,
      "workspace_bytes": 3.0000000000000000e+02,
      "workspace_megabytes": 2.8610229492187500e-04,
      "x_tensor_layout": 1.0000000000000000e+00,
      "y_tensor_layout": 1.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_2__16840028193500049748<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_IDENTITY>/input[0]:2/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 15457,
      "real_time": 4.5212008412817951e+04,
      "cpu_time": 5.1038241250011553e+04,
      "time_unit": "ns",
      "items_per_second": 4.5457148048688154e+12,
      "activation_mode": 5.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 3.0000000000000000e+02,
      "advised_time": 7.7279999852180481e-02,
      "batch_size": 2.0000000000000000e+00,
      "benchmark_file:/home/dakkak/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 1.5291677899427402e+19,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)5; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 4.5833023350607309e+18,
      "bias_tensor_layout": 1.0000000000000000e+00,
      "compute_capability:7.5": 3.8315628306456499e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Quadro RTX 6000": 5.1174270964049613e+18,
      "group": 1.0000000000000000e+00,
      "host_name:aleph": 3.2334478980185999e+18,
      "input[0]": 2.0000000000000000e+00,
      "input[1]": 1.0240000000000000e+03,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 2.0000000000000000e+00,
      "input_channels": 1.0240000000000000e+03,
      "input_height": 1.4000000000000000e+01,
      "input_size": 4.0140800000000000e+05,
      "input_width": 1.4000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 1.5457000000000000e+04,
      "output_batch_size": 2.0000000000000000e+00,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 5.0176000000000000e+04,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "w_filter_layout": 1.0000000000000000e+00,
      "workspace_bytes": 3.0000000000000000e+02,
      "workspace_megabytes": 2.8610229492187500e-04,
      "x_tensor_layout": 1.0000000000000000e+00,
      "y_tensor_layout": 1.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_2__16840028193500049748<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_SIGMOID>/input[0]:2/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_2__16840028193500049748<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_TANH>/input[0]:2/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_2__16840028193500049748<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_2__16840028193500049748<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:2/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_2__16840028193500049748<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_ELU>/input[0]:2/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_2__16840028193500049748<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_2__16840028193500049748<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_2__16840028193500049748<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_IDENTITY>/input[0]:2/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_2__16840028193500049748<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_SIGMOID>/input[0]:2/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_2__16840028193500049748<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_TANH>/input[0]:2/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_2__16840028193500049748<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_2__16840028193500049748<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:2/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_2__16840028193500049748<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_ELU>/input[0]:2/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_2__16840028193500049748<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_2__16840028193500049748<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_2__16840028193500049748<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_IDENTITY>/input[0]:2/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_2__16840028193500049748<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_SIGMOID>/input[0]:2/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_2__16840028193500049748<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_TANH>/input[0]:2/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_2__16840028193500049748<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_2__16840028193500049748<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:2/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_2__16840028193500049748<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_ELU>/input[0]:2/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_2__16840028193500049748<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_2__16840028193500049748<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_2__16840028193500049748<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_IDENTITY>/input[0]:2/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_2__16840028193500049748<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_SIGMOID>/input[0]:2/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_2__16840028193500049748<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_TANH>/input[0]:2/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_2__16840028193500049748<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_2__16840028193500049748<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:2/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_2__16840028193500049748<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_ELU>/input[0]:2/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_2__16840028193500049748<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_2__16840028193500049748<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_2__16840028193500049748<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_IDENTITY>/input[0]:2/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_2__16840028193500049748<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_SIGMOID>/input[0]:2/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_2__16840028193500049748<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_TANH>/input[0]:2/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_2__16840028193500049748<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_2__16840028193500049748<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:2/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_2__16840028193500049748<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_ELU>/input[0]:2/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_2__16840028193500049748<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_2__16840028193500049748<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_2__16840028193500049748<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_IDENTITY>/input[0]:2/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_2__16840028193500049748<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_SIGMOID>/input[0]:2/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_2__16840028193500049748<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_TANH>/input[0]:2/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_2__16840028193500049748<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_2__16840028193500049748<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:2/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_2__16840028193500049748<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_ELU>/input[0]:2/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_2__16840028193500049748<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_2__16840028193500049748<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_0_TENSORCOREHALF__BatchSize_2__16840028193500049748<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_IDENTITY>/input[0]:2/input[1]:1024/input[2]:14/input[3]:14/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_2__13560898936118562605<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_SIGMOID>/input[0]:2/input[1]:256/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_2__13560898936118562605<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_TANH>/input[0]:2/input[1]:256/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_2__13560898936118562605<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:256/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 6251,
      "real_time": 1.1183858740677711e+05,
      "cpu_time": 1.1798527115667921e+05,
      "time_unit": "ns",
      "items_per_second": 9.1882820037990759e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 1.1635199934244156e-01,
      "batch_size": 2.0000000000000000e+00,
      "benchmark_file:/home/dakkak/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 1.5291677899427402e+19,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 2.3191971996820818e+18,
      "bias_tensor_layout": 1.0000000000000000e+00,
      "compute_capability:7.5": 3.8315628306456499e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Quadro RTX 6000": 5.1174270964049613e+18,
      "group": 1.0000000000000000e+00,
      "host_name:aleph": 3.2334478980185999e+18,
      "input[0]": 2.0000000000000000e+00,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 2.0000000000000000e+00,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 5.6000000000000000e+01,
      "input_size": 1.6056320000000000e+06,
      "input_width": 5.6000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 6.2510000000000000e+03,
      "output_batch_size": 2.0000000000000000e+00,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 5.6000000000000000e+01,
      "output_size": 4.0140800000000000e+05,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00,
      "x_tensor_layout": 1.0000000000000000e+00,
      "y_tensor_layout": 1.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_2__13560898936118562605<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:2/input[1]:256/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 6269,
      "real_time": 1.1167692229591872e+05,
      "cpu_time": 1.1762635364493770e+05,
      "time_unit": "ns",
      "items_per_second": 9.2015830923158801e+11,
      "activation_mode": 3.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 1.1555200070142746e-01,
      "batch_size": 2.0000000000000000e+00,
      "benchmark_file:/home/dakkak/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 1.5291677899427402e+19,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.9889882919049984e+18,
      "bias_tensor_layout": 1.0000000000000000e+00,
      "compute_capability:7.5": 3.8315628306456499e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Quadro RTX 6000": 5.1174270964049613e+18,
      "group": 1.0000000000000000e+00,
      "host_name:aleph": 3.2334478980185999e+18,
      "input[0]": 2.0000000000000000e+00,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 2.0000000000000000e+00,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 5.6000000000000000e+01,
      "input_size": 1.6056320000000000e+06,
      "input_width": 5.6000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 6.2690000000000000e+03,
      "output_batch_size": 2.0000000000000000e+00,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 5.6000000000000000e+01,
      "output_size": 4.0140800000000000e+05,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00,
      "x_tensor_layout": 1.0000000000000000e+00,
      "y_tensor_layout": 1.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_2__13560898936118562605<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_ELU>/input[0]:2/input[1]:256/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_2__13560898936118562605<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:256/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 6271,
      "real_time": 1.1165879279122381e+05,
      "cpu_time": 1.1759267852012967e+05,
      "time_unit": "ns",
      "items_per_second": 9.2030771093986597e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 1.1241599917411804e-01,
      "batch_size": 2.0000000000000000e+00,
      "benchmark_file:/home/dakkak/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 1.5291677899427402e+19,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 2.3191971996820818e+18,
      "bias_tensor_layout": 1.0000000000000000e+00,
      "compute_capability:7.5": 3.8315628306456499e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Quadro RTX 6000": 5.1174270964049613e+18,
      "group": 1.0000000000000000e+00,
      "host_name:aleph": 3.2334478980185999e+18,
      "input[0]": 2.0000000000000000e+00,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 2.0000000000000000e+00,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 5.6000000000000000e+01,
      "input_size": 1.6056320000000000e+06,
      "input_width": 5.6000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 6.2710000000000000e+03,
      "output_batch_size": 2.0000000000000000e+00,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 5.6000000000000000e+01,
      "output_size": 4.0140800000000000e+05,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00,
      "x_tensor_layout": 1.0000000000000000e+00,
      "y_tensor_layout": 1.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_2__13560898936118562605<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:256/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 6271,
      "real_time": 1.1172491562774740e+05,
      "cpu_time": 1.1764019422719169e+05,
      "time_unit": "ns",
      "items_per_second": 9.1976303962836890e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 1.1433599889278412e-01,
      "batch_size": 2.0000000000000000e+00,
      "benchmark_file:/home/dakkak/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 1.5291677899427402e+19,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 2.3191971996820818e+18,
      "bias_tensor_layout": 1.0000000000000000e+00,
      "compute_capability:7.5": 3.8315628306456499e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Quadro RTX 6000": 5.1174270964049613e+18,
      "group": 1.0000000000000000e+00,
      "host_name:aleph": 3.2334478980185999e+18,
      "input[0]": 2.0000000000000000e+00,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 2.0000000000000000e+00,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 5.6000000000000000e+01,
      "input_size": 1.6056320000000000e+06,
      "input_width": 5.6000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 6.2710000000000000e+03,
      "output_batch_size": 2.0000000000000000e+00,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 5.6000000000000000e+01,
      "output_size": 4.0140800000000000e+05,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00,
      "x_tensor_layout": 1.0000000000000000e+00,
      "y_tensor_layout": 1.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_2__13560898936118562605<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_IDENTITY>/input[0]:2/input[1]:256/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 6264,
      "real_time": 1.1163258773339877e+05,
      "cpu_time": 1.1749861797593873e+05,
      "time_unit": "ns",
      "items_per_second": 9.2052374746890894e+11,
      "activation_mode": 5.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 1.1452800035476685e-01,
      "batch_size": 2.0000000000000000e+00,
      "benchmark_file:/home/dakkak/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 1.5291677899427402e+19,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)5; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.3342635194217454e+19,
      "bias_tensor_layout": 1.0000000000000000e+00,
      "compute_capability:7.5": 3.8315628306456499e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Quadro RTX 6000": 5.1174270964049613e+18,
      "group": 1.0000000000000000e+00,
      "host_name:aleph": 3.2334478980185999e+18,
      "input[0]": 2.0000000000000000e+00,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 2.0000000000000000e+00,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 5.6000000000000000e+01,
      "input_size": 1.6056320000000000e+06,
      "input_width": 5.6000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 6.2640000000000000e+03,
      "output_batch_size": 2.0000000000000000e+00,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 5.6000000000000000e+01,
      "output_size": 4.0140800000000000e+05,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00,
      "x_tensor_layout": 1.0000000000000000e+00,
      "y_tensor_layout": 1.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_2__13560898936118562605<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_SIGMOID>/input[0]:2/input[1]:256/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_2__13560898936118562605<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_TANH>/input[0]:2/input[1]:256/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_2__13560898936118562605<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:256/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 23323,
      "real_time": 2.9970202834213313e+04,
      "cpu_time": 3.5714117523466673e+04,
      "time_unit": "ns",
      "items_per_second": 3.4287538382186382e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.8824000000000000e+04,
      "advised_time": 5.4816000163555145e-02,
      "batch_size": 2.0000000000000000e+00,
      "benchmark_file:/home/dakkak/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 1.5291677899427402e+19,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.5541522464702913e+19,
      "bias_tensor_layout": 1.0000000000000000e+00,
      "compute_capability:7.5": 3.8315628306456499e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Quadro RTX 6000": 5.1174270964049613e+18,
      "group": 1.0000000000000000e+00,
      "host_name:aleph": 3.2334478980185999e+18,
      "input[0]": 2.0000000000000000e+00,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 2.0000000000000000e+00,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 5.6000000000000000e+01,
      "input_size": 1.6056320000000000e+06,
      "input_width": 5.6000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 2.3323000000000000e+04,
      "output_batch_size": 2.0000000000000000e+00,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 5.6000000000000000e+01,
      "output_size": 4.0140800000000000e+05,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 1.0000000000000000e+00,
      "workspace_bytes": 1.8824000000000000e+04,
      "workspace_megabytes": 1.7951965332031250e-02,
      "x_tensor_layout": 1.0000000000000000e+00,
      "y_tensor_layout": 1.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_2__13560898936118562605<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:2/input[1]:256/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 23354,
      "real_time": 3.0045004730143544e+04,
      "cpu_time": 3.5772993106123111e+04,
      "time_unit": "ns",
      "items_per_second": 3.4202174012940830e+12,
      "activation_mode": 3.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.8824000000000000e+04,
      "advised_time": 3.5039998590946198e-02,
      "batch_size": 2.0000000000000000e+00,
      "benchmark_file:/home/dakkak/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 1.5291677899427402e+19,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.5547362882776177e+19,
      "bias_tensor_layout": 1.0000000000000000e+00,
      "compute_capability:7.5": 3.8315628306456499e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Quadro RTX 6000": 5.1174270964049613e+18,
      "group": 1.0000000000000000e+00,
      "host_name:aleph": 3.2334478980185999e+18,
      "input[0]": 2.0000000000000000e+00,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 2.0000000000000000e+00,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 5.6000000000000000e+01,
      "input_size": 1.6056320000000000e+06,
      "input_width": 5.6000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 2.3354000000000000e+04,
      "output_batch_size": 2.0000000000000000e+00,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 5.6000000000000000e+01,
      "output_size": 4.0140800000000000e+05,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 1.0000000000000000e+00,
      "workspace_bytes": 1.8824000000000000e+04,
      "workspace_megabytes": 1.7951965332031250e-02,
      "x_tensor_layout": 1.0000000000000000e+00,
      "y_tensor_layout": 1.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_2__13560898936118562605<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_ELU>/input[0]:2/input[1]:256/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_2__13560898936118562605<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:256/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 23214,
      "real_time": 2.9886824195975307e+04,
      "cpu_time": 3.5578561902353002e+04,
      "time_unit": "ns",
      "items_per_second": 3.4383194188239712e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.8824000000000000e+04,
      "advised_time": 3.7631999701261520e-02,
      "batch_size": 2.0000000000000000e+00,
      "benchmark_file:/home/dakkak/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 1.5291677899427402e+19,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.5541522464702913e+19,
      "bias_tensor_layout": 1.0000000000000000e+00,
      "compute_capability:7.5": 3.8315628306456499e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Quadro RTX 6000": 5.1174270964049613e+18,
      "group": 1.0000000000000000e+00,
      "host_name:aleph": 3.2334478980185999e+18,
      "input[0]": 2.0000000000000000e+00,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 2.0000000000000000e+00,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 5.6000000000000000e+01,
      "input_size": 1.6056320000000000e+06,
      "input_width": 5.6000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 2.3214000000000000e+04,
      "output_batch_size": 2.0000000000000000e+00,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 5.6000000000000000e+01,
      "output_size": 4.0140800000000000e+05,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 1.0000000000000000e+00,
      "workspace_bytes": 1.8824000000000000e+04,
      "workspace_megabytes": 1.7951965332031250e-02,
      "x_tensor_layout": 1.0000000000000000e+00,
      "y_tensor_layout": 1.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_2__13560898936118562605<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:256/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 23259,
      "real_time": 2.9970905049922440e+04,
      "cpu_time": 3.5724557848560427e+04,
      "time_unit": "ns",
      "items_per_second": 3.4286735028132202e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.8824000000000000e+04,
      "advised_time": 3.6063998937606812e-02,
      "batch_size": 2.0000000000000000e+00,
      "benchmark_file:/home/dakkak/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 1.5291677899427402e+19,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.5541522464702913e+19,
      "bias_tensor_layout": 1.0000000000000000e+00,
      "compute_capability:7.5": 3.8315628306456499e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Quadro RTX 6000": 5.1174270964049613e+18,
      "group": 1.0000000000000000e+00,
      "host_name:aleph": 3.2334478980185999e+18,
      "input[0]": 2.0000000000000000e+00,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 2.0000000000000000e+00,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 5.6000000000000000e+01,
      "input_size": 1.6056320000000000e+06,
      "input_width": 5.6000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 2.3259000000000000e+04,
      "output_batch_size": 2.0000000000000000e+00,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 5.6000000000000000e+01,
      "output_size": 4.0140800000000000e+05,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 1.0000000000000000e+00,
      "workspace_bytes": 1.8824000000000000e+04,
      "workspace_megabytes": 1.7951965332031250e-02,
      "x_tensor_layout": 1.0000000000000000e+00,
      "y_tensor_layout": 1.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_2__13560898936118562605<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_IDENTITY>/input[0]:2/input[1]:256/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 23364,
      "real_time": 3.0253790802310727e+04,
      "cpu_time": 3.6056272427545613e+04,
      "time_unit": "ns",
      "items_per_second": 3.3966139539826309e+12,
      "activation_mode": 5.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.8824000000000000e+04,
      "advised_time": 5.5296000093221664e-02,
      "batch_size": 2.0000000000000000e+00,
      "benchmark_file:/home/dakkak/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 1.5291677899427402e+19,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)5; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 4.5833023350607309e+18,
      "bias_tensor_layout": 1.0000000000000000e+00,
      "compute_capability:7.5": 3.8315628306456499e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Quadro RTX 6000": 5.1174270964049613e+18,
      "group": 1.0000000000000000e+00,
      "host_name:aleph": 3.2334478980185999e+18,
      "input[0]": 2.0000000000000000e+00,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 2.0000000000000000e+00,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 5.6000000000000000e+01,
      "input_size": 1.6056320000000000e+06,
      "input_width": 5.6000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 2.3364000000000000e+04,
      "output_batch_size": 2.0000000000000000e+00,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 5.6000000000000000e+01,
      "output_size": 4.0140800000000000e+05,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 1.0000000000000000e+00,
      "workspace_bytes": 1.8824000000000000e+04,
      "workspace_megabytes": 1.7951965332031250e-02,
      "x_tensor_layout": 1.0000000000000000e+00,
      "y_tensor_layout": 1.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_2__13560898936118562605<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_SIGMOID>/input[0]:2/input[1]:256/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_2__13560898936118562605<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_TANH>/input[0]:2/input[1]:256/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_2__13560898936118562605<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:256/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_2__13560898936118562605<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:2/input[1]:256/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_2__13560898936118562605<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_ELU>/input[0]:2/input[1]:256/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_2__13560898936118562605<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:256/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_2__13560898936118562605<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:256/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_2__13560898936118562605<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_IDENTITY>/input[0]:2/input[1]:256/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_2__13560898936118562605<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_SIGMOID>/input[0]:2/input[1]:256/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_2__13560898936118562605<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_TANH>/input[0]:2/input[1]:256/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_2__13560898936118562605<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:256/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_2__13560898936118562605<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:2/input[1]:256/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_2__13560898936118562605<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_ELU>/input[0]:2/input[1]:256/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_2__13560898936118562605<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:256/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_2__13560898936118562605<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:256/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_2__13560898936118562605<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_IDENTITY>/input[0]:2/input[1]:256/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_2__13560898936118562605<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_SIGMOID>/input[0]:2/input[1]:256/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_2__13560898936118562605<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_TANH>/input[0]:2/input[1]:256/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_2__13560898936118562605<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:256/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_2__13560898936118562605<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:2/input[1]:256/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_2__13560898936118562605<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_ELU>/input[0]:2/input[1]:256/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_2__13560898936118562605<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:256/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_2__13560898936118562605<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:256/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_2__13560898936118562605<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_IDENTITY>/input[0]:2/input[1]:256/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_2__13560898936118562605<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_SIGMOID>/input[0]:2/input[1]:256/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_2__13560898936118562605<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_TANH>/input[0]:2/input[1]:256/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_2__13560898936118562605<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:256/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_2__13560898936118562605<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:2/input[1]:256/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_2__13560898936118562605<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_ELU>/input[0]:2/input[1]:256/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_2__13560898936118562605<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:256/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_2__13560898936118562605<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:256/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_2__13560898936118562605<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_IDENTITY>/input[0]:2/input[1]:256/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_2__13560898936118562605<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_SIGMOID>/input[0]:2/input[1]:256/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_2__13560898936118562605<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_TANH>/input[0]:2/input[1]:256/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_2__13560898936118562605<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:256/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_2__13560898936118562605<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:2/input[1]:256/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_2__13560898936118562605<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_ELU>/input[0]:2/input[1]:256/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_2__13560898936118562605<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:256/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_2__13560898936118562605<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:256/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_2__13560898936118562605<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_IDENTITY>/input[0]:2/input[1]:256/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_2__13560898936118562605<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_SIGMOID>/input[0]:2/input[1]:256/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_2__13560898936118562605<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_TANH>/input[0]:2/input[1]:256/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_2__13560898936118562605<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:256/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_2__13560898936118562605<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:2/input[1]:256/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_2__13560898936118562605<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_ELU>/input[0]:2/input[1]:256/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_2__13560898936118562605<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:256/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_2__13560898936118562605<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:256/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_2__13560898936118562605<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_IDENTITY>/input[0]:2/input[1]:256/input[2]:56/input[3]:56/filter_count:64/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_2__18088482933015627516<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_SIGMOID>/input[0]:2/input[1]:128/input[2]:28/input[3]:28/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_2__18088482933015627516<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_TANH>/input[0]:2/input[1]:128/input[2]:28/input[3]:28/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_2__18088482933015627516<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:128/input[2]:28/input[3]:28/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 2959,
      "real_time": 2.3629445815124479e+05,
      "cpu_time": 2.4283246975355558e+05,
      "time_unit": "ns",
      "items_per_second": 1.0872075545485942e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 2.3875199258327484e-01,
      "batch_size": 2.0000000000000000e+00,
      "benchmark_file:/home/dakkak/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 1.5291677899427402e+19,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 2.3191971996820818e+18,
      "bias_tensor_layout": 1.0000000000000000e+00,
      "compute_capability:7.5": 3.8315628306456499e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:Quadro RTX 6000": 5.1174270964049613e+18,
      "group": 1.0000000000000000e+00,
      "host_name:aleph": 3.2334478980185999e+18,
      "input[0]": 2.0000000000000000e+00,
      "input[1]": 1.2800000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 2.0000000000000000e+00,
      "input_channels": 1.2800000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 2.0070400000000000e+05,
      "input_width": 2.8000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 2.9590000000000000e+03,
      "output_batch_size": 2.0000000000000000e+00,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 2.0070400000000000e+05,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00,
      "x_tensor_layout": 1.0000000000000000e+00,
      "y_tensor_layout": 1.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_2__18088482933015627516<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:2/input[1]:128/input[2]:28/input[3]:28/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 2957,
      "real_time": 2.3648098601813504e+05,
      "cpu_time": 2.4298546398373053e+05,
      "time_unit": "ns",
      "items_per_second": 1.0863500035486954e+11,
      "activation_mode": 3.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 2.6790401339530945e-01,
      "batch_size": 2.0000000000000000e+00,
      "benchmark_file:/home/dakkak/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 1.5291677899427402e+19,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.9889882919049984e+18,
      "bias_tensor_layout": 1.0000000000000000e+00,
      "compute_capability:7.5": 3.8315628306456499e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:Quadro RTX 6000": 5.1174270964049613e+18,
      "group": 1.0000000000000000e+00,
      "host_name:aleph": 3.2334478980185999e+18,
      "input[0]": 2.0000000000000000e+00,
      "input[1]": 1.2800000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 2.0000000000000000e+00,
      "input_channels": 1.2800000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 2.0070400000000000e+05,
      "input_width": 2.8000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 2.9570000000000000e+03,
      "output_batch_size": 2.0000000000000000e+00,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 2.0070400000000000e+05,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00,
      "x_tensor_layout": 1.0000000000000000e+00,
      "y_tensor_layout": 1.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_2__18088482933015627516<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_ELU>/input[0]:2/input[1]:128/input[2]:28/input[3]:28/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_2__18088482933015627516<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:128/input[2]:28/input[3]:28/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 2960,
      "real_time": 2.3661698494932451e+05,
      "cpu_time": 2.4312938310776791e+05,
      "time_unit": "ns",
      "items_per_second": 1.0857256086456332e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 2.3948800563812256e-01,
      "batch_size": 2.0000000000000000e+00,
      "benchmark_file:/home/dakkak/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 1.5291677899427402e+19,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 2.3191971996820818e+18,
      "bias_tensor_layout": 1.0000000000000000e+00,
      "compute_capability:7.5": 3.8315628306456499e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:Quadro RTX 6000": 5.1174270964049613e+18,
      "group": 1.0000000000000000e+00,
      "host_name:aleph": 3.2334478980185999e+18,
      "input[0]": 2.0000000000000000e+00,
      "input[1]": 1.2800000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 2.0000000000000000e+00,
      "input_channels": 1.2800000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 2.0070400000000000e+05,
      "input_width": 2.8000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 2.9600000000000000e+03,
      "output_batch_size": 2.0000000000000000e+00,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 2.0070400000000000e+05,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00,
      "x_tensor_layout": 1.0000000000000000e+00,
      "y_tensor_layout": 1.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_2__18088482933015627516<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:128/input[2]:28/input[3]:28/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 2958,
      "real_time": 2.3660049317123624e+05,
      "cpu_time": 2.4312973225134591e+05,
      "time_unit": "ns",
      "items_per_second": 1.0858012870415762e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 2.3929600417613983e-01,
      "batch_size": 2.0000000000000000e+00,
      "benchmark_file:/home/dakkak/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 1.5291677899427402e+19,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 2.3191971996820818e+18,
      "bias_tensor_layout": 1.0000000000000000e+00,
      "compute_capability:7.5": 3.8315628306456499e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:Quadro RTX 6000": 5.1174270964049613e+18,
      "group": 1.0000000000000000e+00,
      "host_name:aleph": 3.2334478980185999e+18,
      "input[0]": 2.0000000000000000e+00,
      "input[1]": 1.2800000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 2.0000000000000000e+00,
      "input_channels": 1.2800000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 2.0070400000000000e+05,
      "input_width": 2.8000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 2.9580000000000000e+03,
      "output_batch_size": 2.0000000000000000e+00,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 2.0070400000000000e+05,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00,
      "x_tensor_layout": 1.0000000000000000e+00,
      "y_tensor_layout": 1.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_2__18088482933015627516<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_IDENTITY>/input[0]:2/input[1]:128/input[2]:28/input[3]:28/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 2955,
      "real_time": 2.3668585133395283e+05,
      "cpu_time": 2.4319116209782925e+05,
      "time_unit": "ns",
      "items_per_second": 1.0854097046870975e+11,
      "activation_mode": 5.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 2.3961600661277771e-01,
      "batch_size": 2.0000000000000000e+00,
      "benchmark_file:/home/dakkak/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 1.5291677899427402e+19,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)5; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.3342635194217454e+19,
      "bias_tensor_layout": 1.0000000000000000e+00,
      "compute_capability:7.5": 3.8315628306456499e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:Quadro RTX 6000": 5.1174270964049613e+18,
      "group": 1.0000000000000000e+00,
      "host_name:aleph": 3.2334478980185999e+18,
      "input[0]": 2.0000000000000000e+00,
      "input[1]": 1.2800000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 2.0000000000000000e+00,
      "input_channels": 1.2800000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 2.0070400000000000e+05,
      "input_width": 2.8000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 2.9550000000000000e+03,
      "output_batch_size": 2.0000000000000000e+00,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 2.0070400000000000e+05,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00,
      "x_tensor_layout": 1.0000000000000000e+00,
      "y_tensor_layout": 1.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_2__18088482933015627516<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_SIGMOID>/input[0]:2/input[1]:128/input[2]:28/input[3]:28/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_2__18088482933015627516<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_TANH>/input[0]:2/input[1]:128/input[2]:28/input[3]:28/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_2__18088482933015627516<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:128/input[2]:28/input[3]:28/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 13288,
      "real_time": 5.1870286921221363e+04,
      "cpu_time": 5.7626919626819072e+04,
      "time_unit": "ns",
      "items_per_second": 4.9527607277394037e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 4.7120000000000000e+03,
      "advised_time": 6.0192000120878220e-02,
      "batch_size": 2.0000000000000000e+00,
      "benchmark_file:/home/dakkak/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 1.5291677899427402e+19,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.5541522464702913e+19,
      "bias_tensor_layout": 1.0000000000000000e+00,
      "compute_capability:7.5": 3.8315628306456499e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:Quadro RTX 6000": 5.1174270964049613e+18,
      "group": 1.0000000000000000e+00,
      "host_name:aleph": 3.2334478980185999e+18,
      "input[0]": 2.0000000000000000e+00,
      "input[1]": 1.2800000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 2.0000000000000000e+00,
      "input_channels": 1.2800000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 2.0070400000000000e+05,
      "input_width": 2.8000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 1.3288000000000000e+04,
      "output_batch_size": 2.0000000000000000e+00,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 2.0070400000000000e+05,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 1.0000000000000000e+00,
      "workspace_bytes": 4.7120000000000000e+03,
      "workspace_megabytes": 4.4937133789062500e-03,
      "x_tensor_layout": 1.0000000000000000e+00,
      "y_tensor_layout": 1.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_2__18088482933015627516<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:2/input[1]:128/input[2]:28/input[3]:28/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 13525,
      "real_time": 5.1897362504481949e+04,
      "cpu_time": 5.7679870240405486e+04,
      "time_unit": "ns",
      "items_per_second": 4.9501768028734314e+11,
      "activation_mode": 3.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 4.7120000000000000e+03,
      "advised_time": 5.7824000716209412e-02,
      "batch_size": 2.0000000000000000e+00,
      "benchmark_file:/home/dakkak/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 1.5291677899427402e+19,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.5547362882776177e+19,
      "bias_tensor_layout": 1.0000000000000000e+00,
      "compute_capability:7.5": 3.8315628306456499e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:Quadro RTX 6000": 5.1174270964049613e+18,
      "group": 1.0000000000000000e+00,
      "host_name:aleph": 3.2334478980185999e+18,
      "input[0]": 2.0000000000000000e+00,
      "input[1]": 1.2800000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 2.0000000000000000e+00,
      "input_channels": 1.2800000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 2.0070400000000000e+05,
      "input_width": 2.8000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 1.3525000000000000e+04,
      "output_batch_size": 2.0000000000000000e+00,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 2.0070400000000000e+05,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 1.0000000000000000e+00,
      "workspace_bytes": 4.7120000000000000e+03,
      "workspace_megabytes": 4.4937133789062500e-03,
      "x_tensor_layout": 1.0000000000000000e+00,
      "y_tensor_layout": 1.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_2__18088482933015627516<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_ELU>/input[0]:2/input[1]:128/input[2]:28/input[3]:28/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_2__18088482933015627516<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:128/input[2]:28/input[3]:28/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 13527,
      "real_time": 5.2001314455494459e+04,
      "cpu_time": 5.7836955348537369e+04,
      "time_unit": "ns",
      "items_per_second": 4.9402812734641522e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 4.7120000000000000e+03,
      "advised_time": 8.3967998623847961e-02,
      "batch_size": 2.0000000000000000e+00,
      "benchmark_file:/home/dakkak/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 1.5291677899427402e+19,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.5541522464702913e+19,
      "bias_tensor_layout": 1.0000000000000000e+00,
      "compute_capability:7.5": 3.8315628306456499e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:Quadro RTX 6000": 5.1174270964049613e+18,
      "group": 1.0000000000000000e+00,
      "host_name:aleph": 3.2334478980185999e+18,
      "input[0]": 2.0000000000000000e+00,
      "input[1]": 1.2800000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 2.0000000000000000e+00,
      "input_channels": 1.2800000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 2.0070400000000000e+05,
      "input_width": 2.8000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 1.3527000000000000e+04,
      "output_batch_size": 2.0000000000000000e+00,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 2.0070400000000000e+05,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 1.0000000000000000e+00,
      "workspace_bytes": 4.7120000000000000e+03,
      "workspace_megabytes": 4.4937133789062500e-03,
      "x_tensor_layout": 1.0000000000000000e+00,
      "y_tensor_layout": 1.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_2__18088482933015627516<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:128/input[2]:28/input[3]:28/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 13447,
      "real_time": 5.2121090926710516e+04,
      "cpu_time": 5.7928993678731538e+04,
      "time_unit": "ns",
      "items_per_second": 4.9289282981670239e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 4.7120000000000000e+03,
      "advised_time": 6.1535999178886414e-02,
      "batch_size": 2.0000000000000000e+00,
      "benchmark_file:/home/dakkak/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 1.5291677899427402e+19,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.5541522464702913e+19,
      "bias_tensor_layout": 1.0000000000000000e+00,
      "compute_capability:7.5": 3.8315628306456499e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:Quadro RTX 6000": 5.1174270964049613e+18,
      "group": 1.0000000000000000e+00,
      "host_name:aleph": 3.2334478980185999e+18,
      "input[0]": 2.0000000000000000e+00,
      "input[1]": 1.2800000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 2.0000000000000000e+00,
      "input_channels": 1.2800000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 2.0070400000000000e+05,
      "input_width": 2.8000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 1.3447000000000000e+04,
      "output_batch_size": 2.0000000000000000e+00,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 2.0070400000000000e+05,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 1.0000000000000000e+00,
      "workspace_bytes": 4.7120000000000000e+03,
      "workspace_megabytes": 4.4937133789062500e-03,
      "x_tensor_layout": 1.0000000000000000e+00,
      "y_tensor_layout": 1.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_2__18088482933015627516<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_IDENTITY>/input[0]:2/input[1]:128/input[2]:28/input[3]:28/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 13531,
      "real_time": 5.1940783480409751e+04,
      "cpu_time": 5.7709742369520602e+04,
      "time_unit": "ns",
      "items_per_second": 4.9460385998392596e+11,
      "activation_mode": 5.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 4.7120000000000000e+03,
      "advised_time": 6.1407998204231262e-02,
      "batch_size": 2.0000000000000000e+00,
      "benchmark_file:/home/dakkak/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 1.5291677899427402e+19,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)5; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 4.5833023350607309e+18,
      "bias_tensor_layout": 1.0000000000000000e+00,
      "compute_capability:7.5": 3.8315628306456499e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:Quadro RTX 6000": 5.1174270964049613e+18,
      "group": 1.0000000000000000e+00,
      "host_name:aleph": 3.2334478980185999e+18,
      "input[0]": 2.0000000000000000e+00,
      "input[1]": 1.2800000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 2.0000000000000000e+00,
      "input_channels": 1.2800000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 2.0070400000000000e+05,
      "input_width": 2.8000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 1.3531000000000000e+04,
      "output_batch_size": 2.0000000000000000e+00,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 2.0070400000000000e+05,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 1.0000000000000000e+00,
      "workspace_bytes": 4.7120000000000000e+03,
      "workspace_megabytes": 4.4937133789062500e-03,
      "x_tensor_layout": 1.0000000000000000e+00,
      "y_tensor_layout": 1.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_2__18088482933015627516<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_SIGMOID>/input[0]:2/input[1]:128/input[2]:28/input[3]:28/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_2__18088482933015627516<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_TANH>/input[0]:2/input[1]:128/input[2]:28/input[3]:28/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_2__18088482933015627516<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:128/input[2]:28/input[3]:28/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_2__18088482933015627516<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:2/input[1]:128/input[2]:28/input[3]:28/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_2__18088482933015627516<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_ELU>/input[0]:2/input[1]:128/input[2]:28/input[3]:28/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_2__18088482933015627516<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:128/input[2]:28/input[3]:28/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_2__18088482933015627516<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:128/input[2]:28/input[3]:28/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_2__18088482933015627516<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_IDENTITY>/input[0]:2/input[1]:128/input[2]:28/input[3]:28/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_2__18088482933015627516<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_SIGMOID>/input[0]:2/input[1]:128/input[2]:28/input[3]:28/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_2__18088482933015627516<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_TANH>/input[0]:2/input[1]:128/input[2]:28/input[3]:28/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_2__18088482933015627516<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:128/input[2]:28/input[3]:28/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_2__18088482933015627516<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:2/input[1]:128/input[2]:28/input[3]:28/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_2__18088482933015627516<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_ELU>/input[0]:2/input[1]:128/input[2]:28/input[3]:28/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_2__18088482933015627516<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:128/input[2]:28/input[3]:28/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_2__18088482933015627516<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:128/input[2]:28/input[3]:28/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_2__18088482933015627516<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_IDENTITY>/input[0]:2/input[1]:128/input[2]:28/input[3]:28/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_2__18088482933015627516<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_SIGMOID>/input[0]:2/input[1]:128/input[2]:28/input[3]:28/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_2__18088482933015627516<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_TANH>/input[0]:2/input[1]:128/input[2]:28/input[3]:28/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_2__18088482933015627516<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:128/input[2]:28/input[3]:28/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_2__18088482933015627516<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:2/input[1]:128/input[2]:28/input[3]:28/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_2__18088482933015627516<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_ELU>/input[0]:2/input[1]:128/input[2]:28/input[3]:28/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_2__18088482933015627516<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:128/input[2]:28/input[3]:28/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_2__18088482933015627516<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:128/input[2]:28/input[3]:28/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_2__18088482933015627516<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_IDENTITY>/input[0]:2/input[1]:128/input[2]:28/input[3]:28/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_2__18088482933015627516<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_SIGMOID>/input[0]:2/input[1]:128/input[2]:28/input[3]:28/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_2__18088482933015627516<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_TANH>/input[0]:2/input[1]:128/input[2]:28/input[3]:28/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_2__18088482933015627516<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:128/input[2]:28/input[3]:28/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_2__18088482933015627516<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:2/input[1]:128/input[2]:28/input[3]:28/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_2__18088482933015627516<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_ELU>/input[0]:2/input[1]:128/input[2]:28/input[3]:28/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_2__18088482933015627516<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:128/input[2]:28/input[3]:28/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_2__18088482933015627516<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:128/input[2]:28/input[3]:28/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_2__18088482933015627516<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_IDENTITY>/input[0]:2/input[1]:128/input[2]:28/input[3]:28/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_2__18088482933015627516<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_SIGMOID>/input[0]:2/input[1]:128/input[2]:28/input[3]:28/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_2__18088482933015627516<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_TANH>/input[0]:2/input[1]:128/input[2]:28/input[3]:28/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_2__18088482933015627516<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:128/input[2]:28/input[3]:28/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_2__18088482933015627516<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:2/input[1]:128/input[2]:28/input[3]:28/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_2__18088482933015627516<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_ELU>/input[0]:2/input[1]:128/input[2]:28/input[3]:28/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_2__18088482933015627516<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:128/input[2]:28/input[3]:28/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_2__18088482933015627516<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:128/input[2]:28/input[3]:28/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_2__18088482933015627516<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_IDENTITY>/input[0]:2/input[1]:128/input[2]:28/input[3]:28/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_2__18088482933015627516<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_SIGMOID>/input[0]:2/input[1]:128/input[2]:28/input[3]:28/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_2__18088482933015627516<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_TANH>/input[0]:2/input[1]:128/input[2]:28/input[3]:28/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_2__18088482933015627516<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:128/input[2]:28/input[3]:28/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_2__18088482933015627516<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:2/input[1]:128/input[2]:28/input[3]:28/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_2__18088482933015627516<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_ELU>/input[0]:2/input[1]:128/input[2]:28/input[3]:28/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_2__18088482933015627516<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:128/input[2]:28/input[3]:28/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_2__18088482933015627516<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:128/input[2]:28/input[3]:28/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_2__18088482933015627516<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_IDENTITY>/input[0]:2/input[1]:128/input[2]:28/input[3]:28/filter_count:128/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_2__6365483407406165156<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_SIGMOID>/input[0]:2/input[1]:512/input[2]:7/input[3]:7/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_2__6365483407406165156<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_TANH>/input[0]:2/input[1]:512/input[2]:7/input[3]:7/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_2__6365483407406165156<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:512/input[2]:7/input[3]:7/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 582,
      "real_time": 1.2024495373816066e+06,
      "cpu_time": 1.2292200446725383e+06,
      "time_unit": "ns",
      "items_per_second": 2.1364815072357624e+10,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 1.2552640438079834e+00,
      "batch_size": 2.0000000000000000e+00,
      "benchmark_file:/home/dakkak/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 1.5291677899427402e+19,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 2.3191971996820818e+18,
      "bias_tensor_layout": 1.0000000000000000e+00,
      "compute_capability:7.5": 3.8315628306456499e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:Quadro RTX 6000": 5.1174270964049613e+18,
      "group": 1.0000000000000000e+00,
      "host_name:aleph": 3.2334478980185999e+18,
      "input[0]": 2.0000000000000000e+00,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input_batch_size": 2.0000000000000000e+00,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 5.0176000000000000e+04,
      "input_width": 7.0000000000000000e+00,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 5.8200000000000000e+02,
      "output_batch_size": 2.0000000000000000e+00,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 5.0176000000000000e+04,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00,
      "x_tensor_layout": 1.0000000000000000e+00,
      "y_tensor_layout": 1.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_2__6365483407406165156<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:2/input[1]:512/input[2]:7/input[3]:7/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 582,
      "real_time": 1.2022700169542965e+06,
      "cpu_time": 1.2290761408932111e+06,
      "time_unit": "ns",
      "items_per_second": 2.1368005221556309e+10,
      "activation_mode": 3.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 1.2413760423660278e+00,
      "batch_size": 2.0000000000000000e+00,
      "benchmark_file:/home/dakkak/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 1.5291677899427402e+19,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.9889882919049984e+18,
      "bias_tensor_layout": 1.0000000000000000e+00,
      "compute_capability:7.5": 3.8315628306456499e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:Quadro RTX 6000": 5.1174270964049613e+18,
      "group": 1.0000000000000000e+00,
      "host_name:aleph": 3.2334478980185999e+18,
      "input[0]": 2.0000000000000000e+00,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input_batch_size": 2.0000000000000000e+00,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 5.0176000000000000e+04,
      "input_width": 7.0000000000000000e+00,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 5.8200000000000000e+02,
      "output_batch_size": 2.0000000000000000e+00,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 5.0176000000000000e+04,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00,
      "x_tensor_layout": 1.0000000000000000e+00,
      "y_tensor_layout": 1.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_2__6365483407406165156<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_ELU>/input[0]:2/input[1]:512/input[2]:7/input[3]:7/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_2__6365483407406165156<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:512/input[2]:7/input[3]:7/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 582,
      "real_time": 1.2025780300929809e+06,
      "cpu_time": 1.2292434656349358e+06,
      "time_unit": "ns",
      "items_per_second": 2.1362532290743488e+10,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 1.2551679611206055e+00,
      "batch_size": 2.0000000000000000e+00,
      "benchmark_file:/home/dakkak/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 1.5291677899427402e+19,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 2.3191971996820818e+18,
      "bias_tensor_layout": 1.0000000000000000e+00,
      "compute_capability:7.5": 3.8315628306456499e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:Quadro RTX 6000": 5.1174270964049613e+18,
      "group": 1.0000000000000000e+00,
      "host_name:aleph": 3.2334478980185999e+18,
      "input[0]": 2.0000000000000000e+00,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input_batch_size": 2.0000000000000000e+00,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 5.0176000000000000e+04,
      "input_width": 7.0000000000000000e+00,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 5.8200000000000000e+02,
      "output_batch_size": 2.0000000000000000e+00,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 5.0176000000000000e+04,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00,
      "x_tensor_layout": 1.0000000000000000e+00,
      "y_tensor_layout": 1.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_2__6365483407406165156<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:512/input[2]:7/input[3]:7/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 582,
      "real_time": 1.2024307313064735e+06,
      "cpu_time": 1.2291529742265104e+06,
      "time_unit": "ns",
      "items_per_second": 2.1365149219104706e+10,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 1.2553600072860718e+00,
      "batch_size": 2.0000000000000000e+00,
      "benchmark_file:/home/dakkak/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 1.5291677899427402e+19,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 2.3191971996820818e+18,
      "bias_tensor_layout": 1.0000000000000000e+00,
      "compute_capability:7.5": 3.8315628306456499e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:Quadro RTX 6000": 5.1174270964049613e+18,
      "group": 1.0000000000000000e+00,
      "host_name:aleph": 3.2334478980185999e+18,
      "input[0]": 2.0000000000000000e+00,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input_batch_size": 2.0000000000000000e+00,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 5.0176000000000000e+04,
      "input_width": 7.0000000000000000e+00,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 5.8200000000000000e+02,
      "output_batch_size": 2.0000000000000000e+00,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 5.0176000000000000e+04,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00,
      "x_tensor_layout": 1.0000000000000000e+00,
      "y_tensor_layout": 1.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_2__6365483407406165156<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_IDENTITY>/input[0]:2/input[1]:512/input[2]:7/input[3]:7/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 582,
      "real_time": 1.2024600361633878e+06,
      "cpu_time": 1.2291178711337158e+06,
      "time_unit": "ns",
      "items_per_second": 2.1364628534323513e+10,
      "activation_mode": 5.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 1.2329280376434326e+00,
      "batch_size": 2.0000000000000000e+00,
      "benchmark_file:/home/dakkak/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 1.5291677899427402e+19,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)5; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.3342635194217454e+19,
      "bias_tensor_layout": 1.0000000000000000e+00,
      "compute_capability:7.5": 3.8315628306456499e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:Quadro RTX 6000": 5.1174270964049613e+18,
      "group": 1.0000000000000000e+00,
      "host_name:aleph": 3.2334478980185999e+18,
      "input[0]": 2.0000000000000000e+00,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input_batch_size": 2.0000000000000000e+00,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 5.0176000000000000e+04,
      "input_width": 7.0000000000000000e+00,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 5.8200000000000000e+02,
      "output_batch_size": 2.0000000000000000e+00,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 5.0176000000000000e+04,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00,
      "x_tensor_layout": 1.0000000000000000e+00,
      "y_tensor_layout": 1.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_2__6365483407406165156<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_SIGMOID>/input[0]:2/input[1]:512/input[2]:7/input[3]:7/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_2__6365483407406165156<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_TANH>/input[0]:2/input[1]:512/input[2]:7/input[3]:7/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_2__6365483407406165156<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:512/input[2]:7/input[3]:7/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 5312,
      "real_time": 1.3177101786494453e+05,
      "cpu_time": 1.3775452936764475e+05,
      "time_unit": "ns",
      "items_per_second": 1.9496026073298187e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 3.0000000000000000e+02,
      "advised_time": 1.4428800344467163e-01,
      "batch_size": 2.0000000000000000e+00,
      "benchmark_file:/home/dakkak/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 1.5291677899427402e+19,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.5541522464702913e+19,
      "bias_tensor_layout": 1.0000000000000000e+00,
      "compute_capability:7.5": 3.8315628306456499e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:Quadro RTX 6000": 5.1174270964049613e+18,
      "group": 1.0000000000000000e+00,
      "host_name:aleph": 3.2334478980185999e+18,
      "input[0]": 2.0000000000000000e+00,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input_batch_size": 2.0000000000000000e+00,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 5.0176000000000000e+04,
      "input_width": 7.0000000000000000e+00,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 5.3120000000000000e+03,
      "output_batch_size": 2.0000000000000000e+00,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 5.0176000000000000e+04,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 1.0000000000000000e+00,
      "workspace_bytes": 3.0000000000000000e+02,
      "workspace_megabytes": 2.8610229492187500e-04,
      "x_tensor_layout": 1.0000000000000000e+00,
      "y_tensor_layout": 1.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_2__6365483407406165156<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:2/input[1]:512/input[2]:7/input[3]:7/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 5313,
      "real_time": 1.3172058854263055e+05,
      "cpu_time": 1.3779840316231910e+05,
      "time_unit": "ns",
      "items_per_second": 1.9503490140939929e+11,
      "activation_mode": 3.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 3.0000000000000000e+02,
      "advised_time": 1.7353600263595581e-01,
      "batch_size": 2.0000000000000000e+00,
      "benchmark_file:/home/dakkak/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 1.5291677899427402e+19,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.5547362882776177e+19,
      "bias_tensor_layout": 1.0000000000000000e+00,
      "compute_capability:7.5": 3.8315628306456499e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:Quadro RTX 6000": 5.1174270964049613e+18,
      "group": 1.0000000000000000e+00,
      "host_name:aleph": 3.2334478980185999e+18,
      "input[0]": 2.0000000000000000e+00,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input_batch_size": 2.0000000000000000e+00,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 5.0176000000000000e+04,
      "input_width": 7.0000000000000000e+00,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 5.3130000000000000e+03,
      "output_batch_size": 2.0000000000000000e+00,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 5.0176000000000000e+04,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 1.0000000000000000e+00,
      "workspace_bytes": 3.0000000000000000e+02,
      "workspace_megabytes": 2.8610229492187500e-04,
      "x_tensor_layout": 1.0000000000000000e+00,
      "y_tensor_layout": 1.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_2__6365483407406165156<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_ELU>/input[0]:2/input[1]:512/input[2]:7/input[3]:7/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_2__6365483407406165156<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:512/input[2]:7/input[3]:7/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 5319,
      "real_time": 1.3171834076685936e+05,
      "cpu_time": 1.3776591577384435e+05,
      "time_unit": "ns",
      "items_per_second": 1.9503822968337671e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 3.0000000000000000e+02,
      "advised_time": 1.7407999932765961e-01,
      "batch_size": 2.0000000000000000e+00,
      "benchmark_file:/home/dakkak/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 1.5291677899427402e+19,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.5541522464702913e+19,
      "bias_tensor_layout": 1.0000000000000000e+00,
      "compute_capability:7.5": 3.8315628306456499e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:Quadro RTX 6000": 5.1174270964049613e+18,
      "group": 1.0000000000000000e+00,
      "host_name:aleph": 3.2334478980185999e+18,
      "input[0]": 2.0000000000000000e+00,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input_batch_size": 2.0000000000000000e+00,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 5.0176000000000000e+04,
      "input_width": 7.0000000000000000e+00,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 5.3190000000000000e+03,
      "output_batch_size": 2.0000000000000000e+00,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 5.0176000000000000e+04,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 1.0000000000000000e+00,
      "workspace_bytes": 3.0000000000000000e+02,
      "workspace_megabytes": 2.8610229492187500e-04,
      "x_tensor_layout": 1.0000000000000000e+00,
      "y_tensor_layout": 1.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_2__6365483407406165156<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:512/input[2]:7/input[3]:7/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 5322,
      "real_time": 1.3169149045889504e+05,
      "cpu_time": 1.3773438293885466e+05,
      "time_unit": "ns",
      "items_per_second": 1.9507799562811292e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 3.0000000000000000e+02,
      "advised_time": 1.4483200013637543e-01,
      "batch_size": 2.0000000000000000e+00,
      "benchmark_file:/home/dakkak/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 1.5291677899427402e+19,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.5541522464702913e+19,
      "bias_tensor_layout": 1.0000000000000000e+00,
      "compute_capability:7.5": 3.8315628306456499e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:Quadro RTX 6000": 5.1174270964049613e+18,
      "group": 1.0000000000000000e+00,
      "host_name:aleph": 3.2334478980185999e+18,
      "input[0]": 2.0000000000000000e+00,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input_batch_size": 2.0000000000000000e+00,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 5.0176000000000000e+04,
      "input_width": 7.0000000000000000e+00,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 5.3220000000000000e+03,
      "output_batch_size": 2.0000000000000000e+00,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 5.0176000000000000e+04,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 1.0000000000000000e+00,
      "workspace_bytes": 3.0000000000000000e+02,
      "workspace_megabytes": 2.8610229492187500e-04,
      "x_tensor_layout": 1.0000000000000000e+00,
      "y_tensor_layout": 1.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_2__6365483407406165156<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_IDENTITY>/input[0]:2/input[1]:512/input[2]:7/input[3]:7/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 5297,
      "real_time": 1.3159147270017405e+05,
      "cpu_time": 1.3753131036450752e+05,
      "time_unit": "ns",
      "items_per_second": 1.9522626711940445e+11,
      "activation_mode": 5.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 3.0000000000000000e+02,
      "advised_time": 1.4336000382900238e-01,
      "batch_size": 2.0000000000000000e+00,
      "benchmark_file:/home/dakkak/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 1.5291677899427402e+19,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)5; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 4.5833023350607309e+18,
      "bias_tensor_layout": 1.0000000000000000e+00,
      "compute_capability:7.5": 3.8315628306456499e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 3.0000000000000000e+00,
      "filter_width": 3.0000000000000000e+00,
      "gpu_name:Quadro RTX 6000": 5.1174270964049613e+18,
      "group": 1.0000000000000000e+00,
      "host_name:aleph": 3.2334478980185999e+18,
      "input[0]": 2.0000000000000000e+00,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input_batch_size": 2.0000000000000000e+00,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 5.0176000000000000e+04,
      "input_width": 7.0000000000000000e+00,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 5.2970000000000000e+03,
      "output_batch_size": 2.0000000000000000e+00,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 5.0176000000000000e+04,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 1.0000000000000000e+00,
      "pad_width": 1.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 1.0000000000000000e+00,
      "workspace_bytes": 3.0000000000000000e+02,
      "workspace_megabytes": 2.8610229492187500e-04,
      "x_tensor_layout": 1.0000000000000000e+00,
      "y_tensor_layout": 1.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_2__6365483407406165156<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_SIGMOID>/input[0]:2/input[1]:512/input[2]:7/input[3]:7/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_2__6365483407406165156<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_TANH>/input[0]:2/input[1]:512/input[2]:7/input[3]:7/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_2__6365483407406165156<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:512/input[2]:7/input[3]:7/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_2__6365483407406165156<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:2/input[1]:512/input[2]:7/input[3]:7/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_2__6365483407406165156<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_ELU>/input[0]:2/input[1]:512/input[2]:7/input[3]:7/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_2__6365483407406165156<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:512/input[2]:7/input[3]:7/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_2__6365483407406165156<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:512/input[2]:7/input[3]:7/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_2__6365483407406165156<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_IDENTITY>/input[0]:2/input[1]:512/input[2]:7/input[3]:7/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_2__6365483407406165156<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_SIGMOID>/input[0]:2/input[1]:512/input[2]:7/input[3]:7/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_2__6365483407406165156<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_TANH>/input[0]:2/input[1]:512/input[2]:7/input[3]:7/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_2__6365483407406165156<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:512/input[2]:7/input[3]:7/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_2__6365483407406165156<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:2/input[1]:512/input[2]:7/input[3]:7/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_2__6365483407406165156<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_ELU>/input[0]:2/input[1]:512/input[2]:7/input[3]:7/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_2__6365483407406165156<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:512/input[2]:7/input[3]:7/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_2__6365483407406165156<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:512/input[2]:7/input[3]:7/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_2__6365483407406165156<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_IDENTITY>/input[0]:2/input[1]:512/input[2]:7/input[3]:7/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_2__6365483407406165156<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_SIGMOID>/input[0]:2/input[1]:512/input[2]:7/input[3]:7/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_2__6365483407406165156<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_TANH>/input[0]:2/input[1]:512/input[2]:7/input[3]:7/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_2__6365483407406165156<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:512/input[2]:7/input[3]:7/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_2__6365483407406165156<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:2/input[1]:512/input[2]:7/input[3]:7/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_2__6365483407406165156<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_ELU>/input[0]:2/input[1]:512/input[2]:7/input[3]:7/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_2__6365483407406165156<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:512/input[2]:7/input[3]:7/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_2__6365483407406165156<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:512/input[2]:7/input[3]:7/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_2__6365483407406165156<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_IDENTITY>/input[0]:2/input[1]:512/input[2]:7/input[3]:7/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_2__6365483407406165156<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_SIGMOID>/input[0]:2/input[1]:512/input[2]:7/input[3]:7/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_2__6365483407406165156<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_TANH>/input[0]:2/input[1]:512/input[2]:7/input[3]:7/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_2__6365483407406165156<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:512/input[2]:7/input[3]:7/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_2__6365483407406165156<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:2/input[1]:512/input[2]:7/input[3]:7/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_2__6365483407406165156<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_ELU>/input[0]:2/input[1]:512/input[2]:7/input[3]:7/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_2__6365483407406165156<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:512/input[2]:7/input[3]:7/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_2__6365483407406165156<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:512/input[2]:7/input[3]:7/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_2__6365483407406165156<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_IDENTITY>/input[0]:2/input[1]:512/input[2]:7/input[3]:7/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_2__6365483407406165156<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_SIGMOID>/input[0]:2/input[1]:512/input[2]:7/input[3]:7/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_2__6365483407406165156<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_TANH>/input[0]:2/input[1]:512/input[2]:7/input[3]:7/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_2__6365483407406165156<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:512/input[2]:7/input[3]:7/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_2__6365483407406165156<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:2/input[1]:512/input[2]:7/input[3]:7/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_2__6365483407406165156<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_ELU>/input[0]:2/input[1]:512/input[2]:7/input[3]:7/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_2__6365483407406165156<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:512/input[2]:7/input[3]:7/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_2__6365483407406165156<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:512/input[2]:7/input[3]:7/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_2__6365483407406165156<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_IDENTITY>/input[0]:2/input[1]:512/input[2]:7/input[3]:7/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_2__6365483407406165156<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_SIGMOID>/input[0]:2/input[1]:512/input[2]:7/input[3]:7/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_2__6365483407406165156<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_TANH>/input[0]:2/input[1]:512/input[2]:7/input[3]:7/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_2__6365483407406165156<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:512/input[2]:7/input[3]:7/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_2__6365483407406165156<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:2/input[1]:512/input[2]:7/input[3]:7/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_2__6365483407406165156<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_ELU>/input[0]:2/input[1]:512/input[2]:7/input[3]:7/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_2__6365483407406165156<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:512/input[2]:7/input[3]:7/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_2__6365483407406165156<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:512/input[2]:7/input[3]:7/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_2__6365483407406165156<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_IDENTITY>/input[0]:2/input[1]:512/input[2]:7/input[3]:7/filter_count:512/filter_height:3/filter_width:3/pad_height:1/pad_width:1/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_2__13265586500781038438<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_SIGMOID>/input[0]:2/input[1]:512/input[2]:7/input[3]:7/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_2__13265586500781038438<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_TANH>/input[0]:2/input[1]:512/input[2]:7/input[3]:7/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_2__13265586500781038438<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:512/input[2]:7/input[3]:7/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 4517,
      "real_time": 1.5142311520201524e+05,
      "cpu_time": 1.5748816758913617e+05,
      "time_unit": "ns",
      "items_per_second": 6.7863118430040332e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 1.5257599949836731e-01,
      "batch_size": 2.0000000000000000e+00,
      "benchmark_file:/home/dakkak/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 1.5291677899427402e+19,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 2.3191971996820818e+18,
      "bias_tensor_layout": 1.0000000000000000e+00,
      "compute_capability:7.5": 3.8315628306456499e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.0480000000000000e+03,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Quadro RTX 6000": 5.1174270964049613e+18,
      "group": 1.0000000000000000e+00,
      "host_name:aleph": 3.2334478980185999e+18,
      "input[0]": 2.0000000000000000e+00,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input_batch_size": 2.0000000000000000e+00,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 5.0176000000000000e+04,
      "input_width": 7.0000000000000000e+00,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 2.0480000000000000e+03,
      "num_iterations": 4.5170000000000000e+03,
      "output_batch_size": 2.0000000000000000e+00,
      "output_channels": 2.0480000000000000e+03,
      "output_height": 7.0000000000000000e+00,
      "output_size": 2.0070400000000000e+05,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00,
      "x_tensor_layout": 1.0000000000000000e+00,
      "y_tensor_layout": 1.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_2__13265586500781038438<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:2/input[1]:512/input[2]:7/input[3]:7/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 4634,
      "real_time": 1.5090396970573388e+05,
      "cpu_time": 1.5695390526550691e+05,
      "time_unit": "ns",
      "items_per_second": 6.8096583675290430e+11,
      "activation_mode": 3.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 1.5059199929237366e-01,
      "batch_size": 2.0000000000000000e+00,
      "benchmark_file:/home/dakkak/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 1.5291677899427402e+19,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.9889882919049984e+18,
      "bias_tensor_layout": 1.0000000000000000e+00,
      "compute_capability:7.5": 3.8315628306456499e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.0480000000000000e+03,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Quadro RTX 6000": 5.1174270964049613e+18,
      "group": 1.0000000000000000e+00,
      "host_name:aleph": 3.2334478980185999e+18,
      "input[0]": 2.0000000000000000e+00,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input_batch_size": 2.0000000000000000e+00,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 5.0176000000000000e+04,
      "input_width": 7.0000000000000000e+00,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 2.0480000000000000e+03,
      "num_iterations": 4.6340000000000000e+03,
      "output_batch_size": 2.0000000000000000e+00,
      "output_channels": 2.0480000000000000e+03,
      "output_height": 7.0000000000000000e+00,
      "output_size": 2.0070400000000000e+05,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00,
      "x_tensor_layout": 1.0000000000000000e+00,
      "y_tensor_layout": 1.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_2__13265586500781038438<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_ELU>/input[0]:2/input[1]:512/input[2]:7/input[3]:7/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_2__13265586500781038438<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:512/input[2]:7/input[3]:7/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 4632,
      "real_time": 1.5087889529391579e+05,
      "cpu_time": 1.5688869430037905e+05,
      "time_unit": "ns",
      "items_per_second": 6.8107900578023267e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 1.5059199929237366e-01,
      "batch_size": 2.0000000000000000e+00,
      "benchmark_file:/home/dakkak/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 1.5291677899427402e+19,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 2.3191971996820818e+18,
      "bias_tensor_layout": 1.0000000000000000e+00,
      "compute_capability:7.5": 3.8315628306456499e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.0480000000000000e+03,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Quadro RTX 6000": 5.1174270964049613e+18,
      "group": 1.0000000000000000e+00,
      "host_name:aleph": 3.2334478980185999e+18,
      "input[0]": 2.0000000000000000e+00,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input_batch_size": 2.0000000000000000e+00,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 5.0176000000000000e+04,
      "input_width": 7.0000000000000000e+00,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 2.0480000000000000e+03,
      "num_iterations": 4.6320000000000000e+03,
      "output_batch_size": 2.0000000000000000e+00,
      "output_channels": 2.0480000000000000e+03,
      "output_height": 7.0000000000000000e+00,
      "output_size": 2.0070400000000000e+05,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00,
      "x_tensor_layout": 1.0000000000000000e+00,
      "y_tensor_layout": 1.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_2__13265586500781038438<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:512/input[2]:7/input[3]:7/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 4637,
      "real_time": 1.5099169363576820e+05,
      "cpu_time": 1.5698704464076841e+05,
      "time_unit": "ns",
      "items_per_second": 6.8057020572194714e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 1.6816000640392303e-01,
      "batch_size": 2.0000000000000000e+00,
      "benchmark_file:/home/dakkak/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 1.5291677899427402e+19,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 2.3191971996820818e+18,
      "bias_tensor_layout": 1.0000000000000000e+00,
      "compute_capability:7.5": 3.8315628306456499e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.0480000000000000e+03,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Quadro RTX 6000": 5.1174270964049613e+18,
      "group": 1.0000000000000000e+00,
      "host_name:aleph": 3.2334478980185999e+18,
      "input[0]": 2.0000000000000000e+00,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input_batch_size": 2.0000000000000000e+00,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 5.0176000000000000e+04,
      "input_width": 7.0000000000000000e+00,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 2.0480000000000000e+03,
      "num_iterations": 4.6370000000000000e+03,
      "output_batch_size": 2.0000000000000000e+00,
      "output_channels": 2.0480000000000000e+03,
      "output_height": 7.0000000000000000e+00,
      "output_size": 2.0070400000000000e+05,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00,
      "x_tensor_layout": 1.0000000000000000e+00,
      "y_tensor_layout": 1.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_2__13265586500781038438<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_IDENTITY>/input[0]:2/input[1]:512/input[2]:7/input[3]:7/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 4637,
      "real_time": 1.5086680603010149e+05,
      "cpu_time": 1.5690884278630241e+05,
      "time_unit": "ns",
      "items_per_second": 6.8113358202530542e+11,
      "activation_mode": 5.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 1.5151999890804291e-01,
      "batch_size": 2.0000000000000000e+00,
      "benchmark_file:/home/dakkak/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 1.5291677899427402e+19,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)5; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.3342635194217454e+19,
      "bias_tensor_layout": 1.0000000000000000e+00,
      "compute_capability:7.5": 3.8315628306456499e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.0480000000000000e+03,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Quadro RTX 6000": 5.1174270964049613e+18,
      "group": 1.0000000000000000e+00,
      "host_name:aleph": 3.2334478980185999e+18,
      "input[0]": 2.0000000000000000e+00,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input_batch_size": 2.0000000000000000e+00,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 5.0176000000000000e+04,
      "input_width": 7.0000000000000000e+00,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 2.0480000000000000e+03,
      "num_iterations": 4.6370000000000000e+03,
      "output_batch_size": 2.0000000000000000e+00,
      "output_channels": 2.0480000000000000e+03,
      "output_height": 7.0000000000000000e+00,
      "output_size": 2.0070400000000000e+05,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00,
      "x_tensor_layout": 1.0000000000000000e+00,
      "y_tensor_layout": 1.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_2__13265586500781038438<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_SIGMOID>/input[0]:2/input[1]:512/input[2]:7/input[3]:7/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_2__13265586500781038438<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_TANH>/input[0]:2/input[1]:512/input[2]:7/input[3]:7/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_2__13265586500781038438<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:512/input[2]:7/input[3]:7/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 21305,
      "real_time": 3.2747838529047807e+04,
      "cpu_time": 3.8518803895884630e+04,
      "time_unit": "ns",
      "items_per_second": 3.1379307036966729e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 3.0000000000000000e+02,
      "advised_time": 5.5296000093221664e-02,
      "batch_size": 2.0000000000000000e+00,
      "benchmark_file:/home/dakkak/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 1.5291677899427402e+19,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.5541522464702913e+19,
      "bias_tensor_layout": 1.0000000000000000e+00,
      "compute_capability:7.5": 3.8315628306456499e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.0480000000000000e+03,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Quadro RTX 6000": 5.1174270964049613e+18,
      "group": 1.0000000000000000e+00,
      "host_name:aleph": 3.2334478980185999e+18,
      "input[0]": 2.0000000000000000e+00,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input_batch_size": 2.0000000000000000e+00,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 5.0176000000000000e+04,
      "input_width": 7.0000000000000000e+00,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 2.0480000000000000e+03,
      "num_iterations": 2.1305000000000000e+04,
      "output_batch_size": 2.0000000000000000e+00,
      "output_channels": 2.0480000000000000e+03,
      "output_height": 7.0000000000000000e+00,
      "output_size": 2.0070400000000000e+05,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 1.0000000000000000e+00,
      "workspace_bytes": 3.0000000000000000e+02,
      "workspace_megabytes": 2.8610229492187500e-04,
      "x_tensor_layout": 1.0000000000000000e+00,
      "y_tensor_layout": 1.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_2__13265586500781038438<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:2/input[1]:512/input[2]:7/input[3]:7/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 21369,
      "real_time": 3.2938227703704601e+04,
      "cpu_time": 3.8760130469484211e+04,
      "time_unit": "ns",
      "items_per_second": 3.1197928718078052e+12,
      "activation_mode": 3.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 3.0000000000000000e+02,
      "advised_time": 4.0543999522924423e-02,
      "batch_size": 2.0000000000000000e+00,
      "benchmark_file:/home/dakkak/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 1.5291677899427402e+19,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.5547362882776177e+19,
      "bias_tensor_layout": 1.0000000000000000e+00,
      "compute_capability:7.5": 3.8315628306456499e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.0480000000000000e+03,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Quadro RTX 6000": 5.1174270964049613e+18,
      "group": 1.0000000000000000e+00,
      "host_name:aleph": 3.2334478980185999e+18,
      "input[0]": 2.0000000000000000e+00,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input_batch_size": 2.0000000000000000e+00,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 5.0176000000000000e+04,
      "input_width": 7.0000000000000000e+00,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 2.0480000000000000e+03,
      "num_iterations": 2.1369000000000000e+04,
      "output_batch_size": 2.0000000000000000e+00,
      "output_channels": 2.0480000000000000e+03,
      "output_height": 7.0000000000000000e+00,
      "output_size": 2.0070400000000000e+05,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 1.0000000000000000e+00,
      "workspace_bytes": 3.0000000000000000e+02,
      "workspace_megabytes": 2.8610229492187500e-04,
      "x_tensor_layout": 1.0000000000000000e+00,
      "y_tensor_layout": 1.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_2__13265586500781038438<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_ELU>/input[0]:2/input[1]:512/input[2]:7/input[3]:7/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_2__13265586500781038438<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:512/input[2]:7/input[3]:7/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 21351,
      "real_time": 3.2944989686206463e+04,
      "cpu_time": 3.8751369303511347e+04,
      "time_unit": "ns",
      "items_per_second": 3.1191525321079136e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 3.0000000000000000e+02,
      "advised_time": 3.9680000394582748e-02,
      "batch_size": 2.0000000000000000e+00,
      "benchmark_file:/home/dakkak/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 1.5291677899427402e+19,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.5541522464702913e+19,
      "bias_tensor_layout": 1.0000000000000000e+00,
      "compute_capability:7.5": 3.8315628306456499e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.0480000000000000e+03,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Quadro RTX 6000": 5.1174270964049613e+18,
      "group": 1.0000000000000000e+00,
      "host_name:aleph": 3.2334478980185999e+18,
      "input[0]": 2.0000000000000000e+00,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input_batch_size": 2.0000000000000000e+00,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 5.0176000000000000e+04,
      "input_width": 7.0000000000000000e+00,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 2.0480000000000000e+03,
      "num_iterations": 2.1351000000000000e+04,
      "output_batch_size": 2.0000000000000000e+00,
      "output_channels": 2.0480000000000000e+03,
      "output_height": 7.0000000000000000e+00,
      "output_size": 2.0070400000000000e+05,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 1.0000000000000000e+00,
      "workspace_bytes": 3.0000000000000000e+02,
      "workspace_megabytes": 2.8610229492187500e-04,
      "x_tensor_layout": 1.0000000000000000e+00,
      "y_tensor_layout": 1.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_2__13265586500781038438<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:512/input[2]:7/input[3]:7/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 21291,
      "real_time": 3.2752723470732832e+04,
      "cpu_time": 3.8512444413101170e+04,
      "time_unit": "ns",
      "items_per_second": 3.1374626935016455e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 3.0000000000000000e+02,
      "advised_time": 3.8911998271942139e-02,
      "batch_size": 2.0000000000000000e+00,
      "benchmark_file:/home/dakkak/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 1.5291677899427402e+19,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.5541522464702913e+19,
      "bias_tensor_layout": 1.0000000000000000e+00,
      "compute_capability:7.5": 3.8315628306456499e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.0480000000000000e+03,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Quadro RTX 6000": 5.1174270964049613e+18,
      "group": 1.0000000000000000e+00,
      "host_name:aleph": 3.2334478980185999e+18,
      "input[0]": 2.0000000000000000e+00,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input_batch_size": 2.0000000000000000e+00,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 5.0176000000000000e+04,
      "input_width": 7.0000000000000000e+00,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 2.0480000000000000e+03,
      "num_iterations": 2.1291000000000000e+04,
      "output_batch_size": 2.0000000000000000e+00,
      "output_channels": 2.0480000000000000e+03,
      "output_height": 7.0000000000000000e+00,
      "output_size": 2.0070400000000000e+05,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 1.0000000000000000e+00,
      "workspace_bytes": 3.0000000000000000e+02,
      "workspace_megabytes": 2.8610229492187500e-04,
      "x_tensor_layout": 1.0000000000000000e+00,
      "y_tensor_layout": 1.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_2__13265586500781038438<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_IDENTITY>/input[0]:2/input[1]:512/input[2]:7/input[3]:7/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 21158,
      "real_time": 3.2821120889576443e+04,
      "cpu_time": 3.8614453209055398e+04,
      "time_unit": "ns",
      "items_per_second": 3.1309243930372705e+12,
      "activation_mode": 5.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 3.0000000000000000e+02,
      "advised_time": 5.9615999460220337e-02,
      "batch_size": 2.0000000000000000e+00,
      "benchmark_file:/home/dakkak/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 1.5291677899427402e+19,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)5; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 4.5833023350607309e+18,
      "bias_tensor_layout": 1.0000000000000000e+00,
      "compute_capability:7.5": 3.8315628306456499e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.0480000000000000e+03,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Quadro RTX 6000": 5.1174270964049613e+18,
      "group": 1.0000000000000000e+00,
      "host_name:aleph": 3.2334478980185999e+18,
      "input[0]": 2.0000000000000000e+00,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input_batch_size": 2.0000000000000000e+00,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 7.0000000000000000e+00,
      "input_size": 5.0176000000000000e+04,
      "input_width": 7.0000000000000000e+00,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 2.0480000000000000e+03,
      "num_iterations": 2.1158000000000000e+04,
      "output_batch_size": 2.0000000000000000e+00,
      "output_channels": 2.0480000000000000e+03,
      "output_height": 7.0000000000000000e+00,
      "output_size": 2.0070400000000000e+05,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 1.0000000000000000e+00,
      "workspace_bytes": 3.0000000000000000e+02,
      "workspace_megabytes": 2.8610229492187500e-04,
      "x_tensor_layout": 1.0000000000000000e+00,
      "y_tensor_layout": 1.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_2__13265586500781038438<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_SIGMOID>/input[0]:2/input[1]:512/input[2]:7/input[3]:7/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_2__13265586500781038438<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_TANH>/input[0]:2/input[1]:512/input[2]:7/input[3]:7/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_2__13265586500781038438<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:512/input[2]:7/input[3]:7/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_2__13265586500781038438<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:2/input[1]:512/input[2]:7/input[3]:7/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_2__13265586500781038438<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_ELU>/input[0]:2/input[1]:512/input[2]:7/input[3]:7/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_2__13265586500781038438<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:512/input[2]:7/input[3]:7/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_2__13265586500781038438<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:512/input[2]:7/input[3]:7/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_2__13265586500781038438<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_IDENTITY>/input[0]:2/input[1]:512/input[2]:7/input[3]:7/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_2__13265586500781038438<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_SIGMOID>/input[0]:2/input[1]:512/input[2]:7/input[3]:7/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_2__13265586500781038438<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_TANH>/input[0]:2/input[1]:512/input[2]:7/input[3]:7/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_2__13265586500781038438<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:512/input[2]:7/input[3]:7/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_2__13265586500781038438<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:2/input[1]:512/input[2]:7/input[3]:7/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_2__13265586500781038438<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_ELU>/input[0]:2/input[1]:512/input[2]:7/input[3]:7/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_2__13265586500781038438<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:512/input[2]:7/input[3]:7/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_2__13265586500781038438<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:512/input[2]:7/input[3]:7/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_2__13265586500781038438<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_IDENTITY>/input[0]:2/input[1]:512/input[2]:7/input[3]:7/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_2__13265586500781038438<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_SIGMOID>/input[0]:2/input[1]:512/input[2]:7/input[3]:7/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_2__13265586500781038438<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_TANH>/input[0]:2/input[1]:512/input[2]:7/input[3]:7/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_2__13265586500781038438<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:512/input[2]:7/input[3]:7/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_2__13265586500781038438<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:2/input[1]:512/input[2]:7/input[3]:7/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_2__13265586500781038438<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_ELU>/input[0]:2/input[1]:512/input[2]:7/input[3]:7/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_2__13265586500781038438<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:512/input[2]:7/input[3]:7/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_2__13265586500781038438<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:512/input[2]:7/input[3]:7/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_2__13265586500781038438<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_IDENTITY>/input[0]:2/input[1]:512/input[2]:7/input[3]:7/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_2__13265586500781038438<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_SIGMOID>/input[0]:2/input[1]:512/input[2]:7/input[3]:7/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_2__13265586500781038438<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_TANH>/input[0]:2/input[1]:512/input[2]:7/input[3]:7/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_2__13265586500781038438<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:512/input[2]:7/input[3]:7/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_2__13265586500781038438<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:2/input[1]:512/input[2]:7/input[3]:7/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_2__13265586500781038438<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_ELU>/input[0]:2/input[1]:512/input[2]:7/input[3]:7/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_2__13265586500781038438<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:512/input[2]:7/input[3]:7/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_2__13265586500781038438<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:512/input[2]:7/input[3]:7/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_2__13265586500781038438<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_IDENTITY>/input[0]:2/input[1]:512/input[2]:7/input[3]:7/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_2__13265586500781038438<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_SIGMOID>/input[0]:2/input[1]:512/input[2]:7/input[3]:7/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_2__13265586500781038438<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_TANH>/input[0]:2/input[1]:512/input[2]:7/input[3]:7/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_2__13265586500781038438<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:512/input[2]:7/input[3]:7/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_2__13265586500781038438<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:2/input[1]:512/input[2]:7/input[3]:7/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_2__13265586500781038438<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_ELU>/input[0]:2/input[1]:512/input[2]:7/input[3]:7/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_2__13265586500781038438<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:512/input[2]:7/input[3]:7/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_2__13265586500781038438<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:512/input[2]:7/input[3]:7/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_2__13265586500781038438<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_IDENTITY>/input[0]:2/input[1]:512/input[2]:7/input[3]:7/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_2__13265586500781038438<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_SIGMOID>/input[0]:2/input[1]:512/input[2]:7/input[3]:7/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_2__13265586500781038438<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_TANH>/input[0]:2/input[1]:512/input[2]:7/input[3]:7/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_2__13265586500781038438<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:512/input[2]:7/input[3]:7/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_2__13265586500781038438<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:2/input[1]:512/input[2]:7/input[3]:7/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_2__13265586500781038438<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_ELU>/input[0]:2/input[1]:512/input[2]:7/input[3]:7/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_2__13265586500781038438<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:512/input[2]:7/input[3]:7/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_2__13265586500781038438<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:512/input[2]:7/input[3]:7/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_2__13265586500781038438<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_IDENTITY>/input[0]:2/input[1]:512/input[2]:7/input[3]:7/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_2__9829853329635220510<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_SIGMOID>/input[0]:2/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_2__9829853329635220510<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_TANH>/input[0]:2/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_2__9829853329635220510<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 4648,
      "real_time": 1.5063206948116125e+05,
      "cpu_time": 1.5675030120495619e+05,
      "time_unit": "ns",
      "items_per_second": 1.3643900446159866e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 1.5116800367832184e-01,
      "batch_size": 2.0000000000000000e+00,
      "benchmark_file:/home/dakkak/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 1.5291677899427402e+19,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 2.3191971996820818e+18,
      "bias_tensor_layout": 1.0000000000000000e+00,
      "compute_capability:7.5": 3.8315628306456499e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.5600000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Quadro RTX 6000": 5.1174270964049613e+18,
      "group": 1.0000000000000000e+00,
      "host_name:aleph": 3.2334478980185999e+18,
      "input[0]": 2.0000000000000000e+00,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 2.0000000000000000e+00,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 8.0281600000000000e+05,
      "input_width": 2.8000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 2.5600000000000000e+02,
      "num_iterations": 4.6480000000000000e+03,
      "output_batch_size": 2.0000000000000000e+00,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 1.0035200000000000e+05,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "w_filter_layout": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00,
      "x_tensor_layout": 1.0000000000000000e+00,
      "y_tensor_layout": 1.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_2__9829853329635220510<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:2/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 4648,
      "real_time": 1.5072196274778401e+05,
      "cpu_time": 1.5678895826164979e+05,
      "time_unit": "ns",
      "items_per_second": 1.3635762980602617e+12,
      "activation_mode": 3.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 1.5132799744606018e-01,
      "batch_size": 2.0000000000000000e+00,
      "benchmark_file:/home/dakkak/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 1.5291677899427402e+19,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.9889882919049984e+18,
      "bias_tensor_layout": 1.0000000000000000e+00,
      "compute_capability:7.5": 3.8315628306456499e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.5600000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Quadro RTX 6000": 5.1174270964049613e+18,
      "group": 1.0000000000000000e+00,
      "host_name:aleph": 3.2334478980185999e+18,
      "input[0]": 2.0000000000000000e+00,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 2.0000000000000000e+00,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 8.0281600000000000e+05,
      "input_width": 2.8000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 2.5600000000000000e+02,
      "num_iterations": 4.6480000000000000e+03,
      "output_batch_size": 2.0000000000000000e+00,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 1.0035200000000000e+05,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "w_filter_layout": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00,
      "x_tensor_layout": 1.0000000000000000e+00,
      "y_tensor_layout": 1.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_2__9829853329635220510<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_ELU>/input[0]:2/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_2__9829853329635220510<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 4643,
      "real_time": 1.5079172658843847e+05,
      "cpu_time": 1.5681712384216714e+05,
      "time_unit": "ns",
      "items_per_second": 1.3629454390487612e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 1.5283200144767761e-01,
      "batch_size": 2.0000000000000000e+00,
      "benchmark_file:/home/dakkak/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 1.5291677899427402e+19,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 2.3191971996820818e+18,
      "bias_tensor_layout": 1.0000000000000000e+00,
      "compute_capability:7.5": 3.8315628306456499e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.5600000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Quadro RTX 6000": 5.1174270964049613e+18,
      "group": 1.0000000000000000e+00,
      "host_name:aleph": 3.2334478980185999e+18,
      "input[0]": 2.0000000000000000e+00,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 2.0000000000000000e+00,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 8.0281600000000000e+05,
      "input_width": 2.8000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 2.5600000000000000e+02,
      "num_iterations": 4.6430000000000000e+03,
      "output_batch_size": 2.0000000000000000e+00,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 1.0035200000000000e+05,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "w_filter_layout": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00,
      "x_tensor_layout": 1.0000000000000000e+00,
      "y_tensor_layout": 1.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_2__9829853329635220510<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 4640,
      "real_time": 1.5074201442232527e+05,
      "cpu_time": 1.5683559224139998e+05,
      "time_unit": "ns",
      "items_per_second": 1.3633949153963398e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 1.5155200660228729e-01,
      "batch_size": 2.0000000000000000e+00,
      "benchmark_file:/home/dakkak/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 1.5291677899427402e+19,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 2.3191971996820818e+18,
      "bias_tensor_layout": 1.0000000000000000e+00,
      "compute_capability:7.5": 3.8315628306456499e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.5600000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Quadro RTX 6000": 5.1174270964049613e+18,
      "group": 1.0000000000000000e+00,
      "host_name:aleph": 3.2334478980185999e+18,
      "input[0]": 2.0000000000000000e+00,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 2.0000000000000000e+00,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 8.0281600000000000e+05,
      "input_width": 2.8000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 2.5600000000000000e+02,
      "num_iterations": 4.6400000000000000e+03,
      "output_batch_size": 2.0000000000000000e+00,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 1.0035200000000000e+05,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "w_filter_layout": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00,
      "x_tensor_layout": 1.0000000000000000e+00,
      "y_tensor_layout": 1.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_2__9829853329635220510<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_IDENTITY>/input[0]:2/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 4646,
      "real_time": 1.5073768123369437e+05,
      "cpu_time": 1.5676298923789119e+05,
      "time_unit": "ns",
      "items_per_second": 1.3634341082995244e+12,
      "activation_mode": 5.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 1.5337599813938141e-01,
      "batch_size": 2.0000000000000000e+00,
      "benchmark_file:/home/dakkak/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 1.5291677899427402e+19,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)5; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.3342635194217454e+19,
      "bias_tensor_layout": 1.0000000000000000e+00,
      "compute_capability:7.5": 3.8315628306456499e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.5600000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Quadro RTX 6000": 5.1174270964049613e+18,
      "group": 1.0000000000000000e+00,
      "host_name:aleph": 3.2334478980185999e+18,
      "input[0]": 2.0000000000000000e+00,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 2.0000000000000000e+00,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 8.0281600000000000e+05,
      "input_width": 2.8000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 2.5600000000000000e+02,
      "num_iterations": 4.6460000000000000e+03,
      "output_batch_size": 2.0000000000000000e+00,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 1.0035200000000000e+05,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "w_filter_layout": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00,
      "x_tensor_layout": 1.0000000000000000e+00,
      "y_tensor_layout": 1.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_2__9829853329635220510<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_SIGMOID>/input[0]:2/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_2__9829853329635220510<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_TANH>/input[0]:2/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_2__9829853329635220510<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 19723,
      "real_time": 3.5483312565147433e+04,
      "cpu_time": 4.1257918369425082e+04,
      "time_unit": "ns",
      "items_per_second": 5.7920436718714805e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.1840000000000000e+03,
      "advised_time": 4.0575999766588211e-02,
      "batch_size": 2.0000000000000000e+00,
      "benchmark_file:/home/dakkak/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 1.5291677899427402e+19,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.5541522464702913e+19,
      "bias_tensor_layout": 1.0000000000000000e+00,
      "compute_capability:7.5": 3.8315628306456499e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.5600000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Quadro RTX 6000": 5.1174270964049613e+18,
      "group": 1.0000000000000000e+00,
      "host_name:aleph": 3.2334478980185999e+18,
      "input[0]": 2.0000000000000000e+00,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 2.0000000000000000e+00,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 8.0281600000000000e+05,
      "input_width": 2.8000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 2.5600000000000000e+02,
      "num_iterations": 1.9723000000000000e+04,
      "output_batch_size": 2.0000000000000000e+00,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 1.0035200000000000e+05,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "w_filter_layout": 1.0000000000000000e+00,
      "workspace_bytes": 1.1840000000000000e+03,
      "workspace_megabytes": 1.1291503906250000e-03,
      "x_tensor_layout": 1.0000000000000000e+00,
      "y_tensor_layout": 1.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_2__9829853329635220510<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:2/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 19809,
      "real_time": 3.5296634614514172e+04,
      "cpu_time": 4.1022837952661845e+04,
      "time_unit": "ns",
      "items_per_second": 5.8226768145053887e+12,
      "activation_mode": 3.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.1840000000000000e+03,
      "advised_time": 6.1439998447895050e-02,
      "batch_size": 2.0000000000000000e+00,
      "benchmark_file:/home/dakkak/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 1.5291677899427402e+19,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.5547362882776177e+19,
      "bias_tensor_layout": 1.0000000000000000e+00,
      "compute_capability:7.5": 3.8315628306456499e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.5600000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Quadro RTX 6000": 5.1174270964049613e+18,
      "group": 1.0000000000000000e+00,
      "host_name:aleph": 3.2334478980185999e+18,
      "input[0]": 2.0000000000000000e+00,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 2.0000000000000000e+00,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 8.0281600000000000e+05,
      "input_width": 2.8000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 2.5600000000000000e+02,
      "num_iterations": 1.9809000000000000e+04,
      "output_batch_size": 2.0000000000000000e+00,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 1.0035200000000000e+05,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "w_filter_layout": 1.0000000000000000e+00,
      "workspace_bytes": 1.1840000000000000e+03,
      "workspace_megabytes": 1.1291503906250000e-03,
      "x_tensor_layout": 1.0000000000000000e+00,
      "y_tensor_layout": 1.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_2__9829853329635220510<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_ELU>/input[0]:2/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_2__9829853329635220510<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 19712,
      "real_time": 3.5380519316871330e+04,
      "cpu_time": 4.1135025720415200e+04,
      "time_unit": "ns",
      "items_per_second": 5.8088716606823975e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.1840000000000000e+03,
      "advised_time": 6.1983998864889145e-02,
      "batch_size": 2.0000000000000000e+00,
      "benchmark_file:/home/dakkak/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 1.5291677899427402e+19,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.5541522464702913e+19,
      "bias_tensor_layout": 1.0000000000000000e+00,
      "compute_capability:7.5": 3.8315628306456499e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.5600000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Quadro RTX 6000": 5.1174270964049613e+18,
      "group": 1.0000000000000000e+00,
      "host_name:aleph": 3.2334478980185999e+18,
      "input[0]": 2.0000000000000000e+00,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 2.0000000000000000e+00,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 8.0281600000000000e+05,
      "input_width": 2.8000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 2.5600000000000000e+02,
      "num_iterations": 1.9712000000000000e+04,
      "output_batch_size": 2.0000000000000000e+00,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 1.0035200000000000e+05,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "w_filter_layout": 1.0000000000000000e+00,
      "workspace_bytes": 1.1840000000000000e+03,
      "workspace_megabytes": 1.1291503906250000e-03,
      "x_tensor_layout": 1.0000000000000000e+00,
      "y_tensor_layout": 1.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_2__9829853329635220510<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 19851,
      "real_time": 3.5545182759578041e+04,
      "cpu_time": 4.1355183920135183e+04,
      "time_unit": "ns",
      "items_per_second": 5.7819620000299512e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.1840000000000000e+03,
      "advised_time": 4.2624000459909439e-02,
      "batch_size": 2.0000000000000000e+00,
      "benchmark_file:/home/dakkak/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 1.5291677899427402e+19,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.5541522464702913e+19,
      "bias_tensor_layout": 1.0000000000000000e+00,
      "compute_capability:7.5": 3.8315628306456499e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.5600000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Quadro RTX 6000": 5.1174270964049613e+18,
      "group": 1.0000000000000000e+00,
      "host_name:aleph": 3.2334478980185999e+18,
      "input[0]": 2.0000000000000000e+00,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 2.0000000000000000e+00,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 8.0281600000000000e+05,
      "input_width": 2.8000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 2.5600000000000000e+02,
      "num_iterations": 1.9851000000000000e+04,
      "output_batch_size": 2.0000000000000000e+00,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 1.0035200000000000e+05,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "w_filter_layout": 1.0000000000000000e+00,
      "workspace_bytes": 1.1840000000000000e+03,
      "workspace_megabytes": 1.1291503906250000e-03,
      "x_tensor_layout": 1.0000000000000000e+00,
      "y_tensor_layout": 1.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_2__9829853329635220510<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_IDENTITY>/input[0]:2/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 19677,
      "real_time": 3.5623031836800998e+04,
      "cpu_time": 4.1456499415495913e+04,
      "time_unit": "ns",
      "items_per_second": 5.7693263431801172e+12,
      "activation_mode": 5.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.1840000000000000e+03,
      "advised_time": 4.3423999100923538e-02,
      "batch_size": 2.0000000000000000e+00,
      "benchmark_file:/home/dakkak/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 1.5291677899427402e+19,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)5; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 4.5833023350607309e+18,
      "bias_tensor_layout": 1.0000000000000000e+00,
      "compute_capability:7.5": 3.8315628306456499e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.5600000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Quadro RTX 6000": 5.1174270964049613e+18,
      "group": 1.0000000000000000e+00,
      "host_name:aleph": 3.2334478980185999e+18,
      "input[0]": 2.0000000000000000e+00,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 2.0000000000000000e+00,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 8.0281600000000000e+05,
      "input_width": 2.8000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 2.5600000000000000e+02,
      "num_iterations": 1.9677000000000000e+04,
      "output_batch_size": 2.0000000000000000e+00,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 1.0035200000000000e+05,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "w_filter_layout": 1.0000000000000000e+00,
      "workspace_bytes": 1.1840000000000000e+03,
      "workspace_megabytes": 1.1291503906250000e-03,
      "x_tensor_layout": 1.0000000000000000e+00,
      "y_tensor_layout": 1.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_2__9829853329635220510<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_SIGMOID>/input[0]:2/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_2__9829853329635220510<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_TANH>/input[0]:2/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_2__9829853329635220510<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_2__9829853329635220510<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:2/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_2__9829853329635220510<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_ELU>/input[0]:2/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_2__9829853329635220510<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_2__9829853329635220510<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_2__9829853329635220510<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_IDENTITY>/input[0]:2/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_2__9829853329635220510<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_SIGMOID>/input[0]:2/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_2__9829853329635220510<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_TANH>/input[0]:2/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_2__9829853329635220510<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_2__9829853329635220510<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:2/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_2__9829853329635220510<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_ELU>/input[0]:2/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_2__9829853329635220510<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_2__9829853329635220510<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_2__9829853329635220510<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_IDENTITY>/input[0]:2/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_2__9829853329635220510<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_SIGMOID>/input[0]:2/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_2__9829853329635220510<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_TANH>/input[0]:2/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_2__9829853329635220510<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_2__9829853329635220510<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:2/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_2__9829853329635220510<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_ELU>/input[0]:2/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_2__9829853329635220510<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_2__9829853329635220510<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_2__9829853329635220510<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_IDENTITY>/input[0]:2/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_2__9829853329635220510<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_SIGMOID>/input[0]:2/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_2__9829853329635220510<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_TANH>/input[0]:2/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_2__9829853329635220510<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_2__9829853329635220510<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:2/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_2__9829853329635220510<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_ELU>/input[0]:2/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_2__9829853329635220510<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_2__9829853329635220510<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_2__9829853329635220510<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_IDENTITY>/input[0]:2/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_2__9829853329635220510<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_SIGMOID>/input[0]:2/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_2__9829853329635220510<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_TANH>/input[0]:2/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_2__9829853329635220510<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_2__9829853329635220510<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:2/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_2__9829853329635220510<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_ELU>/input[0]:2/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_2__9829853329635220510<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_2__9829853329635220510<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_2__9829853329635220510<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_IDENTITY>/input[0]:2/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_2__9829853329635220510<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_SIGMOID>/input[0]:2/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_2__9829853329635220510<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_TANH>/input[0]:2/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_2__9829853329635220510<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_2__9829853329635220510<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:2/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_2__9829853329635220510<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_ELU>/input[0]:2/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_2__9829853329635220510<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_2__9829853329635220510<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_1_TENSORCOREHALF__BatchSize_2__9829853329635220510<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_IDENTITY>/input[0]:2/input[1]:512/input[2]:28/input[3]:28/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_2__8784890181968114745<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_SIGMOID>/input[0]:2/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:7/filter_width:7/pad_height:3/pad_width:3/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_2__8784890181968114745<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_TANH>/input[0]:2/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:7/filter_width:7/pad_height:3/pad_width:3/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_2__8784890181968114745<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:7/filter_width:7/pad_height:3/pad_width:3/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 6370,
      "real_time": 1.1075037761758231e+05,
      "cpu_time": 1.1685863281009947e+05,
      "time_unit": "ns",
      "items_per_second": 1.7397307724340573e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 1.1254400014877319e-01,
      "batch_size": 2.0000000000000000e+00,
      "benchmark_file:/home/dakkak/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 1.5291677899427402e+19,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 2.3191971996820818e+18,
      "bias_tensor_layout": 1.0000000000000000e+00,
      "compute_capability:7.5": 3.8315628306456499e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 7.0000000000000000e+00,
      "filter_width": 7.0000000000000000e+00,
      "gpu_name:Quadro RTX 6000": 5.1174270964049613e+18,
      "group": 1.0000000000000000e+00,
      "host_name:aleph": 3.2334478980185999e+18,
      "input[0]": 2.0000000000000000e+00,
      "input[1]": 3.0000000000000000e+00,
      "input[2]": 2.2400000000000000e+02,
      "input[3]": 2.2400000000000000e+02,
      "input_batch_size": 2.0000000000000000e+00,
      "input_channels": 3.0000000000000000e+00,
      "input_height": 2.2400000000000000e+02,
      "input_size": 3.0105600000000000e+05,
      "input_width": 2.2400000000000000e+02,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 6.3700000000000000e+03,
      "output_batch_size": 2.0000000000000000e+00,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 1.1200000000000000e+02,
      "output_size": 1.6056320000000000e+06,
      "output_width": 1.1200000000000000e+02,
      "pad_height": 3.0000000000000000e+00,
      "pad_width": 3.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "w_filter_layout": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00,
      "x_tensor_layout": 1.0000000000000000e+00,
      "y_tensor_layout": 1.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_2__8784890181968114745<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:2/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:7/filter_width:7/pad_height:3/pad_width:3/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 6357,
      "real_time": 1.1012013991581563e+05,
      "cpu_time": 1.1604331524278298e+05,
      "time_unit": "ns",
      "items_per_second": 1.7496875698423227e+11,
      "activation_mode": 3.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 1.1244799941778183e-01,
      "batch_size": 2.0000000000000000e+00,
      "benchmark_file:/home/dakkak/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 1.5291677899427402e+19,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.9889882919049984e+18,
      "bias_tensor_layout": 1.0000000000000000e+00,
      "compute_capability:7.5": 3.8315628306456499e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 7.0000000000000000e+00,
      "filter_width": 7.0000000000000000e+00,
      "gpu_name:Quadro RTX 6000": 5.1174270964049613e+18,
      "group": 1.0000000000000000e+00,
      "host_name:aleph": 3.2334478980185999e+18,
      "input[0]": 2.0000000000000000e+00,
      "input[1]": 3.0000000000000000e+00,
      "input[2]": 2.2400000000000000e+02,
      "input[3]": 2.2400000000000000e+02,
      "input_batch_size": 2.0000000000000000e+00,
      "input_channels": 3.0000000000000000e+00,
      "input_height": 2.2400000000000000e+02,
      "input_size": 3.0105600000000000e+05,
      "input_width": 2.2400000000000000e+02,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 6.3570000000000000e+03,
      "output_batch_size": 2.0000000000000000e+00,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 1.1200000000000000e+02,
      "output_size": 1.6056320000000000e+06,
      "output_width": 1.1200000000000000e+02,
      "pad_height": 3.0000000000000000e+00,
      "pad_width": 3.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "w_filter_layout": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00,
      "x_tensor_layout": 1.0000000000000000e+00,
      "y_tensor_layout": 1.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_2__8784890181968114745<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_ELU>/input[0]:2/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:7/filter_width:7/pad_height:3/pad_width:3/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_2__8784890181968114745<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:7/filter_width:7/pad_height:3/pad_width:3/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 6344,
      "real_time": 1.0972209848633608e+05,
      "cpu_time": 1.1568006352458263e+05,
      "time_unit": "ns",
      "items_per_second": 1.7560349524667023e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 1.1264000087976456e-01,
      "batch_size": 2.0000000000000000e+00,
      "benchmark_file:/home/dakkak/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 1.5291677899427402e+19,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 2.3191971996820818e+18,
      "bias_tensor_layout": 1.0000000000000000e+00,
      "compute_capability:7.5": 3.8315628306456499e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 7.0000000000000000e+00,
      "filter_width": 7.0000000000000000e+00,
      "gpu_name:Quadro RTX 6000": 5.1174270964049613e+18,
      "group": 1.0000000000000000e+00,
      "host_name:aleph": 3.2334478980185999e+18,
      "input[0]": 2.0000000000000000e+00,
      "input[1]": 3.0000000000000000e+00,
      "input[2]": 2.2400000000000000e+02,
      "input[3]": 2.2400000000000000e+02,
      "input_batch_size": 2.0000000000000000e+00,
      "input_channels": 3.0000000000000000e+00,
      "input_height": 2.2400000000000000e+02,
      "input_size": 3.0105600000000000e+05,
      "input_width": 2.2400000000000000e+02,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 6.3440000000000000e+03,
      "output_batch_size": 2.0000000000000000e+00,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 1.1200000000000000e+02,
      "output_size": 1.6056320000000000e+06,
      "output_width": 1.1200000000000000e+02,
      "pad_height": 3.0000000000000000e+00,
      "pad_width": 3.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "w_filter_layout": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00,
      "x_tensor_layout": 1.0000000000000000e+00,
      "y_tensor_layout": 1.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_2__8784890181968114745<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:7/filter_width:7/pad_height:3/pad_width:3/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 6357,
      "real_time": 1.1052542792787956e+05,
      "cpu_time": 1.1649020261115290e+05,
      "time_unit": "ns",
      "items_per_second": 1.7432716037591412e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 1.1264000087976456e-01,
      "batch_size": 2.0000000000000000e+00,
      "benchmark_file:/home/dakkak/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 1.5291677899427402e+19,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 2.3191971996820818e+18,
      "bias_tensor_layout": 1.0000000000000000e+00,
      "compute_capability:7.5": 3.8315628306456499e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 7.0000000000000000e+00,
      "filter_width": 7.0000000000000000e+00,
      "gpu_name:Quadro RTX 6000": 5.1174270964049613e+18,
      "group": 1.0000000000000000e+00,
      "host_name:aleph": 3.2334478980185999e+18,
      "input[0]": 2.0000000000000000e+00,
      "input[1]": 3.0000000000000000e+00,
      "input[2]": 2.2400000000000000e+02,
      "input[3]": 2.2400000000000000e+02,
      "input_batch_size": 2.0000000000000000e+00,
      "input_channels": 3.0000000000000000e+00,
      "input_height": 2.2400000000000000e+02,
      "input_size": 3.0105600000000000e+05,
      "input_width": 2.2400000000000000e+02,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 6.3570000000000000e+03,
      "output_batch_size": 2.0000000000000000e+00,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 1.1200000000000000e+02,
      "output_size": 1.6056320000000000e+06,
      "output_width": 1.1200000000000000e+02,
      "pad_height": 3.0000000000000000e+00,
      "pad_width": 3.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "w_filter_layout": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00,
      "x_tensor_layout": 1.0000000000000000e+00,
      "y_tensor_layout": 1.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_2__8784890181968114745<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_IDENTITY>/input[0]:2/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:7/filter_width:7/pad_height:3/pad_width:3/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 6371,
      "real_time": 1.0984442774614613e+05,
      "cpu_time": 1.1574352048341668e+05,
      "time_unit": "ns",
      "items_per_second": 1.7540793279498880e+11,
      "activation_mode": 5.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 1.1215999722480774e-01,
      "batch_size": 2.0000000000000000e+00,
      "benchmark_file:/home/dakkak/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 1.5291677899427402e+19,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)5; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.3342635194217454e+19,
      "bias_tensor_layout": 1.0000000000000000e+00,
      "compute_capability:7.5": 3.8315628306456499e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 7.0000000000000000e+00,
      "filter_width": 7.0000000000000000e+00,
      "gpu_name:Quadro RTX 6000": 5.1174270964049613e+18,
      "group": 1.0000000000000000e+00,
      "host_name:aleph": 3.2334478980185999e+18,
      "input[0]": 2.0000000000000000e+00,
      "input[1]": 3.0000000000000000e+00,
      "input[2]": 2.2400000000000000e+02,
      "input[3]": 2.2400000000000000e+02,
      "input_batch_size": 2.0000000000000000e+00,
      "input_channels": 3.0000000000000000e+00,
      "input_height": 2.2400000000000000e+02,
      "input_size": 3.0105600000000000e+05,
      "input_width": 2.2400000000000000e+02,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 6.3710000000000000e+03,
      "output_batch_size": 2.0000000000000000e+00,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 1.1200000000000000e+02,
      "output_size": 1.6056320000000000e+06,
      "output_width": 1.1200000000000000e+02,
      "pad_height": 3.0000000000000000e+00,
      "pad_width": 3.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "w_filter_layout": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00,
      "x_tensor_layout": 1.0000000000000000e+00,
      "y_tensor_layout": 1.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_2__8784890181968114745<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_SIGMOID>/input[0]:2/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:7/filter_width:7/pad_height:3/pad_width:3/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_2__8784890181968114745<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_TANH>/input[0]:2/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:7/filter_width:7/pad_height:3/pad_width:3/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_2__8784890181968114745<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:7/filter_width:7/pad_height:3/pad_width:3/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 6321,
      "real_time": 1.1116708889552231e+05,
      "cpu_time": 1.1710276680926440e+05,
      "time_unit": "ns",
      "items_per_second": 1.7332093690164157e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 5.8800000000000000e+02,
      "advised_time": 1.1427199840545654e-01,
      "batch_size": 2.0000000000000000e+00,
      "benchmark_file:/home/dakkak/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 1.5291677899427402e+19,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.5541522464702913e+19,
      "bias_tensor_layout": 1.0000000000000000e+00,
      "compute_capability:7.5": 3.8315628306456499e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 7.0000000000000000e+00,
      "filter_width": 7.0000000000000000e+00,
      "gpu_name:Quadro RTX 6000": 5.1174270964049613e+18,
      "group": 1.0000000000000000e+00,
      "host_name:aleph": 3.2334478980185999e+18,
      "input[0]": 2.0000000000000000e+00,
      "input[1]": 3.0000000000000000e+00,
      "input[2]": 2.2400000000000000e+02,
      "input[3]": 2.2400000000000000e+02,
      "input_batch_size": 2.0000000000000000e+00,
      "input_channels": 3.0000000000000000e+00,
      "input_height": 2.2400000000000000e+02,
      "input_size": 3.0105600000000000e+05,
      "input_width": 2.2400000000000000e+02,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 6.3210000000000000e+03,
      "output_batch_size": 2.0000000000000000e+00,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 1.1200000000000000e+02,
      "output_size": 1.6056320000000000e+06,
      "output_width": 1.1200000000000000e+02,
      "pad_height": 3.0000000000000000e+00,
      "pad_width": 3.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "w_filter_layout": 1.0000000000000000e+00,
      "workspace_bytes": 5.8800000000000000e+02,
      "workspace_megabytes": 5.6076049804687500e-04,
      "x_tensor_layout": 1.0000000000000000e+00,
      "y_tensor_layout": 1.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_2__8784890181968114745<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:2/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:7/filter_width:7/pad_height:3/pad_width:3/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 6295,
      "real_time": 1.1092188221010777e+05,
      "cpu_time": 1.1681675710876043e+05,
      "time_unit": "ns",
      "items_per_second": 1.7370408449708255e+11,
      "activation_mode": 3.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 5.8800000000000000e+02,
      "advised_time": 1.1084800213575363e-01,
      "batch_size": 2.0000000000000000e+00,
      "benchmark_file:/home/dakkak/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 1.5291677899427402e+19,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.5547362882776177e+19,
      "bias_tensor_layout": 1.0000000000000000e+00,
      "compute_capability:7.5": 3.8315628306456499e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 7.0000000000000000e+00,
      "filter_width": 7.0000000000000000e+00,
      "gpu_name:Quadro RTX 6000": 5.1174270964049613e+18,
      "group": 1.0000000000000000e+00,
      "host_name:aleph": 3.2334478980185999e+18,
      "input[0]": 2.0000000000000000e+00,
      "input[1]": 3.0000000000000000e+00,
      "input[2]": 2.2400000000000000e+02,
      "input[3]": 2.2400000000000000e+02,
      "input_batch_size": 2.0000000000000000e+00,
      "input_channels": 3.0000000000000000e+00,
      "input_height": 2.2400000000000000e+02,
      "input_size": 3.0105600000000000e+05,
      "input_width": 2.2400000000000000e+02,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 6.2950000000000000e+03,
      "output_batch_size": 2.0000000000000000e+00,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 1.1200000000000000e+02,
      "output_size": 1.6056320000000000e+06,
      "output_width": 1.1200000000000000e+02,
      "pad_height": 3.0000000000000000e+00,
      "pad_width": 3.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "w_filter_layout": 1.0000000000000000e+00,
      "workspace_bytes": 5.8800000000000000e+02,
      "workspace_megabytes": 5.6076049804687500e-04,
      "x_tensor_layout": 1.0000000000000000e+00,
      "y_tensor_layout": 1.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_2__8784890181968114745<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_ELU>/input[0]:2/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:7/filter_width:7/pad_height:3/pad_width:3/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_2__8784890181968114745<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:7/filter_width:7/pad_height:3/pad_width:3/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 6311,
      "real_time": 1.1101953048356638e+05,
      "cpu_time": 1.1692510901595677e+05,
      "time_unit": "ns",
      "items_per_second": 1.7355130143386865e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 5.8800000000000000e+02,
      "advised_time": 1.1264000087976456e-01,
      "batch_size": 2.0000000000000000e+00,
      "benchmark_file:/home/dakkak/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 1.5291677899427402e+19,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.5541522464702913e+19,
      "bias_tensor_layout": 1.0000000000000000e+00,
      "compute_capability:7.5": 3.8315628306456499e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 7.0000000000000000e+00,
      "filter_width": 7.0000000000000000e+00,
      "gpu_name:Quadro RTX 6000": 5.1174270964049613e+18,
      "group": 1.0000000000000000e+00,
      "host_name:aleph": 3.2334478980185999e+18,
      "input[0]": 2.0000000000000000e+00,
      "input[1]": 3.0000000000000000e+00,
      "input[2]": 2.2400000000000000e+02,
      "input[3]": 2.2400000000000000e+02,
      "input_batch_size": 2.0000000000000000e+00,
      "input_channels": 3.0000000000000000e+00,
      "input_height": 2.2400000000000000e+02,
      "input_size": 3.0105600000000000e+05,
      "input_width": 2.2400000000000000e+02,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 6.3110000000000000e+03,
      "output_batch_size": 2.0000000000000000e+00,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 1.1200000000000000e+02,
      "output_size": 1.6056320000000000e+06,
      "output_width": 1.1200000000000000e+02,
      "pad_height": 3.0000000000000000e+00,
      "pad_width": 3.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "w_filter_layout": 1.0000000000000000e+00,
      "workspace_bytes": 5.8800000000000000e+02,
      "workspace_megabytes": 5.6076049804687500e-04,
      "x_tensor_layout": 1.0000000000000000e+00,
      "y_tensor_layout": 1.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_2__8784890181968114745<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:7/filter_width:7/pad_height:3/pad_width:3/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 6347,
      "real_time": 1.1094902672706617e+05,
      "cpu_time": 1.1686538711218118e+05,
      "time_unit": "ns",
      "items_per_second": 1.7366158648149408e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 5.8800000000000000e+02,
      "advised_time": 1.1097600311040878e-01,
      "batch_size": 2.0000000000000000e+00,
      "benchmark_file:/home/dakkak/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 1.5291677899427402e+19,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.5541522464702913e+19,
      "bias_tensor_layout": 1.0000000000000000e+00,
      "compute_capability:7.5": 3.8315628306456499e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 7.0000000000000000e+00,
      "filter_width": 7.0000000000000000e+00,
      "gpu_name:Quadro RTX 6000": 5.1174270964049613e+18,
      "group": 1.0000000000000000e+00,
      "host_name:aleph": 3.2334478980185999e+18,
      "input[0]": 2.0000000000000000e+00,
      "input[1]": 3.0000000000000000e+00,
      "input[2]": 2.2400000000000000e+02,
      "input[3]": 2.2400000000000000e+02,
      "input_batch_size": 2.0000000000000000e+00,
      "input_channels": 3.0000000000000000e+00,
      "input_height": 2.2400000000000000e+02,
      "input_size": 3.0105600000000000e+05,
      "input_width": 2.2400000000000000e+02,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 6.3470000000000000e+03,
      "output_batch_size": 2.0000000000000000e+00,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 1.1200000000000000e+02,
      "output_size": 1.6056320000000000e+06,
      "output_width": 1.1200000000000000e+02,
      "pad_height": 3.0000000000000000e+00,
      "pad_width": 3.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "w_filter_layout": 1.0000000000000000e+00,
      "workspace_bytes": 5.8800000000000000e+02,
      "workspace_megabytes": 5.6076049804687500e-04,
      "x_tensor_layout": 1.0000000000000000e+00,
      "y_tensor_layout": 1.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_2__8784890181968114745<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_IDENTITY>/input[0]:2/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:7/filter_width:7/pad_height:3/pad_width:3/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 6295,
      "real_time": 1.1067639468738927e+05,
      "cpu_time": 1.1657992772048013e+05,
      "time_unit": "ns",
      "items_per_second": 1.7408937158119586e+11,
      "activation_mode": 5.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 5.8800000000000000e+02,
      "advised_time": 1.1286400258541107e-01,
      "batch_size": 2.0000000000000000e+00,
      "benchmark_file:/home/dakkak/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 1.5291677899427402e+19,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)5; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 4.5833023350607309e+18,
      "bias_tensor_layout": 1.0000000000000000e+00,
      "compute_capability:7.5": 3.8315628306456499e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 6.4000000000000000e+01,
      "filter_height": 7.0000000000000000e+00,
      "filter_width": 7.0000000000000000e+00,
      "gpu_name:Quadro RTX 6000": 5.1174270964049613e+18,
      "group": 1.0000000000000000e+00,
      "host_name:aleph": 3.2334478980185999e+18,
      "input[0]": 2.0000000000000000e+00,
      "input[1]": 3.0000000000000000e+00,
      "input[2]": 2.2400000000000000e+02,
      "input[3]": 2.2400000000000000e+02,
      "input_batch_size": 2.0000000000000000e+00,
      "input_channels": 3.0000000000000000e+00,
      "input_height": 2.2400000000000000e+02,
      "input_size": 3.0105600000000000e+05,
      "input_width": 2.2400000000000000e+02,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 6.4000000000000000e+01,
      "num_iterations": 6.2950000000000000e+03,
      "output_batch_size": 2.0000000000000000e+00,
      "output_channels": 6.4000000000000000e+01,
      "output_height": 1.1200000000000000e+02,
      "output_size": 1.6056320000000000e+06,
      "output_width": 1.1200000000000000e+02,
      "pad_height": 3.0000000000000000e+00,
      "pad_width": 3.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "w_filter_layout": 1.0000000000000000e+00,
      "workspace_bytes": 5.8800000000000000e+02,
      "workspace_megabytes": 5.6076049804687500e-04,
      "x_tensor_layout": 1.0000000000000000e+00,
      "y_tensor_layout": 1.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_2__8784890181968114745<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_SIGMOID>/input[0]:2/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:7/filter_width:7/pad_height:3/pad_width:3/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_2__8784890181968114745<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_TANH>/input[0]:2/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:7/filter_width:7/pad_height:3/pad_width:3/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_2__8784890181968114745<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:7/filter_width:7/pad_height:3/pad_width:3/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_2__8784890181968114745<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:2/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:7/filter_width:7/pad_height:3/pad_width:3/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_2__8784890181968114745<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_ELU>/input[0]:2/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:7/filter_width:7/pad_height:3/pad_width:3/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_2__8784890181968114745<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:7/filter_width:7/pad_height:3/pad_width:3/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_2__8784890181968114745<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:7/filter_width:7/pad_height:3/pad_width:3/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_2__8784890181968114745<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_IDENTITY>/input[0]:2/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:7/filter_width:7/pad_height:3/pad_width:3/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_2__8784890181968114745<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_SIGMOID>/input[0]:2/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:7/filter_width:7/pad_height:3/pad_width:3/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_2__8784890181968114745<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_TANH>/input[0]:2/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:7/filter_width:7/pad_height:3/pad_width:3/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_2__8784890181968114745<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:7/filter_width:7/pad_height:3/pad_width:3/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_2__8784890181968114745<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:2/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:7/filter_width:7/pad_height:3/pad_width:3/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_2__8784890181968114745<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_ELU>/input[0]:2/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:7/filter_width:7/pad_height:3/pad_width:3/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_2__8784890181968114745<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:7/filter_width:7/pad_height:3/pad_width:3/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_2__8784890181968114745<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:7/filter_width:7/pad_height:3/pad_width:3/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_2__8784890181968114745<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_IDENTITY>/input[0]:2/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:7/filter_width:7/pad_height:3/pad_width:3/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_2__8784890181968114745<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_SIGMOID>/input[0]:2/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:7/filter_width:7/pad_height:3/pad_width:3/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_2__8784890181968114745<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_TANH>/input[0]:2/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:7/filter_width:7/pad_height:3/pad_width:3/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_2__8784890181968114745<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:7/filter_width:7/pad_height:3/pad_width:3/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_2__8784890181968114745<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:2/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:7/filter_width:7/pad_height:3/pad_width:3/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_2__8784890181968114745<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_ELU>/input[0]:2/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:7/filter_width:7/pad_height:3/pad_width:3/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_2__8784890181968114745<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:7/filter_width:7/pad_height:3/pad_width:3/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_2__8784890181968114745<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:7/filter_width:7/pad_height:3/pad_width:3/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_2__8784890181968114745<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_IDENTITY>/input[0]:2/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:7/filter_width:7/pad_height:3/pad_width:3/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_2__8784890181968114745<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_SIGMOID>/input[0]:2/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:7/filter_width:7/pad_height:3/pad_width:3/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_2__8784890181968114745<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_TANH>/input[0]:2/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:7/filter_width:7/pad_height:3/pad_width:3/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_2__8784890181968114745<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:7/filter_width:7/pad_height:3/pad_width:3/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_2__8784890181968114745<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:2/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:7/filter_width:7/pad_height:3/pad_width:3/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_2__8784890181968114745<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_ELU>/input[0]:2/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:7/filter_width:7/pad_height:3/pad_width:3/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_2__8784890181968114745<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:7/filter_width:7/pad_height:3/pad_width:3/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_2__8784890181968114745<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:7/filter_width:7/pad_height:3/pad_width:3/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_2__8784890181968114745<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_IDENTITY>/input[0]:2/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:7/filter_width:7/pad_height:3/pad_width:3/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_2__8784890181968114745<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_SIGMOID>/input[0]:2/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:7/filter_width:7/pad_height:3/pad_width:3/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_2__8784890181968114745<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_TANH>/input[0]:2/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:7/filter_width:7/pad_height:3/pad_width:3/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_2__8784890181968114745<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:7/filter_width:7/pad_height:3/pad_width:3/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_2__8784890181968114745<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:2/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:7/filter_width:7/pad_height:3/pad_width:3/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_2__8784890181968114745<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_ELU>/input[0]:2/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:7/filter_width:7/pad_height:3/pad_width:3/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_2__8784890181968114745<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:7/filter_width:7/pad_height:3/pad_width:3/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_2__8784890181968114745<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:7/filter_width:7/pad_height:3/pad_width:3/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_2__8784890181968114745<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_IDENTITY>/input[0]:2/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:7/filter_width:7/pad_height:3/pad_width:3/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_2__8784890181968114745<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_SIGMOID>/input[0]:2/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:7/filter_width:7/pad_height:3/pad_width:3/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_2__8784890181968114745<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_TANH>/input[0]:2/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:7/filter_width:7/pad_height:3/pad_width:3/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_2__8784890181968114745<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:7/filter_width:7/pad_height:3/pad_width:3/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_2__8784890181968114745<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:2/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:7/filter_width:7/pad_height:3/pad_width:3/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_2__8784890181968114745<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_ELU>/input[0]:2/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:7/filter_width:7/pad_height:3/pad_width:3/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_2__8784890181968114745<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:7/filter_width:7/pad_height:3/pad_width:3/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_2__8784890181968114745<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:7/filter_width:7/pad_height:3/pad_width:3/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_2__8784890181968114745<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_IDENTITY>/input[0]:2/input[1]:3/input[2]:224/input[3]:224/filter_count:64/filter_height:7/filter_width:7/pad_height:3/pad_width:3/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_2__7070109029515514731<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_SIGMOID>/input[0]:2/input[1]:256/input[2]:56/input[3]:56/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_2__7070109029515514731<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_TANH>/input[0]:2/input[1]:256/input[2]:56/input[3]:56/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_2__7070109029515514731<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:256/input[2]:56/input[3]:56/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 7281,
      "real_time": 9.6074917421666556e+04,
      "cpu_time": 1.0210868369738522e+05,
      "time_unit": "ns",
      "items_per_second": 8.5566931105642139e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 9.7312003374099731e-02,
      "batch_size": 2.0000000000000000e+00,
      "benchmark_file:/home/dakkak/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 1.5291677899427402e+19,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 2.3191971996820818e+18,
      "bias_tensor_layout": 1.0000000000000000e+00,
      "compute_capability:7.5": 3.8315628306456499e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Quadro RTX 6000": 5.1174270964049613e+18,
      "group": 1.0000000000000000e+00,
      "host_name:aleph": 3.2334478980185999e+18,
      "input[0]": 2.0000000000000000e+00,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 2.0000000000000000e+00,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 5.6000000000000000e+01,
      "input_size": 1.6056320000000000e+06,
      "input_width": 5.6000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 7.2810000000000000e+03,
      "output_batch_size": 2.0000000000000000e+00,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 8.0281600000000000e+05,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "w_filter_layout": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00,
      "x_tensor_layout": 1.0000000000000000e+00,
      "y_tensor_layout": 1.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_2__7070109029515514731<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:2/input[1]:256/input[2]:56/input[3]:56/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 7286,
      "real_time": 9.6006039166939983e+04,
      "cpu_time": 1.0187810787798149e+05,
      "time_unit": "ns",
      "items_per_second": 8.5628319961260029e+12,
      "activation_mode": 3.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 9.7280003130435944e-02,
      "batch_size": 2.0000000000000000e+00,
      "benchmark_file:/home/dakkak/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 1.5291677899427402e+19,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.9889882919049984e+18,
      "bias_tensor_layout": 1.0000000000000000e+00,
      "compute_capability:7.5": 3.8315628306456499e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Quadro RTX 6000": 5.1174270964049613e+18,
      "group": 1.0000000000000000e+00,
      "host_name:aleph": 3.2334478980185999e+18,
      "input[0]": 2.0000000000000000e+00,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 2.0000000000000000e+00,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 5.6000000000000000e+01,
      "input_size": 1.6056320000000000e+06,
      "input_width": 5.6000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 7.2860000000000000e+03,
      "output_batch_size": 2.0000000000000000e+00,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 8.0281600000000000e+05,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "w_filter_layout": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00,
      "x_tensor_layout": 1.0000000000000000e+00,
      "y_tensor_layout": 1.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_2__7070109029515514731<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_ELU>/input[0]:2/input[1]:256/input[2]:56/input[3]:56/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_2__7070109029515514731<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:256/input[2]:56/input[3]:56/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 7273,
      "real_time": 9.6057928386612693e+04,
      "cpu_time": 1.0198014203203707e+05,
      "time_unit": "ns",
      "items_per_second": 8.5582064677814912e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 9.6639998257160187e-02,
      "batch_size": 2.0000000000000000e+00,
      "benchmark_file:/home/dakkak/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 1.5291677899427402e+19,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 2.3191971996820818e+18,
      "bias_tensor_layout": 1.0000000000000000e+00,
      "compute_capability:7.5": 3.8315628306456499e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Quadro RTX 6000": 5.1174270964049613e+18,
      "group": 1.0000000000000000e+00,
      "host_name:aleph": 3.2334478980185999e+18,
      "input[0]": 2.0000000000000000e+00,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 2.0000000000000000e+00,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 5.6000000000000000e+01,
      "input_size": 1.6056320000000000e+06,
      "input_width": 5.6000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 7.2730000000000000e+03,
      "output_batch_size": 2.0000000000000000e+00,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 8.0281600000000000e+05,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "w_filter_layout": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00,
      "x_tensor_layout": 1.0000000000000000e+00,
      "y_tensor_layout": 1.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_2__7070109029515514731<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:256/input[2]:56/input[3]:56/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 7288,
      "real_time": 9.6092026527769049e+04,
      "cpu_time": 1.0200833918776180e+05,
      "time_unit": "ns",
      "items_per_second": 8.5551695984102383e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 9.7952000796794891e-02,
      "batch_size": 2.0000000000000000e+00,
      "benchmark_file:/home/dakkak/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 1.5291677899427402e+19,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 2.3191971996820818e+18,
      "bias_tensor_layout": 1.0000000000000000e+00,
      "compute_capability:7.5": 3.8315628306456499e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Quadro RTX 6000": 5.1174270964049613e+18,
      "group": 1.0000000000000000e+00,
      "host_name:aleph": 3.2334478980185999e+18,
      "input[0]": 2.0000000000000000e+00,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 2.0000000000000000e+00,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 5.6000000000000000e+01,
      "input_size": 1.6056320000000000e+06,
      "input_width": 5.6000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 7.2880000000000000e+03,
      "output_batch_size": 2.0000000000000000e+00,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 8.0281600000000000e+05,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "w_filter_layout": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00,
      "x_tensor_layout": 1.0000000000000000e+00,
      "y_tensor_layout": 1.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_2__7070109029515514731<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_IDENTITY>/input[0]:2/input[1]:256/input[2]:56/input[3]:56/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 7296,
      "real_time": 9.5983960755730601e+04,
      "cpu_time": 1.0186571230823014e+05,
      "time_unit": "ns",
      "items_per_second": 8.5648016348493779e+12,
      "activation_mode": 5.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 9.8304003477096558e-02,
      "batch_size": 2.0000000000000000e+00,
      "benchmark_file:/home/dakkak/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 1.5291677899427402e+19,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)5; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.3342635194217454e+19,
      "bias_tensor_layout": 1.0000000000000000e+00,
      "compute_capability:7.5": 3.8315628306456499e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Quadro RTX 6000": 5.1174270964049613e+18,
      "group": 1.0000000000000000e+00,
      "host_name:aleph": 3.2334478980185999e+18,
      "input[0]": 2.0000000000000000e+00,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 2.0000000000000000e+00,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 5.6000000000000000e+01,
      "input_size": 1.6056320000000000e+06,
      "input_width": 5.6000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 7.2960000000000000e+03,
      "output_batch_size": 2.0000000000000000e+00,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 8.0281600000000000e+05,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "w_filter_layout": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00,
      "x_tensor_layout": 1.0000000000000000e+00,
      "y_tensor_layout": 1.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_2__7070109029515514731<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_SIGMOID>/input[0]:2/input[1]:256/input[2]:56/input[3]:56/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_2__7070109029515514731<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_TANH>/input[0]:2/input[1]:256/input[2]:56/input[3]:56/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_2__7070109029515514731<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:256/input[2]:56/input[3]:56/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 22830,
      "real_time": 3.0723474674969417e+04,
      "cpu_time": 3.6437521988695138e+04,
      "time_unit": "ns",
      "items_per_second": 2.6757506847679438e+13,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 4.7120000000000000e+03,
      "advised_time": 3.6864001303911209e-02,
      "batch_size": 2.0000000000000000e+00,
      "benchmark_file:/home/dakkak/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 1.5291677899427402e+19,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.5541522464702913e+19,
      "bias_tensor_layout": 1.0000000000000000e+00,
      "compute_capability:7.5": 3.8315628306456499e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Quadro RTX 6000": 5.1174270964049613e+18,
      "group": 1.0000000000000000e+00,
      "host_name:aleph": 3.2334478980185999e+18,
      "input[0]": 2.0000000000000000e+00,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 2.0000000000000000e+00,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 5.6000000000000000e+01,
      "input_size": 1.6056320000000000e+06,
      "input_width": 5.6000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 2.2830000000000000e+04,
      "output_batch_size": 2.0000000000000000e+00,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 8.0281600000000000e+05,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "w_filter_layout": 1.0000000000000000e+00,
      "workspace_bytes": 4.7120000000000000e+03,
      "workspace_megabytes": 4.4937133789062500e-03,
      "x_tensor_layout": 1.0000000000000000e+00,
      "y_tensor_layout": 1.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_2__7070109029515514731<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:2/input[1]:256/input[2]:56/input[3]:56/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 22977,
      "real_time": 3.1056613405893899e+04,
      "cpu_time": 3.6852127997593758e+04,
      "time_unit": "ns",
      "items_per_second": 2.6470483862995367e+13,
      "activation_mode": 3.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 4.7120000000000000e+03,
      "advised_time": 3.6864001303911209e-02,
      "batch_size": 2.0000000000000000e+00,
      "benchmark_file:/home/dakkak/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 1.5291677899427402e+19,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.5547362882776177e+19,
      "bias_tensor_layout": 1.0000000000000000e+00,
      "compute_capability:7.5": 3.8315628306456499e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Quadro RTX 6000": 5.1174270964049613e+18,
      "group": 1.0000000000000000e+00,
      "host_name:aleph": 3.2334478980185999e+18,
      "input[0]": 2.0000000000000000e+00,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 2.0000000000000000e+00,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 5.6000000000000000e+01,
      "input_size": 1.6056320000000000e+06,
      "input_width": 5.6000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 2.2977000000000000e+04,
      "output_batch_size": 2.0000000000000000e+00,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 8.0281600000000000e+05,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "w_filter_layout": 1.0000000000000000e+00,
      "workspace_bytes": 4.7120000000000000e+03,
      "workspace_megabytes": 4.4937133789062500e-03,
      "x_tensor_layout": 1.0000000000000000e+00,
      "y_tensor_layout": 1.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_2__7070109029515514731<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_ELU>/input[0]:2/input[1]:256/input[2]:56/input[3]:56/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_2__7070109029515514731<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:256/input[2]:56/input[3]:56/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 22654,
      "real_time": 3.0592703385345580e+04,
      "cpu_time": 3.6275134766620140e+04,
      "time_unit": "ns",
      "items_per_second": 2.6871884241318535e+13,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 4.7120000000000000e+03,
      "advised_time": 3.7919998168945312e-02,
      "batch_size": 2.0000000000000000e+00,
      "benchmark_file:/home/dakkak/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 1.5291677899427402e+19,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.5541522464702913e+19,
      "bias_tensor_layout": 1.0000000000000000e+00,
      "compute_capability:7.5": 3.8315628306456499e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Quadro RTX 6000": 5.1174270964049613e+18,
      "group": 1.0000000000000000e+00,
      "host_name:aleph": 3.2334478980185999e+18,
      "input[0]": 2.0000000000000000e+00,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 2.0000000000000000e+00,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 5.6000000000000000e+01,
      "input_size": 1.6056320000000000e+06,
      "input_width": 5.6000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 2.2654000000000000e+04,
      "output_batch_size": 2.0000000000000000e+00,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 8.0281600000000000e+05,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "w_filter_layout": 1.0000000000000000e+00,
      "workspace_bytes": 4.7120000000000000e+03,
      "workspace_megabytes": 4.4937133789062500e-03,
      "x_tensor_layout": 1.0000000000000000e+00,
      "y_tensor_layout": 1.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_2__7070109029515514731<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:256/input[2]:56/input[3]:56/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 22769,
      "real_time": 3.0640219899882472e+04,
      "cpu_time": 3.6385764855880938e+04,
      "time_unit": "ns",
      "items_per_second": 2.6830211620091973e+13,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 4.7120000000000000e+03,
      "advised_time": 4.0063999593257904e-02,
      "batch_size": 2.0000000000000000e+00,
      "benchmark_file:/home/dakkak/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 1.5291677899427402e+19,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.5541522464702913e+19,
      "bias_tensor_layout": 1.0000000000000000e+00,
      "compute_capability:7.5": 3.8315628306456499e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Quadro RTX 6000": 5.1174270964049613e+18,
      "group": 1.0000000000000000e+00,
      "host_name:aleph": 3.2334478980185999e+18,
      "input[0]": 2.0000000000000000e+00,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 2.0000000000000000e+00,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 5.6000000000000000e+01,
      "input_size": 1.6056320000000000e+06,
      "input_width": 5.6000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 2.2769000000000000e+04,
      "output_batch_size": 2.0000000000000000e+00,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 8.0281600000000000e+05,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "w_filter_layout": 1.0000000000000000e+00,
      "workspace_bytes": 4.7120000000000000e+03,
      "workspace_megabytes": 4.4937133789062500e-03,
      "x_tensor_layout": 1.0000000000000000e+00,
      "y_tensor_layout": 1.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_2__7070109029515514731<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_IDENTITY>/input[0]:2/input[1]:256/input[2]:56/input[3]:56/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 22779,
      "real_time": 3.0626604437971240e+04,
      "cpu_time": 3.6341554940985021e+04,
      "time_unit": "ns",
      "items_per_second": 2.6842139345384648e+13,
      "activation_mode": 5.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 4.7120000000000000e+03,
      "advised_time": 3.6832001060247421e-02,
      "batch_size": 2.0000000000000000e+00,
      "benchmark_file:/home/dakkak/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 1.5291677899427402e+19,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)5; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 4.5833023350607309e+18,
      "bias_tensor_layout": 1.0000000000000000e+00,
      "compute_capability:7.5": 3.8315628306456499e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Quadro RTX 6000": 5.1174270964049613e+18,
      "group": 1.0000000000000000e+00,
      "host_name:aleph": 3.2334478980185999e+18,
      "input[0]": 2.0000000000000000e+00,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 2.0000000000000000e+00,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 5.6000000000000000e+01,
      "input_size": 1.6056320000000000e+06,
      "input_width": 5.6000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 2.2779000000000000e+04,
      "output_batch_size": 2.0000000000000000e+00,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 8.0281600000000000e+05,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "w_filter_layout": 1.0000000000000000e+00,
      "workspace_bytes": 4.7120000000000000e+03,
      "workspace_megabytes": 4.4937133789062500e-03,
      "x_tensor_layout": 1.0000000000000000e+00,
      "y_tensor_layout": 1.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_2__7070109029515514731<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_SIGMOID>/input[0]:2/input[1]:256/input[2]:56/input[3]:56/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_2__7070109029515514731<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_TANH>/input[0]:2/input[1]:256/input[2]:56/input[3]:56/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_2__7070109029515514731<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:256/input[2]:56/input[3]:56/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_2__7070109029515514731<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:2/input[1]:256/input[2]:56/input[3]:56/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_2__7070109029515514731<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_ELU>/input[0]:2/input[1]:256/input[2]:56/input[3]:56/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_2__7070109029515514731<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:256/input[2]:56/input[3]:56/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_2__7070109029515514731<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:256/input[2]:56/input[3]:56/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_2__7070109029515514731<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_IDENTITY>/input[0]:2/input[1]:256/input[2]:56/input[3]:56/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_2__7070109029515514731<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_SIGMOID>/input[0]:2/input[1]:256/input[2]:56/input[3]:56/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_2__7070109029515514731<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_TANH>/input[0]:2/input[1]:256/input[2]:56/input[3]:56/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_2__7070109029515514731<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:256/input[2]:56/input[3]:56/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_2__7070109029515514731<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:2/input[1]:256/input[2]:56/input[3]:56/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_2__7070109029515514731<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_ELU>/input[0]:2/input[1]:256/input[2]:56/input[3]:56/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_2__7070109029515514731<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:256/input[2]:56/input[3]:56/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_2__7070109029515514731<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:256/input[2]:56/input[3]:56/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_2__7070109029515514731<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_IDENTITY>/input[0]:2/input[1]:256/input[2]:56/input[3]:56/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_2__7070109029515514731<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_SIGMOID>/input[0]:2/input[1]:256/input[2]:56/input[3]:56/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_2__7070109029515514731<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_TANH>/input[0]:2/input[1]:256/input[2]:56/input[3]:56/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_2__7070109029515514731<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:256/input[2]:56/input[3]:56/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_2__7070109029515514731<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:2/input[1]:256/input[2]:56/input[3]:56/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_2__7070109029515514731<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_ELU>/input[0]:2/input[1]:256/input[2]:56/input[3]:56/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_2__7070109029515514731<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:256/input[2]:56/input[3]:56/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_2__7070109029515514731<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:256/input[2]:56/input[3]:56/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_2__7070109029515514731<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_IDENTITY>/input[0]:2/input[1]:256/input[2]:56/input[3]:56/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_2__7070109029515514731<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_SIGMOID>/input[0]:2/input[1]:256/input[2]:56/input[3]:56/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_2__7070109029515514731<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_TANH>/input[0]:2/input[1]:256/input[2]:56/input[3]:56/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_2__7070109029515514731<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:256/input[2]:56/input[3]:56/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_2__7070109029515514731<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:2/input[1]:256/input[2]:56/input[3]:56/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_2__7070109029515514731<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_ELU>/input[0]:2/input[1]:256/input[2]:56/input[3]:56/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_2__7070109029515514731<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:256/input[2]:56/input[3]:56/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_2__7070109029515514731<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:256/input[2]:56/input[3]:56/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_2__7070109029515514731<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_IDENTITY>/input[0]:2/input[1]:256/input[2]:56/input[3]:56/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_2__7070109029515514731<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_SIGMOID>/input[0]:2/input[1]:256/input[2]:56/input[3]:56/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_2__7070109029515514731<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_TANH>/input[0]:2/input[1]:256/input[2]:56/input[3]:56/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_2__7070109029515514731<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:256/input[2]:56/input[3]:56/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_2__7070109029515514731<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:2/input[1]:256/input[2]:56/input[3]:56/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_2__7070109029515514731<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_ELU>/input[0]:2/input[1]:256/input[2]:56/input[3]:56/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_2__7070109029515514731<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:256/input[2]:56/input[3]:56/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_2__7070109029515514731<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:256/input[2]:56/input[3]:56/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_2__7070109029515514731<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_IDENTITY>/input[0]:2/input[1]:256/input[2]:56/input[3]:56/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_2__7070109029515514731<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_SIGMOID>/input[0]:2/input[1]:256/input[2]:56/input[3]:56/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_2__7070109029515514731<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_TANH>/input[0]:2/input[1]:256/input[2]:56/input[3]:56/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_2__7070109029515514731<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:256/input[2]:56/input[3]:56/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_2__7070109029515514731<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:2/input[1]:256/input[2]:56/input[3]:56/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_2__7070109029515514731<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_ELU>/input[0]:2/input[1]:256/input[2]:56/input[3]:56/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_2__7070109029515514731<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:256/input[2]:56/input[3]:56/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_2__7070109029515514731<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:256/input[2]:56/input[3]:56/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_2__7070109029515514731<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_IDENTITY>/input[0]:2/input[1]:256/input[2]:56/input[3]:56/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_2__7261539804651029798<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_SIGMOID>/input[0]:2/input[1]:1024/input[2]:14/input[3]:14/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_2__7261539804651029798<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_TANH>/input[0]:2/input[1]:1024/input[2]:14/input[3]:14/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_2__7261539804651029798<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:1024/input[2]:14/input[3]:14/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 2397,
      "real_time": 2.8817213487828482e+05,
      "cpu_time": 2.9514327325848350e+05,
      "time_unit": "ns",
      "items_per_second": 2.8527518260820854e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 3.0067199468612671e-01,
      "batch_size": 2.0000000000000000e+00,
      "benchmark_file:/home/dakkak/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 1.5291677899427402e+19,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 2.3191971996820818e+18,
      "bias_tensor_layout": 1.0000000000000000e+00,
      "compute_capability:7.5": 3.8315628306456499e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.0480000000000000e+03,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Quadro RTX 6000": 5.1174270964049613e+18,
      "group": 1.0000000000000000e+00,
      "host_name:aleph": 3.2334478980185999e+18,
      "input[0]": 2.0000000000000000e+00,
      "input[1]": 1.0240000000000000e+03,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 2.0000000000000000e+00,
      "input_channels": 1.0240000000000000e+03,
      "input_height": 1.4000000000000000e+01,
      "input_size": 4.0140800000000000e+05,
      "input_width": 1.4000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 2.0480000000000000e+03,
      "num_iterations": 2.3970000000000000e+03,
      "output_batch_size": 2.0000000000000000e+00,
      "output_channels": 2.0480000000000000e+03,
      "output_height": 7.0000000000000000e+00,
      "output_size": 2.0070400000000000e+05,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "w_filter_layout": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00,
      "x_tensor_layout": 1.0000000000000000e+00,
      "y_tensor_layout": 1.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_2__7261539804651029798<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:2/input[1]:1024/input[2]:14/input[3]:14/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 2428,
      "real_time": 2.8805153177008935e+05,
      "cpu_time": 2.9489472446502995e+05,
      "time_unit": "ns",
      "items_per_second": 2.8539462329822031e+12,
      "activation_mode": 3.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 3.1727999448776245e-01,
      "batch_size": 2.0000000000000000e+00,
      "benchmark_file:/home/dakkak/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 1.5291677899427402e+19,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.9889882919049984e+18,
      "bias_tensor_layout": 1.0000000000000000e+00,
      "compute_capability:7.5": 3.8315628306456499e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.0480000000000000e+03,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Quadro RTX 6000": 5.1174270964049613e+18,
      "group": 1.0000000000000000e+00,
      "host_name:aleph": 3.2334478980185999e+18,
      "input[0]": 2.0000000000000000e+00,
      "input[1]": 1.0240000000000000e+03,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 2.0000000000000000e+00,
      "input_channels": 1.0240000000000000e+03,
      "input_height": 1.4000000000000000e+01,
      "input_size": 4.0140800000000000e+05,
      "input_width": 1.4000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 2.0480000000000000e+03,
      "num_iterations": 2.4280000000000000e+03,
      "output_batch_size": 2.0000000000000000e+00,
      "output_channels": 2.0480000000000000e+03,
      "output_height": 7.0000000000000000e+00,
      "output_size": 2.0070400000000000e+05,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "w_filter_layout": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00,
      "x_tensor_layout": 1.0000000000000000e+00,
      "y_tensor_layout": 1.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_2__7261539804651029798<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_ELU>/input[0]:2/input[1]:1024/input[2]:14/input[3]:14/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_2__7261539804651029798<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:1024/input[2]:14/input[3]:14/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 2427,
      "real_time": 2.8810235453210463e+05,
      "cpu_time": 2.9495539678637538e+05,
      "time_unit": "ns",
      "items_per_second": 2.8534427819415522e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 2.9913601279258728e-01,
      "batch_size": 2.0000000000000000e+00,
      "benchmark_file:/home/dakkak/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 1.5291677899427402e+19,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 2.3191971996820818e+18,
      "bias_tensor_layout": 1.0000000000000000e+00,
      "compute_capability:7.5": 3.8315628306456499e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.0480000000000000e+03,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Quadro RTX 6000": 5.1174270964049613e+18,
      "group": 1.0000000000000000e+00,
      "host_name:aleph": 3.2334478980185999e+18,
      "input[0]": 2.0000000000000000e+00,
      "input[1]": 1.0240000000000000e+03,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 2.0000000000000000e+00,
      "input_channels": 1.0240000000000000e+03,
      "input_height": 1.4000000000000000e+01,
      "input_size": 4.0140800000000000e+05,
      "input_width": 1.4000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 2.0480000000000000e+03,
      "num_iterations": 2.4270000000000000e+03,
      "output_batch_size": 2.0000000000000000e+00,
      "output_channels": 2.0480000000000000e+03,
      "output_height": 7.0000000000000000e+00,
      "output_size": 2.0070400000000000e+05,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "w_filter_layout": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00,
      "x_tensor_layout": 1.0000000000000000e+00,
      "y_tensor_layout": 1.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_2__7261539804651029798<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:1024/input[2]:14/input[3]:14/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 2426,
      "real_time": 2.8803202647572616e+05,
      "cpu_time": 2.9491428854048299e+05,
      "time_unit": "ns",
      "items_per_second": 2.8541394998978730e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 2.9776000976562500e-01,
      "batch_size": 2.0000000000000000e+00,
      "benchmark_file:/home/dakkak/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 1.5291677899427402e+19,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 2.3191971996820818e+18,
      "bias_tensor_layout": 1.0000000000000000e+00,
      "compute_capability:7.5": 3.8315628306456499e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.0480000000000000e+03,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Quadro RTX 6000": 5.1174270964049613e+18,
      "group": 1.0000000000000000e+00,
      "host_name:aleph": 3.2334478980185999e+18,
      "input[0]": 2.0000000000000000e+00,
      "input[1]": 1.0240000000000000e+03,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 2.0000000000000000e+00,
      "input_channels": 1.0240000000000000e+03,
      "input_height": 1.4000000000000000e+01,
      "input_size": 4.0140800000000000e+05,
      "input_width": 1.4000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 2.0480000000000000e+03,
      "num_iterations": 2.4260000000000000e+03,
      "output_batch_size": 2.0000000000000000e+00,
      "output_channels": 2.0480000000000000e+03,
      "output_height": 7.0000000000000000e+00,
      "output_size": 2.0070400000000000e+05,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "w_filter_layout": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00,
      "x_tensor_layout": 1.0000000000000000e+00,
      "y_tensor_layout": 1.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_2__7261539804651029798<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_IDENTITY>/input[0]:2/input[1]:1024/input[2]:14/input[3]:14/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 2429,
      "real_time": 2.8797627339504211e+05,
      "cpu_time": 2.9487493371777073e+05,
      "time_unit": "ns",
      "items_per_second": 2.8546920699688213e+12,
      "activation_mode": 5.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 3.2054400444030762e-01,
      "batch_size": 2.0000000000000000e+00,
      "benchmark_file:/home/dakkak/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 1.5291677899427402e+19,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)5; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.3342635194217454e+19,
      "bias_tensor_layout": 1.0000000000000000e+00,
      "compute_capability:7.5": 3.8315628306456499e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.0480000000000000e+03,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Quadro RTX 6000": 5.1174270964049613e+18,
      "group": 1.0000000000000000e+00,
      "host_name:aleph": 3.2334478980185999e+18,
      "input[0]": 2.0000000000000000e+00,
      "input[1]": 1.0240000000000000e+03,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 2.0000000000000000e+00,
      "input_channels": 1.0240000000000000e+03,
      "input_height": 1.4000000000000000e+01,
      "input_size": 4.0140800000000000e+05,
      "input_width": 1.4000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 2.0480000000000000e+03,
      "num_iterations": 2.4290000000000000e+03,
      "output_batch_size": 2.0000000000000000e+00,
      "output_channels": 2.0480000000000000e+03,
      "output_height": 7.0000000000000000e+00,
      "output_size": 2.0070400000000000e+05,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "w_filter_layout": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00,
      "x_tensor_layout": 1.0000000000000000e+00,
      "y_tensor_layout": 1.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_2__7261539804651029798<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_SIGMOID>/input[0]:2/input[1]:1024/input[2]:14/input[3]:14/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_2__7261539804651029798<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_TANH>/input[0]:2/input[1]:1024/input[2]:14/input[3]:14/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_2__7261539804651029798<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:1024/input[2]:14/input[3]:14/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 15415,
      "real_time": 4.5766304411858240e+04,
      "cpu_time": 5.1635867920919700e+04,
      "time_unit": "ns",
      "items_per_second": 1.7962638551759375e+13,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 3.0000000000000000e+02,
      "advised_time": 7.5999997556209564e-02,
      "batch_size": 2.0000000000000000e+00,
      "benchmark_file:/home/dakkak/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 1.5291677899427402e+19,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.5541522464702913e+19,
      "bias_tensor_layout": 1.0000000000000000e+00,
      "compute_capability:7.5": 3.8315628306456499e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.0480000000000000e+03,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Quadro RTX 6000": 5.1174270964049613e+18,
      "group": 1.0000000000000000e+00,
      "host_name:aleph": 3.2334478980185999e+18,
      "input[0]": 2.0000000000000000e+00,
      "input[1]": 1.0240000000000000e+03,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 2.0000000000000000e+00,
      "input_channels": 1.0240000000000000e+03,
      "input_height": 1.4000000000000000e+01,
      "input_size": 4.0140800000000000e+05,
      "input_width": 1.4000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 2.0480000000000000e+03,
      "num_iterations": 1.5415000000000000e+04,
      "output_batch_size": 2.0000000000000000e+00,
      "output_channels": 2.0480000000000000e+03,
      "output_height": 7.0000000000000000e+00,
      "output_size": 2.0070400000000000e+05,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "w_filter_layout": 1.0000000000000000e+00,
      "workspace_bytes": 3.0000000000000000e+02,
      "workspace_megabytes": 2.8610229492187500e-04,
      "x_tensor_layout": 1.0000000000000000e+00,
      "y_tensor_layout": 1.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_2__7261539804651029798<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:2/input[1]:1024/input[2]:14/input[3]:14/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 15243,
      "real_time": 4.5484197005409857e+04,
      "cpu_time": 5.1244860854194376e+04,
      "time_unit": "ns",
      "items_per_second": 1.8074048529475457e+13,
      "activation_mode": 3.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 3.0000000000000000e+02,
      "advised_time": 8.7552003562450409e-02,
      "batch_size": 2.0000000000000000e+00,
      "benchmark_file:/home/dakkak/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 1.5291677899427402e+19,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.5547362882776177e+19,
      "bias_tensor_layout": 1.0000000000000000e+00,
      "compute_capability:7.5": 3.8315628306456499e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.0480000000000000e+03,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Quadro RTX 6000": 5.1174270964049613e+18,
      "group": 1.0000000000000000e+00,
      "host_name:aleph": 3.2334478980185999e+18,
      "input[0]": 2.0000000000000000e+00,
      "input[1]": 1.0240000000000000e+03,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 2.0000000000000000e+00,
      "input_channels": 1.0240000000000000e+03,
      "input_height": 1.4000000000000000e+01,
      "input_size": 4.0140800000000000e+05,
      "input_width": 1.4000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 2.0480000000000000e+03,
      "num_iterations": 1.5243000000000000e+04,
      "output_batch_size": 2.0000000000000000e+00,
      "output_channels": 2.0480000000000000e+03,
      "output_height": 7.0000000000000000e+00,
      "output_size": 2.0070400000000000e+05,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "w_filter_layout": 1.0000000000000000e+00,
      "workspace_bytes": 3.0000000000000000e+02,
      "workspace_megabytes": 2.8610229492187500e-04,
      "x_tensor_layout": 1.0000000000000000e+00,
      "y_tensor_layout": 1.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_2__7261539804651029798<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_ELU>/input[0]:2/input[1]:1024/input[2]:14/input[3]:14/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_2__7261539804651029798<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:1024/input[2]:14/input[3]:14/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 15225,
      "real_time": 4.5739776367745602e+04,
      "cpu_time": 5.1584831658662100e+04,
      "time_unit": "ns",
      "items_per_second": 1.7973056479124156e+13,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 3.0000000000000000e+02,
      "advised_time": 9.5968000590801239e-02,
      "batch_size": 2.0000000000000000e+00,
      "benchmark_file:/home/dakkak/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 1.5291677899427402e+19,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.5541522464702913e+19,
      "bias_tensor_layout": 1.0000000000000000e+00,
      "compute_capability:7.5": 3.8315628306456499e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.0480000000000000e+03,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Quadro RTX 6000": 5.1174270964049613e+18,
      "group": 1.0000000000000000e+00,
      "host_name:aleph": 3.2334478980185999e+18,
      "input[0]": 2.0000000000000000e+00,
      "input[1]": 1.0240000000000000e+03,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 2.0000000000000000e+00,
      "input_channels": 1.0240000000000000e+03,
      "input_height": 1.4000000000000000e+01,
      "input_size": 4.0140800000000000e+05,
      "input_width": 1.4000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 2.0480000000000000e+03,
      "num_iterations": 1.5225000000000000e+04,
      "output_batch_size": 2.0000000000000000e+00,
      "output_channels": 2.0480000000000000e+03,
      "output_height": 7.0000000000000000e+00,
      "output_size": 2.0070400000000000e+05,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "w_filter_layout": 1.0000000000000000e+00,
      "workspace_bytes": 3.0000000000000000e+02,
      "workspace_megabytes": 2.8610229492187500e-04,
      "x_tensor_layout": 1.0000000000000000e+00,
      "y_tensor_layout": 1.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_2__7261539804651029798<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:1024/input[2]:14/input[3]:14/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 15325,
      "real_time": 4.5787848998288449e+04,
      "cpu_time": 5.1509863947915750e+04,
      "time_unit": "ns",
      "items_per_second": 1.7954186579734934e+13,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 3.0000000000000000e+02,
      "advised_time": 7.3728002607822418e-02,
      "batch_size": 2.0000000000000000e+00,
      "benchmark_file:/home/dakkak/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 1.5291677899427402e+19,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.5541522464702913e+19,
      "bias_tensor_layout": 1.0000000000000000e+00,
      "compute_capability:7.5": 3.8315628306456499e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.0480000000000000e+03,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Quadro RTX 6000": 5.1174270964049613e+18,
      "group": 1.0000000000000000e+00,
      "host_name:aleph": 3.2334478980185999e+18,
      "input[0]": 2.0000000000000000e+00,
      "input[1]": 1.0240000000000000e+03,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 2.0000000000000000e+00,
      "input_channels": 1.0240000000000000e+03,
      "input_height": 1.4000000000000000e+01,
      "input_size": 4.0140800000000000e+05,
      "input_width": 1.4000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 2.0480000000000000e+03,
      "num_iterations": 1.5325000000000000e+04,
      "output_batch_size": 2.0000000000000000e+00,
      "output_channels": 2.0480000000000000e+03,
      "output_height": 7.0000000000000000e+00,
      "output_size": 2.0070400000000000e+05,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "w_filter_layout": 1.0000000000000000e+00,
      "workspace_bytes": 3.0000000000000000e+02,
      "workspace_megabytes": 2.8610229492187500e-04,
      "x_tensor_layout": 1.0000000000000000e+00,
      "y_tensor_layout": 1.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_2__7261539804651029798<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_IDENTITY>/input[0]:2/input[1]:1024/input[2]:14/input[3]:14/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 15140,
      "real_time": 4.5729788159803553e+04,
      "cpu_time": 5.1491772721164089e+04,
      "time_unit": "ns",
      "items_per_second": 1.7976982117809391e+13,
      "activation_mode": 5.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 3.0000000000000000e+02,
      "advised_time": 5.8687999844551086e-02,
      "batch_size": 2.0000000000000000e+00,
      "benchmark_file:/home/dakkak/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 1.5291677899427402e+19,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)5; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 4.5833023350607309e+18,
      "bias_tensor_layout": 1.0000000000000000e+00,
      "compute_capability:7.5": 3.8315628306456499e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.0480000000000000e+03,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Quadro RTX 6000": 5.1174270964049613e+18,
      "group": 1.0000000000000000e+00,
      "host_name:aleph": 3.2334478980185999e+18,
      "input[0]": 2.0000000000000000e+00,
      "input[1]": 1.0240000000000000e+03,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 2.0000000000000000e+00,
      "input_channels": 1.0240000000000000e+03,
      "input_height": 1.4000000000000000e+01,
      "input_size": 4.0140800000000000e+05,
      "input_width": 1.4000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 2.0480000000000000e+03,
      "num_iterations": 1.5140000000000000e+04,
      "output_batch_size": 2.0000000000000000e+00,
      "output_channels": 2.0480000000000000e+03,
      "output_height": 7.0000000000000000e+00,
      "output_size": 2.0070400000000000e+05,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "w_filter_layout": 1.0000000000000000e+00,
      "workspace_bytes": 3.0000000000000000e+02,
      "workspace_megabytes": 2.8610229492187500e-04,
      "x_tensor_layout": 1.0000000000000000e+00,
      "y_tensor_layout": 1.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_2__7261539804651029798<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_SIGMOID>/input[0]:2/input[1]:1024/input[2]:14/input[3]:14/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_2__7261539804651029798<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_TANH>/input[0]:2/input[1]:1024/input[2]:14/input[3]:14/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_2__7261539804651029798<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:1024/input[2]:14/input[3]:14/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_2__7261539804651029798<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:2/input[1]:1024/input[2]:14/input[3]:14/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_2__7261539804651029798<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_ELU>/input[0]:2/input[1]:1024/input[2]:14/input[3]:14/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_2__7261539804651029798<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:1024/input[2]:14/input[3]:14/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_2__7261539804651029798<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:1024/input[2]:14/input[3]:14/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_2__7261539804651029798<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_IDENTITY>/input[0]:2/input[1]:1024/input[2]:14/input[3]:14/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_2__7261539804651029798<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_SIGMOID>/input[0]:2/input[1]:1024/input[2]:14/input[3]:14/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_2__7261539804651029798<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_TANH>/input[0]:2/input[1]:1024/input[2]:14/input[3]:14/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_2__7261539804651029798<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:1024/input[2]:14/input[3]:14/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_2__7261539804651029798<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:2/input[1]:1024/input[2]:14/input[3]:14/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_2__7261539804651029798<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_ELU>/input[0]:2/input[1]:1024/input[2]:14/input[3]:14/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_2__7261539804651029798<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:1024/input[2]:14/input[3]:14/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_2__7261539804651029798<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:1024/input[2]:14/input[3]:14/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_2__7261539804651029798<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_IDENTITY>/input[0]:2/input[1]:1024/input[2]:14/input[3]:14/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_2__7261539804651029798<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_SIGMOID>/input[0]:2/input[1]:1024/input[2]:14/input[3]:14/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_2__7261539804651029798<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_TANH>/input[0]:2/input[1]:1024/input[2]:14/input[3]:14/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_2__7261539804651029798<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:1024/input[2]:14/input[3]:14/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_2__7261539804651029798<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:2/input[1]:1024/input[2]:14/input[3]:14/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_2__7261539804651029798<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_ELU>/input[0]:2/input[1]:1024/input[2]:14/input[3]:14/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_2__7261539804651029798<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:1024/input[2]:14/input[3]:14/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_2__7261539804651029798<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:1024/input[2]:14/input[3]:14/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_2__7261539804651029798<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_IDENTITY>/input[0]:2/input[1]:1024/input[2]:14/input[3]:14/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_2__7261539804651029798<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_SIGMOID>/input[0]:2/input[1]:1024/input[2]:14/input[3]:14/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_2__7261539804651029798<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_TANH>/input[0]:2/input[1]:1024/input[2]:14/input[3]:14/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_2__7261539804651029798<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:1024/input[2]:14/input[3]:14/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_2__7261539804651029798<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:2/input[1]:1024/input[2]:14/input[3]:14/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_2__7261539804651029798<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_ELU>/input[0]:2/input[1]:1024/input[2]:14/input[3]:14/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_2__7261539804651029798<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:1024/input[2]:14/input[3]:14/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_2__7261539804651029798<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:1024/input[2]:14/input[3]:14/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_2__7261539804651029798<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_IDENTITY>/input[0]:2/input[1]:1024/input[2]:14/input[3]:14/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_2__7261539804651029798<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_SIGMOID>/input[0]:2/input[1]:1024/input[2]:14/input[3]:14/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_2__7261539804651029798<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_TANH>/input[0]:2/input[1]:1024/input[2]:14/input[3]:14/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_2__7261539804651029798<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:1024/input[2]:14/input[3]:14/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_2__7261539804651029798<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:2/input[1]:1024/input[2]:14/input[3]:14/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_2__7261539804651029798<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_ELU>/input[0]:2/input[1]:1024/input[2]:14/input[3]:14/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_2__7261539804651029798<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:1024/input[2]:14/input[3]:14/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_2__7261539804651029798<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:1024/input[2]:14/input[3]:14/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_2__7261539804651029798<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_IDENTITY>/input[0]:2/input[1]:1024/input[2]:14/input[3]:14/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_2__7261539804651029798<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_SIGMOID>/input[0]:2/input[1]:1024/input[2]:14/input[3]:14/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_2__7261539804651029798<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_TANH>/input[0]:2/input[1]:1024/input[2]:14/input[3]:14/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_2__7261539804651029798<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:1024/input[2]:14/input[3]:14/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_2__7261539804651029798<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:2/input[1]:1024/input[2]:14/input[3]:14/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_2__7261539804651029798<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_ELU>/input[0]:2/input[1]:1024/input[2]:14/input[3]:14/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_2__7261539804651029798<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:1024/input[2]:14/input[3]:14/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_2__7261539804651029798<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:1024/input[2]:14/input[3]:14/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_2__7261539804651029798<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_IDENTITY>/input[0]:2/input[1]:1024/input[2]:14/input[3]:14/filter_count:2048/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_2__14846363627961004541<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_SIGMOID>/input[0]:2/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_2__14846363627961004541<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_TANH>/input[0]:2/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_2__14846363627961004541<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 11137,
      "real_time": 6.2399574554353843e+04,
      "cpu_time": 6.8257175989787269e+04,
      "time_unit": "ns",
      "items_per_second": 3.2936265586390938e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 6.3487999141216278e-02,
      "batch_size": 2.0000000000000000e+00,
      "benchmark_file:/home/dakkak/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 1.5291677899427402e+19,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 2.3191971996820818e+18,
      "bias_tensor_layout": 1.0000000000000000e+00,
      "compute_capability:7.5": 3.8315628306456499e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Quadro RTX 6000": 5.1174270964049613e+18,
      "group": 1.0000000000000000e+00,
      "host_name:aleph": 3.2334478980185999e+18,
      "input[0]": 2.0000000000000000e+00,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 2.0000000000000000e+00,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 5.6000000000000000e+01,
      "input_size": 1.6056320000000000e+06,
      "input_width": 5.6000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 1.1137000000000000e+04,
      "output_batch_size": 2.0000000000000000e+00,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 2.0070400000000000e+05,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "w_filter_layout": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00,
      "x_tensor_layout": 1.0000000000000000e+00,
      "y_tensor_layout": 1.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_2__14846363627961004541<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:2/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 11185,
      "real_time": 6.2332180447437328e+04,
      "cpu_time": 6.8220355833315174e+04,
      "time_unit": "ns",
      "items_per_second": 3.2971876569167827e+12,
      "activation_mode": 3.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 6.4159996807575226e-02,
      "batch_size": 2.0000000000000000e+00,
      "benchmark_file:/home/dakkak/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 1.5291677899427402e+19,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.9889882919049984e+18,
      "bias_tensor_layout": 1.0000000000000000e+00,
      "compute_capability:7.5": 3.8315628306456499e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Quadro RTX 6000": 5.1174270964049613e+18,
      "group": 1.0000000000000000e+00,
      "host_name:aleph": 3.2334478980185999e+18,
      "input[0]": 2.0000000000000000e+00,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 2.0000000000000000e+00,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 5.6000000000000000e+01,
      "input_size": 1.6056320000000000e+06,
      "input_width": 5.6000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 1.1185000000000000e+04,
      "output_batch_size": 2.0000000000000000e+00,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 2.0070400000000000e+05,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "w_filter_layout": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00,
      "x_tensor_layout": 1.0000000000000000e+00,
      "y_tensor_layout": 1.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_2__14846363627961004541<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_ELU>/input[0]:2/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_2__14846363627961004541<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 11128,
      "real_time": 6.2349331282649859e+04,
      "cpu_time": 6.8223426671461901e+04,
      "time_unit": "ns",
      "items_per_second": 3.2962806781087476e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 6.3487999141216278e-02,
      "batch_size": 2.0000000000000000e+00,
      "benchmark_file:/home/dakkak/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 1.5291677899427402e+19,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 2.3191971996820818e+18,
      "bias_tensor_layout": 1.0000000000000000e+00,
      "compute_capability:7.5": 3.8315628306456499e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Quadro RTX 6000": 5.1174270964049613e+18,
      "group": 1.0000000000000000e+00,
      "host_name:aleph": 3.2334478980185999e+18,
      "input[0]": 2.0000000000000000e+00,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 2.0000000000000000e+00,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 5.6000000000000000e+01,
      "input_size": 1.6056320000000000e+06,
      "input_width": 5.6000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 1.1128000000000000e+04,
      "output_batch_size": 2.0000000000000000e+00,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 2.0070400000000000e+05,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "w_filter_layout": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00,
      "x_tensor_layout": 1.0000000000000000e+00,
      "y_tensor_layout": 1.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_2__14846363627961004541<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 11217,
      "real_time": 6.2375862141088910e+04,
      "cpu_time": 6.8243555228796002e+04,
      "time_unit": "ns",
      "items_per_second": 3.2948786428815874e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 6.3744001090526581e-02,
      "batch_size": 2.0000000000000000e+00,
      "benchmark_file:/home/dakkak/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 1.5291677899427402e+19,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 2.3191971996820818e+18,
      "bias_tensor_layout": 1.0000000000000000e+00,
      "compute_capability:7.5": 3.8315628306456499e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Quadro RTX 6000": 5.1174270964049613e+18,
      "group": 1.0000000000000000e+00,
      "host_name:aleph": 3.2334478980185999e+18,
      "input[0]": 2.0000000000000000e+00,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 2.0000000000000000e+00,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 5.6000000000000000e+01,
      "input_size": 1.6056320000000000e+06,
      "input_width": 5.6000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 1.1217000000000000e+04,
      "output_batch_size": 2.0000000000000000e+00,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 2.0070400000000000e+05,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "w_filter_layout": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00,
      "x_tensor_layout": 1.0000000000000000e+00,
      "y_tensor_layout": 1.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_2__14846363627961004541<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_IDENTITY>/input[0]:2/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 11234,
      "real_time": 6.2355953541934097e+04,
      "cpu_time": 6.8252631119922327e+04,
      "time_unit": "ns",
      "items_per_second": 3.2959306100866235e+12,
      "activation_mode": 5.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 6.3936002552509308e-02,
      "batch_size": 2.0000000000000000e+00,
      "benchmark_file:/home/dakkak/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 1.5291677899427402e+19,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)5; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.3342635194217454e+19,
      "bias_tensor_layout": 1.0000000000000000e+00,
      "compute_capability:7.5": 3.8315628306456499e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Quadro RTX 6000": 5.1174270964049613e+18,
      "group": 1.0000000000000000e+00,
      "host_name:aleph": 3.2334478980185999e+18,
      "input[0]": 2.0000000000000000e+00,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 2.0000000000000000e+00,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 5.6000000000000000e+01,
      "input_size": 1.6056320000000000e+06,
      "input_width": 5.6000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 1.1234000000000000e+04,
      "output_batch_size": 2.0000000000000000e+00,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 2.0070400000000000e+05,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "w_filter_layout": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00,
      "x_tensor_layout": 1.0000000000000000e+00,
      "y_tensor_layout": 1.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_2__14846363627961004541<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_SIGMOID>/input[0]:2/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_2__14846363627961004541<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_TANH>/input[0]:2/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_2__14846363627961004541<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 24996,
      "real_time": 2.8104015427052105e+04,
      "cpu_time": 3.3864265442327167e+04,
      "time_unit": "ns",
      "items_per_second": 7.3128658975247920e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 4.7120000000000000e+03,
      "advised_time": 3.5456001758575439e-02,
      "batch_size": 2.0000000000000000e+00,
      "benchmark_file:/home/dakkak/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 1.5291677899427402e+19,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.5541522464702913e+19,
      "bias_tensor_layout": 1.0000000000000000e+00,
      "compute_capability:7.5": 3.8315628306456499e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Quadro RTX 6000": 5.1174270964049613e+18,
      "group": 1.0000000000000000e+00,
      "host_name:aleph": 3.2334478980185999e+18,
      "input[0]": 2.0000000000000000e+00,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 2.0000000000000000e+00,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 5.6000000000000000e+01,
      "input_size": 1.6056320000000000e+06,
      "input_width": 5.6000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 2.4996000000000000e+04,
      "output_batch_size": 2.0000000000000000e+00,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 2.0070400000000000e+05,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "w_filter_layout": 1.0000000000000000e+00,
      "workspace_bytes": 4.7120000000000000e+03,
      "workspace_megabytes": 4.4937133789062500e-03,
      "x_tensor_layout": 1.0000000000000000e+00,
      "y_tensor_layout": 1.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_2__14846363627961004541<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:2/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 24689,
      "real_time": 2.8253534836270293e+04,
      "cpu_time": 3.4105771315335347e+04,
      "time_unit": "ns",
      "items_per_second": 7.2741657704424248e+12,
      "activation_mode": 3.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 4.7120000000000000e+03,
      "advised_time": 3.4719999879598618e-02,
      "batch_size": 2.0000000000000000e+00,
      "benchmark_file:/home/dakkak/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 1.5291677899427402e+19,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.5547362882776177e+19,
      "bias_tensor_layout": 1.0000000000000000e+00,
      "compute_capability:7.5": 3.8315628306456499e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Quadro RTX 6000": 5.1174270964049613e+18,
      "group": 1.0000000000000000e+00,
      "host_name:aleph": 3.2334478980185999e+18,
      "input[0]": 2.0000000000000000e+00,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 2.0000000000000000e+00,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 5.6000000000000000e+01,
      "input_size": 1.6056320000000000e+06,
      "input_width": 5.6000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 2.4689000000000000e+04,
      "output_batch_size": 2.0000000000000000e+00,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 2.0070400000000000e+05,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "w_filter_layout": 1.0000000000000000e+00,
      "workspace_bytes": 4.7120000000000000e+03,
      "workspace_megabytes": 4.4937133789062500e-03,
      "x_tensor_layout": 1.0000000000000000e+00,
      "y_tensor_layout": 1.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_2__14846363627961004541<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_ELU>/input[0]:2/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_2__14846363627961004541<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 24823,
      "real_time": 2.8208610458123934e+04,
      "cpu_time": 3.3995460822636625e+04,
      "time_unit": "ns",
      "items_per_second": 7.2857504379770342e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 4.7120000000000000e+03,
      "advised_time": 3.6063998937606812e-02,
      "batch_size": 2.0000000000000000e+00,
      "benchmark_file:/home/dakkak/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 1.5291677899427402e+19,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.5541522464702913e+19,
      "bias_tensor_layout": 1.0000000000000000e+00,
      "compute_capability:7.5": 3.8315628306456499e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Quadro RTX 6000": 5.1174270964049613e+18,
      "group": 1.0000000000000000e+00,
      "host_name:aleph": 3.2334478980185999e+18,
      "input[0]": 2.0000000000000000e+00,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 2.0000000000000000e+00,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 5.6000000000000000e+01,
      "input_size": 1.6056320000000000e+06,
      "input_width": 5.6000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 2.4823000000000000e+04,
      "output_batch_size": 2.0000000000000000e+00,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 2.0070400000000000e+05,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "w_filter_layout": 1.0000000000000000e+00,
      "workspace_bytes": 4.7120000000000000e+03,
      "workspace_megabytes": 4.4937133789062500e-03,
      "x_tensor_layout": 1.0000000000000000e+00,
      "y_tensor_layout": 1.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_2__14846363627961004541<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 24874,
      "real_time": 2.8297116071162203e+04,
      "cpu_time": 3.4065266261683842e+04,
      "time_unit": "ns",
      "items_per_second": 7.2629626101526250e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 4.7120000000000000e+03,
      "advised_time": 3.4784000366926193e-02,
      "batch_size": 2.0000000000000000e+00,
      "benchmark_file:/home/dakkak/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 1.5291677899427402e+19,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.5541522464702913e+19,
      "bias_tensor_layout": 1.0000000000000000e+00,
      "compute_capability:7.5": 3.8315628306456499e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Quadro RTX 6000": 5.1174270964049613e+18,
      "group": 1.0000000000000000e+00,
      "host_name:aleph": 3.2334478980185999e+18,
      "input[0]": 2.0000000000000000e+00,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 2.0000000000000000e+00,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 5.6000000000000000e+01,
      "input_size": 1.6056320000000000e+06,
      "input_width": 5.6000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 2.4874000000000000e+04,
      "output_batch_size": 2.0000000000000000e+00,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 2.0070400000000000e+05,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "w_filter_layout": 1.0000000000000000e+00,
      "workspace_bytes": 4.7120000000000000e+03,
      "workspace_megabytes": 4.4937133789062500e-03,
      "x_tensor_layout": 1.0000000000000000e+00,
      "y_tensor_layout": 1.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_2__14846363627961004541<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_IDENTITY>/input[0]:2/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 24714,
      "real_time": 2.8170260151377424e+04,
      "cpu_time": 3.3936154163758867e+04,
      "time_unit": "ns",
      "items_per_second": 7.2956690813503457e+12,
      "activation_mode": 5.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 4.7120000000000000e+03,
      "advised_time": 3.5967998206615448e-02,
      "batch_size": 2.0000000000000000e+00,
      "benchmark_file:/home/dakkak/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 1.5291677899427402e+19,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)5; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 4.5833023350607309e+18,
      "bias_tensor_layout": 1.0000000000000000e+00,
      "compute_capability:7.5": 3.8315628306456499e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.2800000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Quadro RTX 6000": 5.1174270964049613e+18,
      "group": 1.0000000000000000e+00,
      "host_name:aleph": 3.2334478980185999e+18,
      "input[0]": 2.0000000000000000e+00,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 2.0000000000000000e+00,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 5.6000000000000000e+01,
      "input_size": 1.6056320000000000e+06,
      "input_width": 5.6000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 1.2800000000000000e+02,
      "num_iterations": 2.4714000000000000e+04,
      "output_batch_size": 2.0000000000000000e+00,
      "output_channels": 1.2800000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 2.0070400000000000e+05,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "w_filter_layout": 1.0000000000000000e+00,
      "workspace_bytes": 4.7120000000000000e+03,
      "workspace_megabytes": 4.4937133789062500e-03,
      "x_tensor_layout": 1.0000000000000000e+00,
      "y_tensor_layout": 1.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_2__14846363627961004541<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_SIGMOID>/input[0]:2/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_2__14846363627961004541<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_TANH>/input[0]:2/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_2__14846363627961004541<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_2__14846363627961004541<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:2/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_2__14846363627961004541<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_ELU>/input[0]:2/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_2__14846363627961004541<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_2__14846363627961004541<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_2__14846363627961004541<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_IDENTITY>/input[0]:2/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_2__14846363627961004541<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_SIGMOID>/input[0]:2/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_2__14846363627961004541<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_TANH>/input[0]:2/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_2__14846363627961004541<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_2__14846363627961004541<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:2/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_2__14846363627961004541<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_ELU>/input[0]:2/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_2__14846363627961004541<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_2__14846363627961004541<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_2__14846363627961004541<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_IDENTITY>/input[0]:2/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_2__14846363627961004541<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_SIGMOID>/input[0]:2/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_2__14846363627961004541<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_TANH>/input[0]:2/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_2__14846363627961004541<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_2__14846363627961004541<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:2/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_2__14846363627961004541<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_ELU>/input[0]:2/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_2__14846363627961004541<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_2__14846363627961004541<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_2__14846363627961004541<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_IDENTITY>/input[0]:2/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_2__14846363627961004541<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_SIGMOID>/input[0]:2/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_2__14846363627961004541<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_TANH>/input[0]:2/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_2__14846363627961004541<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_2__14846363627961004541<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:2/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_2__14846363627961004541<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_ELU>/input[0]:2/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_2__14846363627961004541<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_2__14846363627961004541<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_2__14846363627961004541<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_IDENTITY>/input[0]:2/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_2__14846363627961004541<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_SIGMOID>/input[0]:2/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_2__14846363627961004541<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_TANH>/input[0]:2/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_2__14846363627961004541<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_2__14846363627961004541<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:2/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_2__14846363627961004541<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_ELU>/input[0]:2/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_2__14846363627961004541<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_2__14846363627961004541<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_2__14846363627961004541<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_IDENTITY>/input[0]:2/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_2__14846363627961004541<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_SIGMOID>/input[0]:2/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_2__14846363627961004541<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_TANH>/input[0]:2/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_2__14846363627961004541<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_2__14846363627961004541<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:2/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_2__14846363627961004541<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_ELU>/input[0]:2/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_2__14846363627961004541<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_2__14846363627961004541<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_2__14846363627961004541<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_IDENTITY>/input[0]:2/input[1]:256/input[2]:56/input[3]:56/filter_count:128/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_2__808692790385538400<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_SIGMOID>/input[0]:2/input[1]:64/input[2]:56/input[3]:56/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_2__808692790385538400<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_TANH>/input[0]:2/input[1]:64/input[2]:56/input[3]:56/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_2__808692790385538400<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:64/input[2]:56/input[3]:56/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 12695,
      "real_time": 5.5046314237320737e+04,
      "cpu_time": 6.1052779992270196e+04,
      "time_unit": "ns",
      "items_per_second": 1.8667997925704834e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 5.9071999043226242e-02,
      "batch_size": 2.0000000000000000e+00,
      "benchmark_file:/home/dakkak/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 1.5291677899427402e+19,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 2.3191971996820818e+18,
      "bias_tensor_layout": 1.0000000000000000e+00,
      "compute_capability:7.5": 3.8315628306456499e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.5600000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Quadro RTX 6000": 5.1174270964049613e+18,
      "group": 1.0000000000000000e+00,
      "host_name:aleph": 3.2334478980185999e+18,
      "input[0]": 2.0000000000000000e+00,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 2.0000000000000000e+00,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 4.0140800000000000e+05,
      "input_width": 5.6000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 2.5600000000000000e+02,
      "num_iterations": 1.2695000000000000e+04,
      "output_batch_size": 2.0000000000000000e+00,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 5.6000000000000000e+01,
      "output_size": 1.6056320000000000e+06,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00,
      "x_tensor_layout": 1.0000000000000000e+00,
      "y_tensor_layout": 1.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_2__808692790385538400<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:2/input[1]:64/input[2]:56/input[3]:56/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 12733,
      "real_time": 5.4866964225998490e+04,
      "cpu_time": 6.0734375088354485e+04,
      "time_unit": "ns",
      "items_per_second": 1.8729020176280752e+12,
      "activation_mode": 3.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 5.9296000748872757e-02,
      "batch_size": 2.0000000000000000e+00,
      "benchmark_file:/home/dakkak/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 1.5291677899427402e+19,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.9889882919049984e+18,
      "bias_tensor_layout": 1.0000000000000000e+00,
      "compute_capability:7.5": 3.8315628306456499e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.5600000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Quadro RTX 6000": 5.1174270964049613e+18,
      "group": 1.0000000000000000e+00,
      "host_name:aleph": 3.2334478980185999e+18,
      "input[0]": 2.0000000000000000e+00,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 2.0000000000000000e+00,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 4.0140800000000000e+05,
      "input_width": 5.6000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 2.5600000000000000e+02,
      "num_iterations": 1.2733000000000000e+04,
      "output_batch_size": 2.0000000000000000e+00,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 5.6000000000000000e+01,
      "output_size": 1.6056320000000000e+06,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00,
      "x_tensor_layout": 1.0000000000000000e+00,
      "y_tensor_layout": 1.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_2__808692790385538400<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_ELU>/input[0]:2/input[1]:64/input[2]:56/input[3]:56/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_2__808692790385538400<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:64/input[2]:56/input[3]:56/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 12697,
      "real_time": 5.4920200933222310e+04,
      "cpu_time": 6.0800194219247707e+04,
      "time_unit": "ns",
      "items_per_second": 1.8710865265213950e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 5.9392001479864120e-02,
      "batch_size": 2.0000000000000000e+00,
      "benchmark_file:/home/dakkak/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 1.5291677899427402e+19,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 2.3191971996820818e+18,
      "bias_tensor_layout": 1.0000000000000000e+00,
      "compute_capability:7.5": 3.8315628306456499e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.5600000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Quadro RTX 6000": 5.1174270964049613e+18,
      "group": 1.0000000000000000e+00,
      "host_name:aleph": 3.2334478980185999e+18,
      "input[0]": 2.0000000000000000e+00,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 2.0000000000000000e+00,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 4.0140800000000000e+05,
      "input_width": 5.6000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 2.5600000000000000e+02,
      "num_iterations": 1.2697000000000000e+04,
      "output_batch_size": 2.0000000000000000e+00,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 5.6000000000000000e+01,
      "output_size": 1.6056320000000000e+06,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00,
      "x_tensor_layout": 1.0000000000000000e+00,
      "y_tensor_layout": 1.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_2__808692790385538400<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:64/input[2]:56/input[3]:56/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 12730,
      "real_time": 5.4888931279925637e+04,
      "cpu_time": 6.0750048153707809e+04,
      "time_unit": "ns",
      "items_per_second": 1.8721524650559604e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 5.7952001690864563e-02,
      "batch_size": 2.0000000000000000e+00,
      "benchmark_file:/home/dakkak/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 1.5291677899427402e+19,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 2.3191971996820818e+18,
      "bias_tensor_layout": 1.0000000000000000e+00,
      "compute_capability:7.5": 3.8315628306456499e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.5600000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Quadro RTX 6000": 5.1174270964049613e+18,
      "group": 1.0000000000000000e+00,
      "host_name:aleph": 3.2334478980185999e+18,
      "input[0]": 2.0000000000000000e+00,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 2.0000000000000000e+00,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 4.0140800000000000e+05,
      "input_width": 5.6000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 2.5600000000000000e+02,
      "num_iterations": 1.2730000000000000e+04,
      "output_batch_size": 2.0000000000000000e+00,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 5.6000000000000000e+01,
      "output_size": 1.6056320000000000e+06,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00,
      "x_tensor_layout": 1.0000000000000000e+00,
      "y_tensor_layout": 1.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_2__808692790385538400<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_IDENTITY>/input[0]:2/input[1]:64/input[2]:56/input[3]:56/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 12716,
      "real_time": 5.4915070110341607e+04,
      "cpu_time": 6.0831766829091663e+04,
      "time_unit": "ns",
      "items_per_second": 1.8712613458113049e+12,
      "activation_mode": 5.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 5.9200000017881393e-02,
      "batch_size": 2.0000000000000000e+00,
      "benchmark_file:/home/dakkak/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 1.5291677899427402e+19,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)5; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.3342635194217454e+19,
      "bias_tensor_layout": 1.0000000000000000e+00,
      "compute_capability:7.5": 3.8315628306456499e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.5600000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Quadro RTX 6000": 5.1174270964049613e+18,
      "group": 1.0000000000000000e+00,
      "host_name:aleph": 3.2334478980185999e+18,
      "input[0]": 2.0000000000000000e+00,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 2.0000000000000000e+00,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 4.0140800000000000e+05,
      "input_width": 5.6000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 2.5600000000000000e+02,
      "num_iterations": 1.2716000000000000e+04,
      "output_batch_size": 2.0000000000000000e+00,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 5.6000000000000000e+01,
      "output_size": 1.6056320000000000e+06,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00,
      "x_tensor_layout": 1.0000000000000000e+00,
      "y_tensor_layout": 1.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_2__808692790385538400<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_SIGMOID>/input[0]:2/input[1]:64/input[2]:56/input[3]:56/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_2__808692790385538400<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_TANH>/input[0]:2/input[1]:64/input[2]:56/input[3]:56/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_2__808692790385538400<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:64/input[2]:56/input[3]:56/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 26450,
      "real_time": 2.6877586407523002e+04,
      "cpu_time": 3.2761267939328147e+04,
      "time_unit": "ns",
      "items_per_second": 3.8232766306440923e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.8824000000000000e+04,
      "advised_time": 3.3119998872280121e-02,
      "batch_size": 2.0000000000000000e+00,
      "benchmark_file:/home/dakkak/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 1.5291677899427402e+19,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.5541522464702913e+19,
      "bias_tensor_layout": 1.0000000000000000e+00,
      "compute_capability:7.5": 3.8315628306456499e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.5600000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Quadro RTX 6000": 5.1174270964049613e+18,
      "group": 1.0000000000000000e+00,
      "host_name:aleph": 3.2334478980185999e+18,
      "input[0]": 2.0000000000000000e+00,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 2.0000000000000000e+00,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 4.0140800000000000e+05,
      "input_width": 5.6000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 2.5600000000000000e+02,
      "num_iterations": 2.6450000000000000e+04,
      "output_batch_size": 2.0000000000000000e+00,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 5.6000000000000000e+01,
      "output_size": 1.6056320000000000e+06,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 1.0000000000000000e+00,
      "workspace_bytes": 1.8824000000000000e+04,
      "workspace_megabytes": 1.7951965332031250e-02,
      "x_tensor_layout": 1.0000000000000000e+00,
      "y_tensor_layout": 1.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_2__808692790385538400<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:2/input[1]:64/input[2]:56/input[3]:56/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 26169,
      "real_time": 2.6763463967111940e+04,
      "cpu_time": 3.2637401543934920e+04,
      "time_unit": "ns",
      "items_per_second": 3.8395795150536689e+12,
      "activation_mode": 3.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.8824000000000000e+04,
      "advised_time": 3.3183999359607697e-02,
      "batch_size": 2.0000000000000000e+00,
      "benchmark_file:/home/dakkak/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 1.5291677899427402e+19,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.5547362882776177e+19,
      "bias_tensor_layout": 1.0000000000000000e+00,
      "compute_capability:7.5": 3.8315628306456499e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.5600000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Quadro RTX 6000": 5.1174270964049613e+18,
      "group": 1.0000000000000000e+00,
      "host_name:aleph": 3.2334478980185999e+18,
      "input[0]": 2.0000000000000000e+00,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 2.0000000000000000e+00,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 4.0140800000000000e+05,
      "input_width": 5.6000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 2.5600000000000000e+02,
      "num_iterations": 2.6169000000000000e+04,
      "output_batch_size": 2.0000000000000000e+00,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 5.6000000000000000e+01,
      "output_size": 1.6056320000000000e+06,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 1.0000000000000000e+00,
      "workspace_bytes": 1.8824000000000000e+04,
      "workspace_megabytes": 1.7951965332031250e-02,
      "x_tensor_layout": 1.0000000000000000e+00,
      "y_tensor_layout": 1.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_2__808692790385538400<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_ELU>/input[0]:2/input[1]:64/input[2]:56/input[3]:56/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_2__808692790385538400<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:64/input[2]:56/input[3]:56/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 25992,
      "real_time": 2.6938798417484533e+04,
      "cpu_time": 3.2808963065601703e+04,
      "time_unit": "ns",
      "items_per_second": 3.8145891441581040e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.8824000000000000e+04,
      "advised_time": 3.4304000437259674e-02,
      "batch_size": 2.0000000000000000e+00,
      "benchmark_file:/home/dakkak/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 1.5291677899427402e+19,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.5541522464702913e+19,
      "bias_tensor_layout": 1.0000000000000000e+00,
      "compute_capability:7.5": 3.8315628306456499e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.5600000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Quadro RTX 6000": 5.1174270964049613e+18,
      "group": 1.0000000000000000e+00,
      "host_name:aleph": 3.2334478980185999e+18,
      "input[0]": 2.0000000000000000e+00,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 2.0000000000000000e+00,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 4.0140800000000000e+05,
      "input_width": 5.6000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 2.5600000000000000e+02,
      "num_iterations": 2.5992000000000000e+04,
      "output_batch_size": 2.0000000000000000e+00,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 5.6000000000000000e+01,
      "output_size": 1.6056320000000000e+06,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 1.0000000000000000e+00,
      "workspace_bytes": 1.8824000000000000e+04,
      "workspace_megabytes": 1.7951965332031250e-02,
      "x_tensor_layout": 1.0000000000000000e+00,
      "y_tensor_layout": 1.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_2__808692790385538400<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:64/input[2]:56/input[3]:56/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 25841,
      "real_time": 2.6745781058482677e+04,
      "cpu_time": 3.2621135017876899e+04,
      "time_unit": "ns",
      "items_per_second": 3.8421180437880146e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.8824000000000000e+04,
      "advised_time": 3.3952001482248306e-02,
      "batch_size": 2.0000000000000000e+00,
      "benchmark_file:/home/dakkak/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 1.5291677899427402e+19,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.5541522464702913e+19,
      "bias_tensor_layout": 1.0000000000000000e+00,
      "compute_capability:7.5": 3.8315628306456499e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.5600000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Quadro RTX 6000": 5.1174270964049613e+18,
      "group": 1.0000000000000000e+00,
      "host_name:aleph": 3.2334478980185999e+18,
      "input[0]": 2.0000000000000000e+00,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 2.0000000000000000e+00,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 4.0140800000000000e+05,
      "input_width": 5.6000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 2.5600000000000000e+02,
      "num_iterations": 2.5841000000000000e+04,
      "output_batch_size": 2.0000000000000000e+00,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 5.6000000000000000e+01,
      "output_size": 1.6056320000000000e+06,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 1.0000000000000000e+00,
      "workspace_bytes": 1.8824000000000000e+04,
      "workspace_megabytes": 1.7951965332031250e-02,
      "x_tensor_layout": 1.0000000000000000e+00,
      "y_tensor_layout": 1.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_2__808692790385538400<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_IDENTITY>/input[0]:2/input[1]:64/input[2]:56/input[3]:56/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 26158,
      "real_time": 2.6972078013061266e+04,
      "cpu_time": 3.2919584104159912e+04,
      "time_unit": "ns",
      "items_per_second": 3.8098824996071167e+12,
      "activation_mode": 5.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.8824000000000000e+04,
      "advised_time": 3.3856000751256943e-02,
      "batch_size": 2.0000000000000000e+00,
      "benchmark_file:/home/dakkak/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 1.5291677899427402e+19,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)5; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 4.5833023350607309e+18,
      "bias_tensor_layout": 1.0000000000000000e+00,
      "compute_capability:7.5": 3.8315628306456499e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.5600000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Quadro RTX 6000": 5.1174270964049613e+18,
      "group": 1.0000000000000000e+00,
      "host_name:aleph": 3.2334478980185999e+18,
      "input[0]": 2.0000000000000000e+00,
      "input[1]": 6.4000000000000000e+01,
      "input[2]": 5.6000000000000000e+01,
      "input[3]": 5.6000000000000000e+01,
      "input_batch_size": 2.0000000000000000e+00,
      "input_channels": 6.4000000000000000e+01,
      "input_height": 5.6000000000000000e+01,
      "input_size": 4.0140800000000000e+05,
      "input_width": 5.6000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 2.5600000000000000e+02,
      "num_iterations": 2.6158000000000000e+04,
      "output_batch_size": 2.0000000000000000e+00,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 5.6000000000000000e+01,
      "output_size": 1.6056320000000000e+06,
      "output_width": 5.6000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 1.0000000000000000e+00,
      "workspace_bytes": 1.8824000000000000e+04,
      "workspace_megabytes": 1.7951965332031250e-02,
      "x_tensor_layout": 1.0000000000000000e+00,
      "y_tensor_layout": 1.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_2__808692790385538400<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_SIGMOID>/input[0]:2/input[1]:64/input[2]:56/input[3]:56/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_2__808692790385538400<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_TANH>/input[0]:2/input[1]:64/input[2]:56/input[3]:56/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_2__808692790385538400<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:64/input[2]:56/input[3]:56/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_2__808692790385538400<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:2/input[1]:64/input[2]:56/input[3]:56/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_2__808692790385538400<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_ELU>/input[0]:2/input[1]:64/input[2]:56/input[3]:56/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_2__808692790385538400<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:64/input[2]:56/input[3]:56/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_2__808692790385538400<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:64/input[2]:56/input[3]:56/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_2__808692790385538400<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_IDENTITY>/input[0]:2/input[1]:64/input[2]:56/input[3]:56/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_2__808692790385538400<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_SIGMOID>/input[0]:2/input[1]:64/input[2]:56/input[3]:56/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_2__808692790385538400<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_TANH>/input[0]:2/input[1]:64/input[2]:56/input[3]:56/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_2__808692790385538400<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:64/input[2]:56/input[3]:56/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_2__808692790385538400<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:2/input[1]:64/input[2]:56/input[3]:56/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_2__808692790385538400<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_ELU>/input[0]:2/input[1]:64/input[2]:56/input[3]:56/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_2__808692790385538400<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:64/input[2]:56/input[3]:56/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_2__808692790385538400<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:64/input[2]:56/input[3]:56/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_2__808692790385538400<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_IDENTITY>/input[0]:2/input[1]:64/input[2]:56/input[3]:56/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_2__808692790385538400<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_SIGMOID>/input[0]:2/input[1]:64/input[2]:56/input[3]:56/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_2__808692790385538400<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_TANH>/input[0]:2/input[1]:64/input[2]:56/input[3]:56/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_2__808692790385538400<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:64/input[2]:56/input[3]:56/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_2__808692790385538400<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:2/input[1]:64/input[2]:56/input[3]:56/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_2__808692790385538400<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_ELU>/input[0]:2/input[1]:64/input[2]:56/input[3]:56/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_2__808692790385538400<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:64/input[2]:56/input[3]:56/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_2__808692790385538400<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:64/input[2]:56/input[3]:56/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_2__808692790385538400<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_IDENTITY>/input[0]:2/input[1]:64/input[2]:56/input[3]:56/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_2__808692790385538400<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_SIGMOID>/input[0]:2/input[1]:64/input[2]:56/input[3]:56/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_2__808692790385538400<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_TANH>/input[0]:2/input[1]:64/input[2]:56/input[3]:56/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_2__808692790385538400<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:64/input[2]:56/input[3]:56/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_2__808692790385538400<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:2/input[1]:64/input[2]:56/input[3]:56/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_2__808692790385538400<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_ELU>/input[0]:2/input[1]:64/input[2]:56/input[3]:56/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_2__808692790385538400<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:64/input[2]:56/input[3]:56/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_2__808692790385538400<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:64/input[2]:56/input[3]:56/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_2__808692790385538400<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_IDENTITY>/input[0]:2/input[1]:64/input[2]:56/input[3]:56/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_2__808692790385538400<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_SIGMOID>/input[0]:2/input[1]:64/input[2]:56/input[3]:56/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_2__808692790385538400<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_TANH>/input[0]:2/input[1]:64/input[2]:56/input[3]:56/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_2__808692790385538400<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:64/input[2]:56/input[3]:56/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_2__808692790385538400<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:2/input[1]:64/input[2]:56/input[3]:56/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_2__808692790385538400<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_ELU>/input[0]:2/input[1]:64/input[2]:56/input[3]:56/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_2__808692790385538400<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:64/input[2]:56/input[3]:56/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_2__808692790385538400<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:64/input[2]:56/input[3]:56/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_2__808692790385538400<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_IDENTITY>/input[0]:2/input[1]:64/input[2]:56/input[3]:56/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_2__808692790385538400<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_SIGMOID>/input[0]:2/input[1]:64/input[2]:56/input[3]:56/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_2__808692790385538400<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_TANH>/input[0]:2/input[1]:64/input[2]:56/input[3]:56/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_2__808692790385538400<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:64/input[2]:56/input[3]:56/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_2__808692790385538400<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:2/input[1]:64/input[2]:56/input[3]:56/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_2__808692790385538400<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_ELU>/input[0]:2/input[1]:64/input[2]:56/input[3]:56/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_2__808692790385538400<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:64/input[2]:56/input[3]:56/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_2__808692790385538400<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:64/input[2]:56/input[3]:56/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_2_TENSORCOREHALF__BatchSize_2__808692790385538400<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_IDENTITY>/input[0]:2/input[1]:64/input[2]:56/input[3]:56/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_2__1634197824869498431<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_SIGMOID>/input[0]:2/input[1]:1024/input[2]:14/input[3]:14/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_2__1634197824869498431<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_TANH>/input[0]:2/input[1]:1024/input[2]:14/input[3]:14/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_2__1634197824869498431<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:1024/input[2]:14/input[3]:14/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 2430,
      "real_time": 2.8540794547204574e+05,
      "cpu_time": 2.9246784362179053e+05,
      "time_unit": "ns",
      "items_per_second": 3.6004760774981604e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 2.9801601171493530e-01,
      "batch_size": 2.0000000000000000e+00,
      "benchmark_file:/home/dakkak/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 1.5291677899427402e+19,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 2.3191971996820818e+18,
      "bias_tensor_layout": 1.0000000000000000e+00,
      "compute_capability:7.5": 3.8315628306456499e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.5600000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Quadro RTX 6000": 5.1174270964049613e+18,
      "group": 1.0000000000000000e+00,
      "host_name:aleph": 3.2334478980185999e+18,
      "input[0]": 2.0000000000000000e+00,
      "input[1]": 1.0240000000000000e+03,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 2.0000000000000000e+00,
      "input_channels": 1.0240000000000000e+03,
      "input_height": 1.4000000000000000e+01,
      "input_size": 4.0140800000000000e+05,
      "input_width": 1.4000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 2.5600000000000000e+02,
      "num_iterations": 2.4300000000000000e+03,
      "output_batch_size": 2.0000000000000000e+00,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 1.0035200000000000e+05,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00,
      "x_tensor_layout": 1.0000000000000000e+00,
      "y_tensor_layout": 1.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_2__1634197824869498431<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:2/input[1]:1024/input[2]:14/input[3]:14/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 2454,
      "real_time": 2.8518571909448737e+05,
      "cpu_time": 2.9214044457989541e+05,
      "time_unit": "ns",
      "items_per_second": 3.6032816904816168e+11,
      "activation_mode": 3.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 2.9769599437713623e-01,
      "batch_size": 2.0000000000000000e+00,
      "benchmark_file:/home/dakkak/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 1.5291677899427402e+19,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.9889882919049984e+18,
      "bias_tensor_layout": 1.0000000000000000e+00,
      "compute_capability:7.5": 3.8315628306456499e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.5600000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Quadro RTX 6000": 5.1174270964049613e+18,
      "group": 1.0000000000000000e+00,
      "host_name:aleph": 3.2334478980185999e+18,
      "input[0]": 2.0000000000000000e+00,
      "input[1]": 1.0240000000000000e+03,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 2.0000000000000000e+00,
      "input_channels": 1.0240000000000000e+03,
      "input_height": 1.4000000000000000e+01,
      "input_size": 4.0140800000000000e+05,
      "input_width": 1.4000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 2.5600000000000000e+02,
      "num_iterations": 2.4540000000000000e+03,
      "output_batch_size": 2.0000000000000000e+00,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 1.0035200000000000e+05,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00,
      "x_tensor_layout": 1.0000000000000000e+00,
      "y_tensor_layout": 1.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_2__1634197824869498431<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_ELU>/input[0]:2/input[1]:1024/input[2]:14/input[3]:14/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_2__1634197824869498431<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:1024/input[2]:14/input[3]:14/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 2456,
      "real_time": 2.8509779583741620e+05,
      "cpu_time": 2.9208985993399058e+05,
      "time_unit": "ns",
      "items_per_second": 3.6043929311400775e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 2.9519999027252197e-01,
      "batch_size": 2.0000000000000000e+00,
      "benchmark_file:/home/dakkak/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 1.5291677899427402e+19,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 2.3191971996820818e+18,
      "bias_tensor_layout": 1.0000000000000000e+00,
      "compute_capability:7.5": 3.8315628306456499e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.5600000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Quadro RTX 6000": 5.1174270964049613e+18,
      "group": 1.0000000000000000e+00,
      "host_name:aleph": 3.2334478980185999e+18,
      "input[0]": 2.0000000000000000e+00,
      "input[1]": 1.0240000000000000e+03,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 2.0000000000000000e+00,
      "input_channels": 1.0240000000000000e+03,
      "input_height": 1.4000000000000000e+01,
      "input_size": 4.0140800000000000e+05,
      "input_width": 1.4000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 2.5600000000000000e+02,
      "num_iterations": 2.4560000000000000e+03,
      "output_batch_size": 2.0000000000000000e+00,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 1.0035200000000000e+05,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00,
      "x_tensor_layout": 1.0000000000000000e+00,
      "y_tensor_layout": 1.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_2__1634197824869498431<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:1024/input[2]:14/input[3]:14/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 2454,
      "real_time": 2.8498568670065526e+05,
      "cpu_time": 2.9189793031801365e+05,
      "time_unit": "ns",
      "items_per_second": 3.6058108457895306e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 2.9567998647689819e-01,
      "batch_size": 2.0000000000000000e+00,
      "benchmark_file:/home/dakkak/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 1.5291677899427402e+19,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 2.3191971996820818e+18,
      "bias_tensor_layout": 1.0000000000000000e+00,
      "compute_capability:7.5": 3.8315628306456499e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.5600000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Quadro RTX 6000": 5.1174270964049613e+18,
      "group": 1.0000000000000000e+00,
      "host_name:aleph": 3.2334478980185999e+18,
      "input[0]": 2.0000000000000000e+00,
      "input[1]": 1.0240000000000000e+03,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 2.0000000000000000e+00,
      "input_channels": 1.0240000000000000e+03,
      "input_height": 1.4000000000000000e+01,
      "input_size": 4.0140800000000000e+05,
      "input_width": 1.4000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 2.5600000000000000e+02,
      "num_iterations": 2.4540000000000000e+03,
      "output_batch_size": 2.0000000000000000e+00,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 1.0035200000000000e+05,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00,
      "x_tensor_layout": 1.0000000000000000e+00,
      "y_tensor_layout": 1.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_2__1634197824869498431<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_IDENTITY>/input[0]:2/input[1]:1024/input[2]:14/input[3]:14/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 2453,
      "real_time": 2.8514873660553008e+05,
      "cpu_time": 2.9220271871198458e+05,
      "time_unit": "ns",
      "items_per_second": 3.6037490196618707e+11,
      "activation_mode": 5.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 2.9695999622344971e-01,
      "batch_size": 2.0000000000000000e+00,
      "benchmark_file:/home/dakkak/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 1.5291677899427402e+19,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)5; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.3342635194217454e+19,
      "bias_tensor_layout": 1.0000000000000000e+00,
      "compute_capability:7.5": 3.8315628306456499e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.5600000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Quadro RTX 6000": 5.1174270964049613e+18,
      "group": 1.0000000000000000e+00,
      "host_name:aleph": 3.2334478980185999e+18,
      "input[0]": 2.0000000000000000e+00,
      "input[1]": 1.0240000000000000e+03,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 2.0000000000000000e+00,
      "input_channels": 1.0240000000000000e+03,
      "input_height": 1.4000000000000000e+01,
      "input_size": 4.0140800000000000e+05,
      "input_width": 1.4000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 2.5600000000000000e+02,
      "num_iterations": 2.4530000000000000e+03,
      "output_batch_size": 2.0000000000000000e+00,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 1.0035200000000000e+05,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00,
      "x_tensor_layout": 1.0000000000000000e+00,
      "y_tensor_layout": 1.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_2__1634197824869498431<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_SIGMOID>/input[0]:2/input[1]:1024/input[2]:14/input[3]:14/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_2__1634197824869498431<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_TANH>/input[0]:2/input[1]:1024/input[2]:14/input[3]:14/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_2__1634197824869498431<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:1024/input[2]:14/input[3]:14/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 13863,
      "real_time": 5.0204519060370440e+04,
      "cpu_time": 5.6252589554878614e+04,
      "time_unit": "ns",
      "items_per_second": 2.0468366179632468e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.1840000000000000e+03,
      "advised_time": 5.6255999952554703e-02,
      "batch_size": 2.0000000000000000e+00,
      "benchmark_file:/home/dakkak/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 1.5291677899427402e+19,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.5541522464702913e+19,
      "bias_tensor_layout": 1.0000000000000000e+00,
      "compute_capability:7.5": 3.8315628306456499e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.5600000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Quadro RTX 6000": 5.1174270964049613e+18,
      "group": 1.0000000000000000e+00,
      "host_name:aleph": 3.2334478980185999e+18,
      "input[0]": 2.0000000000000000e+00,
      "input[1]": 1.0240000000000000e+03,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 2.0000000000000000e+00,
      "input_channels": 1.0240000000000000e+03,
      "input_height": 1.4000000000000000e+01,
      "input_size": 4.0140800000000000e+05,
      "input_width": 1.4000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 2.5600000000000000e+02,
      "num_iterations": 1.3863000000000000e+04,
      "output_batch_size": 2.0000000000000000e+00,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 1.0035200000000000e+05,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 1.0000000000000000e+00,
      "workspace_bytes": 1.1840000000000000e+03,
      "workspace_megabytes": 1.1291503906250000e-03,
      "x_tensor_layout": 1.0000000000000000e+00,
      "y_tensor_layout": 1.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_2__1634197824869498431<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:2/input[1]:1024/input[2]:14/input[3]:14/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 13853,
      "real_time": 5.0443940197202355e+04,
      "cpu_time": 5.6549406338072549e+04,
      "time_unit": "ns",
      "items_per_second": 2.0371217553243223e+12,
      "activation_mode": 3.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.1840000000000000e+03,
      "advised_time": 6.3616000115871429e-02,
      "batch_size": 2.0000000000000000e+00,
      "benchmark_file:/home/dakkak/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 1.5291677899427402e+19,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.5547362882776177e+19,
      "bias_tensor_layout": 1.0000000000000000e+00,
      "compute_capability:7.5": 3.8315628306456499e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.5600000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Quadro RTX 6000": 5.1174270964049613e+18,
      "group": 1.0000000000000000e+00,
      "host_name:aleph": 3.2334478980185999e+18,
      "input[0]": 2.0000000000000000e+00,
      "input[1]": 1.0240000000000000e+03,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 2.0000000000000000e+00,
      "input_channels": 1.0240000000000000e+03,
      "input_height": 1.4000000000000000e+01,
      "input_size": 4.0140800000000000e+05,
      "input_width": 1.4000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 2.5600000000000000e+02,
      "num_iterations": 1.3853000000000000e+04,
      "output_batch_size": 2.0000000000000000e+00,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 1.0035200000000000e+05,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 1.0000000000000000e+00,
      "workspace_bytes": 1.1840000000000000e+03,
      "workspace_megabytes": 1.1291503906250000e-03,
      "x_tensor_layout": 1.0000000000000000e+00,
      "y_tensor_layout": 1.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_2__1634197824869498431<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_ELU>/input[0]:2/input[1]:1024/input[2]:14/input[3]:14/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_2__1634197824869498431<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:1024/input[2]:14/input[3]:14/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 13997,
      "real_time": 5.0288410359163390e+04,
      "cpu_time": 5.6383367793082958e+04,
      "time_unit": "ns",
      "items_per_second": 2.0434220780907092e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.1840000000000000e+03,
      "advised_time": 6.3551999628543854e-02,
      "batch_size": 2.0000000000000000e+00,
      "benchmark_file:/home/dakkak/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 1.5291677899427402e+19,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.5541522464702913e+19,
      "bias_tensor_layout": 1.0000000000000000e+00,
      "compute_capability:7.5": 3.8315628306456499e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.5600000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Quadro RTX 6000": 5.1174270964049613e+18,
      "group": 1.0000000000000000e+00,
      "host_name:aleph": 3.2334478980185999e+18,
      "input[0]": 2.0000000000000000e+00,
      "input[1]": 1.0240000000000000e+03,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 2.0000000000000000e+00,
      "input_channels": 1.0240000000000000e+03,
      "input_height": 1.4000000000000000e+01,
      "input_size": 4.0140800000000000e+05,
      "input_width": 1.4000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 2.5600000000000000e+02,
      "num_iterations": 1.3997000000000000e+04,
      "output_batch_size": 2.0000000000000000e+00,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 1.0035200000000000e+05,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 1.0000000000000000e+00,
      "workspace_bytes": 1.1840000000000000e+03,
      "workspace_megabytes": 1.1291503906250000e-03,
      "x_tensor_layout": 1.0000000000000000e+00,
      "y_tensor_layout": 1.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_2__1634197824869498431<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:1024/input[2]:14/input[3]:14/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 13994,
      "real_time": 5.0783055476647300e+04,
      "cpu_time": 5.6939170144741955e+04,
      "time_unit": "ns",
      "items_per_second": 2.0235184164382275e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.1840000000000000e+03,
      "advised_time": 6.4127996563911438e-02,
      "batch_size": 2.0000000000000000e+00,
      "benchmark_file:/home/dakkak/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 1.5291677899427402e+19,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.5541522464702913e+19,
      "bias_tensor_layout": 1.0000000000000000e+00,
      "compute_capability:7.5": 3.8315628306456499e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.5600000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Quadro RTX 6000": 5.1174270964049613e+18,
      "group": 1.0000000000000000e+00,
      "host_name:aleph": 3.2334478980185999e+18,
      "input[0]": 2.0000000000000000e+00,
      "input[1]": 1.0240000000000000e+03,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 2.0000000000000000e+00,
      "input_channels": 1.0240000000000000e+03,
      "input_height": 1.4000000000000000e+01,
      "input_size": 4.0140800000000000e+05,
      "input_width": 1.4000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 2.5600000000000000e+02,
      "num_iterations": 1.3994000000000000e+04,
      "output_batch_size": 2.0000000000000000e+00,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 1.0035200000000000e+05,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 1.0000000000000000e+00,
      "workspace_bytes": 1.1840000000000000e+03,
      "workspace_megabytes": 1.1291503906250000e-03,
      "x_tensor_layout": 1.0000000000000000e+00,
      "y_tensor_layout": 1.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_2__1634197824869498431<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_IDENTITY>/input[0]:2/input[1]:1024/input[2]:14/input[3]:14/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 13822,
      "real_time": 5.0401247849652995e+04,
      "cpu_time": 5.6438446751424621e+04,
      "time_unit": "ns",
      "items_per_second": 2.0388472981171931e+12,
      "activation_mode": 5.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.1840000000000000e+03,
      "advised_time": 5.9232000261545181e-02,
      "batch_size": 2.0000000000000000e+00,
      "benchmark_file:/home/dakkak/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 1.5291677899427402e+19,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)5; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 4.5833023350607309e+18,
      "bias_tensor_layout": 1.0000000000000000e+00,
      "compute_capability:7.5": 3.8315628306456499e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 2.5600000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Quadro RTX 6000": 5.1174270964049613e+18,
      "group": 1.0000000000000000e+00,
      "host_name:aleph": 3.2334478980185999e+18,
      "input[0]": 2.0000000000000000e+00,
      "input[1]": 1.0240000000000000e+03,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 2.0000000000000000e+00,
      "input_channels": 1.0240000000000000e+03,
      "input_height": 1.4000000000000000e+01,
      "input_size": 4.0140800000000000e+05,
      "input_width": 1.4000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 2.5600000000000000e+02,
      "num_iterations": 1.3822000000000000e+04,
      "output_batch_size": 2.0000000000000000e+00,
      "output_channels": 2.5600000000000000e+02,
      "output_height": 1.4000000000000000e+01,
      "output_size": 1.0035200000000000e+05,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 1.0000000000000000e+00,
      "workspace_bytes": 1.1840000000000000e+03,
      "workspace_megabytes": 1.1291503906250000e-03,
      "x_tensor_layout": 1.0000000000000000e+00,
      "y_tensor_layout": 1.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_2__1634197824869498431<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_SIGMOID>/input[0]:2/input[1]:1024/input[2]:14/input[3]:14/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_2__1634197824869498431<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_TANH>/input[0]:2/input[1]:1024/input[2]:14/input[3]:14/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_2__1634197824869498431<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:1024/input[2]:14/input[3]:14/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_2__1634197824869498431<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:2/input[1]:1024/input[2]:14/input[3]:14/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_2__1634197824869498431<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_ELU>/input[0]:2/input[1]:1024/input[2]:14/input[3]:14/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_2__1634197824869498431<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:1024/input[2]:14/input[3]:14/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_2__1634197824869498431<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:1024/input[2]:14/input[3]:14/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_2__1634197824869498431<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_IDENTITY>/input[0]:2/input[1]:1024/input[2]:14/input[3]:14/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_2__1634197824869498431<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_SIGMOID>/input[0]:2/input[1]:1024/input[2]:14/input[3]:14/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_2__1634197824869498431<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_TANH>/input[0]:2/input[1]:1024/input[2]:14/input[3]:14/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_2__1634197824869498431<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:1024/input[2]:14/input[3]:14/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_2__1634197824869498431<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:2/input[1]:1024/input[2]:14/input[3]:14/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_2__1634197824869498431<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_ELU>/input[0]:2/input[1]:1024/input[2]:14/input[3]:14/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_2__1634197824869498431<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:1024/input[2]:14/input[3]:14/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_2__1634197824869498431<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:1024/input[2]:14/input[3]:14/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_2__1634197824869498431<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_IDENTITY>/input[0]:2/input[1]:1024/input[2]:14/input[3]:14/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_2__1634197824869498431<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_SIGMOID>/input[0]:2/input[1]:1024/input[2]:14/input[3]:14/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_2__1634197824869498431<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_TANH>/input[0]:2/input[1]:1024/input[2]:14/input[3]:14/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_2__1634197824869498431<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:1024/input[2]:14/input[3]:14/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_2__1634197824869498431<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:2/input[1]:1024/input[2]:14/input[3]:14/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_2__1634197824869498431<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_ELU>/input[0]:2/input[1]:1024/input[2]:14/input[3]:14/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_2__1634197824869498431<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:1024/input[2]:14/input[3]:14/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_2__1634197824869498431<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:1024/input[2]:14/input[3]:14/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_2__1634197824869498431<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_IDENTITY>/input[0]:2/input[1]:1024/input[2]:14/input[3]:14/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_2__1634197824869498431<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_SIGMOID>/input[0]:2/input[1]:1024/input[2]:14/input[3]:14/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_2__1634197824869498431<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_TANH>/input[0]:2/input[1]:1024/input[2]:14/input[3]:14/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_2__1634197824869498431<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:1024/input[2]:14/input[3]:14/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_2__1634197824869498431<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:2/input[1]:1024/input[2]:14/input[3]:14/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_2__1634197824869498431<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_ELU>/input[0]:2/input[1]:1024/input[2]:14/input[3]:14/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_2__1634197824869498431<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:1024/input[2]:14/input[3]:14/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_2__1634197824869498431<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:1024/input[2]:14/input[3]:14/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_2__1634197824869498431<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_IDENTITY>/input[0]:2/input[1]:1024/input[2]:14/input[3]:14/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_2__1634197824869498431<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_SIGMOID>/input[0]:2/input[1]:1024/input[2]:14/input[3]:14/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_2__1634197824869498431<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_TANH>/input[0]:2/input[1]:1024/input[2]:14/input[3]:14/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_2__1634197824869498431<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:1024/input[2]:14/input[3]:14/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_2__1634197824869498431<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:2/input[1]:1024/input[2]:14/input[3]:14/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_2__1634197824869498431<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_ELU>/input[0]:2/input[1]:1024/input[2]:14/input[3]:14/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_2__1634197824869498431<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:1024/input[2]:14/input[3]:14/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_2__1634197824869498431<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:1024/input[2]:14/input[3]:14/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_2__1634197824869498431<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_IDENTITY>/input[0]:2/input[1]:1024/input[2]:14/input[3]:14/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_2__1634197824869498431<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_SIGMOID>/input[0]:2/input[1]:1024/input[2]:14/input[3]:14/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_2__1634197824869498431<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_TANH>/input[0]:2/input[1]:1024/input[2]:14/input[3]:14/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_2__1634197824869498431<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:1024/input[2]:14/input[3]:14/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_2__1634197824869498431<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:2/input[1]:1024/input[2]:14/input[3]:14/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_2__1634197824869498431<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_ELU>/input[0]:2/input[1]:1024/input[2]:14/input[3]:14/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_2__1634197824869498431<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:1024/input[2]:14/input[3]:14/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_2__1634197824869498431<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:1024/input[2]:14/input[3]:14/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_2__1634197824869498431<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_IDENTITY>/input[0]:2/input[1]:1024/input[2]:14/input[3]:14/filter_count:256/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_2__679271369126623378<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_SIGMOID>/input[0]:2/input[1]:128/input[2]:28/input[3]:28/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_2__679271369126623378<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_TANH>/input[0]:2/input[1]:128/input[2]:28/input[3]:28/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_2__679271369126623378<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:128/input[2]:28/input[3]:28/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 11866,
      "real_time": 5.9074084794677859e+04,
      "cpu_time": 6.5096034467966987e+04,
      "time_unit": "ns",
      "items_per_second": 1.7395182398028103e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 6.1312001198530197e-02,
      "batch_size": 2.0000000000000000e+00,
      "benchmark_file:/home/dakkak/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 1.5291677899427402e+19,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 2.3191971996820818e+18,
      "bias_tensor_layout": 1.0000000000000000e+00,
      "compute_capability:7.5": 3.8315628306456499e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Quadro RTX 6000": 5.1174270964049613e+18,
      "group": 1.0000000000000000e+00,
      "host_name:aleph": 3.2334478980185999e+18,
      "input[0]": 2.0000000000000000e+00,
      "input[1]": 1.2800000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 2.0000000000000000e+00,
      "input_channels": 1.2800000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 2.0070400000000000e+05,
      "input_width": 2.8000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 1.1866000000000000e+04,
      "output_batch_size": 2.0000000000000000e+00,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 8.0281600000000000e+05,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00,
      "x_tensor_layout": 1.0000000000000000e+00,
      "y_tensor_layout": 1.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_2__679271369126623378<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:2/input[1]:128/input[2]:28/input[3]:28/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 11875,
      "real_time": 5.8865445865452981e+04,
      "cpu_time": 6.4805135410499228e+04,
      "time_unit": "ns",
      "items_per_second": 1.7456836772268157e+12,
      "activation_mode": 3.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 6.1599999666213989e-02,
      "batch_size": 2.0000000000000000e+00,
      "benchmark_file:/home/dakkak/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 1.5291677899427402e+19,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.9889882919049984e+18,
      "bias_tensor_layout": 1.0000000000000000e+00,
      "compute_capability:7.5": 3.8315628306456499e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Quadro RTX 6000": 5.1174270964049613e+18,
      "group": 1.0000000000000000e+00,
      "host_name:aleph": 3.2334478980185999e+18,
      "input[0]": 2.0000000000000000e+00,
      "input[1]": 1.2800000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 2.0000000000000000e+00,
      "input_channels": 1.2800000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 2.0070400000000000e+05,
      "input_width": 2.8000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 1.1875000000000000e+04,
      "output_batch_size": 2.0000000000000000e+00,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 8.0281600000000000e+05,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00,
      "x_tensor_layout": 1.0000000000000000e+00,
      "y_tensor_layout": 1.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_2__679271369126623378<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_ELU>/input[0]:2/input[1]:128/input[2]:28/input[3]:28/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_2__679271369126623378<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:128/input[2]:28/input[3]:28/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 11885,
      "real_time": 5.8886534757356771e+04,
      "cpu_time": 6.4824920488002783e+04,
      "time_unit": "ns",
      "items_per_second": 1.7450584997644475e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 6.1439998447895050e-02,
      "batch_size": 2.0000000000000000e+00,
      "benchmark_file:/home/dakkak/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 1.5291677899427402e+19,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 2.3191971996820818e+18,
      "bias_tensor_layout": 1.0000000000000000e+00,
      "compute_capability:7.5": 3.8315628306456499e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Quadro RTX 6000": 5.1174270964049613e+18,
      "group": 1.0000000000000000e+00,
      "host_name:aleph": 3.2334478980185999e+18,
      "input[0]": 2.0000000000000000e+00,
      "input[1]": 1.2800000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 2.0000000000000000e+00,
      "input_channels": 1.2800000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 2.0070400000000000e+05,
      "input_width": 2.8000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 1.1885000000000000e+04,
      "output_batch_size": 2.0000000000000000e+00,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 8.0281600000000000e+05,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00,
      "x_tensor_layout": 1.0000000000000000e+00,
      "y_tensor_layout": 1.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_2__679271369126623378<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:128/input[2]:28/input[3]:28/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 11886,
      "real_time": 5.8901341570627534e+04,
      "cpu_time": 6.4851678108686821e+04,
      "time_unit": "ns",
      "items_per_second": 1.7446198212103848e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 6.0800001025199890e-02,
      "batch_size": 2.0000000000000000e+00,
      "benchmark_file:/home/dakkak/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 1.5291677899427402e+19,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 2.3191971996820818e+18,
      "bias_tensor_layout": 1.0000000000000000e+00,
      "compute_capability:7.5": 3.8315628306456499e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Quadro RTX 6000": 5.1174270964049613e+18,
      "group": 1.0000000000000000e+00,
      "host_name:aleph": 3.2334478980185999e+18,
      "input[0]": 2.0000000000000000e+00,
      "input[1]": 1.2800000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 2.0000000000000000e+00,
      "input_channels": 1.2800000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 2.0070400000000000e+05,
      "input_width": 2.8000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 1.1886000000000000e+04,
      "output_batch_size": 2.0000000000000000e+00,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 8.0281600000000000e+05,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00,
      "x_tensor_layout": 1.0000000000000000e+00,
      "y_tensor_layout": 1.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_2__679271369126623378<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_IDENTITY>/input[0]:2/input[1]:128/input[2]:28/input[3]:28/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 11823,
      "real_time": 5.8893985069365386e+04,
      "cpu_time": 6.4846562294178220e+04,
      "time_unit": "ns",
      "items_per_second": 1.7448377432596665e+12,
      "activation_mode": 5.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 7.6991997659206390e-02,
      "batch_size": 2.0000000000000000e+00,
      "benchmark_file:/home/dakkak/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 1.5291677899427402e+19,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)5; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.3342635194217454e+19,
      "bias_tensor_layout": 1.0000000000000000e+00,
      "compute_capability:7.5": 3.8315628306456499e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Quadro RTX 6000": 5.1174270964049613e+18,
      "group": 1.0000000000000000e+00,
      "host_name:aleph": 3.2334478980185999e+18,
      "input[0]": 2.0000000000000000e+00,
      "input[1]": 1.2800000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 2.0000000000000000e+00,
      "input_channels": 1.2800000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 2.0070400000000000e+05,
      "input_width": 2.8000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 1.1823000000000000e+04,
      "output_batch_size": 2.0000000000000000e+00,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 8.0281600000000000e+05,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00,
      "x_tensor_layout": 1.0000000000000000e+00,
      "y_tensor_layout": 1.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_2__679271369126623378<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_SIGMOID>/input[0]:2/input[1]:128/input[2]:28/input[3]:28/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_2__679271369126623378<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_TANH>/input[0]:2/input[1]:128/input[2]:28/input[3]:28/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_2__679271369126623378<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:128/input[2]:28/input[3]:28/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 26387,
      "real_time": 2.6426202012726288e+04,
      "cpu_time": 3.2378094743564543e+04,
      "time_unit": "ns",
      "items_per_second": 3.8885817928173252e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 4.7120000000000000e+03,
      "advised_time": 3.4623999148607254e-02,
      "batch_size": 2.0000000000000000e+00,
      "benchmark_file:/home/dakkak/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 1.5291677899427402e+19,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.5541522464702913e+19,
      "bias_tensor_layout": 1.0000000000000000e+00,
      "compute_capability:7.5": 3.8315628306456499e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Quadro RTX 6000": 5.1174270964049613e+18,
      "group": 1.0000000000000000e+00,
      "host_name:aleph": 3.2334478980185999e+18,
      "input[0]": 2.0000000000000000e+00,
      "input[1]": 1.2800000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 2.0000000000000000e+00,
      "input_channels": 1.2800000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 2.0070400000000000e+05,
      "input_width": 2.8000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 2.6387000000000000e+04,
      "output_batch_size": 2.0000000000000000e+00,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 8.0281600000000000e+05,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 1.0000000000000000e+00,
      "workspace_bytes": 4.7120000000000000e+03,
      "workspace_megabytes": 4.4937133789062500e-03,
      "x_tensor_layout": 1.0000000000000000e+00,
      "y_tensor_layout": 1.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_2__679271369126623378<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:2/input[1]:128/input[2]:28/input[3]:28/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 26175,
      "real_time": 2.6442084756088640e+04,
      "cpu_time": 3.2397151977110319e+04,
      "time_unit": "ns",
      "items_per_second": 3.8862460712874785e+12,
      "activation_mode": 3.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 4.7120000000000000e+03,
      "advised_time": 3.3792000263929367e-02,
      "batch_size": 2.0000000000000000e+00,
      "benchmark_file:/home/dakkak/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 1.5291677899427402e+19,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.5547362882776177e+19,
      "bias_tensor_layout": 1.0000000000000000e+00,
      "compute_capability:7.5": 3.8315628306456499e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Quadro RTX 6000": 5.1174270964049613e+18,
      "group": 1.0000000000000000e+00,
      "host_name:aleph": 3.2334478980185999e+18,
      "input[0]": 2.0000000000000000e+00,
      "input[1]": 1.2800000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 2.0000000000000000e+00,
      "input_channels": 1.2800000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 2.0070400000000000e+05,
      "input_width": 2.8000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 2.6175000000000000e+04,
      "output_batch_size": 2.0000000000000000e+00,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 8.0281600000000000e+05,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 1.0000000000000000e+00,
      "workspace_bytes": 4.7120000000000000e+03,
      "workspace_megabytes": 4.4937133789062500e-03,
      "x_tensor_layout": 1.0000000000000000e+00,
      "y_tensor_layout": 1.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_2__679271369126623378<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_ELU>/input[0]:2/input[1]:128/input[2]:28/input[3]:28/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_2__679271369126623378<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:128/input[2]:28/input[3]:28/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 26298,
      "real_time": 2.6406467441396861e+04,
      "cpu_time": 3.2301221461711146e+04,
      "time_unit": "ns",
      "items_per_second": 3.8914878799314380e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 4.7120000000000000e+03,
      "advised_time": 3.6864001303911209e-02,
      "batch_size": 2.0000000000000000e+00,
      "benchmark_file:/home/dakkak/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 1.5291677899427402e+19,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.5541522464702913e+19,
      "bias_tensor_layout": 1.0000000000000000e+00,
      "compute_capability:7.5": 3.8315628306456499e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Quadro RTX 6000": 5.1174270964049613e+18,
      "group": 1.0000000000000000e+00,
      "host_name:aleph": 3.2334478980185999e+18,
      "input[0]": 2.0000000000000000e+00,
      "input[1]": 1.2800000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 2.0000000000000000e+00,
      "input_channels": 1.2800000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 2.0070400000000000e+05,
      "input_width": 2.8000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 2.6298000000000000e+04,
      "output_batch_size": 2.0000000000000000e+00,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 8.0281600000000000e+05,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 1.0000000000000000e+00,
      "workspace_bytes": 4.7120000000000000e+03,
      "workspace_megabytes": 4.4937133789062500e-03,
      "x_tensor_layout": 1.0000000000000000e+00,
      "y_tensor_layout": 1.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_2__679271369126623378<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:128/input[2]:28/input[3]:28/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 26576,
      "real_time": 2.6501874790611946e+04,
      "cpu_time": 3.2445909843578716e+04,
      "time_unit": "ns",
      "items_per_second": 3.8774784354653267e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 4.7120000000000000e+03,
      "advised_time": 3.1552001833915710e-02,
      "batch_size": 2.0000000000000000e+00,
      "benchmark_file:/home/dakkak/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 1.5291677899427402e+19,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.5541522464702913e+19,
      "bias_tensor_layout": 1.0000000000000000e+00,
      "compute_capability:7.5": 3.8315628306456499e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Quadro RTX 6000": 5.1174270964049613e+18,
      "group": 1.0000000000000000e+00,
      "host_name:aleph": 3.2334478980185999e+18,
      "input[0]": 2.0000000000000000e+00,
      "input[1]": 1.2800000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 2.0000000000000000e+00,
      "input_channels": 1.2800000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 2.0070400000000000e+05,
      "input_width": 2.8000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 2.6576000000000000e+04,
      "output_batch_size": 2.0000000000000000e+00,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 8.0281600000000000e+05,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 1.0000000000000000e+00,
      "workspace_bytes": 4.7120000000000000e+03,
      "workspace_megabytes": 4.4937133789062500e-03,
      "x_tensor_layout": 1.0000000000000000e+00,
      "y_tensor_layout": 1.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_2__679271369126623378<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_IDENTITY>/input[0]:2/input[1]:128/input[2]:28/input[3]:28/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 26759,
      "real_time": 2.6019650976486311e+04,
      "cpu_time": 3.1767890279923766e+04,
      "time_unit": "ns",
      "items_per_second": 3.9493399851083145e+12,
      "activation_mode": 5.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 4.7120000000000000e+03,
      "advised_time": 3.2512001693248749e-02,
      "batch_size": 2.0000000000000000e+00,
      "benchmark_file:/home/dakkak/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 1.5291677899427402e+19,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)5; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 4.5833023350607309e+18,
      "bias_tensor_layout": 1.0000000000000000e+00,
      "compute_capability:7.5": 3.8315628306456499e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Quadro RTX 6000": 5.1174270964049613e+18,
      "group": 1.0000000000000000e+00,
      "host_name:aleph": 3.2334478980185999e+18,
      "input[0]": 2.0000000000000000e+00,
      "input[1]": 1.2800000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 2.0000000000000000e+00,
      "input_channels": 1.2800000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 2.0070400000000000e+05,
      "input_width": 2.8000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 2.6759000000000000e+04,
      "output_batch_size": 2.0000000000000000e+00,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 2.8000000000000000e+01,
      "output_size": 8.0281600000000000e+05,
      "output_width": 2.8000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 1.0000000000000000e+00,
      "workspace_bytes": 4.7120000000000000e+03,
      "workspace_megabytes": 4.4937133789062500e-03,
      "x_tensor_layout": 1.0000000000000000e+00,
      "y_tensor_layout": 1.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_2__679271369126623378<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_SIGMOID>/input[0]:2/input[1]:128/input[2]:28/input[3]:28/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_2__679271369126623378<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_TANH>/input[0]:2/input[1]:128/input[2]:28/input[3]:28/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_2__679271369126623378<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:128/input[2]:28/input[3]:28/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_2__679271369126623378<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:2/input[1]:128/input[2]:28/input[3]:28/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_2__679271369126623378<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_ELU>/input[0]:2/input[1]:128/input[2]:28/input[3]:28/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_2__679271369126623378<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:128/input[2]:28/input[3]:28/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_2__679271369126623378<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:128/input[2]:28/input[3]:28/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_2__679271369126623378<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_IDENTITY>/input[0]:2/input[1]:128/input[2]:28/input[3]:28/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_2__679271369126623378<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_SIGMOID>/input[0]:2/input[1]:128/input[2]:28/input[3]:28/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_2__679271369126623378<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_TANH>/input[0]:2/input[1]:128/input[2]:28/input[3]:28/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_2__679271369126623378<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:128/input[2]:28/input[3]:28/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_2__679271369126623378<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:2/input[1]:128/input[2]:28/input[3]:28/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_2__679271369126623378<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_ELU>/input[0]:2/input[1]:128/input[2]:28/input[3]:28/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_2__679271369126623378<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:128/input[2]:28/input[3]:28/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_2__679271369126623378<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:128/input[2]:28/input[3]:28/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_2__679271369126623378<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_IDENTITY>/input[0]:2/input[1]:128/input[2]:28/input[3]:28/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_2__679271369126623378<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_SIGMOID>/input[0]:2/input[1]:128/input[2]:28/input[3]:28/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_2__679271369126623378<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_TANH>/input[0]:2/input[1]:128/input[2]:28/input[3]:28/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_2__679271369126623378<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:128/input[2]:28/input[3]:28/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_2__679271369126623378<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:2/input[1]:128/input[2]:28/input[3]:28/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_2__679271369126623378<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_ELU>/input[0]:2/input[1]:128/input[2]:28/input[3]:28/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_2__679271369126623378<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:128/input[2]:28/input[3]:28/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_2__679271369126623378<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:128/input[2]:28/input[3]:28/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_2__679271369126623378<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_IDENTITY>/input[0]:2/input[1]:128/input[2]:28/input[3]:28/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_2__679271369126623378<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_SIGMOID>/input[0]:2/input[1]:128/input[2]:28/input[3]:28/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_2__679271369126623378<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_TANH>/input[0]:2/input[1]:128/input[2]:28/input[3]:28/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_2__679271369126623378<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:128/input[2]:28/input[3]:28/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_2__679271369126623378<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:2/input[1]:128/input[2]:28/input[3]:28/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_2__679271369126623378<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_ELU>/input[0]:2/input[1]:128/input[2]:28/input[3]:28/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_2__679271369126623378<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:128/input[2]:28/input[3]:28/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_2__679271369126623378<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:128/input[2]:28/input[3]:28/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_2__679271369126623378<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_IDENTITY>/input[0]:2/input[1]:128/input[2]:28/input[3]:28/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_2__679271369126623378<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_SIGMOID>/input[0]:2/input[1]:128/input[2]:28/input[3]:28/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_2__679271369126623378<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_TANH>/input[0]:2/input[1]:128/input[2]:28/input[3]:28/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_2__679271369126623378<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:128/input[2]:28/input[3]:28/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_2__679271369126623378<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:2/input[1]:128/input[2]:28/input[3]:28/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_2__679271369126623378<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_ELU>/input[0]:2/input[1]:128/input[2]:28/input[3]:28/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_2__679271369126623378<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:128/input[2]:28/input[3]:28/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_2__679271369126623378<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:128/input[2]:28/input[3]:28/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_2__679271369126623378<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_IDENTITY>/input[0]:2/input[1]:128/input[2]:28/input[3]:28/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_2__679271369126623378<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_SIGMOID>/input[0]:2/input[1]:128/input[2]:28/input[3]:28/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_2__679271369126623378<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_TANH>/input[0]:2/input[1]:128/input[2]:28/input[3]:28/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_2__679271369126623378<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:128/input[2]:28/input[3]:28/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_2__679271369126623378<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:2/input[1]:128/input[2]:28/input[3]:28/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_2__679271369126623378<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_ELU>/input[0]:2/input[1]:128/input[2]:28/input[3]:28/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_2__679271369126623378<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:128/input[2]:28/input[3]:28/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_2__679271369126623378<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:128/input[2]:28/input[3]:28/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_3_TENSORCOREHALF__BatchSize_2__679271369126623378<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_IDENTITY>/input[0]:2/input[1]:128/input[2]:28/input[3]:28/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_2__10563156757672288263<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_SIGMOID>/input[0]:2/input[1]:512/input[2]:28/input[3]:28/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_2__10563156757672288263<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_TANH>/input[0]:2/input[1]:512/input[2]:28/input[3]:28/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_2__10563156757672288263<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:512/input[2]:28/input[3]:28/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 4561,
      "real_time": 1.5210882021521899e+05,
      "cpu_time": 1.5830645713637318e+05,
      "time_unit": "ns",
      "items_per_second": 5.4045753746352949e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 1.5340800583362579e-01,
      "batch_size": 2.0000000000000000e+00,
      "benchmark_file:/home/dakkak/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 1.5291677899427402e+19,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 2.3191971996820818e+18,
      "bias_tensor_layout": 1.0000000000000000e+00,
      "compute_capability:7.5": 3.8315628306456499e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.0240000000000000e+03,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Quadro RTX 6000": 5.1174270964049613e+18,
      "group": 1.0000000000000000e+00,
      "host_name:aleph": 3.2334478980185999e+18,
      "input[0]": 2.0000000000000000e+00,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 2.0000000000000000e+00,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 8.0281600000000000e+05,
      "input_width": 2.8000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 1.0240000000000000e+03,
      "num_iterations": 4.5610000000000000e+03,
      "output_batch_size": 2.0000000000000000e+00,
      "output_channels": 1.0240000000000000e+03,
      "output_height": 1.4000000000000000e+01,
      "output_size": 4.0140800000000000e+05,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "w_filter_layout": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00,
      "x_tensor_layout": 1.0000000000000000e+00,
      "y_tensor_layout": 1.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_2__10563156757672288263<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:2/input[1]:512/input[2]:28/input[3]:28/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 4616,
      "real_time": 1.5153927435213033e+05,
      "cpu_time": 1.5759112781577199e+05,
      "time_unit": "ns",
      "items_per_second": 5.4248879540608887e+12,
      "activation_mode": 3.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 1.5155200660228729e-01,
      "batch_size": 2.0000000000000000e+00,
      "benchmark_file:/home/dakkak/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 1.5291677899427402e+19,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.9889882919049984e+18,
      "bias_tensor_layout": 1.0000000000000000e+00,
      "compute_capability:7.5": 3.8315628306456499e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.0240000000000000e+03,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Quadro RTX 6000": 5.1174270964049613e+18,
      "group": 1.0000000000000000e+00,
      "host_name:aleph": 3.2334478980185999e+18,
      "input[0]": 2.0000000000000000e+00,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 2.0000000000000000e+00,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 8.0281600000000000e+05,
      "input_width": 2.8000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 1.0240000000000000e+03,
      "num_iterations": 4.6160000000000000e+03,
      "output_batch_size": 2.0000000000000000e+00,
      "output_channels": 1.0240000000000000e+03,
      "output_height": 1.4000000000000000e+01,
      "output_size": 4.0140800000000000e+05,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "w_filter_layout": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00,
      "x_tensor_layout": 1.0000000000000000e+00,
      "y_tensor_layout": 1.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_2__10563156757672288263<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_ELU>/input[0]:2/input[1]:512/input[2]:28/input[3]:28/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_2__10563156757672288263<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:512/input[2]:28/input[3]:28/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 4624,
      "real_time": 1.5155466658347828e+05,
      "cpu_time": 1.5766560207584576e+05,
      "time_unit": "ns",
      "items_per_second": 5.4243369902911289e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 1.5222400426864624e-01,
      "batch_size": 2.0000000000000000e+00,
      "benchmark_file:/home/dakkak/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 1.5291677899427402e+19,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 2.3191971996820818e+18,
      "bias_tensor_layout": 1.0000000000000000e+00,
      "compute_capability:7.5": 3.8315628306456499e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.0240000000000000e+03,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Quadro RTX 6000": 5.1174270964049613e+18,
      "group": 1.0000000000000000e+00,
      "host_name:aleph": 3.2334478980185999e+18,
      "input[0]": 2.0000000000000000e+00,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 2.0000000000000000e+00,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 8.0281600000000000e+05,
      "input_width": 2.8000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 1.0240000000000000e+03,
      "num_iterations": 4.6240000000000000e+03,
      "output_batch_size": 2.0000000000000000e+00,
      "output_channels": 1.0240000000000000e+03,
      "output_height": 1.4000000000000000e+01,
      "output_size": 4.0140800000000000e+05,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "w_filter_layout": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00,
      "x_tensor_layout": 1.0000000000000000e+00,
      "y_tensor_layout": 1.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_2__10563156757672288263<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:512/input[2]:28/input[3]:28/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 4622,
      "real_time": 1.5149617898165100e+05,
      "cpu_time": 1.5752210190354832e+05,
      "time_unit": "ns",
      "items_per_second": 5.4264311451681533e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 1.5350399911403656e-01,
      "batch_size": 2.0000000000000000e+00,
      "benchmark_file:/home/dakkak/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 1.5291677899427402e+19,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 2.3191971996820818e+18,
      "bias_tensor_layout": 1.0000000000000000e+00,
      "compute_capability:7.5": 3.8315628306456499e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.0240000000000000e+03,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Quadro RTX 6000": 5.1174270964049613e+18,
      "group": 1.0000000000000000e+00,
      "host_name:aleph": 3.2334478980185999e+18,
      "input[0]": 2.0000000000000000e+00,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 2.0000000000000000e+00,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 8.0281600000000000e+05,
      "input_width": 2.8000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 1.0240000000000000e+03,
      "num_iterations": 4.6220000000000000e+03,
      "output_batch_size": 2.0000000000000000e+00,
      "output_channels": 1.0240000000000000e+03,
      "output_height": 1.4000000000000000e+01,
      "output_size": 4.0140800000000000e+05,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "w_filter_layout": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00,
      "x_tensor_layout": 1.0000000000000000e+00,
      "y_tensor_layout": 1.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_2__10563156757672288263<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_IDENTITY>/input[0]:2/input[1]:512/input[2]:28/input[3]:28/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 4618,
      "real_time": 1.5158676727439047e+05,
      "cpu_time": 1.5764055153734391e+05,
      "time_unit": "ns",
      "items_per_second": 5.4231883084618389e+12,
      "activation_mode": 5.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 1.5286399424076080e-01,
      "batch_size": 2.0000000000000000e+00,
      "benchmark_file:/home/dakkak/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 1.5291677899427402e+19,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)5; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.3342635194217454e+19,
      "bias_tensor_layout": 1.0000000000000000e+00,
      "compute_capability:7.5": 3.8315628306456499e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.0240000000000000e+03,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Quadro RTX 6000": 5.1174270964049613e+18,
      "group": 1.0000000000000000e+00,
      "host_name:aleph": 3.2334478980185999e+18,
      "input[0]": 2.0000000000000000e+00,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 2.0000000000000000e+00,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 8.0281600000000000e+05,
      "input_width": 2.8000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 1.0240000000000000e+03,
      "num_iterations": 4.6180000000000000e+03,
      "output_batch_size": 2.0000000000000000e+00,
      "output_channels": 1.0240000000000000e+03,
      "output_height": 1.4000000000000000e+01,
      "output_size": 4.0140800000000000e+05,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "w_filter_layout": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00,
      "x_tensor_layout": 1.0000000000000000e+00,
      "y_tensor_layout": 1.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_2__10563156757672288263<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_SIGMOID>/input[0]:2/input[1]:512/input[2]:28/input[3]:28/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_2__10563156757672288263<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_TANH>/input[0]:2/input[1]:512/input[2]:28/input[3]:28/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_2__10563156757672288263<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:512/input[2]:28/input[3]:28/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 19709,
      "real_time": 3.5708754304146365e+04,
      "cpu_time": 4.1633162159280662e+04,
      "time_unit": "ns",
      "items_per_second": 2.3021905972915520e+13,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.1840000000000000e+03,
      "advised_time": 4.2240001261234283e-02,
      "batch_size": 2.0000000000000000e+00,
      "benchmark_file:/home/dakkak/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 1.5291677899427402e+19,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.5541522464702913e+19,
      "bias_tensor_layout": 1.0000000000000000e+00,
      "compute_capability:7.5": 3.8315628306456499e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.0240000000000000e+03,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Quadro RTX 6000": 5.1174270964049613e+18,
      "group": 1.0000000000000000e+00,
      "host_name:aleph": 3.2334478980185999e+18,
      "input[0]": 2.0000000000000000e+00,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 2.0000000000000000e+00,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 8.0281600000000000e+05,
      "input_width": 2.8000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 1.0240000000000000e+03,
      "num_iterations": 1.9709000000000000e+04,
      "output_batch_size": 2.0000000000000000e+00,
      "output_channels": 1.0240000000000000e+03,
      "output_height": 1.4000000000000000e+01,
      "output_size": 4.0140800000000000e+05,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "w_filter_layout": 1.0000000000000000e+00,
      "workspace_bytes": 1.1840000000000000e+03,
      "workspace_megabytes": 1.1291503906250000e-03,
      "x_tensor_layout": 1.0000000000000000e+00,
      "y_tensor_layout": 1.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_2__10563156757672288263<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:2/input[1]:512/input[2]:28/input[3]:28/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 19459,
      "real_time": 3.5718875522606621e+04,
      "cpu_time": 4.1628508299236441e+04,
      "time_unit": "ns",
      "items_per_second": 2.3015382538560039e+13,
      "activation_mode": 3.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.1840000000000000e+03,
      "advised_time": 4.3007999658584595e-02,
      "batch_size": 2.0000000000000000e+00,
      "benchmark_file:/home/dakkak/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 1.5291677899427402e+19,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.5547362882776177e+19,
      "bias_tensor_layout": 1.0000000000000000e+00,
      "compute_capability:7.5": 3.8315628306456499e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.0240000000000000e+03,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Quadro RTX 6000": 5.1174270964049613e+18,
      "group": 1.0000000000000000e+00,
      "host_name:aleph": 3.2334478980185999e+18,
      "input[0]": 2.0000000000000000e+00,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 2.0000000000000000e+00,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 8.0281600000000000e+05,
      "input_width": 2.8000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 1.0240000000000000e+03,
      "num_iterations": 1.9459000000000000e+04,
      "output_batch_size": 2.0000000000000000e+00,
      "output_channels": 1.0240000000000000e+03,
      "output_height": 1.4000000000000000e+01,
      "output_size": 4.0140800000000000e+05,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "w_filter_layout": 1.0000000000000000e+00,
      "workspace_bytes": 1.1840000000000000e+03,
      "workspace_megabytes": 1.1291503906250000e-03,
      "x_tensor_layout": 1.0000000000000000e+00,
      "y_tensor_layout": 1.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_2__10563156757672288263<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_ELU>/input[0]:2/input[1]:512/input[2]:28/input[3]:28/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_2__10563156757672288263<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:512/input[2]:28/input[3]:28/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 19631,
      "real_time": 3.5712766026600613e+04,
      "cpu_time": 4.1658466812622915e+04,
      "time_unit": "ns",
      "items_per_second": 2.3019319852953199e+13,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.1840000000000000e+03,
      "advised_time": 4.1792001575231552e-02,
      "batch_size": 2.0000000000000000e+00,
      "benchmark_file:/home/dakkak/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 1.5291677899427402e+19,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.5541522464702913e+19,
      "bias_tensor_layout": 1.0000000000000000e+00,
      "compute_capability:7.5": 3.8315628306456499e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.0240000000000000e+03,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Quadro RTX 6000": 5.1174270964049613e+18,
      "group": 1.0000000000000000e+00,
      "host_name:aleph": 3.2334478980185999e+18,
      "input[0]": 2.0000000000000000e+00,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 2.0000000000000000e+00,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 8.0281600000000000e+05,
      "input_width": 2.8000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 1.0240000000000000e+03,
      "num_iterations": 1.9631000000000000e+04,
      "output_batch_size": 2.0000000000000000e+00,
      "output_channels": 1.0240000000000000e+03,
      "output_height": 1.4000000000000000e+01,
      "output_size": 4.0140800000000000e+05,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "w_filter_layout": 1.0000000000000000e+00,
      "workspace_bytes": 1.1840000000000000e+03,
      "workspace_megabytes": 1.1291503906250000e-03,
      "x_tensor_layout": 1.0000000000000000e+00,
      "y_tensor_layout": 1.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_2__10563156757672288263<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:512/input[2]:28/input[3]:28/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 19650,
      "real_time": 3.5779607027479382e+04,
      "cpu_time": 4.1657736641101452e+04,
      "time_unit": "ns",
      "items_per_second": 2.2976316742903996e+13,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.1840000000000000e+03,
      "advised_time": 6.2272001057863235e-02,
      "batch_size": 2.0000000000000000e+00,
      "benchmark_file:/home/dakkak/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 1.5291677899427402e+19,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.5541522464702913e+19,
      "bias_tensor_layout": 1.0000000000000000e+00,
      "compute_capability:7.5": 3.8315628306456499e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.0240000000000000e+03,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Quadro RTX 6000": 5.1174270964049613e+18,
      "group": 1.0000000000000000e+00,
      "host_name:aleph": 3.2334478980185999e+18,
      "input[0]": 2.0000000000000000e+00,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 2.0000000000000000e+00,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 8.0281600000000000e+05,
      "input_width": 2.8000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 1.0240000000000000e+03,
      "num_iterations": 1.9650000000000000e+04,
      "output_batch_size": 2.0000000000000000e+00,
      "output_channels": 1.0240000000000000e+03,
      "output_height": 1.4000000000000000e+01,
      "output_size": 4.0140800000000000e+05,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "w_filter_layout": 1.0000000000000000e+00,
      "workspace_bytes": 1.1840000000000000e+03,
      "workspace_megabytes": 1.1291503906250000e-03,
      "x_tensor_layout": 1.0000000000000000e+00,
      "y_tensor_layout": 1.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_2__10563156757672288263<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_IDENTITY>/input[0]:2/input[1]:512/input[2]:28/input[3]:28/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 19631,
      "real_time": 3.5539247862127821e+04,
      "cpu_time": 4.1448762060114357e+04,
      "time_unit": "ns",
      "items_per_second": 2.3131710248602316e+13,
      "activation_mode": 5.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.1840000000000000e+03,
      "advised_time": 4.1439998894929886e-02,
      "batch_size": 2.0000000000000000e+00,
      "benchmark_file:/home/dakkak/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 1.5291677899427402e+19,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)5; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 4.5833023350607309e+18,
      "bias_tensor_layout": 1.0000000000000000e+00,
      "compute_capability:7.5": 3.8315628306456499e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.0240000000000000e+03,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Quadro RTX 6000": 5.1174270964049613e+18,
      "group": 1.0000000000000000e+00,
      "host_name:aleph": 3.2334478980185999e+18,
      "input[0]": 2.0000000000000000e+00,
      "input[1]": 5.1200000000000000e+02,
      "input[2]": 2.8000000000000000e+01,
      "input[3]": 2.8000000000000000e+01,
      "input_batch_size": 2.0000000000000000e+00,
      "input_channels": 5.1200000000000000e+02,
      "input_height": 2.8000000000000000e+01,
      "input_size": 8.0281600000000000e+05,
      "input_width": 2.8000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 1.0240000000000000e+03,
      "num_iterations": 1.9631000000000000e+04,
      "output_batch_size": 2.0000000000000000e+00,
      "output_channels": 1.0240000000000000e+03,
      "output_height": 1.4000000000000000e+01,
      "output_size": 4.0140800000000000e+05,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 2.0000000000000000e+00,
      "stride_width": 2.0000000000000000e+00,
      "w_filter_layout": 1.0000000000000000e+00,
      "workspace_bytes": 1.1840000000000000e+03,
      "workspace_megabytes": 1.1291503906250000e-03,
      "x_tensor_layout": 1.0000000000000000e+00,
      "y_tensor_layout": 1.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_2__10563156757672288263<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_SIGMOID>/input[0]:2/input[1]:512/input[2]:28/input[3]:28/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_2__10563156757672288263<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_TANH>/input[0]:2/input[1]:512/input[2]:28/input[3]:28/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_2__10563156757672288263<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:512/input[2]:28/input[3]:28/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_2__10563156757672288263<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:2/input[1]:512/input[2]:28/input[3]:28/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_2__10563156757672288263<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_ELU>/input[0]:2/input[1]:512/input[2]:28/input[3]:28/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_2__10563156757672288263<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:512/input[2]:28/input[3]:28/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_2__10563156757672288263<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:512/input[2]:28/input[3]:28/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_2__10563156757672288263<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_IDENTITY>/input[0]:2/input[1]:512/input[2]:28/input[3]:28/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_2__10563156757672288263<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_SIGMOID>/input[0]:2/input[1]:512/input[2]:28/input[3]:28/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_2__10563156757672288263<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_TANH>/input[0]:2/input[1]:512/input[2]:28/input[3]:28/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_2__10563156757672288263<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:512/input[2]:28/input[3]:28/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_2__10563156757672288263<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:2/input[1]:512/input[2]:28/input[3]:28/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_2__10563156757672288263<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_ELU>/input[0]:2/input[1]:512/input[2]:28/input[3]:28/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_2__10563156757672288263<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:512/input[2]:28/input[3]:28/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_2__10563156757672288263<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:512/input[2]:28/input[3]:28/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_2__10563156757672288263<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_IDENTITY>/input[0]:2/input[1]:512/input[2]:28/input[3]:28/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_2__10563156757672288263<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_SIGMOID>/input[0]:2/input[1]:512/input[2]:28/input[3]:28/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_2__10563156757672288263<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_TANH>/input[0]:2/input[1]:512/input[2]:28/input[3]:28/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_2__10563156757672288263<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:512/input[2]:28/input[3]:28/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_2__10563156757672288263<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:2/input[1]:512/input[2]:28/input[3]:28/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_2__10563156757672288263<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_ELU>/input[0]:2/input[1]:512/input[2]:28/input[3]:28/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_2__10563156757672288263<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:512/input[2]:28/input[3]:28/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_2__10563156757672288263<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:512/input[2]:28/input[3]:28/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_2__10563156757672288263<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_IDENTITY>/input[0]:2/input[1]:512/input[2]:28/input[3]:28/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_2__10563156757672288263<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_SIGMOID>/input[0]:2/input[1]:512/input[2]:28/input[3]:28/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_2__10563156757672288263<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_TANH>/input[0]:2/input[1]:512/input[2]:28/input[3]:28/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_2__10563156757672288263<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:512/input[2]:28/input[3]:28/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_2__10563156757672288263<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:2/input[1]:512/input[2]:28/input[3]:28/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_2__10563156757672288263<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_ELU>/input[0]:2/input[1]:512/input[2]:28/input[3]:28/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_2__10563156757672288263<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:512/input[2]:28/input[3]:28/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_2__10563156757672288263<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:512/input[2]:28/input[3]:28/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_2__10563156757672288263<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_IDENTITY>/input[0]:2/input[1]:512/input[2]:28/input[3]:28/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_2__10563156757672288263<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_SIGMOID>/input[0]:2/input[1]:512/input[2]:28/input[3]:28/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_2__10563156757672288263<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_TANH>/input[0]:2/input[1]:512/input[2]:28/input[3]:28/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_2__10563156757672288263<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:512/input[2]:28/input[3]:28/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_2__10563156757672288263<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:2/input[1]:512/input[2]:28/input[3]:28/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_2__10563156757672288263<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_ELU>/input[0]:2/input[1]:512/input[2]:28/input[3]:28/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_2__10563156757672288263<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:512/input[2]:28/input[3]:28/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_2__10563156757672288263<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:512/input[2]:28/input[3]:28/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_2__10563156757672288263<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_IDENTITY>/input[0]:2/input[1]:512/input[2]:28/input[3]:28/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_2__10563156757672288263<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_SIGMOID>/input[0]:2/input[1]:512/input[2]:28/input[3]:28/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_2__10563156757672288263<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_TANH>/input[0]:2/input[1]:512/input[2]:28/input[3]:28/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_2__10563156757672288263<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:512/input[2]:28/input[3]:28/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_2__10563156757672288263<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:2/input[1]:512/input[2]:28/input[3]:28/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_2__10563156757672288263<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_ELU>/input[0]:2/input[1]:512/input[2]:28/input[3]:28/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_2__10563156757672288263<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:512/input[2]:28/input[3]:28/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_2__10563156757672288263<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:512/input[2]:28/input[3]:28/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_2__10563156757672288263<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_IDENTITY>/input[0]:2/input[1]:512/input[2]:28/input[3]:28/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:2/stride_width:2/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_2__14584214619229659880<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_SIGMOID>/input[0]:2/input[1]:2048/input[2]:7/input[3]:7/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_2__14584214619229659880<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_TANH>/input[0]:2/input[1]:2048/input[2]:7/input[3]:7/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_2__14584214619229659880<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:2048/input[2]:7/input[3]:7/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 1241,
      "real_time": 5.5952487224682944e+05,
      "cpu_time": 5.7001399355576641e+05,
      "time_unit": "ns",
      "items_per_second": 1.8365662206821100e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 5.9983998537063599e-01,
      "batch_size": 2.0000000000000000e+00,
      "benchmark_file:/home/dakkak/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 1.5291677899427402e+19,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 2.3191971996820818e+18,
      "bias_tensor_layout": 1.0000000000000000e+00,
      "compute_capability:7.5": 3.8315628306456499e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Quadro RTX 6000": 5.1174270964049613e+18,
      "group": 1.0000000000000000e+00,
      "host_name:aleph": 3.2334478980185999e+18,
      "input[0]": 2.0000000000000000e+00,
      "input[1]": 2.0480000000000000e+03,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input_batch_size": 2.0000000000000000e+00,
      "input_channels": 2.0480000000000000e+03,
      "input_height": 7.0000000000000000e+00,
      "input_size": 2.0070400000000000e+05,
      "input_width": 7.0000000000000000e+00,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 1.2410000000000000e+03,
      "output_batch_size": 2.0000000000000000e+00,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 5.0176000000000000e+04,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00,
      "x_tensor_layout": 1.0000000000000000e+00,
      "y_tensor_layout": 1.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_2__14584214619229659880<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:2/input[1]:2048/input[2]:7/input[3]:7/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 1259,
      "real_time": 5.5606527171875152e+05,
      "cpu_time": 5.6622529547428968e+05,
      "time_unit": "ns",
      "items_per_second": 1.8479925509891312e+11,
      "activation_mode": 3.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 5.8652800321578979e-01,
      "batch_size": 2.0000000000000000e+00,
      "benchmark_file:/home/dakkak/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 1.5291677899427402e+19,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.9889882919049984e+18,
      "bias_tensor_layout": 1.0000000000000000e+00,
      "compute_capability:7.5": 3.8315628306456499e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Quadro RTX 6000": 5.1174270964049613e+18,
      "group": 1.0000000000000000e+00,
      "host_name:aleph": 3.2334478980185999e+18,
      "input[0]": 2.0000000000000000e+00,
      "input[1]": 2.0480000000000000e+03,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input_batch_size": 2.0000000000000000e+00,
      "input_channels": 2.0480000000000000e+03,
      "input_height": 7.0000000000000000e+00,
      "input_size": 2.0070400000000000e+05,
      "input_width": 7.0000000000000000e+00,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 1.2590000000000000e+03,
      "output_batch_size": 2.0000000000000000e+00,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 5.0176000000000000e+04,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00,
      "x_tensor_layout": 1.0000000000000000e+00,
      "y_tensor_layout": 1.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_2__14584214619229659880<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_ELU>/input[0]:2/input[1]:2048/input[2]:7/input[3]:7/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_2__14584214619229659880<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:2048/input[2]:7/input[3]:7/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 1260,
      "real_time": 5.5607720541523851e+05,
      "cpu_time": 5.6624756190448324e+05,
      "time_unit": "ns",
      "items_per_second": 1.8479528921396060e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 5.8819198608398438e-01,
      "batch_size": 2.0000000000000000e+00,
      "benchmark_file:/home/dakkak/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 1.5291677899427402e+19,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 2.3191971996820818e+18,
      "bias_tensor_layout": 1.0000000000000000e+00,
      "compute_capability:7.5": 3.8315628306456499e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Quadro RTX 6000": 5.1174270964049613e+18,
      "group": 1.0000000000000000e+00,
      "host_name:aleph": 3.2334478980185999e+18,
      "input[0]": 2.0000000000000000e+00,
      "input[1]": 2.0480000000000000e+03,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input_batch_size": 2.0000000000000000e+00,
      "input_channels": 2.0480000000000000e+03,
      "input_height": 7.0000000000000000e+00,
      "input_size": 2.0070400000000000e+05,
      "input_width": 7.0000000000000000e+00,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 1.2600000000000000e+03,
      "output_batch_size": 2.0000000000000000e+00,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 5.0176000000000000e+04,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00,
      "x_tensor_layout": 1.0000000000000000e+00,
      "y_tensor_layout": 1.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_2__14584214619229659880<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:2048/input[2]:7/input[3]:7/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 1259,
      "real_time": 5.5602778122309851e+05,
      "cpu_time": 5.6622565369311755e+05,
      "time_unit": "ns",
      "items_per_second": 1.8481171529587433e+11,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 6.0854399204254150e-01,
      "batch_size": 2.0000000000000000e+00,
      "benchmark_file:/home/dakkak/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 1.5291677899427402e+19,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 2.3191971996820818e+18,
      "bias_tensor_layout": 1.0000000000000000e+00,
      "compute_capability:7.5": 3.8315628306456499e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Quadro RTX 6000": 5.1174270964049613e+18,
      "group": 1.0000000000000000e+00,
      "host_name:aleph": 3.2334478980185999e+18,
      "input[0]": 2.0000000000000000e+00,
      "input[1]": 2.0480000000000000e+03,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input_batch_size": 2.0000000000000000e+00,
      "input_channels": 2.0480000000000000e+03,
      "input_height": 7.0000000000000000e+00,
      "input_size": 2.0070400000000000e+05,
      "input_width": 7.0000000000000000e+00,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 1.2590000000000000e+03,
      "output_batch_size": 2.0000000000000000e+00,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 5.0176000000000000e+04,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00,
      "x_tensor_layout": 1.0000000000000000e+00,
      "y_tensor_layout": 1.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_2__14584214619229659880<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_IDENTITY>/input[0]:2/input[1]:2048/input[2]:7/input[3]:7/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 1260,
      "real_time": 5.5599951786765212e+05,
      "cpu_time": 5.6612914841242030e+05,
      "time_unit": "ns",
      "items_per_second": 1.8482110990689868e+11,
      "activation_mode": 5.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 5.8659201860427856e-01,
      "batch_size": 2.0000000000000000e+00,
      "benchmark_file:/home/dakkak/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 1.5291677899427402e+19,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)5; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.3342635194217454e+19,
      "bias_tensor_layout": 1.0000000000000000e+00,
      "compute_capability:7.5": 3.8315628306456499e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Quadro RTX 6000": 5.1174270964049613e+18,
      "group": 1.0000000000000000e+00,
      "host_name:aleph": 3.2334478980185999e+18,
      "input[0]": 2.0000000000000000e+00,
      "input[1]": 2.0480000000000000e+03,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input_batch_size": 2.0000000000000000e+00,
      "input_channels": 2.0480000000000000e+03,
      "input_height": 7.0000000000000000e+00,
      "input_size": 2.0070400000000000e+05,
      "input_width": 7.0000000000000000e+00,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 1.2600000000000000e+03,
      "output_batch_size": 2.0000000000000000e+00,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 5.0176000000000000e+04,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00,
      "x_tensor_layout": 1.0000000000000000e+00,
      "y_tensor_layout": 1.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_2__14584214619229659880<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_SIGMOID>/input[0]:2/input[1]:2048/input[2]:7/input[3]:7/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_2__14584214619229659880<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_TANH>/input[0]:2/input[1]:2048/input[2]:7/input[3]:7/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_2__14584214619229659880<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:2048/input[2]:7/input[3]:7/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 9887,
      "real_time": 7.0351979281996144e+04,
      "cpu_time": 7.6122667543451389e+04,
      "time_unit": "ns",
      "items_per_second": 1.4606617901693855e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 3.0000000000000000e+02,
      "advised_time": 8.1919997930526733e-02,
      "batch_size": 2.0000000000000000e+00,
      "benchmark_file:/home/dakkak/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 1.5291677899427402e+19,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.5541522464702913e+19,
      "bias_tensor_layout": 1.0000000000000000e+00,
      "compute_capability:7.5": 3.8315628306456499e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Quadro RTX 6000": 5.1174270964049613e+18,
      "group": 1.0000000000000000e+00,
      "host_name:aleph": 3.2334478980185999e+18,
      "input[0]": 2.0000000000000000e+00,
      "input[1]": 2.0480000000000000e+03,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input_batch_size": 2.0000000000000000e+00,
      "input_channels": 2.0480000000000000e+03,
      "input_height": 7.0000000000000000e+00,
      "input_size": 2.0070400000000000e+05,
      "input_width": 7.0000000000000000e+00,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 9.8870000000000000e+03,
      "output_batch_size": 2.0000000000000000e+00,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 5.0176000000000000e+04,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 1.0000000000000000e+00,
      "workspace_bytes": 3.0000000000000000e+02,
      "workspace_megabytes": 2.8610229492187500e-04,
      "x_tensor_layout": 1.0000000000000000e+00,
      "y_tensor_layout": 1.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_2__14584214619229659880<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:2/input[1]:2048/input[2]:7/input[3]:7/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 9891,
      "real_time": 7.0467720971135306e+04,
      "cpu_time": 7.6332674856303478e+04,
      "time_unit": "ns",
      "items_per_second": 1.4582626851532817e+12,
      "activation_mode": 3.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 3.0000000000000000e+02,
      "advised_time": 1.1055999994277954e-01,
      "batch_size": 2.0000000000000000e+00,
      "benchmark_file:/home/dakkak/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 1.5291677899427402e+19,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.5547362882776177e+19,
      "bias_tensor_layout": 1.0000000000000000e+00,
      "compute_capability:7.5": 3.8315628306456499e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Quadro RTX 6000": 5.1174270964049613e+18,
      "group": 1.0000000000000000e+00,
      "host_name:aleph": 3.2334478980185999e+18,
      "input[0]": 2.0000000000000000e+00,
      "input[1]": 2.0480000000000000e+03,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input_batch_size": 2.0000000000000000e+00,
      "input_channels": 2.0480000000000000e+03,
      "input_height": 7.0000000000000000e+00,
      "input_size": 2.0070400000000000e+05,
      "input_width": 7.0000000000000000e+00,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 9.8910000000000000e+03,
      "output_batch_size": 2.0000000000000000e+00,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 5.0176000000000000e+04,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 1.0000000000000000e+00,
      "workspace_bytes": 3.0000000000000000e+02,
      "workspace_megabytes": 2.8610229492187500e-04,
      "x_tensor_layout": 1.0000000000000000e+00,
      "y_tensor_layout": 1.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_2__14584214619229659880<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_ELU>/input[0]:2/input[1]:2048/input[2]:7/input[3]:7/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_2__14584214619229659880<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:2048/input[2]:7/input[3]:7/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 9954,
      "real_time": 7.0552188329194687e+04,
      "cpu_time": 7.6467067108711577e+04,
      "time_unit": "ns",
      "items_per_second": 1.4565168059780430e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 3.0000000000000000e+02,
      "advised_time": 8.5119999945163727e-02,
      "batch_size": 2.0000000000000000e+00,
      "benchmark_file:/home/dakkak/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 1.5291677899427402e+19,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.5541522464702913e+19,
      "bias_tensor_layout": 1.0000000000000000e+00,
      "compute_capability:7.5": 3.8315628306456499e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Quadro RTX 6000": 5.1174270964049613e+18,
      "group": 1.0000000000000000e+00,
      "host_name:aleph": 3.2334478980185999e+18,
      "input[0]": 2.0000000000000000e+00,
      "input[1]": 2.0480000000000000e+03,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input_batch_size": 2.0000000000000000e+00,
      "input_channels": 2.0480000000000000e+03,
      "input_height": 7.0000000000000000e+00,
      "input_size": 2.0070400000000000e+05,
      "input_width": 7.0000000000000000e+00,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 9.9540000000000000e+03,
      "output_batch_size": 2.0000000000000000e+00,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 5.0176000000000000e+04,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 1.0000000000000000e+00,
      "workspace_bytes": 3.0000000000000000e+02,
      "workspace_megabytes": 2.8610229492187500e-04,
      "x_tensor_layout": 1.0000000000000000e+00,
      "y_tensor_layout": 1.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_2__14584214619229659880<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:2048/input[2]:7/input[3]:7/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 9932,
      "real_time": 7.0938726060109198e+04,
      "cpu_time": 7.6854815646675328e+04,
      "time_unit": "ns",
      "items_per_second": 1.4485803975803994e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 3.0000000000000000e+02,
      "advised_time": 8.5695996880531311e-02,
      "batch_size": 2.0000000000000000e+00,
      "benchmark_file:/home/dakkak/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 1.5291677899427402e+19,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.5541522464702913e+19,
      "bias_tensor_layout": 1.0000000000000000e+00,
      "compute_capability:7.5": 3.8315628306456499e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Quadro RTX 6000": 5.1174270964049613e+18,
      "group": 1.0000000000000000e+00,
      "host_name:aleph": 3.2334478980185999e+18,
      "input[0]": 2.0000000000000000e+00,
      "input[1]": 2.0480000000000000e+03,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input_batch_size": 2.0000000000000000e+00,
      "input_channels": 2.0480000000000000e+03,
      "input_height": 7.0000000000000000e+00,
      "input_size": 2.0070400000000000e+05,
      "input_width": 7.0000000000000000e+00,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 9.9320000000000000e+03,
      "output_batch_size": 2.0000000000000000e+00,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 5.0176000000000000e+04,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 1.0000000000000000e+00,
      "workspace_bytes": 3.0000000000000000e+02,
      "workspace_megabytes": 2.8610229492187500e-04,
      "x_tensor_layout": 1.0000000000000000e+00,
      "y_tensor_layout": 1.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_2__14584214619229659880<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_IDENTITY>/input[0]:2/input[1]:2048/input[2]:7/input[3]:7/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 9953,
      "real_time": 7.0571192317889494e+04,
      "cpu_time": 7.6451280417578993e+04,
      "time_unit": "ns",
      "items_per_second": 1.4561245832026375e+12,
      "activation_mode": 5.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 3.0000000000000000e+02,
      "advised_time": 8.3903998136520386e-02,
      "batch_size": 2.0000000000000000e+00,
      "benchmark_file:/home/dakkak/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 1.5291677899427402e+19,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)5; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 4.5833023350607309e+18,
      "bias_tensor_layout": 1.0000000000000000e+00,
      "compute_capability:7.5": 3.8315628306456499e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 5.1200000000000000e+02,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Quadro RTX 6000": 5.1174270964049613e+18,
      "group": 1.0000000000000000e+00,
      "host_name:aleph": 3.2334478980185999e+18,
      "input[0]": 2.0000000000000000e+00,
      "input[1]": 2.0480000000000000e+03,
      "input[2]": 7.0000000000000000e+00,
      "input[3]": 7.0000000000000000e+00,
      "input_batch_size": 2.0000000000000000e+00,
      "input_channels": 2.0480000000000000e+03,
      "input_height": 7.0000000000000000e+00,
      "input_size": 2.0070400000000000e+05,
      "input_width": 7.0000000000000000e+00,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 5.1200000000000000e+02,
      "num_iterations": 9.9530000000000000e+03,
      "output_batch_size": 2.0000000000000000e+00,
      "output_channels": 5.1200000000000000e+02,
      "output_height": 7.0000000000000000e+00,
      "output_size": 5.0176000000000000e+04,
      "output_width": 7.0000000000000000e+00,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 1.0000000000000000e+00,
      "workspace_bytes": 3.0000000000000000e+02,
      "workspace_megabytes": 2.8610229492187500e-04,
      "x_tensor_layout": 1.0000000000000000e+00,
      "y_tensor_layout": 1.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_2__14584214619229659880<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_SIGMOID>/input[0]:2/input[1]:2048/input[2]:7/input[3]:7/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_2__14584214619229659880<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_TANH>/input[0]:2/input[1]:2048/input[2]:7/input[3]:7/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_2__14584214619229659880<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:2048/input[2]:7/input[3]:7/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_2__14584214619229659880<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:2/input[1]:2048/input[2]:7/input[3]:7/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_2__14584214619229659880<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_ELU>/input[0]:2/input[1]:2048/input[2]:7/input[3]:7/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_2__14584214619229659880<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:2048/input[2]:7/input[3]:7/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_2__14584214619229659880<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:2048/input[2]:7/input[3]:7/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_2__14584214619229659880<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_IDENTITY>/input[0]:2/input[1]:2048/input[2]:7/input[3]:7/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_2__14584214619229659880<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_SIGMOID>/input[0]:2/input[1]:2048/input[2]:7/input[3]:7/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_2__14584214619229659880<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_TANH>/input[0]:2/input[1]:2048/input[2]:7/input[3]:7/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_2__14584214619229659880<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:2048/input[2]:7/input[3]:7/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_2__14584214619229659880<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:2/input[1]:2048/input[2]:7/input[3]:7/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_2__14584214619229659880<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_ELU>/input[0]:2/input[1]:2048/input[2]:7/input[3]:7/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_2__14584214619229659880<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:2048/input[2]:7/input[3]:7/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_2__14584214619229659880<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:2048/input[2]:7/input[3]:7/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_2__14584214619229659880<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_IDENTITY>/input[0]:2/input[1]:2048/input[2]:7/input[3]:7/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_2__14584214619229659880<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_SIGMOID>/input[0]:2/input[1]:2048/input[2]:7/input[3]:7/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_2__14584214619229659880<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_TANH>/input[0]:2/input[1]:2048/input[2]:7/input[3]:7/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_2__14584214619229659880<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:2048/input[2]:7/input[3]:7/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_2__14584214619229659880<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:2/input[1]:2048/input[2]:7/input[3]:7/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_2__14584214619229659880<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_ELU>/input[0]:2/input[1]:2048/input[2]:7/input[3]:7/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_2__14584214619229659880<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:2048/input[2]:7/input[3]:7/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_2__14584214619229659880<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:2048/input[2]:7/input[3]:7/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_2__14584214619229659880<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_IDENTITY>/input[0]:2/input[1]:2048/input[2]:7/input[3]:7/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_2__14584214619229659880<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_SIGMOID>/input[0]:2/input[1]:2048/input[2]:7/input[3]:7/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_2__14584214619229659880<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_TANH>/input[0]:2/input[1]:2048/input[2]:7/input[3]:7/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_2__14584214619229659880<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:2048/input[2]:7/input[3]:7/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_2__14584214619229659880<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:2/input[1]:2048/input[2]:7/input[3]:7/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_2__14584214619229659880<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_ELU>/input[0]:2/input[1]:2048/input[2]:7/input[3]:7/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_2__14584214619229659880<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:2048/input[2]:7/input[3]:7/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_2__14584214619229659880<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:2048/input[2]:7/input[3]:7/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_2__14584214619229659880<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_IDENTITY>/input[0]:2/input[1]:2048/input[2]:7/input[3]:7/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_2__14584214619229659880<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_SIGMOID>/input[0]:2/input[1]:2048/input[2]:7/input[3]:7/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_2__14584214619229659880<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_TANH>/input[0]:2/input[1]:2048/input[2]:7/input[3]:7/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_2__14584214619229659880<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:2048/input[2]:7/input[3]:7/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_2__14584214619229659880<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:2/input[1]:2048/input[2]:7/input[3]:7/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_2__14584214619229659880<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_ELU>/input[0]:2/input[1]:2048/input[2]:7/input[3]:7/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_2__14584214619229659880<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:2048/input[2]:7/input[3]:7/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_2__14584214619229659880<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:2048/input[2]:7/input[3]:7/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_2__14584214619229659880<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_IDENTITY>/input[0]:2/input[1]:2048/input[2]:7/input[3]:7/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_2__14584214619229659880<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_SIGMOID>/input[0]:2/input[1]:2048/input[2]:7/input[3]:7/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_2__14584214619229659880<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_TANH>/input[0]:2/input[1]:2048/input[2]:7/input[3]:7/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_2__14584214619229659880<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:2048/input[2]:7/input[3]:7/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_2__14584214619229659880<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:2/input[1]:2048/input[2]:7/input[3]:7/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_2__14584214619229659880<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_ELU>/input[0]:2/input[1]:2048/input[2]:7/input[3]:7/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_2__14584214619229659880<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:2048/input[2]:7/input[3]:7/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_2__14584214619229659880<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:2048/input[2]:7/input[3]:7/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_2__14584214619229659880<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_IDENTITY>/input[0]:2/input[1]:2048/input[2]:7/input[3]:7/filter_count:512/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_2__8483978016521470561<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_SIGMOID>/input[0]:2/input[1]:256/input[2]:14/input[3]:14/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_2__8483978016521470561<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_TANH>/input[0]:2/input[1]:256/input[2]:14/input[3]:14/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_2__8483978016521470561<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:256/input[2]:14/input[3]:14/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 8283,
      "real_time": 8.4454327743327260e+04,
      "cpu_time": 9.0315427260077442e+04,
      "time_unit": "ns",
      "items_per_second": 1.2167576339285835e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 8.5695996880531311e-02,
      "batch_size": 2.0000000000000000e+00,
      "benchmark_file:/home/dakkak/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 1.5291677899427402e+19,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 2.3191971996820818e+18,
      "bias_tensor_layout": 1.0000000000000000e+00,
      "compute_capability:7.5": 3.8315628306456499e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.0240000000000000e+03,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Quadro RTX 6000": 5.1174270964049613e+18,
      "group": 1.0000000000000000e+00,
      "host_name:aleph": 3.2334478980185999e+18,
      "input[0]": 2.0000000000000000e+00,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 2.0000000000000000e+00,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 1.0035200000000000e+05,
      "input_width": 1.4000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 1.0240000000000000e+03,
      "num_iterations": 8.2830000000000000e+03,
      "output_batch_size": 2.0000000000000000e+00,
      "output_channels": 1.0240000000000000e+03,
      "output_height": 1.4000000000000000e+01,
      "output_size": 4.0140800000000000e+05,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00,
      "x_tensor_layout": 1.0000000000000000e+00,
      "y_tensor_layout": 1.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_2__8483978016521470561<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:2/input[1]:256/input[2]:14/input[3]:14/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 8290,
      "real_time": 8.4425630418648914e+04,
      "cpu_time": 9.0277040169295709e+04,
      "time_unit": "ns",
      "items_per_second": 1.2171712250229297e+12,
      "activation_mode": 3.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 8.3967998623847961e-02,
      "batch_size": 2.0000000000000000e+00,
      "benchmark_file:/home/dakkak/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 1.5291677899427402e+19,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.9889882919049984e+18,
      "bias_tensor_layout": 1.0000000000000000e+00,
      "compute_capability:7.5": 3.8315628306456499e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.0240000000000000e+03,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Quadro RTX 6000": 5.1174270964049613e+18,
      "group": 1.0000000000000000e+00,
      "host_name:aleph": 3.2334478980185999e+18,
      "input[0]": 2.0000000000000000e+00,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 2.0000000000000000e+00,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 1.0035200000000000e+05,
      "input_width": 1.4000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 1.0240000000000000e+03,
      "num_iterations": 8.2900000000000000e+03,
      "output_batch_size": 2.0000000000000000e+00,
      "output_channels": 1.0240000000000000e+03,
      "output_height": 1.4000000000000000e+01,
      "output_size": 4.0140800000000000e+05,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00,
      "x_tensor_layout": 1.0000000000000000e+00,
      "y_tensor_layout": 1.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_2__8483978016521470561<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_ELU>/input[0]:2/input[1]:256/input[2]:14/input[3]:14/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_2__8483978016521470561<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:256/input[2]:14/input[3]:14/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 8260,
      "real_time": 8.4399821326542777e+04,
      "cpu_time": 9.0203011622494392e+04,
      "time_unit": "ns",
      "items_per_second": 1.2175434306006406e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 8.5119999945163727e-02,
      "batch_size": 2.0000000000000000e+00,
      "benchmark_file:/home/dakkak/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 1.5291677899427402e+19,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 2.3191971996820818e+18,
      "bias_tensor_layout": 1.0000000000000000e+00,
      "compute_capability:7.5": 3.8315628306456499e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.0240000000000000e+03,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Quadro RTX 6000": 5.1174270964049613e+18,
      "group": 1.0000000000000000e+00,
      "host_name:aleph": 3.2334478980185999e+18,
      "input[0]": 2.0000000000000000e+00,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 2.0000000000000000e+00,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 1.0035200000000000e+05,
      "input_width": 1.4000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 1.0240000000000000e+03,
      "num_iterations": 8.2600000000000000e+03,
      "output_batch_size": 2.0000000000000000e+00,
      "output_channels": 1.0240000000000000e+03,
      "output_height": 1.4000000000000000e+01,
      "output_size": 4.0140800000000000e+05,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00,
      "x_tensor_layout": 1.0000000000000000e+00,
      "y_tensor_layout": 1.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_2__8483978016521470561<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:256/input[2]:14/input[3]:14/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 8290,
      "real_time": 8.4368524419342371e+04,
      "cpu_time": 9.0247635343562783e+04,
      "time_unit": "ns",
      "items_per_second": 1.2179950841529841e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 8.4735997021198273e-02,
      "batch_size": 2.0000000000000000e+00,
      "benchmark_file:/home/dakkak/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 1.5291677899427402e+19,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 2.3191971996820818e+18,
      "bias_tensor_layout": 1.0000000000000000e+00,
      "compute_capability:7.5": 3.8315628306456499e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.0240000000000000e+03,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Quadro RTX 6000": 5.1174270964049613e+18,
      "group": 1.0000000000000000e+00,
      "host_name:aleph": 3.2334478980185999e+18,
      "input[0]": 2.0000000000000000e+00,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 2.0000000000000000e+00,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 1.0035200000000000e+05,
      "input_width": 1.4000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 1.0240000000000000e+03,
      "num_iterations": 8.2900000000000000e+03,
      "output_batch_size": 2.0000000000000000e+00,
      "output_channels": 1.0240000000000000e+03,
      "output_height": 1.4000000000000000e+01,
      "output_size": 4.0140800000000000e+05,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00,
      "x_tensor_layout": 1.0000000000000000e+00,
      "y_tensor_layout": 1.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_2__8483978016521470561<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM, CUDNN_ACTIVATION_IDENTITY>/input[0]:2/input[1]:256/input[2]:14/input[3]:14/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 8292,
      "real_time": 8.4376072771361753e+04,
      "cpu_time": 9.0237941389247921e+04,
      "time_unit": "ns",
      "items_per_second": 1.2178861213232256e+12,
      "activation_mode": 5.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 0.0000000000000000e+00,
      "advised_time": 8.5023999214172363e-02,
      "batch_size": 2.0000000000000000e+00,
      "benchmark_file:/home/dakkak/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 1.5291677899427402e+19,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)0; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)5; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.3342635194217454e+19,
      "bias_tensor_layout": 1.0000000000000000e+00,
      "compute_capability:7.5": 3.8315628306456499e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 0.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.0240000000000000e+03,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Quadro RTX 6000": 5.1174270964049613e+18,
      "group": 1.0000000000000000e+00,
      "host_name:aleph": 3.2334478980185999e+18,
      "input[0]": 2.0000000000000000e+00,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 2.0000000000000000e+00,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 1.0035200000000000e+05,
      "input_width": 1.4000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 1.0240000000000000e+03,
      "num_iterations": 8.2920000000000000e+03,
      "output_batch_size": 2.0000000000000000e+00,
      "output_channels": 1.0240000000000000e+03,
      "output_height": 1.4000000000000000e+01,
      "output_size": 4.0140800000000000e+05,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 1.0000000000000000e+00,
      "workspace_bytes": 0.0000000000000000e+00,
      "workspace_megabytes": 0.0000000000000000e+00,
      "x_tensor_layout": 1.0000000000000000e+00,
      "y_tensor_layout": 1.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_2__8483978016521470561<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_SIGMOID>/input[0]:2/input[1]:256/input[2]:14/input[3]:14/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_2__8483978016521470561<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_TANH>/input[0]:2/input[1]:256/input[2]:14/input[3]:14/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_2__8483978016521470561<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:256/input[2]:14/input[3]:14/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 24715,
      "real_time": 2.8211623378217864e+04,
      "cpu_time": 3.3969380335968039e+04,
      "time_unit": "ns",
      "items_per_second": 3.6424861704109209e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.1840000000000000e+03,
      "advised_time": 3.3408001065254211e-02,
      "batch_size": 2.0000000000000000e+00,
      "benchmark_file:/home/dakkak/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 1.5291677899427402e+19,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.5541522464702913e+19,
      "bias_tensor_layout": 1.0000000000000000e+00,
      "compute_capability:7.5": 3.8315628306456499e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.0240000000000000e+03,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Quadro RTX 6000": 5.1174270964049613e+18,
      "group": 1.0000000000000000e+00,
      "host_name:aleph": 3.2334478980185999e+18,
      "input[0]": 2.0000000000000000e+00,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 2.0000000000000000e+00,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 1.0035200000000000e+05,
      "input_width": 1.4000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 1.0240000000000000e+03,
      "num_iterations": 2.4715000000000000e+04,
      "output_batch_size": 2.0000000000000000e+00,
      "output_channels": 1.0240000000000000e+03,
      "output_height": 1.4000000000000000e+01,
      "output_size": 4.0140800000000000e+05,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 1.0000000000000000e+00,
      "workspace_bytes": 1.1840000000000000e+03,
      "workspace_megabytes": 1.1291503906250000e-03,
      "x_tensor_layout": 1.0000000000000000e+00,
      "y_tensor_layout": 1.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_2__8483978016521470561<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:2/input[1]:256/input[2]:14/input[3]:14/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 24592,
      "real_time": 2.8342756003991217e+04,
      "cpu_time": 3.4101425341634320e+04,
      "time_unit": "ns",
      "items_per_second": 3.6256335828996064e+12,
      "activation_mode": 3.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.1840000000000000e+03,
      "advised_time": 3.4432001411914825e-02,
      "batch_size": 2.0000000000000000e+00,
      "benchmark_file:/home/dakkak/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 1.5291677899427402e+19,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)3; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.5547362882776177e+19,
      "bias_tensor_layout": 1.0000000000000000e+00,
      "compute_capability:7.5": 3.8315628306456499e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.0240000000000000e+03,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Quadro RTX 6000": 5.1174270964049613e+18,
      "group": 1.0000000000000000e+00,
      "host_name:aleph": 3.2334478980185999e+18,
      "input[0]": 2.0000000000000000e+00,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 2.0000000000000000e+00,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 1.0035200000000000e+05,
      "input_width": 1.4000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 1.0240000000000000e+03,
      "num_iterations": 2.4592000000000000e+04,
      "output_batch_size": 2.0000000000000000e+00,
      "output_channels": 1.0240000000000000e+03,
      "output_height": 1.4000000000000000e+01,
      "output_size": 4.0140800000000000e+05,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 1.0000000000000000e+00,
      "workspace_bytes": 1.1840000000000000e+03,
      "workspace_megabytes": 1.1291503906250000e-03,
      "x_tensor_layout": 1.0000000000000000e+00,
      "y_tensor_layout": 1.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_2__8483978016521470561<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_ELU>/input[0]:2/input[1]:256/input[2]:14/input[3]:14/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_2__8483978016521470561<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:256/input[2]:14/input[3]:14/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 24687,
      "real_time": 2.8303966938850313e+04,
      "cpu_time": 3.4078296066764429e+04,
      "time_unit": "ns",
      "items_per_second": 3.6306023188201919e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.1840000000000000e+03,
      "advised_time": 3.3792000263929367e-02,
      "batch_size": 2.0000000000000000e+00,
      "benchmark_file:/home/dakkak/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 1.5291677899427402e+19,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.5541522464702913e+19,
      "bias_tensor_layout": 1.0000000000000000e+00,
      "compute_capability:7.5": 3.8315628306456499e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.0240000000000000e+03,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Quadro RTX 6000": 5.1174270964049613e+18,
      "group": 1.0000000000000000e+00,
      "host_name:aleph": 3.2334478980185999e+18,
      "input[0]": 2.0000000000000000e+00,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 2.0000000000000000e+00,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 1.0035200000000000e+05,
      "input_width": 1.4000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 1.0240000000000000e+03,
      "num_iterations": 2.4687000000000000e+04,
      "output_batch_size": 2.0000000000000000e+00,
      "output_channels": 1.0240000000000000e+03,
      "output_height": 1.4000000000000000e+01,
      "output_size": 4.0140800000000000e+05,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 1.0000000000000000e+00,
      "workspace_bytes": 1.1840000000000000e+03,
      "workspace_megabytes": 1.1291503906250000e-03,
      "x_tensor_layout": 1.0000000000000000e+00,
      "y_tensor_layout": 1.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_2__8483978016521470561<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:256/input[2]:14/input[3]:14/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 24869,
      "real_time": 2.8400097123421772e+04,
      "cpu_time": 3.4196914632818531e+04,
      "time_unit": "ns",
      "items_per_second": 3.6183132597547593e+12,
      "activation_mode": 1.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.1840000000000000e+03,
      "advised_time": 3.4784000366926193e-02,
      "batch_size": 2.0000000000000000e+00,
      "benchmark_file:/home/dakkak/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 1.5291677899427402e+19,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)1; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 1.5541522464702913e+19,
      "bias_tensor_layout": 1.0000000000000000e+00,
      "compute_capability:7.5": 3.8315628306456499e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.0240000000000000e+03,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Quadro RTX 6000": 5.1174270964049613e+18,
      "group": 1.0000000000000000e+00,
      "host_name:aleph": 3.2334478980185999e+18,
      "input[0]": 2.0000000000000000e+00,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 2.0000000000000000e+00,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 1.0035200000000000e+05,
      "input_width": 1.4000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 1.0240000000000000e+03,
      "num_iterations": 2.4869000000000000e+04,
      "output_batch_size": 2.0000000000000000e+00,
      "output_channels": 1.0240000000000000e+03,
      "output_height": 1.4000000000000000e+01,
      "output_size": 4.0140800000000000e+05,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 1.0000000000000000e+00,
      "workspace_bytes": 1.1840000000000000e+03,
      "workspace_megabytes": 1.1291503906250000e-03,
      "x_tensor_layout": 1.0000000000000000e+00,
      "y_tensor_layout": 1.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_2__8483978016521470561<CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM, CUDNN_ACTIVATION_IDENTITY>/input[0]:2/input[1]:256/input[2]:14/input[3]:14/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "iterations": 24464,
      "real_time": 2.8293701756026621e+04,
      "cpu_time": 3.4117159540637687e+04,
      "time_unit": "ns",
      "items_per_second": 3.6319195305758037e+12,
      "activation_mode": 5.0000000000000000e+00,
      "advised_convolution_algorithm": 1.0000000000000000e+00,
      "advised_determinism": 1.0000000000000000e+00,
      "advised_memory": 1.1840000000000000e+03,
      "advised_time": 5.3119998425245285e-02,
      "batch_size": 2.0000000000000000e+00,
      "benchmark_file:/home/dakkak/scope/scopes/cudnn_scope/src/cudnn_conv_bias_activation_fwd.inc": 1.5291677899427402e+19,
      "benchmark_func:void iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl(benchmark::State&) [with T = __half; cudnnConvolutionFwdAlgo_t convolution_algorithm = (cudnnConvolutionFwdAlgo_t)1; cudnnActivationMode_t activation_mode = (cudnnActivationMode_t)5; cudnnMathType_t math_type0 = (cudnnMathType_t)1]": 4.5833023350607309e+18,
      "bias_tensor_layout": 1.0000000000000000e+00,
      "compute_capability:7.5": 3.8315628306456499e+18,
      "conv_bwd_type": 0.0000000000000000e+00,
      "conv_fwd_type": 2.0000000000000000e+00,
      "conv_mode": 1.0000000000000000e+00,
      "convolution_algorithm": 1.0000000000000000e+00,
      "cublas_version:10.1": 9.6389230149667533e+17,
      "cuda_driver_version:10.10": 3.1909591731558548e+18,
      "cuda_runtime_version:10.20": 3.1881246321788943e+18,
      "cudnn_version:7.6.3": 1.5847091547736381e+19,
      "cupti_enabled": 0.0000000000000000e+00,
      "demangled_benchmark_func:iLAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_Impl": 3.7501726223256182e+18,
      "dilation_height": 1.0000000000000000e+00,
      "dilation_width": 1.0000000000000000e+00,
      "filter_count": 1.0240000000000000e+03,
      "filter_height": 1.0000000000000000e+00,
      "filter_width": 1.0000000000000000e+00,
      "gpu_name:Quadro RTX 6000": 5.1174270964049613e+18,
      "group": 1.0000000000000000e+00,
      "host_name:aleph": 3.2334478980185999e+18,
      "input[0]": 2.0000000000000000e+00,
      "input[1]": 2.5600000000000000e+02,
      "input[2]": 1.4000000000000000e+01,
      "input[3]": 1.4000000000000000e+01,
      "input_batch_size": 2.0000000000000000e+00,
      "input_channels": 2.5600000000000000e+02,
      "input_height": 1.4000000000000000e+01,
      "input_size": 1.0035200000000000e+05,
      "input_width": 1.4000000000000000e+01,
      "math_type": 1.0000000000000000e+00,
      "num_filters": 1.0240000000000000e+03,
      "num_iterations": 2.4464000000000000e+04,
      "output_batch_size": 2.0000000000000000e+00,
      "output_channels": 1.0240000000000000e+03,
      "output_height": 1.4000000000000000e+01,
      "output_size": 4.0140800000000000e+05,
      "output_width": 1.4000000000000000e+01,
      "pad_height": 0.0000000000000000e+00,
      "pad_width": 0.0000000000000000e+00,
      "stride_height": 1.0000000000000000e+00,
      "stride_width": 1.0000000000000000e+00,
      "w_filter_layout": 1.0000000000000000e+00,
      "workspace_bytes": 1.1840000000000000e+03,
      "workspace_megabytes": 1.1291503906250000e-03,
      "x_tensor_layout": 1.0000000000000000e+00,
      "y_tensor_layout": 1.0000000000000000e+00
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_2__8483978016521470561<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_SIGMOID>/input[0]:2/input[1]:256/input[2]:14/input[3]:14/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_2__8483978016521470561<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_TANH>/input[0]:2/input[1]:256/input[2]:14/input[3]:14/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_2__8483978016521470561<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:256/input[2]:14/input[3]:14/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_2__8483978016521470561<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:2/input[1]:256/input[2]:14/input[3]:14/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_2__8483978016521470561<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_ELU>/input[0]:2/input[1]:256/input[2]:14/input[3]:14/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_2__8483978016521470561<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:256/input[2]:14/input[3]:14/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_2__8483978016521470561<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:256/input[2]:14/input[3]:14/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_2__8483978016521470561<CUDNN_CONVOLUTION_FWD_ALGO_GEMM, CUDNN_ACTIVATION_IDENTITY>/input[0]:2/input[1]:256/input[2]:14/input[3]:14/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_2__8483978016521470561<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_SIGMOID>/input[0]:2/input[1]:256/input[2]:14/input[3]:14/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_2__8483978016521470561<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_TANH>/input[0]:2/input[1]:256/input[2]:14/input[3]:14/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_2__8483978016521470561<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:256/input[2]:14/input[3]:14/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_2__8483978016521470561<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:2/input[1]:256/input[2]:14/input[3]:14/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_2__8483978016521470561<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_ELU>/input[0]:2/input[1]:256/input[2]:14/input[3]:14/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_2__8483978016521470561<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:256/input[2]:14/input[3]:14/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_2__8483978016521470561<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:256/input[2]:14/input[3]:14/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_2__8483978016521470561<CUDNN_CONVOLUTION_FWD_ALGO_DIRECT, CUDNN_ACTIVATION_IDENTITY>/input[0]:2/input[1]:256/input[2]:14/input[3]:14/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_2__8483978016521470561<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_SIGMOID>/input[0]:2/input[1]:256/input[2]:14/input[3]:14/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_2__8483978016521470561<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_TANH>/input[0]:2/input[1]:256/input[2]:14/input[3]:14/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_2__8483978016521470561<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:256/input[2]:14/input[3]:14/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_2__8483978016521470561<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:2/input[1]:256/input[2]:14/input[3]:14/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_2__8483978016521470561<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_ELU>/input[0]:2/input[1]:256/input[2]:14/input[3]:14/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_2__8483978016521470561<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:256/input[2]:14/input[3]:14/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_2__8483978016521470561<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:256/input[2]:14/input[3]:14/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_2__8483978016521470561<CUDNN_CONVOLUTION_FWD_ALGO_FFT, CUDNN_ACTIVATION_IDENTITY>/input[0]:2/input[1]:256/input[2]:14/input[3]:14/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_2__8483978016521470561<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_SIGMOID>/input[0]:2/input[1]:256/input[2]:14/input[3]:14/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_2__8483978016521470561<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_TANH>/input[0]:2/input[1]:256/input[2]:14/input[3]:14/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_2__8483978016521470561<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:256/input[2]:14/input[3]:14/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_2__8483978016521470561<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:2/input[1]:256/input[2]:14/input[3]:14/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_2__8483978016521470561<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_ELU>/input[0]:2/input[1]:256/input[2]:14/input[3]:14/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_2__8483978016521470561<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:256/input[2]:14/input[3]:14/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_2__8483978016521470561<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:256/input[2]:14/input[3]:14/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_2__8483978016521470561<CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING, CUDNN_ACTIVATION_IDENTITY>/input[0]:2/input[1]:256/input[2]:14/input[3]:14/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_2__8483978016521470561<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_SIGMOID>/input[0]:2/input[1]:256/input[2]:14/input[3]:14/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_2__8483978016521470561<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_TANH>/input[0]:2/input[1]:256/input[2]:14/input[3]:14/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_2__8483978016521470561<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:256/input[2]:14/input[3]:14/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_2__8483978016521470561<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:2/input[1]:256/input[2]:14/input[3]:14/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_2__8483978016521470561<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_ELU>/input[0]:2/input[1]:256/input[2]:14/input[3]:14/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_2__8483978016521470561<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:256/input[2]:14/input[3]:14/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_2__8483978016521470561<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:256/input[2]:14/input[3]:14/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_2__8483978016521470561<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD, CUDNN_ACTIVATION_IDENTITY>/input[0]:2/input[1]:256/input[2]:14/input[3]:14/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_2__8483978016521470561<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_SIGMOID>/input[0]:2/input[1]:256/input[2]:14/input[3]:14/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_2__8483978016521470561<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_TANH>/input[0]:2/input[1]:256/input[2]:14/input[3]:14/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_2__8483978016521470561<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:256/input[2]:14/input[3]:14/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_2__8483978016521470561<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_CLIPPED_RELU>/input[0]:2/input[1]:256/input[2]:14/input[3]:14/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_2__8483978016521470561<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_ELU>/input[0]:2/input[1]:256/input[2]:14/input[3]:14/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_2__8483978016521470561<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:256/input[2]:14/input[3]:14/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_2__8483978016521470561<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_RELU>/input[0]:2/input[1]:256/input[2]:14/input[3]:14/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    },
    {
      "name": "LAYER_CUDNN_CONV_BIAS_ACTIVATION_FWD_4_TENSORCOREHALF__BatchSize_2__8483978016521470561<CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED, CUDNN_ACTIVATION_IDENTITY>/input[0]:2/input[1]:256/input[2]:14/input[3]:14/filter_count:1024/filter_height:1/filter_width:1/pad_height:0/pad_width:0/stride_height:1/stride_width:1/dilation_height:1/dilation_width:1/group:1/batch_size:2/conv_fwd_type:2/conv_bwd_type:0/manual_time",
      "error_occurred": true,
      "error_message": "CUDNN/CONV_BIAS_ACTIVATION_FWD failed to launch kernel because of CUDNN_STATUS_NOT_SUPPORTED",
      "iterations": 1,
      "real_time": 0.0000000000000000e+00,
      "cpu_time": 0.0000000000000000e+00,
      "time_unit": "ns"
    }
  ]
}
